openapi: 3.1.0
info:
  contact:
    name: OpenAI Support
    url: https://help.openai.com/
  description: The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference
    for more details.
  license:
    name: MIT
    url: https://github.com/openai/openai-openapi/blob/master/LICENSE
  termsOfService: https://openai.com/policies/terms-of-use
  title: OpenAI API
  version: 2.3.0
servers:
- url: https://api.openai.com/v1
security:
- ApiKeyAuth: []
tags:
- description: Build Assistants that can call models and use tools.
  name: Assistants
- description: Turn audio into text or text into audio.
  name: Audio
- description: "Given a list of messages comprising a conversation, the model will\
    \ return a response."
  name: Chat
- description: "Given a prompt, the model will return one or more predicted completions,\
    \ and can also return the probabilities of alternative tokens at each position."
  name: Completions
- description: Get a vector representation of a given input that can be easily consumed
    by machine learning models and algorithms.
  name: Embeddings
- description: Manage and run evals in the OpenAI platform.
  name: Evals
- description: Manage fine-tuning jobs to tailor a model to your specific training
    data.
  name: Fine-tuning
- description: Manage and run graders in the OpenAI platform.
  name: Graders
- description: Create large batches of API requests to run asynchronously.
  name: Batch
- description: Files are used to upload documents that can be used with features like
    Assistants and Fine-tuning.
  name: Files
- description: Use Uploads to upload large files in multiple parts.
  name: Uploads
- description: "Given a prompt and/or an input image, the model will generate a new\
    \ image."
  name: Images
- description: List and describe the various models available in the API.
  name: Models
- description: "Given text and/or image inputs, classifies if those inputs are potentially\
    \ harmful."
  name: Moderations
- description: List user actions and configuration changes within this organization.
  name: Audit Logs
paths:
  /assistants:
    get:
      operationId: listAssistants
      parameters:
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListAssistantsResponse"
          description: OK
      summary: Returns a list of assistants.
      tags:
      - Assistants
      x-oaiMeta:
        name: List assistants
        group: assistants
        beta: true
        returns: "A list of [assistant](/docs/api-reference/assistants/object) objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistants = client.beta.assistants.list(
                  order="desc",
                  limit="20",
              )
              print(my_assistants.data)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistants = await openai.beta.assistants.list({
                  order: "desc",
                  limit: "20",
                });

                console.log(myAssistants.data);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "asst_abc123",
                  "object": "assistant",
                  "created_at": 1698982736,
                  "name": "Coding Tutor",
                  "description": null,
                  "model": "gpt-4o",
                  "instructions": "You are a helpful assistant designed to make me better at coding!",
                  "tools": [],
                  "tool_resources": {},
                  "metadata": {},
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "response_format": "auto"
                },
                {
                  "id": "asst_abc456",
                  "object": "assistant",
                  "created_at": 1698982718,
                  "name": "My Assistant",
                  "description": null,
                  "model": "gpt-4o",
                  "instructions": "You are a helpful assistant designed to make me better at coding!",
                  "tools": [],
                  "tool_resources": {},
                  "metadata": {},
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "response_format": "auto"
                },
                {
                  "id": "asst_abc789",
                  "object": "assistant",
                  "created_at": 1698982643,
                  "name": null,
                  "description": null,
                  "model": "gpt-4o",
                  "instructions": null,
                  "tools": [],
                  "tool_resources": {},
                  "metadata": {},
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "response_format": "auto"
                }
              ],
              "first_id": "asst_abc123",
              "last_id": "asst_abc789",
              "has_more": false
            }
    post:
      operationId: createAssistant
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateAssistantRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AssistantObject"
          description: OK
      summary: Create an assistant with a model and instructions.
      tags:
      - Assistants
      x-oaiMeta:
        name: Create assistant
        group: assistants
        beta: true
        returns: "An [assistant](/docs/api-reference/assistants/object) object."
        examples:
        - title: Code Interpreter
          request:
            curl: |
              curl "https://api.openai.com/v1/assistants" \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                  "name": "Math Tutor",
                  "tools": [{"type": "code_interpreter"}],
                  "model": "gpt-4o"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistant = client.beta.assistants.create(
                  instructions="You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                  name="Math Tutor",
                  tools=[{"type": "code_interpreter"}],
                  model="gpt-4o",
              )
              print(my_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistant = await openai.beta.assistants.create({
                  instructions:
                    "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                  name: "Math Tutor",
                  tools: [{ type: "code_interpreter" }],
                  model: "gpt-4o",
                });

                console.log(myAssistant);
              }

              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant",
              "created_at": 1698984975,
              "name": "Math Tutor",
              "description": null,
              "model": "gpt-4o",
              "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
        - title: Files
          request:
            curl: |
              curl https://api.openai.com/v1/assistants \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
                  "tools": [{"type": "file_search"}],
                  "tool_resources": {"file_search": {"vector_store_ids": ["vs_123"]}},
                  "model": "gpt-4o"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistant = client.beta.assistants.create(
                  instructions="You are an HR bot, and you have access to files to answer employee questions about company policies.",
                  name="HR Helper",
                  tools=[{"type": "file_search"}],
                  tool_resources={"file_search": {"vector_store_ids": ["vs_123"]}},
                  model="gpt-4o"
              )
              print(my_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistant = await openai.beta.assistants.create({
                  instructions:
                    "You are an HR bot, and you have access to files to answer employee questions about company policies.",
                  name: "HR Helper",
                  tools: [{ type: "file_search" }],
                  tool_resources: {
                    file_search: {
                      vector_store_ids: ["vs_123"]
                    }
                  },
                  model: "gpt-4o"
                });

                console.log(myAssistant);
              }

              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant",
              "created_at": 1699009403,
              "name": "HR Helper",
              "description": null,
              "model": "gpt-4o",
              "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "tool_resources": {
                "file_search": {
                  "vector_store_ids": ["vs_123"]
                }
              },
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
  /assistants/{assistant_id}:
    delete:
      operationId: deleteAssistant
      parameters:
      - description: The ID of the assistant to delete.
        explode: false
        in: path
        name: assistant_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteAssistantResponse"
          description: OK
      summary: Delete an assistant.
      tags:
      - Assistants
      x-oaiMeta:
        name: Delete assistant
        group: assistants
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/assistants/asst_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.beta.assistants.delete("asst_abc123")
              print(response)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.beta.assistants.delete("asst_abc123");

                console.log(response);
              }
              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant.deleted",
              "deleted": true
            }
    get:
      operationId: getAssistant
      parameters:
      - description: The ID of the assistant to retrieve.
        explode: false
        in: path
        name: assistant_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AssistantObject"
          description: OK
      summary: Retrieves an assistant.
      tags:
      - Assistants
      x-oaiMeta:
        name: Retrieve assistant
        group: assistants
        beta: true
        returns: "The [assistant](/docs/api-reference/assistants/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/assistants/asst_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistant = client.beta.assistants.retrieve("asst_abc123")
              print(my_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistant = await openai.beta.assistants.retrieve(
                  "asst_abc123"
                );

                console.log(myAssistant);
              }

              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant",
              "created_at": 1699009709,
              "name": "HR Helper",
              "description": null,
              "model": "gpt-4o",
              "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
    post:
      operationId: modifyAssistant
      parameters:
      - description: The ID of the assistant to modify.
        explode: false
        in: path
        name: assistant_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ModifyAssistantRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AssistantObject"
          description: OK
      summary: Modifies an assistant.
      tags:
      - Assistants
      x-oaiMeta:
        name: Modify assistant
        group: assistants
        beta: true
        returns: "The modified [assistant](/docs/api-reference/assistants/object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/assistants/asst_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
                    "tools": [{"type": "file_search"}],
                    "model": "gpt-4o"
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_updated_assistant = client.beta.assistants.update(
                "asst_abc123",
                instructions="You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
                name="HR Helper",
                tools=[{"type": "file_search"}],
                model="gpt-4o"
              )

              print(my_updated_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myUpdatedAssistant = await openai.beta.assistants.update(
                  "asst_abc123",
                  {
                    instructions:
                      "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
                    name: "HR Helper",
                    tools: [{ type: "file_search" }],
                    model: "gpt-4o"
                  }
                );

                console.log(myUpdatedAssistant);
              }

              main();
          response: |
            {
              "id": "asst_123",
              "object": "assistant",
              "created_at": 1699009709,
              "name": "HR Helper",
              "description": null,
              "model": "gpt-4o",
              "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "tool_resources": {
                "file_search": {
                  "vector_store_ids": []
                }
              },
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
  /audio/speech:
    post:
      operationId: createSpeech
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateSpeechRequest"
        required: true
      responses:
        "200":
          content:
            application/octet-stream:
              schema:
                format: binary
                type: string
            text/event-stream:
              schema:
                $ref: "#/components/schemas/CreateSpeechResponseStreamEvent"
          description: OK
          headers:
            Transfer-Encoding:
              description: chunked
              explode: false
              schema:
                type: string
              style: simple
      summary: Generates audio from the input text.
      tags:
      - Audio
      x-oaiMeta:
        name: Create speech
        group: audio
        returns: "The audio file content or a [stream of audio events](/docs/api-reference/audio/speech-audio-delta-event)."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/audio/speech \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "model": "gpt-4o-mini-tts",
                  "input": "The quick brown fox jumped over the lazy dog.",
                  "voice": "alloy"
                }' \
                --output speech.mp3
            python: |
              from pathlib import Path
              import openai

              speech_file_path = Path(__file__).parent / "speech.mp3"
              with openai.audio.speech.with_streaming_response.create(
                model="gpt-4o-mini-tts",
                voice="alloy",
                input="The quick brown fox jumped over the lazy dog."
              ) as response:
                response.stream_to_file(speech_file_path)
            javascript: |
              import fs from "fs";
              import path from "path";
              import OpenAI from "openai";

              const openai = new OpenAI();

              const speechFile = path.resolve("./speech.mp3");

              async function main() {
                const mp3 = await openai.audio.speech.create({
                  model: "gpt-4o-mini-tts",
                  voice: "alloy",
                  input: "Today is a wonderful day to build something people love!",
                });
                console.log(speechFile);
                const buffer = Buffer.from(await mp3.arrayBuffer());
                await fs.promises.writeFile(speechFile, buffer);
              }
              main();
            csharp: |
              using System;
              using System.IO;

              using OpenAI.Audio;

              AudioClient client = new(
                  model: "gpt-4o-mini-tts",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              BinaryData speech = client.GenerateSpeech(
                  text: "The quick brown fox jumped over the lazy dog.",
                  voice: GeneratedSpeechVoice.Alloy
              );

              using FileStream stream = File.OpenWrite("speech.mp3");
              speech.ToStream().CopyTo(stream);
        - title: SSE Stream Format
          request:
            curl: |
              curl https://api.openai.com/v1/audio/speech \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "model": "gpt-4o-mini-tts",
                  "input": "The quick brown fox jumped over the lazy dog.",
                  "voice": "alloy",
                  "stream_format": "sse"
                }'
  /audio/transcriptions:
    post:
      operationId: createTranscription
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: "#/components/schemas/CreateTranscriptionRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/createTranscription_200_response"
            text/event-stream:
              schema:
                $ref: "#/components/schemas/CreateTranscriptionResponseStreamEvent"
          description: OK
      summary: Transcribes audio into the input language.
      tags:
      - Audio
      x-oaiMeta:
        name: Create transcription
        group: audio
        returns: "The [transcription object](/docs/api-reference/audio/json-object),\
          \ a [verbose transcription object](/docs/api-reference/audio/verbose-json-object)\
          \ or a [stream of transcript events](/docs/api-reference/audio/transcript-text-delta-event)."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F model="gpt-4o-transcribe"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.transcriptions.create(
                model="gpt-4o-transcribe",
                file=audio_file
              )
            javascript: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const transcription = await openai.audio.transcriptions.create({
                  file: fs.createReadStream("audio.mp3"),
                  model: "gpt-4o-transcribe",
                });

                console.log(transcription.text);
              }
              main();
            csharp: |
              using System;

              using OpenAI.Audio;
              string audioFilePath = "audio.mp3";

              AudioClient client = new(
                  model: "gpt-4o-transcribe",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              AudioTranscription transcription = client.TranscribeAudio(audioFilePath);

              Console.WriteLine($"{transcription.Text}");
          response: |
            {
              "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that.",
              "usage": {
                "type": "tokens",
                "input_tokens": 14,
                "input_token_details": {
                  "text_tokens": 0,
                  "audio_tokens": 14
                },
                "output_tokens": 45,
                "total_tokens": 59
              }
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F model="gpt-4o-mini-transcribe" \
                -F stream=true
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              stream = client.audio.transcriptions.create(
                file=audio_file,
                model="gpt-4o-mini-transcribe",
                stream=True
              )

              for event in stream:
                print(event)
            javascript: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              const stream = await openai.audio.transcriptions.create({
                file: fs.createReadStream("audio.mp3"),
                model: "gpt-4o-mini-transcribe",
                stream: true,
              });

              for await (const event of stream) {
                console.log(event);
              }
          response: |
            data: {"type":"transcript.text.delta","delta":"I","logprobs":[{"token":"I","logprob":-0.00007588794,"bytes":[73]}]}

            data: {"type":"transcript.text.delta","delta":" see","logprobs":[{"token":" see","logprob":-3.1281633e-7,"bytes":[32,115,101,101]}]}

            data: {"type":"transcript.text.delta","delta":" skies","logprobs":[{"token":" skies","logprob":-2.3392786e-6,"bytes":[32,115,107,105,101,115]}]}

            data: {"type":"transcript.text.delta","delta":" of","logprobs":[{"token":" of","logprob":-3.1281633e-7,"bytes":[32,111,102]}]}

            data: {"type":"transcript.text.delta","delta":" blue","logprobs":[{"token":" blue","logprob":-1.0280384e-6,"bytes":[32,98,108,117,101]}]}

            data: {"type":"transcript.text.delta","delta":" and","logprobs":[{"token":" and","logprob":-0.0005108566,"bytes":[32,97,110,100]}]}

            data: {"type":"transcript.text.delta","delta":" clouds","logprobs":[{"token":" clouds","logprob":-1.9361265e-7,"bytes":[32,99,108,111,117,100,115]}]}

            data: {"type":"transcript.text.delta","delta":" of","logprobs":[{"token":" of","logprob":-1.9361265e-7,"bytes":[32,111,102]}]}

            data: {"type":"transcript.text.delta","delta":" white","logprobs":[{"token":" white","logprob":-7.89631e-7,"bytes":[32,119,104,105,116,101]}]}

            data: {"type":"transcript.text.delta","delta":",","logprobs":[{"token":",","logprob":-0.0014890312,"bytes":[44]}]}

            data: {"type":"transcript.text.delta","delta":" the","logprobs":[{"token":" the","logprob":-0.0110956915,"bytes":[32,116,104,101]}]}

            data: {"type":"transcript.text.delta","delta":" bright","logprobs":[{"token":" bright","logprob":0.0,"bytes":[32,98,114,105,103,104,116]}]}

            data: {"type":"transcript.text.delta","delta":" blessed","logprobs":[{"token":" blessed","logprob":-0.000045848617,"bytes":[32,98,108,101,115,115,101,100]}]}

            data: {"type":"transcript.text.delta","delta":" days","logprobs":[{"token":" days","logprob":-0.000010802739,"bytes":[32,100,97,121,115]}]}

            data: {"type":"transcript.text.delta","delta":",","logprobs":[{"token":",","logprob":-0.00001700133,"bytes":[44]}]}

            data: {"type":"transcript.text.delta","delta":" the","logprobs":[{"token":" the","logprob":-0.0000118755715,"bytes":[32,116,104,101]}]}

            data: {"type":"transcript.text.delta","delta":" dark","logprobs":[{"token":" dark","logprob":-5.5122365e-7,"bytes":[32,100,97,114,107]}]}

            data: {"type":"transcript.text.delta","delta":" sacred","logprobs":[{"token":" sacred","logprob":-5.4385737e-6,"bytes":[32,115,97,99,114,101,100]}]}

            data: {"type":"transcript.text.delta","delta":" nights","logprobs":[{"token":" nights","logprob":-4.00813e-6,"bytes":[32,110,105,103,104,116,115]}]}

            data: {"type":"transcript.text.delta","delta":",","logprobs":[{"token":",","logprob":-0.0036910512,"bytes":[44]}]}

            data: {"type":"transcript.text.delta","delta":" and","logprobs":[{"token":" and","logprob":-0.0031903093,"bytes":[32,97,110,100]}]}

            data: {"type":"transcript.text.delta","delta":" I","logprobs":[{"token":" I","logprob":-1.504853e-6,"bytes":[32,73]}]}

            data: {"type":"transcript.text.delta","delta":" think","logprobs":[{"token":" think","logprob":-4.3202e-7,"bytes":[32,116,104,105,110,107]}]}

            data: {"type":"transcript.text.delta","delta":" to","logprobs":[{"token":" to","logprob":-1.9361265e-7,"bytes":[32,116,111]}]}

            data: {"type":"transcript.text.delta","delta":" myself","logprobs":[{"token":" myself","logprob":-1.7432603e-6,"bytes":[32,109,121,115,101,108,102]}]}

            data: {"type":"transcript.text.delta","delta":",","logprobs":[{"token":",","logprob":-0.29254505,"bytes":[44]}]}

            data: {"type":"transcript.text.delta","delta":" what","logprobs":[{"token":" what","logprob":-0.016815351,"bytes":[32,119,104,97,116]}]}

            data: {"type":"transcript.text.delta","delta":" a","logprobs":[{"token":" a","logprob":-3.1281633e-7,"bytes":[32,97]}]}

            data: {"type":"transcript.text.delta","delta":" wonderful","logprobs":[{"token":" wonderful","logprob":-2.1008714e-6,"bytes":[32,119,111,110,100,101,114,102,117,108]}]}

            data: {"type":"transcript.text.delta","delta":" world","logprobs":[{"token":" world","logprob":-8.180258e-6,"bytes":[32,119,111,114,108,100]}]}

            data: {"type":"transcript.text.delta","delta":".","logprobs":[{"token":".","logprob":-0.014231676,"bytes":[46]}]}

            data: {"type":"transcript.text.done","text":"I see skies of blue and clouds of white, the bright blessed days, the dark sacred nights, and I think to myself, what a wonderful world.","logprobs":[{"token":"I","logprob":-0.00007588794,"bytes":[73]},{"token":" see","logprob":-3.1281633e-7,"bytes":[32,115,101,101]},{"token":" skies","logprob":-2.3392786e-6,"bytes":[32,115,107,105,101,115]},{"token":" of","logprob":-3.1281633e-7,"bytes":[32,111,102]},{"token":" blue","logprob":-1.0280384e-6,"bytes":[32,98,108,117,101]},{"token":" and","logprob":-0.0005108566,"bytes":[32,97,110,100]},{"token":" clouds","logprob":-1.9361265e-7,"bytes":[32,99,108,111,117,100,115]},{"token":" of","logprob":-1.9361265e-7,"bytes":[32,111,102]},{"token":" white","logprob":-7.89631e-7,"bytes":[32,119,104,105,116,101]},{"token":",","logprob":-0.0014890312,"bytes":[44]},{"token":" the","logprob":-0.0110956915,"bytes":[32,116,104,101]},{"token":" bright","logprob":0.0,"bytes":[32,98,114,105,103,104,116]},{"token":" blessed","logprob":-0.000045848617,"bytes":[32,98,108,101,115,115,101,100]},{"token":" days","logprob":-0.000010802739,"bytes":[32,100,97,121,115]},{"token":",","logprob":-0.00001700133,"bytes":[44]},{"token":" the","logprob":-0.0000118755715,"bytes":[32,116,104,101]},{"token":" dark","logprob":-5.5122365e-7,"bytes":[32,100,97,114,107]},{"token":" sacred","logprob":-5.4385737e-6,"bytes":[32,115,97,99,114,101,100]},{"token":" nights","logprob":-4.00813e-6,"bytes":[32,110,105,103,104,116,115]},{"token":",","logprob":-0.0036910512,"bytes":[44]},{"token":" and","logprob":-0.0031903093,"bytes":[32,97,110,100]},{"token":" I","logprob":-1.504853e-6,"bytes":[32,73]},{"token":" think","logprob":-4.3202e-7,"bytes":[32,116,104,105,110,107]},{"token":" to","logprob":-1.9361265e-7,"bytes":[32,116,111]},{"token":" myself","logprob":-1.7432603e-6,"bytes":[32,109,121,115,101,108,102]},{"token":",","logprob":-0.29254505,"bytes":[44]},{"token":" what","logprob":-0.016815351,"bytes":[32,119,104,97,116]},{"token":" a","logprob":-3.1281633e-7,"bytes":[32,97]},{"token":" wonderful","logprob":-2.1008714e-6,"bytes":[32,119,111,110,100,101,114,102,117,108]},{"token":" world","logprob":-8.180258e-6,"bytes":[32,119,111,114,108,100]},{"token":".","logprob":-0.014231676,"bytes":[46]}],"usage":{"input_tokens":14,"input_token_details":{"text_tokens":0,"audio_tokens":14},"output_tokens":45,"total_tokens":59}}
        - title: Logprobs
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F "include[]=logprobs" \
                -F model="gpt-4o-transcribe" \
                -F response_format="json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.transcriptions.create(
                file=audio_file,
                model="gpt-4o-transcribe",
                response_format="json",
                include=["logprobs"]
              )

              print(transcript)
            javascript: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const transcription = await openai.audio.transcriptions.create({
                  file: fs.createReadStream("audio.mp3"),
                  model: "gpt-4o-transcribe",
                  response_format: "json",
                  include: ["logprobs"]
                });

                console.log(transcription);
              }
              main();
          response: |
            {
              "text": "Hey, my knee is hurting and I want to see the doctor tomorrow ideally.",
              "logprobs": [
                { "token": "Hey", "logprob": -1.0415299, "bytes": [72, 101, 121] },
                { "token": ",", "logprob": -9.805982e-5, "bytes": [44] },
                { "token": " my", "logprob": -0.00229799, "bytes": [32, 109, 121] },
                {
                  "token": " knee",
                  "logprob": -4.7159858e-5,
                  "bytes": [32, 107, 110, 101, 101]
                },
                { "token": " is", "logprob": -0.043909557, "bytes": [32, 105, 115] },
                {
                  "token": " hurting",
                  "logprob": -1.1041146e-5,
                  "bytes": [32, 104, 117, 114, 116, 105, 110, 103]
                },
                { "token": " and", "logprob": -0.011076359, "bytes": [32, 97, 110, 100] },
                { "token": " I", "logprob": -5.3193703e-6, "bytes": [32, 73] },
                {
                  "token": " want",
                  "logprob": -0.0017156356,
                  "bytes": [32, 119, 97, 110, 116]
                },
                { "token": " to", "logprob": -7.89631e-7, "bytes": [32, 116, 111] },
                { "token": " see", "logprob": -5.5122365e-7, "bytes": [32, 115, 101, 101] },
                { "token": " the", "logprob": -0.0040786397, "bytes": [32, 116, 104, 101] },
                {
                  "token": " doctor",
                  "logprob": -2.3392786e-6,
                  "bytes": [32, 100, 111, 99, 116, 111, 114]
                },
                {
                  "token": " tomorrow",
                  "logprob": -7.89631e-7,
                  "bytes": [32, 116, 111, 109, 111, 114, 114, 111, 119]
                },
                {
                  "token": " ideally",
                  "logprob": -0.5800861,
                  "bytes": [32, 105, 100, 101, 97, 108, 108, 121]
                },
                { "token": ".", "logprob": -0.00011093382, "bytes": [46] }
              ],
              "usage": {
                "type": "tokens",
                "input_tokens": 14,
                "input_token_details": {
                  "text_tokens": 0,
                  "audio_tokens": 14
                },
                "output_tokens": 45,
                "total_tokens": 59
              }
            }
        - title: Word timestamps
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F "timestamp_granularities[]=word" \
                -F model="whisper-1" \
                -F response_format="verbose_json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.transcriptions.create(
                file=audio_file,
                model="whisper-1",
                response_format="verbose_json",
                timestamp_granularities=["word"]
              )

              print(transcript.words)
            javascript: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const transcription = await openai.audio.transcriptions.create({
                  file: fs.createReadStream("audio.mp3"),
                  model: "whisper-1",
                  response_format: "verbose_json",
                  timestamp_granularities: ["word"]
                });

                console.log(transcription.text);
              }
              main();
            csharp: |
              using System;

              using OpenAI.Audio;

              string audioFilePath = "audio.mp3";

              AudioClient client = new(
                  model: "whisper-1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              AudioTranscriptionOptions options = new()
              {
                  ResponseFormat = AudioTranscriptionFormat.Verbose,
                  TimestampGranularities = AudioTimestampGranularities.Word,
              };

              AudioTranscription transcription = client.TranscribeAudio(audioFilePath, options);

              Console.WriteLine($"{transcription.Text}");
          response: |
            {
              "task": "transcribe",
              "language": "english",
              "duration": 8.470000267028809,
              "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
              "words": [
                {
                  "word": "The",
                  "start": 0.0,
                  "end": 0.23999999463558197
                },
                ...
                {
                  "word": "volleyball",
                  "start": 7.400000095367432,
                  "end": 7.900000095367432
                }
              ],
              "usage": {
                "type": "duration",
                "seconds": 9
              }
            }
        - title: Segment timestamps
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F "timestamp_granularities[]=segment" \
                -F model="whisper-1" \
                -F response_format="verbose_json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.transcriptions.create(
                file=audio_file,
                model="whisper-1",
                response_format="verbose_json",
                timestamp_granularities=["segment"]
              )

              print(transcript.words)
            javascript: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const transcription = await openai.audio.transcriptions.create({
                  file: fs.createReadStream("audio.mp3"),
                  model: "whisper-1",
                  response_format: "verbose_json",
                  timestamp_granularities: ["segment"]
                });

                console.log(transcription.text);
              }
              main();
            csharp: |
              using System;

              using OpenAI.Audio;

              string audioFilePath = "audio.mp3";

              AudioClient client = new(
                  model: "whisper-1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              AudioTranscriptionOptions options = new()
              {
                  ResponseFormat = AudioTranscriptionFormat.Verbose,
                  TimestampGranularities = AudioTimestampGranularities.Segment,
              };

              AudioTranscription transcription = client.TranscribeAudio(audioFilePath, options);

              Console.WriteLine($"{transcription.Text}");
          response: |
            {
              "task": "transcribe",
              "language": "english",
              "duration": 8.470000267028809,
              "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
              "segments": [
                {
                  "id": 0,
                  "seek": 0,
                  "start": 0.0,
                  "end": 3.319999933242798,
                  "text": " The beach was a popular spot on a hot summer day.",
                  "tokens": [
                    50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530
                  ],
                  "temperature": 0.0,
                  "avg_logprob": -0.2860786020755768,
                  "compression_ratio": 1.2363636493682861,
                  "no_speech_prob": 0.00985979475080967
                },
                ...
              ],
              "usage": {
                "type": "duration",
                "seconds": 9
              }
            }
  /audio/translations:
    post:
      operationId: createTranslation
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: "#/components/schemas/CreateTranslationRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/createTranslation_200_response"
          description: OK
      summary: Translates audio into English.
      tags:
      - Audio
      x-oaiMeta:
        name: Create translation
        group: audio
        returns: The translated text.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/audio/translations \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/german.m4a" \
                -F model="whisper-1"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.translations.create(
                model="whisper-1",
                file=audio_file
              )
            javascript: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                  const translation = await openai.audio.translations.create({
                      file: fs.createReadStream("speech.mp3"),
                      model: "whisper-1",
                  });

                  console.log(translation.text);
              }
              main();
            csharp: |
              using System;

              using OpenAI.Audio;

              string audioFilePath = "audio.mp3";

              AudioClient client = new(
                  model: "whisper-1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              AudioTranscription transcription = client.TranscribeAudio(audioFilePath);

              Console.WriteLine($"{transcription.Text}");
          response: |
            {
              "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
            }
  /batches:
    get:
      operationId: listBatches
      parameters:
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListBatchesResponse"
          description: Batch listed successfully.
      summary: List your organization's batches.
      tags:
      - Batch
      x-oaiMeta:
        name: List batch
        group: batch
        returns: "A list of paginated [Batch](/docs/api-reference/batch/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches?limit=2 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.list()
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.batches.list();

                for await (const batch of list) {
                  console.log(batch);
                }
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "batch_abc123",
                  "object": "batch",
                  "endpoint": "/v1/chat/completions",
                  "errors": null,
                  "input_file_id": "file-abc123",
                  "completion_window": "24h",
                  "status": "completed",
                  "output_file_id": "file-cvaTdG",
                  "error_file_id": "file-HOWS94",
                  "created_at": 1711471533,
                  "in_progress_at": 1711471538,
                  "expires_at": 1711557933,
                  "finalizing_at": 1711493133,
                  "completed_at": 1711493163,
                  "failed_at": null,
                  "expired_at": null,
                  "cancelling_at": null,
                  "cancelled_at": null,
                  "request_counts": {
                    "total": 100,
                    "completed": 95,
                    "failed": 5
                  },
                  "metadata": {
                    "customer_id": "user_123456789",
                    "batch_description": "Nightly job",
                  }
                },
                { ... },
              ],
              "first_id": "batch_abc123",
              "last_id": "batch_abc456",
              "has_more": true
            }
    post:
      operationId: createBatch
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/createBatch_request"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Batch"
          description: Batch created successfully.
      summary: Creates and executes a batch from an uploaded file of requests
      tags:
      - Batch
      x-oaiMeta:
        name: Create batch
        group: batch
        returns: "The created [Batch](/docs/api-reference/batch/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "input_file_id": "file-abc123",
                  "endpoint": "/v1/chat/completions",
                  "completion_window": "24h"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.create(
                input_file_id="file-abc123",
                endpoint="/v1/chat/completions",
                completion_window="24h"
              )
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const batch = await openai.batches.create({
                  input_file_id: "file-abc123",
                  endpoint: "/v1/chat/completions",
                  completion_window: "24h"
                });

                console.log(batch);
              }

              main();
          response: |
            {
              "id": "batch_abc123",
              "object": "batch",
              "endpoint": "/v1/chat/completions",
              "errors": null,
              "input_file_id": "file-abc123",
              "completion_window": "24h",
              "status": "validating",
              "output_file_id": null,
              "error_file_id": null,
              "created_at": 1711471533,
              "in_progress_at": null,
              "expires_at": null,
              "finalizing_at": null,
              "completed_at": null,
              "failed_at": null,
              "expired_at": null,
              "cancelling_at": null,
              "cancelled_at": null,
              "request_counts": {
                "total": 0,
                "completed": 0,
                "failed": 0
              },
              "metadata": {
                "customer_id": "user_123456789",
                "batch_description": "Nightly eval job",
              }
            }
  /batches/{batch_id}:
    get:
      operationId: retrieveBatch
      parameters:
      - description: The ID of the batch to retrieve.
        explode: false
        in: path
        name: batch_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Batch"
          description: Batch retrieved successfully.
      summary: Retrieves a batch.
      tags:
      - Batch
      x-oaiMeta:
        name: Retrieve batch
        group: batch
        returns: "The [Batch](/docs/api-reference/batch/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches/batch_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.retrieve("batch_abc123")
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const batch = await openai.batches.retrieve("batch_abc123");

                console.log(batch);
              }

              main();
          response: |
            {
              "id": "batch_abc123",
              "object": "batch",
              "endpoint": "/v1/completions",
              "errors": null,
              "input_file_id": "file-abc123",
              "completion_window": "24h",
              "status": "completed",
              "output_file_id": "file-cvaTdG",
              "error_file_id": "file-HOWS94",
              "created_at": 1711471533,
              "in_progress_at": 1711471538,
              "expires_at": 1711557933,
              "finalizing_at": 1711493133,
              "completed_at": 1711493163,
              "failed_at": null,
              "expired_at": null,
              "cancelling_at": null,
              "cancelled_at": null,
              "request_counts": {
                "total": 100,
                "completed": 95,
                "failed": 5
              },
              "metadata": {
                "customer_id": "user_123456789",
                "batch_description": "Nightly eval job",
              }
            }
  /batches/{batch_id}/cancel:
    post:
      operationId: cancelBatch
      parameters:
      - description: The ID of the batch to cancel.
        explode: false
        in: path
        name: batch_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Batch"
          description: Batch is cancelling. Returns the cancelling batch's details.
      summary: "Cancels an in-progress batch. The batch will be in status `cancelling`\
        \ for up to 10 minutes, before changing to `cancelled`, where it will have\
        \ partial results (if any) available in the output file."
      tags:
      - Batch
      x-oaiMeta:
        name: Cancel batch
        group: batch
        returns: "The [Batch](/docs/api-reference/batch/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches/batch_abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -X POST
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.cancel("batch_abc123")
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const batch = await openai.batches.cancel("batch_abc123");

                console.log(batch);
              }

              main();
          response: |
            {
              "id": "batch_abc123",
              "object": "batch",
              "endpoint": "/v1/chat/completions",
              "errors": null,
              "input_file_id": "file-abc123",
              "completion_window": "24h",
              "status": "cancelling",
              "output_file_id": null,
              "error_file_id": null,
              "created_at": 1711471533,
              "in_progress_at": 1711471538,
              "expires_at": 1711557933,
              "finalizing_at": null,
              "completed_at": null,
              "failed_at": null,
              "expired_at": null,
              "cancelling_at": 1711475133,
              "cancelled_at": null,
              "request_counts": {
                "total": 100,
                "completed": 23,
                "failed": 1
              },
              "metadata": {
                "customer_id": "user_123456789",
                "batch_description": "Nightly eval job",
              }
            }
  /chat/completions:
    get:
      operationId: listChatCompletions
      parameters:
      - description: The model used to generate the Chat Completions.
        explode: true
        in: query
        name: model
        required: false
        schema:
          type: string
        style: form
      - description: |
          A list of metadata keys to filter the Chat Completions by. Example:

          `metadata[key1]=value1&metadata[key2]=value2`
        explode: true
        in: query
        name: metadata
        required: false
        schema:
          $ref: "#/components/schemas/Metadata"
        style: form
      - description: Identifier for the last chat completion from the previous pagination
          request.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: Number of Chat Completions to retrieve.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: Sort order for Chat Completions by timestamp. Use `asc` for ascending
          order or `desc` for descending order. Defaults to `asc`.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: asc
          enum:
          - asc
          - desc
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ChatCompletionList"
          description: A list of Chat Completions
      summary: |
        List stored Chat Completions. Only Chat Completions that have been stored
        with the `store` parameter set to `true` will be returned.
      tags:
      - Chat
      x-oaiMeta:
        name: List Chat Completions
        group: chat
        returns: "A list of [Chat Completions](/docs/api-reference/chat/list-object)\
          \ matching the specified filters."
        path: list
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              completions = client.chat.completions.list()
              print(completions)
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "chat.completion",
                  "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
                  "model": "gpt-4.1-2025-04-14",
                  "created": 1738960610,
                  "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
                  "tool_choice": null,
                  "usage": {
                    "total_tokens": 31,
                    "completion_tokens": 18,
                    "prompt_tokens": 13
                  },
                  "seed": 4944116822809979520,
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "presence_penalty": 0.0,
                  "frequency_penalty": 0.0,
                  "system_fingerprint": "fp_50cad350e4",
                  "input_user": null,
                  "service_tier": "default",
                  "tools": null,
                  "metadata": {},
                  "choices": [
                    {
                      "index": 0,
                      "message": {
                        "content": "Mind of circuits hum,  \nLearning patterns in silence  \nFuture's quiet spark.",
                        "role": "assistant",
                        "tool_calls": null,
                        "function_call": null
                      },
                      "finish_reason": "stop",
                      "logprobs": null
                    }
                  ],
                  "response_format": null
                }
              ],
              "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
              "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
              "has_more": false
            }
    post:
      operationId: createChatCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateChatCompletionRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateChatCompletionResponse"
            text/event-stream:
              schema:
                $ref: "#/components/schemas/CreateChatCompletionStreamResponse"
          description: OK
      summary: "**Starting a new project?** We recommend trying [Responses](/docs/api-reference/responses)\
        \ \nto take advantage of the latest OpenAI platform features. Compare\n[Chat\
        \ Completions with Responses](/docs/guides/responses-vs-chat-completions?api-mode=responses).\n\
        \n---\n\nCreates a model response for the given chat conversation. Learn more\
        \ in the\n[text generation](/docs/guides/text-generation), [vision](/docs/guides/vision),\n\
        and [audio](/docs/guides/audio) guides.\n\nParameter support can differ depending\
        \ on the model used to generate the\nresponse, particularly for newer reasoning\
        \ models. Parameters that are only\nsupported for reasoning models are noted\
        \ below. For the current state of \nunsupported parameters in reasoning models,\
        \ \n[refer to the reasoning guide](/docs/guides/reasoning).\n"
      tags:
      - Chat
      x-oaiMeta:
        name: Create chat completion
        group: chat
        returns: |
          Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.
        path: create
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_chat_model_id",
                  "messages": [
                    {
                      "role": "developer",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_chat_model_id",
                messages=[
                  {"role": "developer", "content": "You are a helpful assistant."},
                  {"role": "user", "content": "Hello!"}
                ]
              )

              print(completion.choices[0].message)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  messages: [{ role: "developer", content: "You are a helpful assistant." }],
                  model: "VAR_chat_model_id",
                  store: true,
                });

                console.log(completion.choices[0]);
              }

              main();
            csharp: |
              using System;
              using System.Collections.Generic;

              using OpenAI.Chat;

              ChatClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              List<ChatMessage> messages =
              [
                  new SystemChatMessage("You are a helpful assistant."),
                  new UserChatMessage("Hello!")
              ];

              ChatCompletion completion = client.CompleteChat(messages);

              Console.WriteLine(completion.Content[0].Text);
          response: |
            {
              "id": "chatcmpl-B9MBs8CjcvOU2jLn4n570S5qMJKcT",
              "object": "chat.completion",
              "created": 1741569952,
              "model": "gpt-4.1-2025-04-14",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "Hello! How can I assist you today?",
                    "refusal": null,
                    "annotations": []
                  },
                  "logprobs": null,
                  "finish_reason": "stop"
                }
              ],
              "usage": {
                "prompt_tokens": 19,
                "completion_tokens": 10,
                "total_tokens": 29,
                "prompt_tokens_details": {
                  "cached_tokens": 0,
                  "audio_tokens": 0
                },
                "completion_tokens_details": {
                  "reasoning_tokens": 0,
                  "audio_tokens": 0,
                  "accepted_prediction_tokens": 0,
                  "rejected_prediction_tokens": 0
                }
              },
              "service_tier": "default"
            }
        - title: Image input
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4.1",
                  "messages": [
                    {
                      "role": "user",
                      "content": [
                        {
                          "type": "text",
                          "text": "What is in this image?"
                        },
                        {
                          "type": "image_url",
                          "image_url": {
                            "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                          }
                        }
                      ]
                    }
                  ],
                  "max_tokens": 300
                }'
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.chat.completions.create(
                  model="gpt-4.1",
                  messages=[
                      {
                          "role": "user",
                          "content": [
                              {"type": "text", "text": "What's in this image?"},
                              {
                                  "type": "image_url",
                                  "image_url": {
                                      "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                                  }
                              },
                          ],
                      }
                  ],
                  max_tokens=300,
              )

              print(response.choices[0])
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.chat.completions.create({
                  model: "gpt-4.1",
                  messages: [
                    {
                      role: "user",
                      content: [
                        { type: "text", text: "What's in this image?" },
                        {
                          type: "image_url",
                          image_url: {
                            "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                          },
                        }
                      ],
                    },
                  ],
                });
                console.log(response.choices[0]);
              }
              main();
            csharp: |
              using System;
              using System.Collections.Generic;

              using OpenAI.Chat;

              ChatClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              List<ChatMessage> messages =
              [
                  new UserChatMessage(
                  [
                      ChatMessageContentPart.CreateTextPart("What's in this image?"),
                      ChatMessageContentPart.CreateImagePart(new Uri("https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"))
                  ])
              ];

              ChatCompletion completion = client.CompleteChat(messages);

              Console.WriteLine(completion.Content[0].Text);
          response: |
            {
              "id": "chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG",
              "object": "chat.completion",
              "created": 1741570283,
              "model": "gpt-4.1-2025-04-14",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "The image shows a wooden boardwalk path running through a lush green field or meadow. The sky is bright blue with some scattered clouds, giving the scene a serene and peaceful atmosphere. Trees and shrubs are visible in the background.",
                    "refusal": null,
                    "annotations": []
                  },
                  "logprobs": null,
                  "finish_reason": "stop"
                }
              ],
              "usage": {
                "prompt_tokens": 1117,
                "completion_tokens": 46,
                "total_tokens": 1163,
                "prompt_tokens_details": {
                  "cached_tokens": 0,
                  "audio_tokens": 0
                },
                "completion_tokens_details": {
                  "reasoning_tokens": 0,
                  "audio_tokens": 0,
                  "accepted_prediction_tokens": 0,
                  "rejected_prediction_tokens": 0
                }
              },
              "service_tier": "default"
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_chat_model_id",
                  "messages": [
                    {
                      "role": "developer",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_chat_model_id",
                messages=[
                  {"role": "developer", "content": "You are a helpful assistant."},
                  {"role": "user", "content": "Hello!"}
                ],
                stream=True
              )

              for chunk in completion:
                print(chunk.choices[0].delta)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  model: "VAR_chat_model_id",
                  messages: [
                    {"role": "developer", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ],
                  stream: true,
                });

                for await (const chunk of completion) {
                  console.log(chunk.choices[0].delta.content);
                }
              }

              main();
            csharp: |
              using System;
              using System.ClientModel;
              using System.Collections.Generic;
              using System.Threading.Tasks;

              using OpenAI.Chat;

              ChatClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              List<ChatMessage> messages =
              [
                  new SystemChatMessage("You are a helpful assistant."),
                  new UserChatMessage("Hello!")
              ];

              AsyncCollectionResult<StreamingChatCompletionUpdate> completionUpdates = client.CompleteChatStreamingAsync(messages);

              await foreach (StreamingChatCompletionUpdate completionUpdate in completionUpdates)
              {
                  if (completionUpdate.ContentUpdate.Count > 0)
                  {
                      Console.Write(completionUpdate.ContentUpdate[0].Text);
                  }
              }
          response: |
            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

            ....

            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
        - title: Functions
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $OPENAI_API_KEY" \
              -d '{
                "model": "gpt-4.1",
                "messages": [
                  {
                    "role": "user",
                    "content": "What is the weather like in Boston today?"
                  }
                ],
                "tools": [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA"
                          },
                          "unit": {
                            "type": "string",
                            "enum": ["celsius", "fahrenheit"]
                          }
                        },
                        "required": ["location"]
                      }
                    }
                  }
                ],
                "tool_choice": "auto"
              }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              tools = [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA",
                        },
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                      },
                      "required": ["location"],
                    },
                  }
                }
              ]
              messages = [{"role": "user", "content": "What's the weather like in Boston today?"}]
              completion = client.chat.completions.create(
                model="VAR_chat_model_id",
                messages=messages,
                tools=tools,
                tool_choice="auto"
              )

              print(completion)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const messages = [{"role": "user", "content": "What's the weather like in Boston today?"}];
                const tools = [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA",
                            },
                            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                          },
                          "required": ["location"],
                        },
                      }
                    }
                ];

                const response = await openai.chat.completions.create({
                  model: "gpt-4.1",
                  messages: messages,
                  tools: tools,
                  tool_choice: "auto",
                });

                console.log(response);
              }

              main();
            csharp: |
              using System;
              using System.Collections.Generic;

              using OpenAI.Chat;

              ChatClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              ChatTool getCurrentWeatherTool = ChatTool.CreateFunctionTool(
                  functionName: "get_current_weather",
                  functionDescription: "Get the current weather in a given location",
                  functionParameters: BinaryData.FromString("""
                      {
                          "type": "object",
                          "properties": {
                              "location": {
                                  "type": "string",
                                  "description": "The city and state, e.g. San Francisco, CA"
                              },
                              "unit": {
                                  "type": "string",
                                  "enum": [ "celsius", "fahrenheit" ]
                              }
                          },
                          "required": [ "location" ]
                      }
                  """)
              );

              List<ChatMessage> messages =
              [
                  new UserChatMessage("What's the weather like in Boston today?"),
              ];

              ChatCompletionOptions options = new()
              {
                  Tools =
                  {
                      getCurrentWeatherTool
                  },
                  ToolChoice = ChatToolChoice.CreateAutoChoice(),
              };

              ChatCompletion completion = client.CompleteChat(messages, options);
          response: |
            {
              "id": "chatcmpl-abc123",
              "object": "chat.completion",
              "created": 1699896916,
              "model": "gpt-4o-mini",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": null,
                    "tool_calls": [
                      {
                        "id": "call_abc123",
                        "type": "function",
                        "function": {
                          "name": "get_current_weather",
                          "arguments": "{\n\"location\": \"Boston, MA\"\n}"
                        }
                      }
                    ]
                  },
                  "logprobs": null,
                  "finish_reason": "tool_calls"
                }
              ],
              "usage": {
                "prompt_tokens": 82,
                "completion_tokens": 17,
                "total_tokens": 99,
                "completion_tokens_details": {
                  "reasoning_tokens": 0,
                  "accepted_prediction_tokens": 0,
                  "rejected_prediction_tokens": 0
                }
              }
            }
        - title: Logprobs
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_chat_model_id",
                  "messages": [
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ],
                  "logprobs": true,
                  "top_logprobs": 2
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_chat_model_id",
                messages=[
                  {"role": "user", "content": "Hello!"}
                ],
                logprobs=True,
                top_logprobs=2
              )

              print(completion.choices[0].message)
              print(completion.choices[0].logprobs)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  messages: [{ role: "user", content: "Hello!" }],
                  model: "VAR_chat_model_id",
                  logprobs: true,
                  top_logprobs: 2,
                });

                console.log(completion.choices[0]);
              }

              main();
            csharp: |
              using System;
              using System.Collections.Generic;

              using OpenAI.Chat;

              ChatClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              List<ChatMessage> messages =
              [
                  new UserChatMessage("Hello!")
              ];

              ChatCompletionOptions options = new()
              {
                  IncludeLogProbabilities = true,
                  TopLogProbabilityCount = 2
              };

              ChatCompletion completion = client.CompleteChat(messages, options);

              Console.WriteLine(completion.Content[0].Text);
          response: |
            {
              "id": "chatcmpl-123",
              "object": "chat.completion",
              "created": 1702685778,
              "model": "gpt-4o-mini",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "Hello! How can I assist you today?"
                  },
                  "logprobs": {
                    "content": [
                      {
                        "token": "Hello",
                        "logprob": -0.31725305,
                        "bytes": [72, 101, 108, 108, 111],
                        "top_logprobs": [
                          {
                            "token": "Hello",
                            "logprob": -0.31725305,
                            "bytes": [72, 101, 108, 108, 111]
                          },
                          {
                            "token": "Hi",
                            "logprob": -1.3190403,
                            "bytes": [72, 105]
                          }
                        ]
                      },
                      {
                        "token": "!",
                        "logprob": -0.02380986,
                        "bytes": [
                          33
                        ],
                        "top_logprobs": [
                          {
                            "token": "!",
                            "logprob": -0.02380986,
                            "bytes": [33]
                          },
                          {
                            "token": " there",
                            "logprob": -3.787621,
                            "bytes": [32, 116, 104, 101, 114, 101]
                          }
                        ]
                      },
                      {
                        "token": " How",
                        "logprob": -0.000054669687,
                        "bytes": [32, 72, 111, 119],
                        "top_logprobs": [
                          {
                            "token": " How",
                            "logprob": -0.000054669687,
                            "bytes": [32, 72, 111, 119]
                          },
                          {
                            "token": "<|end|>",
                            "logprob": -10.953937,
                            "bytes": null
                          }
                        ]
                      },
                      {
                        "token": " can",
                        "logprob": -0.015801601,
                        "bytes": [32, 99, 97, 110],
                        "top_logprobs": [
                          {
                            "token": " can",
                            "logprob": -0.015801601,
                            "bytes": [32, 99, 97, 110]
                          },
                          {
                            "token": " may",
                            "logprob": -4.161023,
                            "bytes": [32, 109, 97, 121]
                          }
                        ]
                      },
                      {
                        "token": " I",
                        "logprob": -3.7697225e-6,
                        "bytes": [
                          32,
                          73
                        ],
                        "top_logprobs": [
                          {
                            "token": " I",
                            "logprob": -3.7697225e-6,
                            "bytes": [32, 73]
                          },
                          {
                            "token": " assist",
                            "logprob": -13.596657,
                            "bytes": [32, 97, 115, 115, 105, 115, 116]
                          }
                        ]
                      },
                      {
                        "token": " assist",
                        "logprob": -0.04571125,
                        "bytes": [32, 97, 115, 115, 105, 115, 116],
                        "top_logprobs": [
                          {
                            "token": " assist",
                            "logprob": -0.04571125,
                            "bytes": [32, 97, 115, 115, 105, 115, 116]
                          },
                          {
                            "token": " help",
                            "logprob": -3.1089056,
                            "bytes": [32, 104, 101, 108, 112]
                          }
                        ]
                      },
                      {
                        "token": " you",
                        "logprob": -5.4385737e-6,
                        "bytes": [32, 121, 111, 117],
                        "top_logprobs": [
                          {
                            "token": " you",
                            "logprob": -5.4385737e-6,
                            "bytes": [32, 121, 111, 117]
                          },
                          {
                            "token": " today",
                            "logprob": -12.807695,
                            "bytes": [32, 116, 111, 100, 97, 121]
                          }
                        ]
                      },
                      {
                        "token": " today",
                        "logprob": -0.0040071653,
                        "bytes": [32, 116, 111, 100, 97, 121],
                        "top_logprobs": [
                          {
                            "token": " today",
                            "logprob": -0.0040071653,
                            "bytes": [32, 116, 111, 100, 97, 121]
                          },
                          {
                            "token": "?",
                            "logprob": -5.5247097,
                            "bytes": [63]
                          }
                        ]
                      },
                      {
                        "token": "?",
                        "logprob": -0.0008108172,
                        "bytes": [63],
                        "top_logprobs": [
                          {
                            "token": "?",
                            "logprob": -0.0008108172,
                            "bytes": [63]
                          },
                          {
                            "token": "?\n",
                            "logprob": -7.184561,
                            "bytes": [63, 10]
                          }
                        ]
                      }
                    ]
                  },
                  "finish_reason": "stop"
                }
              ],
              "usage": {
                "prompt_tokens": 9,
                "completion_tokens": 9,
                "total_tokens": 18,
                "completion_tokens_details": {
                  "reasoning_tokens": 0,
                  "accepted_prediction_tokens": 0,
                  "rejected_prediction_tokens": 0
                }
              },
              "system_fingerprint": null
            }
  /chat/completions/{completion_id}:
    delete:
      operationId: deleteChatCompletion
      parameters:
      - description: The ID of the chat completion to delete.
        explode: false
        in: path
        name: completion_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ChatCompletionDeleted"
          description: The chat completion was deleted successfully.
      summary: |
        Delete a stored chat completion. Only Chat Completions that have been
        created with the `store` parameter set to `true` can be deleted.
      tags:
      - Chat
      x-oaiMeta:
        name: Delete chat completion
        group: chat
        returns: A deletion confirmation object.
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/chat/completions/chat_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              completions = client.chat.completions.list()
              first_id = completions[0].id
              delete_response = client.chat.completions.delete(completion_id=first_id)
              print(delete_response)
          response: |
            {
              "object": "chat.completion.deleted",
              "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
              "deleted": true
            }
    get:
      operationId: getChatCompletion
      parameters:
      - description: The ID of the chat completion to retrieve.
        explode: false
        in: path
        name: completion_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateChatCompletionResponse"
          description: A chat completion
      summary: |
        Get a stored chat completion. Only Chat Completions that have been created
        with the `store` parameter set to `true` will be returned.
      tags:
      - Chat
      x-oaiMeta:
        name: Get chat completion
        group: chat
        returns: "The [ChatCompletion](/docs/api-reference/chat/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions/chatcmpl-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              completions = client.chat.completions.list()
              first_id = completions[0].id
              first_completion = client.chat.completions.retrieve(completion_id=first_id)
              print(first_completion)
          response: |
            {
              "object": "chat.completion",
              "id": "chatcmpl-abc123",
              "model": "gpt-4o-2024-08-06",
              "created": 1738960610,
              "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
              "tool_choice": null,
              "usage": {
                "total_tokens": 31,
                "completion_tokens": 18,
                "prompt_tokens": 13
              },
              "seed": 4944116822809979520,
              "top_p": 1.0,
              "temperature": 1.0,
              "presence_penalty": 0.0,
              "frequency_penalty": 0.0,
              "system_fingerprint": "fp_50cad350e4",
              "input_user": null,
              "service_tier": "default",
              "tools": null,
              "metadata": {},
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "content": "Mind of circuits hum,  \nLearning patterns in silence  \nFuture's quiet spark.",
                    "role": "assistant",
                    "tool_calls": null,
                    "function_call": null
                  },
                  "finish_reason": "stop",
                  "logprobs": null
                }
              ],
              "response_format": null
            }
    post:
      operationId: updateChatCompletion
      parameters:
      - description: The ID of the chat completion to update.
        explode: false
        in: path
        name: completion_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/updateChatCompletion_request"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateChatCompletionResponse"
          description: A chat completion
      summary: |
        Modify a stored chat completion. Only Chat Completions that have been
        created with the `store` parameter set to `true` can be modified. Currently,
        the only supported modification is to update the `metadata` field.
      tags:
      - Chat
      x-oaiMeta:
        name: Update chat completion
        group: chat
        returns: "The [ChatCompletion](/docs/api-reference/chat/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/chat/completions/chat_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{"metadata": {"foo": "bar"}}'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completions = client.chat.completions.list()
              first_id = completions[0].id
              updated_completion = client.chat.completions.update(completion_id=first_id, request_body={"metadata": {"foo": "bar"}})
              print(updated_completion)
          response: |
            {
              "object": "chat.completion",
              "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
              "model": "gpt-4o-2024-08-06",
              "created": 1738960610,
              "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
              "tool_choice": null,
              "usage": {
                "total_tokens": 31,
                "completion_tokens": 18,
                "prompt_tokens": 13
              },
              "seed": 4944116822809979520,
              "top_p": 1.0,
              "temperature": 1.0,
              "presence_penalty": 0.0,
              "frequency_penalty": 0.0,
              "system_fingerprint": "fp_50cad350e4",
              "input_user": null,
              "service_tier": "default",
              "tools": null,
              "metadata": {
                "foo": "bar"
              },
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "content": "Mind of circuits hum,  \nLearning patterns in silence  \nFuture's quiet spark.",
                    "role": "assistant",
                    "tool_calls": null,
                    "function_call": null
                  },
                  "finish_reason": "stop",
                  "logprobs": null
                }
              ],
              "response_format": null
            }
  /chat/completions/{completion_id}/messages:
    get:
      operationId: getChatCompletionMessages
      parameters:
      - description: The ID of the chat completion to retrieve messages from.
        explode: false
        in: path
        name: completion_id
        required: true
        schema:
          type: string
        style: simple
      - description: Identifier for the last message from the previous pagination
          request.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: Number of messages to retrieve.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: Sort order for messages by timestamp. Use `asc` for ascending
          order or `desc` for descending order. Defaults to `asc`.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: asc
          enum:
          - asc
          - desc
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ChatCompletionMessageList"
          description: A list of messages
      summary: |
        Get the messages in a stored chat completion. Only Chat Completions that
        have been created with the `store` parameter set to `true` will be
        returned.
      tags:
      - Chat
      x-oaiMeta:
        name: Get chat messages
        group: chat
        returns: "A list of [messages](/docs/api-reference/chat/message-list) for\
          \ the specified chat completion."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions/chat_abc123/messages \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              completions = client.chat.completions.list()
              first_id = completions[0].id
              first_completion = client.chat.completions.retrieve(completion_id=first_id)
              messages = client.chat.completions.messages.list(completion_id=first_id)
              print(messages)
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
                  "role": "user",
                  "content": "write a haiku about ai",
                  "name": null,
                  "content_parts": null
                }
              ],
              "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
              "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
              "has_more": false
            }
  /completions:
    post:
      operationId: createCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateCompletionRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateCompletionResponse"
          description: OK
      summary: Creates a completion for the provided prompt and parameters.
      tags:
      - Completions
      x-oaiMeta:
        name: Create completion
        group: completions
        returns: |
          Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.
        legacy: true
        examples:
        - title: No streaming
          request:
            curl: |
              curl https://api.openai.com/v1/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_completion_model_id",
                  "prompt": "Say this is a test",
                  "max_tokens": 7,
                  "temperature": 0
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.completions.create(
                model="VAR_completion_model_id",
                prompt="Say this is a test",
                max_tokens=7,
                temperature=0
              )
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.completions.create({
                  model: "VAR_completion_model_id",
                  prompt: "Say this is a test.",
                  max_tokens: 7,
                  temperature: 0,
                });

                console.log(completion);
              }
              main();
          response: |
            {
              "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
              "object": "text_completion",
              "created": 1589478378,
              "model": "VAR_completion_model_id",
              "system_fingerprint": "fp_44709d6fcb",
              "choices": [
                {
                  "text": "\n\nThis is indeed a test",
                  "index": 0,
                  "logprobs": null,
                  "finish_reason": "length"
                }
              ],
              "usage": {
                "prompt_tokens": 5,
                "completion_tokens": 7,
                "total_tokens": 12
              }
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_completion_model_id",
                  "prompt": "Say this is a test",
                  "max_tokens": 7,
                  "temperature": 0,
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              for chunk in client.completions.create(
                model="VAR_completion_model_id",
                prompt="Say this is a test",
                max_tokens=7,
                temperature=0,
                stream=True
              ):
                print(chunk.choices[0].text)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.completions.create({
                  model: "VAR_completion_model_id",
                  prompt: "Say this is a test.",
                  stream: true,
                });

                for await (const chunk of stream) {
                  console.log(chunk.choices[0].text)
                }
              }
              main();
          response: |
            {
              "id": "cmpl-7iA7iJjj8V2zOkCGvWF2hAkDWBQZe",
              "object": "text_completion",
              "created": 1690759702,
              "choices": [
                {
                  "text": "This",
                  "index": 0,
                  "logprobs": null,
                  "finish_reason": null
                }
              ],
              "model": "gpt-3.5-turbo-instruct"
              "system_fingerprint": "fp_44709d6fcb",
            }
  /containers:
    get:
      description: Lists containers.
      operationId: ListContainers
      parameters:
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ContainerListResource"
          description: Success
      summary: List Containers
      x-oaiMeta:
        name: List containers
        group: containers
        returns: "a list of [container](/docs/api-reference/containers/object) objects."
        path: get
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/containers \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
              "object": "list",
              "data": [
                {
                    "id": "cntr_682dfebaacac8198bbfe9c2474fb6f4a085685cbe3cb5863",
                    "object": "container",
                    "created_at": 1747844794,
                    "status": "running",
                    "expires_after": {
                        "anchor": "last_active_at",
                        "minutes": 20
                    },
                    "last_active_at": 1747844794,
                    "name": "My Container"
                }
              ],
              "first_id": "container_123",
              "last_id": "container_123",
              "has_more": false
            }
    post:
      description: Creates a container.
      operationId: CreateContainer
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateContainerBody"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ContainerResource"
          description: Success
      summary: Create Container
      x-oaiMeta:
        name: Create container
        group: containers
        returns: "The created [container](/docs/api-reference/containers/object) object."
        path: post
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/containers \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                      "name": "My Container"
                    }'
          response: |
            {
                "id": "cntr_682e30645a488191b6363a0cbefc0f0a025ec61b66250591",
                "object": "container",
                "created_at": 1747857508,
                "status": "running",
                "expires_after": {
                    "anchor": "last_active_at",
                    "minutes": 20
                },
                "last_active_at": 1747857508,
                "name": "My Container"
            }
  /containers/{container_id}:
    delete:
      description: Delete a container.
      operationId: DeleteContainer
      parameters:
      - description: The ID of the container to delete.
        explode: false
        in: path
        name: container_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          description: OK
      summary: Delete Container
      x-oaiMeta:
        name: Delete a container
        group: containers
        returns: Deletion Status
        path: delete
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/containers/cntr_682dfebaacac8198bbfe9c2474fb6f4a085685cbe3cb5863 \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
                "id": "cntr_682dfebaacac8198bbfe9c2474fb6f4a085685cbe3cb5863",
                "object": "container.deleted",
                "deleted": true
            }
    get:
      description: Retrieves a container.
      operationId: RetrieveContainer
      parameters:
      - explode: false
        in: path
        name: container_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ContainerResource"
          description: Success
      summary: Retrieve Container
      x-oaiMeta:
        name: Retrieve container
        group: containers
        returns: "The [container](/docs/api-reference/containers/object) object."
        path: get
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/containers/cntr_682dfebaacac8198bbfe9c2474fb6f4a085685cbe3cb5863 \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
                "id": "cntr_682dfebaacac8198bbfe9c2474fb6f4a085685cbe3cb5863",
                "object": "container",
                "created_at": 1747844794,
                "status": "running",
                "expires_after": {
                    "anchor": "last_active_at",
                    "minutes": 20
                },
                "last_active_at": 1747844794,
                "name": "My Container"
            }
  /containers/{container_id}/files:
    get:
      description: Lists container files.
      operationId: ListContainerFiles
      parameters:
      - explode: false
        in: path
        name: container_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ContainerFileListResource"
          description: Success
      summary: List Container files
      x-oaiMeta:
        name: List container files
        group: containers
        returns: "a list of [container file](/docs/api-reference/container-files/object)\
          \ objects."
        path: get
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/containers/cntr_682e0e7318108198aa783fd921ff305e08e78805b9fdbb04/files \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
                "object": "list",
                "data": [
                    {
                        "id": "cfile_682e0e8a43c88191a7978f477a09bdf5",
                        "object": "container.file",
                        "created_at": 1747848842,
                        "bytes": 880,
                        "container_id": "cntr_682e0e7318108198aa783fd921ff305e08e78805b9fdbb04",
                        "path": "/mnt/data/88e12fa445d32636f190a0b33daed6cb-tsconfig.json",
                        "source": "user"
                    }
                ],
                "first_id": "cfile_682e0e8a43c88191a7978f477a09bdf5",
                "has_more": false,
                "last_id": "cfile_682e0e8a43c88191a7978f477a09bdf5"
            }
    post:
      description: |
        Creates a container file.
      operationId: CreateContainerFile
      parameters:
      - explode: false
        in: path
        name: container_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: "#/components/schemas/CreateContainerFileBody"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ContainerFileResource"
          description: Success
      summary: |
        Create a Container File

        You can send either a multipart/form-data request with the raw file content, or a JSON request with a file ID.
      x-oaiMeta:
        name: Create container file
        group: containers
        returns: "The created [container file](/docs/api-reference/container-files/object)\
          \ object."
        path: post
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/containers/cntr_682e0e7318108198aa783fd921ff305e08e78805b9fdbb04/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F file="@example.txt"
          response: |
            {
              "id": "cfile_682e0e8a43c88191a7978f477a09bdf5",
              "object": "container.file",
              "created_at": 1747848842,
              "bytes": 880,
              "container_id": "cntr_682e0e7318108198aa783fd921ff305e08e78805b9fdbb04",
              "path": "/mnt/data/88e12fa445d32636f190a0b33daed6cb-tsconfig.json",
              "source": "user"
            }
  /containers/{container_id}/files/{file_id}:
    delete:
      description: Delete a container file.
      operationId: DeleteContainerFile
      parameters:
      - explode: false
        in: path
        name: container_id
        required: true
        schema:
          type: string
        style: simple
      - explode: false
        in: path
        name: file_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          description: OK
      summary: Delete Container File
      x-oaiMeta:
        name: Delete a container file
        group: containers
        returns: Deletion Status
        path: delete
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/containers/cntr_682dfebaacac8198bbfe9c2474fb6f4a085685cbe3cb5863/files/cfile_682e0e8a43c88191a7978f477a09bdf5 \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
                "id": "cfile_682e0e8a43c88191a7978f477a09bdf5",
                "object": "container.file.deleted",
                "deleted": true
            }
    get:
      description: Retrieves a container file.
      operationId: RetrieveContainerFile
      parameters:
      - explode: false
        in: path
        name: container_id
        required: true
        schema:
          type: string
        style: simple
      - explode: false
        in: path
        name: file_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ContainerFileResource"
          description: Success
      summary: Retrieve Container File
      x-oaiMeta:
        name: Retrieve container file
        group: containers
        returns: "The [container file](/docs/api-reference/container-files/object)\
          \ object."
        path: get
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/containers/container_123/files/file_456 \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
                "id": "cfile_682e0e8a43c88191a7978f477a09bdf5",
                "object": "container.file",
                "created_at": 1747848842,
                "bytes": 880,
                "container_id": "cntr_682e0e7318108198aa783fd921ff305e08e78805b9fdbb04",
                "path": "/mnt/data/88e12fa445d32636f190a0b33daed6cb-tsconfig.json",
                "source": "user"
            }
  /containers/{container_id}/files/{file_id}/content:
    get:
      description: Retrieves a container file content.
      operationId: RetrieveContainerFileContent
      parameters:
      - explode: false
        in: path
        name: container_id
        required: true
        schema:
          type: string
        style: simple
      - explode: false
        in: path
        name: file_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          description: Success
      summary: Retrieve Container File Content
      x-oaiMeta:
        name: Retrieve container file content
        group: containers
        returns: The contents of the container file.
        path: get
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/containers/container_123/files/cfile_456/content \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            <binary content of the file>
  /embeddings:
    post:
      operationId: createEmbedding
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateEmbeddingRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateEmbeddingResponse"
          description: OK
      summary: Creates an embedding vector representing the input text.
      tags:
      - Embeddings
      x-oaiMeta:
        name: Create embeddings
        group: embeddings
        returns: "A list of [embedding](/docs/api-reference/embeddings/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/embeddings \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "input": "The food was delicious and the waiter...",
                  "model": "text-embedding-ada-002",
                  "encoding_format": "float"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.embeddings.create(
                model="text-embedding-ada-002",
                input="The food was delicious and the waiter...",
                encoding_format="float"
              )
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const embedding = await openai.embeddings.create({
                  model: "text-embedding-ada-002",
                  input: "The quick brown fox jumped over the lazy dog",
                  encoding_format: "float",
                });

                console.log(embedding);
              }

              main();
            csharp: |
              using System;

              using OpenAI.Embeddings;

              EmbeddingClient client = new(
                  model: "text-embedding-3-small",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              OpenAIEmbedding embedding = client.GenerateEmbedding(input: "The quick brown fox jumped over the lazy dog");
              ReadOnlyMemory<float> vector = embedding.ToFloats();

              for (int i = 0; i < vector.Length; i++)
              {
                  Console.WriteLine($"  [{i,4}] = {vector.Span[i]}");
              }
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "embedding",
                  "embedding": [
                    0.0023064255,
                    -0.009327292,
                    .... (1536 floats total for ada-002)
                    -0.0028842222,
                  ],
                  "index": 0
                }
              ],
              "model": "text-embedding-ada-002",
              "usage": {
                "prompt_tokens": 8,
                "total_tokens": 8
              }
            }
  /evals:
    get:
      operationId: listEvals
      parameters:
      - description: Identifier for the last eval from the previous pagination request.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: Number of evals to retrieve.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: Sort order for evals by timestamp. Use `asc` for ascending order
          or `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: asc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          Evals can be ordered by creation time or last updated time. Use
          `created_at` for creation time or `updated_at` for last updated time.
        explode: true
        in: query
        name: order_by
        required: false
        schema:
          default: created_at
          enum:
          - created_at
          - updated_at
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/EvalList"
          description: A list of evals
      summary: |
        List evaluations for a project.
      tags:
      - Evals
      x-oaiMeta:
        name: List evals
        group: evals
        returns: "A list of [evals](/docs/api-reference/evals/object) matching the\
          \ specified filters."
        path: list
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals?limit=1 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              evals = client.evals.list(limit=1)
              print(evals)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const evals = await openai.evals.list({ limit: 1 });
              console.log(evals);
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "eval_67abd54d9b0081909a86353f6fb9317a",
                  "object": "eval",
                  "data_source_config": {
                    "type": "stored_completions",
                    "metadata": {
                      "usecase": "push_notifications_summarizer"
                    },
                    "schema": {
                      "type": "object",
                      "properties": {
                        "item": {
                          "type": "object"
                        },
                        "sample": {
                          "type": "object"
                        }
                      },
                      "required": [
                        "item",
                        "sample"
                      ]
                    }
                  },
                  "testing_criteria": [
                    {
                      "name": "Push Notification Summary Grader",
                      "id": "Push Notification Summary Grader-9b876f24-4762-4be9-aff4-db7a9b31c673",
                      "type": "label_model",
                      "model": "o3-mini",
                      "input": [
                        {
                          "type": "message",
                          "role": "developer",
                          "content": {
                            "type": "input_text",
                            "text": "\nLabel the following push notification summary as either correct or incorrect.\nThe push notification and the summary will be provided below.\nA good push notificiation summary is concise and snappy.\nIf it is good, then label it as correct, if not, then incorrect.\n"
                          }
                        },
                        {
                          "type": "message",
                          "role": "user",
                          "content": {
                            "type": "input_text",
                            "text": "\nPush notifications: {{item.input}}\nSummary: {{sample.output_text}}\n"
                          }
                        }
                      ],
                      "passing_labels": [
                        "correct"
                      ],
                      "labels": [
                        "correct",
                        "incorrect"
                      ],
                      "sampling_params": null
                    }
                  ],
                  "name": "Push Notification Summary Grader",
                  "created_at": 1739314509,
                  "metadata": {
                    "description": "A stored completions eval for push notification summaries"
                  }
                }
              ],
              "first_id": "eval_67abd54d9b0081909a86353f6fb9317a",
              "last_id": "eval_67aa884cf6688190b58f657d4441c8b7",
              "has_more": true
            }
    post:
      operationId: createEval
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateEvalRequest"
        required: true
      responses:
        "201":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Eval"
          description: OK
      summary: |
        Create the structure of an evaluation that can be used to test a model's performance.
        An evaluation is a set of testing criteria and the config for a data source, which dictates the schema of the data used in the evaluation. After creating an evaluation, you can run it on different models and model parameters. We support several types of graders and datasources.
        For more information, see the [Evals guide](/docs/guides/evals).
      tags:
      - Evals
      x-oaiMeta:
        name: Create eval
        group: evals
        returns: "The created [Eval](/docs/api-reference/evals/object) object."
        path: post
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                      "name": "Sentiment",
                      "data_source_config": {
                        "type": "stored_completions",
                        "metadata": {
                            "usecase": "chatbot"
                        }
                      },
                      "testing_criteria": [
                        {
                          "type": "label_model",
                          "model": "o3-mini",
                          "input": [
                            {
                              "role": "developer",
                              "content": "Classify the sentiment of the following statement as one of 'positive', 'neutral', or 'negative'"
                            },
                            {
                              "role": "user",
                              "content": "Statement: {{item.input}}"
                            }
                          ],
                          "passing_labels": [
                            "positive"
                          ],
                          "labels": [
                            "positive",
                            "neutral",
                            "negative"
                          ],
                          "name": "Example label grader"
                        }
                      ]
                    }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              eval_obj = client.evals.create(
                name="Sentiment",
                data_source_config={
                  "type": "stored_completions",
                  "metadata": {"usecase": "chatbot"}
                },
                testing_criteria=[
                  {
                    "type": "label_model",
                    "model": "o3-mini",
                    "input": [
                      {"role": "developer", "content": "Classify the sentiment of the following statement as one of 'positive', 'neutral', or 'negative'"},
                      {"role": "user", "content": "Statement: {{item.input}}"}
                    ],
                    "passing_labels": ["positive"],
                    "labels": ["positive", "neutral", "negative"],
                    "name": "Example label grader"
                  }
                ]
              )
              print(eval_obj)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const evalObj = await openai.evals.create({
                name: "Sentiment",
                data_source_config: {
                  type: "stored_completions",
                  metadata: { usecase: "chatbot" }
                },
                testing_criteria: [
                  {
                    type: "label_model",
                    model: "o3-mini",
                    input: [
                      { role: "developer", content: "Classify the sentiment of the following statement as one of 'positive', 'neutral', or 'negative'" },
                      { role: "user", content: "Statement: {{item.input}}" }
                    ],
                    passing_labels: ["positive"],
                    labels: ["positive", "neutral", "negative"],
                    name: "Example label grader"
                  }
                ]
              });
              console.log(evalObj);
          response: |
            {
              "object": "eval",
              "id": "eval_67b7fa9a81a88190ab4aa417e397ea21",
              "data_source_config": {
                "type": "stored_completions",
                "metadata": {
                  "usecase": "chatbot"
                },
                "schema": {
                  "type": "object",
                  "properties": {
                    "item": {
                      "type": "object"
                    },
                    "sample": {
                      "type": "object"
                    }
                  },
                  "required": [
                    "item",
                    "sample"
                  ]
              },
              "testing_criteria": [
                {
                  "name": "Example label grader",
                  "type": "label_model",
                  "model": "o3-mini",
                  "input": [
                    {
                      "type": "message",
                      "role": "developer",
                      "content": {
                        "type": "input_text",
                        "text": "Classify the sentiment of the following statement as one of positive, neutral, or negative"
                      }
                    },
                    {
                      "type": "message",
                      "role": "user",
                      "content": {
                        "type": "input_text",
                        "text": "Statement: {{item.input}}"
                      }
                    }
                  ],
                  "passing_labels": [
                    "positive"
                  ],
                  "labels": [
                    "positive",
                    "neutral",
                    "negative"
                  ]
                }
              ],
              "name": "Sentiment",
              "created_at": 1740110490,
              "metadata": {
                "description": "An eval for sentiment analysis"
              }
            }
  /evals/{eval_id}:
    delete:
      operationId: deleteEval
      parameters:
      - description: The ID of the evaluation to delete.
        explode: false
        in: path
        name: eval_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/deleteEval_200_response"
          description: Successfully deleted the evaluation.
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Error"
          description: Evaluation not found.
      summary: |
        Delete an evaluation.
      tags:
      - Evals
      x-oaiMeta:
        name: Delete an eval
        group: evals
        returns: A deletion confirmation object.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_abc123 \
                -X DELETE \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted = client.evals.delete("eval_abc123")
              print(deleted)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const deleted = await openai.evals.delete("eval_abc123");
              console.log(deleted);
          response: |
            {
              "object": "eval.deleted",
              "deleted": true,
              "eval_id": "eval_abc123"
            }
    get:
      operationId: getEval
      parameters:
      - description: The ID of the evaluation to retrieve.
        explode: false
        in: path
        name: eval_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Eval"
          description: The evaluation
      summary: |
        Get an evaluation by ID.
      tags:
      - Evals
      x-oaiMeta:
        name: Get an eval
        group: evals
        returns: "The [Eval](/docs/api-reference/evals/object) object matching the\
          \ specified ID."
        path: get
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              eval_obj = client.evals.retrieve("eval_67abd54d9b0081909a86353f6fb9317a")
              print(eval_obj)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const evalObj = await openai.evals.retrieve("eval_67abd54d9b0081909a86353f6fb9317a");
              console.log(evalObj);
          response: |
            {
              "object": "eval",
              "id": "eval_67abd54d9b0081909a86353f6fb9317a",
              "data_source_config": {
                "type": "custom",
                "schema": {
                  "type": "object",
                  "properties": {
                    "item": {
                      "type": "object",
                      "properties": {
                        "input": {
                          "type": "string"
                        },
                        "ground_truth": {
                          "type": "string"
                        }
                      },
                      "required": [
                        "input",
                        "ground_truth"
                      ]
                    }
                  },
                  "required": [
                    "item"
                  ]
                }
              },
              "testing_criteria": [
                {
                  "name": "String check",
                  "id": "String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2",
                  "type": "string_check",
                  "input": "{{item.input}}",
                  "reference": "{{item.ground_truth}}",
                  "operation": "eq"
                }
              ],
              "name": "External Data Eval",
              "created_at": 1739314509,
              "metadata": {},
            }
    post:
      operationId: updateEval
      parameters:
      - description: The ID of the evaluation to update.
        explode: false
        in: path
        name: eval_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/updateEval_request"
        description: Request to update an evaluation
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Eval"
          description: The updated evaluation
      summary: |
        Update certain properties of an evaluation.
      tags:
      - Evals
      x-oaiMeta:
        name: Update an eval
        group: evals
        returns: "The [Eval](/docs/api-reference/evals/object) object matching the\
          \ updated version."
        path: update
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{"name": "Updated Eval", "metadata": {"description": "Updated description"}}'
            python: |
              from openai import OpenAI
              client = OpenAI()

              updated_eval = client.evals.update(
                "eval_67abd54d9b0081909a86353f6fb9317a",
                name="Updated Eval",
                metadata={"description": "Updated description"}
              )
              print(updated_eval)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const updatedEval = await openai.evals.update(
                "eval_67abd54d9b0081909a86353f6fb9317a",
                {
                  name: "Updated Eval",
                  metadata: { description: "Updated description" }
                }
              );
              console.log(updatedEval);
          response: |
            {
              "object": "eval",
              "id": "eval_67abd54d9b0081909a86353f6fb9317a",
              "data_source_config": {
                "type": "custom",
                "schema": {
                  "type": "object",
                  "properties": {
                    "item": {
                      "type": "object",
                      "properties": {
                        "input": {
                          "type": "string"
                        },
                        "ground_truth": {
                          "type": "string"
                        }
                      },
                      "required": [
                        "input",
                        "ground_truth"
                      ]
                    }
                  },
                  "required": [
                    "item"
                  ]
                }
              },
              "testing_criteria": [
                {
                  "name": "String check",
                  "id": "String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2",
                  "type": "string_check",
                  "input": "{{item.input}}",
                  "reference": "{{item.ground_truth}}",
                  "operation": "eq"
                }
              ],
              "name": "Updated Eval",
              "created_at": 1739314509,
              "metadata": {"description": "Updated description"},
            }
  /evals/{eval_id}/runs:
    get:
      operationId: getEvalRuns
      parameters:
      - description: The ID of the evaluation to retrieve runs for.
        explode: false
        in: path
        name: eval_id
        required: true
        schema:
          type: string
        style: simple
      - description: Identifier for the last run from the previous pagination request.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: Number of runs to retrieve.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: Sort order for runs by timestamp. Use `asc` for ascending order
          or `desc` for descending order. Defaults to `asc`.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: asc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: Filter runs by status. One of `queued` | `in_progress` | `failed`
          | `completed` | `canceled`.
        explode: true
        in: query
        name: status
        required: false
        schema:
          enum:
          - queued
          - in_progress
          - completed
          - canceled
          - failed
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/EvalRunList"
          description: A list of runs for the evaluation
      summary: |
        Get a list of runs for an evaluation.
      tags:
      - Evals
      x-oaiMeta:
        name: Get eval runs
        group: evals
        returns: "A list of [EvalRun](/docs/api-reference/evals/run-object) objects\
          \ matching the specified ID."
        path: get-runs
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/egroup_67abd54d9b0081909a86353f6fb9317a/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              runs = client.evals.runs.list("egroup_67abd54d9b0081909a86353f6fb9317a")
              print(runs)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const runs = await openai.evals.runs.list("egroup_67abd54d9b0081909a86353f6fb9317a");
              console.log(runs);
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "eval.run",
                  "id": "evalrun_67e0c7d31560819090d60c0780591042",
                  "eval_id": "eval_67e0c726d560819083f19a957c4c640b",
                  "report_url": "https://platform.openai.com/evaluations/eval_67e0c726d560819083f19a957c4c640b",
                  "status": "completed",
                  "model": "o3-mini",
                  "name": "bulk_with_negative_examples_o3-mini",
                  "created_at": 1742784467,
                  "result_counts": {
                    "total": 1,
                    "errored": 0,
                    "failed": 0,
                    "passed": 1
                  },
                  "per_model_usage": [
                    {
                      "model_name": "o3-mini",
                      "invocation_count": 1,
                      "prompt_tokens": 563,
                      "completion_tokens": 874,
                      "total_tokens": 1437,
                      "cached_tokens": 0
                    }
                  ],
                  "per_testing_criteria_results": [
                    {
                      "testing_criteria": "Push Notification Summary Grader-1808cd0b-eeec-4e0b-a519-337e79f4f5d1",
                      "passed": 1,
                      "failed": 0
                    }
                  ],
                  "data_source": {
                    "type": "completions",
                    "source": {
                      "type": "file_content",
                      "content": [
                        {
                          "item": {
                            "notifications": "\n- New message from Sarah: \"Can you call me later?\"\n- Your package has been delivered!\n- Flash sale: 20% off electronics for the next 2 hours!\n"
                          }
                        }
                      ]
                    },
                    "input_messages": {
                      "type": "template",
                      "template": [
                        {
                          "type": "message",
                          "role": "developer",
                          "content": {
                            "type": "input_text",
                            "text": "\n\n\n\nYou are a helpful assistant that takes in an array of push notifications and returns a collapsed summary of them.\nThe push notification will be provided as follows:\n<push_notifications>\n...notificationlist...\n</push_notifications>\n\nYou should return just the summary and nothing else.\n\n\nYou should return a summary that is concise and snappy.\n\n\nHere is an example of a good summary:\n<push_notifications>\n- Traffic alert: Accident reported on Main Street.- Package out for delivery: Expected by 5 PM.- New friend suggestion: Connect with Emma.\n</push_notifications>\n<summary>\nTraffic alert, package expected by 5pm, suggestion for new friend (Emily).\n</summary>\n\n\nHere is an example of a bad summary:\n<push_notifications>\n- Traffic alert: Accident reported on Main Street.- Package out for delivery: Expected by 5 PM.- New friend suggestion: Connect with Emma.\n</push_notifications>\n<summary>\nTraffic alert reported on main street. You have a package that will arrive by 5pm, Emily is a new friend suggested for you.\n</summary>\n"
                          }
                        },
                        {
                          "type": "message",
                          "role": "user",
                          "content": {
                            "type": "input_text",
                            "text": "<push_notifications>{{item.notifications}}</push_notifications>"
                          }
                        }
                      ]
                    },
                    "model": "o3-mini",
                    "sampling_params": null
                  },
                  "error": null,
                  "metadata": {}
                }
              ],
              "first_id": "evalrun_67e0c7d31560819090d60c0780591042",
              "last_id": "evalrun_67e0c7d31560819090d60c0780591042",
              "has_more": true
            }
    post:
      operationId: createEvalRun
      parameters:
      - description: The ID of the evaluation to create a run for.
        explode: false
        in: path
        name: eval_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateEvalRunRequest"
        required: true
      responses:
        "201":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/EvalRun"
          description: Successfully created a run for the evaluation
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Error"
          description: "Bad request (for example, missing eval object)"
      summary: |
        Kicks off a new run for a given evaluation, specifying the data source, and what model configuration to use to test. The datasource will be validated against the schema specified in the config of the evaluation.
      tags:
      - Evals
      x-oaiMeta:
        name: Create eval run
        group: evals
        returns: "The [EvalRun](/docs/api-reference/evals/run-object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_67e579652b548190aaa83ada4b125f47/runs \
                -X POST \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{"name":"gpt-4o-mini","data_source":{"type":"completions","input_messages":{"type":"template","template":[{"role":"developer","content":"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"} , {"role":"user","content":"{{item.input}}"}]} ,"sampling_params":{"temperature":1,"max_completions_tokens":2048,"top_p":1,"seed":42},"model":"gpt-4o-mini","source":{"type":"file_content","content":[{"item":{"input":"Tech Company Launches Advanced Artificial Intelligence Platform","ground_truth":"Technology"}}]}}'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.evals.runs.create(
                "eval_67e579652b548190aaa83ada4b125f47",
                name="gpt-4o-mini",
                data_source={
                  "type": "completions",
                  "input_messages": {
                    "type": "template",
                    "template": [
                      {
                        "role": "developer",
                        "content": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
                      },
                      {
                        "role": "user",
                        "content": "{{item.input}}"
                      }
                    ]
                  },
                  "sampling_params": {
                    "temperature": 1,
                    "max_completions_tokens": 2048,
                    "top_p": 1,
                    "seed": 42
                  },
                  "model": "gpt-4o-mini",
                  "source": {
                    "type": "file_content",
                    "content": [
                      {
                        "item": {
                          "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                          "ground_truth": "Technology"
                        }
                      }
                    ]
                  }
                }
              )
              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const run = await openai.evals.runs.create(
                "eval_67e579652b548190aaa83ada4b125f47",
                {
                  name: "gpt-4o-mini",
                  data_source: {
                    type: "completions",
                    input_messages: {
                      type: "template",
                      template: [
                        {
                          role: "developer",
                          content: "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
                        },
                        {
                          role: "user",
                          content: "{{item.input}}"
                        }
                      ]
                    },
                    sampling_params: {
                      temperature: 1,
                      max_completions_tokens: 2048,
                      top_p: 1,
                      seed: 42
                    },
                    model: "gpt-4o-mini",
                    source: {
                      type: "file_content",
                      content: [
                        {
                          item: {
                            input: "Tech Company Launches Advanced Artificial Intelligence Platform",
                            ground_truth: "Technology"
                          }
                        }
                      ]
                    }
                  }
                }
              );
              console.log(run);
          response: |
            {
              "object": "eval.run",
              "id": "evalrun_67e57965b480819094274e3a32235e4c",
              "eval_id": "eval_67e579652b548190aaa83ada4b125f47",
              "report_url": "https://platform.openai.com/evaluations/eval_67e579652b548190aaa83ada4b125f47&run_id=evalrun_67e57965b480819094274e3a32235e4c",
              "status": "queued",
              "model": "gpt-4o-mini",
              "name": "gpt-4o-mini",
              "created_at": 1743092069,
              "result_counts": {
                "total": 0,
                "errored": 0,
                "failed": 0,
                "passed": 0
              },
              "per_model_usage": null,
              "per_testing_criteria_results": null,
              "data_source": {
                "type": "completions",
                "source": {
                  "type": "file_content",
                  "content": [
                    {
                      "item": {
                        "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                        "ground_truth": "Technology"
                      }
                    }
                  ]
                },
                "input_messages": {
                  "type": "template",
                  "template": [
                    {
                      "type": "message",
                      "role": "developer",
                      "content": {
                        "type": "input_text",
                        "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
                      }
                    },
                    {
                      "type": "message",
                      "role": "user",
                      "content": {
                        "type": "input_text",
                        "text": "{{item.input}}"
                      }
                    }
                  ]
                },
                "model": "gpt-4o-mini",
                "sampling_params": {
                  "seed": 42,
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_completions_tokens": 2048
                }
              },
              "error": null,
              "metadata": {}
            }
  /evals/{eval_id}/runs/{run_id}:
    delete:
      operationId: deleteEvalRun
      parameters:
      - description: The ID of the evaluation to delete the run from.
        explode: false
        in: path
        name: eval_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run to delete.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/deleteEvalRun_200_response"
          description: Successfully deleted the eval run
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Error"
          description: Run not found
      summary: |
        Delete an eval run.
      tags:
      - Evals
      x-oaiMeta:
        name: Delete eval run
        group: evals
        returns: An object containing the status of the delete operation.
        path: delete
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_123abc/runs/evalrun_abc456 \
                -X DELETE \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted = client.evals.runs.delete(
                "eval_123abc",
                "evalrun_abc456"
              )
              print(deleted)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const deleted = await openai.evals.runs.delete(
                "eval_123abc",
                "evalrun_abc456"
              );
              console.log(deleted);
          response: |
            {
              "object": "eval.run.deleted",
              "deleted": true,
              "run_id": "evalrun_abc456"
            }
    get:
      operationId: getEvalRun
      parameters:
      - description: The ID of the evaluation to retrieve runs for.
        explode: false
        in: path
        name: eval_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run to retrieve.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/EvalRun"
          description: The evaluation run
      summary: |
        Get an evaluation run by ID.
      tags:
      - Evals
      x-oaiMeta:
        name: Get an eval run
        group: evals
        returns: "The [EvalRun](/docs/api-reference/evals/run-object) object matching\
          \ the specified ID."
        path: get
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.evals.runs.retrieve(
                "eval_67abd54d9b0081909a86353f6fb9317a",
                "evalrun_67abd54d60ec8190832b46859da808f7"
              )
              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const run = await openai.evals.runs.retrieve(
                "evalrun_67abd54d60ec8190832b46859da808f7",
                { eval_id: "eval_67abd54d9b0081909a86353f6fb9317a" }
              );
              console.log(run);
          response: |
            {
              "object": "eval.run",
              "id": "evalrun_67abd54d60ec8190832b46859da808f7",
              "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
              "report_url": "https://platform.openai.com/evaluations/eval_67abd54d9b0081909a86353f6fb9317a?run_id=evalrun_67abd54d60ec8190832b46859da808f7",
              "status": "queued",
              "model": "gpt-4o-mini",
              "name": "gpt-4o-mini",
              "created_at": 1743092069,
              "result_counts": {
                "total": 0,
                "errored": 0,
                "failed": 0,
                "passed": 0
              },
              "per_model_usage": null,
              "per_testing_criteria_results": null,
              "data_source": {
                "type": "completions",
                "source": {
                  "type": "file_content",
                  "content": [
                    {
                      "item": {
                        "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                        "ground_truth": "Technology"
                      }
                    },
                    {
                      "item": {
                        "input": "Central Bank Increases Interest Rates Amid Inflation Concerns",
                        "ground_truth": "Markets"
                      }
                    },
                    {
                      "item": {
                        "input": "International Summit Addresses Climate Change Strategies",
                        "ground_truth": "World"
                      }
                    },
                    {
                      "item": {
                        "input": "Major Retailer Reports Record-Breaking Holiday Sales",
                        "ground_truth": "Business"
                      }
                    },
                    {
                      "item": {
                        "input": "National Team Qualifies for World Championship Finals",
                        "ground_truth": "Sports"
                      }
                    },
                    {
                      "item": {
                        "input": "Stock Markets Rally After Positive Economic Data Released",
                        "ground_truth": "Markets"
                      }
                    },
                    {
                      "item": {
                        "input": "Global Manufacturer Announces Merger with Competitor",
                        "ground_truth": "Business"
                      }
                    },
                    {
                      "item": {
                        "input": "Breakthrough in Renewable Energy Technology Unveiled",
                        "ground_truth": "Technology"
                      }
                    },
                    {
                      "item": {
                        "input": "World Leaders Sign Historic Climate Agreement",
                        "ground_truth": "World"
                      }
                    },
                    {
                      "item": {
                        "input": "Professional Athlete Sets New Record in Championship Event",
                        "ground_truth": "Sports"
                      }
                    },
                    {
                      "item": {
                        "input": "Financial Institutions Adapt to New Regulatory Requirements",
                        "ground_truth": "Business"
                      }
                    },
                    {
                      "item": {
                        "input": "Tech Conference Showcases Advances in Artificial Intelligence",
                        "ground_truth": "Technology"
                      }
                    },
                    {
                      "item": {
                        "input": "Global Markets Respond to Oil Price Fluctuations",
                        "ground_truth": "Markets"
                      }
                    },
                    {
                      "item": {
                        "input": "International Cooperation Strengthened Through New Treaty",
                        "ground_truth": "World"
                      }
                    },
                    {
                      "item": {
                        "input": "Sports League Announces Revised Schedule for Upcoming Season",
                        "ground_truth": "Sports"
                      }
                    }
                  ]
                },
                "input_messages": {
                  "type": "template",
                  "template": [
                    {
                      "type": "message",
                      "role": "developer",
                      "content": {
                        "type": "input_text",
                        "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
                      }
                    },
                    {
                      "type": "message",
                      "role": "user",
                      "content": {
                        "type": "input_text",
                        "text": "{{item.input}}"
                      }
                    }
                  ]
                },
                "model": "gpt-4o-mini",
                "sampling_params": {
                  "seed": 42,
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_completions_tokens": 2048
                }
              },
              "error": null,
              "metadata": {}
            }
    post:
      operationId: cancelEvalRun
      parameters:
      - description: The ID of the evaluation whose run you want to cancel.
        explode: false
        in: path
        name: eval_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run to cancel.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/EvalRun"
          description: The canceled eval run object
      summary: |
        Cancel an ongoing evaluation run.
      tags:
      - Evals
      x-oaiMeta:
        name: Cancel eval run
        group: evals
        returns: "The updated [EvalRun](/docs/api-reference/evals/run-object) object\
          \ reflecting that the run is canceled."
        path: post
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7/cancel \
                -X POST \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              canceled_run = client.evals.runs.cancel(
                "eval_67abd54d9b0081909a86353f6fb9317a",
                "evalrun_67abd54d60ec8190832b46859da808f7"
              )
              print(canceled_run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const canceledRun = await openai.evals.runs.cancel(
                "evalrun_67abd54d60ec8190832b46859da808f7",
                { eval_id: "eval_67abd54d9b0081909a86353f6fb9317a" }
              );
              console.log(canceledRun);
          response: |
            {
              "object": "eval.run",
              "id": "evalrun_67abd54d60ec8190832b46859da808f7",
              "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
              "report_url": "https://platform.openai.com/evaluations/eval_67abd54d9b0081909a86353f6fb9317a?run_id=evalrun_67abd54d60ec8190832b46859da808f7",
              "status": "canceled",
              "model": "gpt-4o-mini",
              "name": "gpt-4o-mini",
              "created_at": 1743092069,
              "result_counts": {
                "total": 0,
                "errored": 0,
                "failed": 0,
                "passed": 0
              },
              "per_model_usage": null,
              "per_testing_criteria_results": null,
              "data_source": {
                "type": "completions",
                "source": {
                  "type": "file_content",
                  "content": [
                    {
                      "item": {
                        "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                        "ground_truth": "Technology"
                      }
                    },
                    {
                      "item": {
                        "input": "Central Bank Increases Interest Rates Amid Inflation Concerns",
                        "ground_truth": "Markets"
                      }
                    },
                    {
                      "item": {
                        "input": "International Summit Addresses Climate Change Strategies",
                        "ground_truth": "World"
                      }
                    },
                    {
                      "item": {
                        "input": "Major Retailer Reports Record-Breaking Holiday Sales",
                        "ground_truth": "Business"
                      }
                    },
                    {
                      "item": {
                        "input": "National Team Qualifies for World Championship Finals",
                        "ground_truth": "Sports"
                      }
                    },
                    {
                      "item": {
                        "input": "Stock Markets Rally After Positive Economic Data Released",
                        "ground_truth": "Markets"
                      }
                    },
                    {
                      "item": {
                        "input": "Global Manufacturer Announces Merger with Competitor",
                        "ground_truth": "Business"
                      }
                    },
                    {
                      "item": {
                        "input": "Breakthrough in Renewable Energy Technology Unveiled",
                        "ground_truth": "Technology"
                      }
                    },
                    {
                      "item": {
                        "input": "World Leaders Sign Historic Climate Agreement",
                        "ground_truth": "World"
                      }
                    },
                    {
                      "item": {
                        "input": "Professional Athlete Sets New Record in Championship Event",
                        "ground_truth": "Sports"
                      }
                    },
                    {
                      "item": {
                        "input": "Financial Institutions Adapt to New Regulatory Requirements",
                        "ground_truth": "Business"
                      }
                    },
                    {
                      "item": {
                        "input": "Tech Conference Showcases Advances in Artificial Intelligence",
                        "ground_truth": "Technology"
                      }
                    },
                    {
                      "item": {
                        "input": "Global Markets Respond to Oil Price Fluctuations",
                        "ground_truth": "Markets"
                      }
                    },
                    {
                      "item": {
                        "input": "International Cooperation Strengthened Through New Treaty",
                        "ground_truth": "World"
                      }
                    },
                    {
                      "item": {
                        "input": "Sports League Announces Revised Schedule for Upcoming Season",
                        "ground_truth": "Sports"
                      }
                    }
                  ]
                },
                "input_messages": {
                  "type": "template",
                  "template": [
                    {
                      "type": "message",
                      "role": "developer",
                      "content": {
                        "type": "input_text",
                        "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
                      }
                    },
                    {
                      "type": "message",
                      "role": "user",
                      "content": {
                        "type": "input_text",
                        "text": "{{item.input}}"
                      }
                    }
                  ]
                },
                "model": "gpt-4o-mini",
                "sampling_params": {
                  "seed": 42,
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_completions_tokens": 2048
                }
              },
              "error": null,
              "metadata": {}
            }
  /evals/{eval_id}/runs/{run_id}/output_items:
    get:
      operationId: getEvalRunOutputItems
      parameters:
      - description: The ID of the evaluation to retrieve runs for.
        explode: false
        in: path
        name: eval_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run to retrieve output items for.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      - description: Identifier for the last output item from the previous pagination
          request.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: Number of output items to retrieve.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Filter output items by status. Use `failed` to filter by failed output
          items or `pass` to filter by passed output items.
        explode: true
        in: query
        name: status
        required: false
        schema:
          enum:
          - fail
          - pass
          type: string
        style: form
      - description: Sort order for output items by timestamp. Use `asc` for ascending
          order or `desc` for descending order. Defaults to `asc`.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: asc
          enum:
          - asc
          - desc
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/EvalRunOutputItemList"
          description: A list of output items for the evaluation run
      summary: |
        Get a list of output items for an evaluation run.
      tags:
      - Evals
      x-oaiMeta:
        name: Get eval run output items
        group: evals
        returns: "A list of [EvalRunOutputItem](/docs/api-reference/evals/run-output-item-object)\
          \ objects matching the specified ID."
        path: get
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/egroup_67abd54d9b0081909a86353f6fb9317a/runs/erun_67abd54d60ec8190832b46859da808f7/output_items \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              output_items = client.evals.runs.output_items.list(
                "egroup_67abd54d9b0081909a86353f6fb9317a",
                "erun_67abd54d60ec8190832b46859da808f7"
              )
              print(output_items)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const outputItems = await openai.evals.runs.outputItems.list(
                "egroup_67abd54d9b0081909a86353f6fb9317a",
                "erun_67abd54d60ec8190832b46859da808f7"
              );
              console.log(outputItems);
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "eval.run.output_item",
                  "id": "outputitem_67e5796c28e081909917bf79f6e6214d",
                  "created_at": 1743092076,
                  "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
                  "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
                  "status": "pass",
                  "datasource_item_id": 5,
                  "datasource_item": {
                    "input": "Stock Markets Rally After Positive Economic Data Released",
                    "ground_truth": "Markets"
                  },
                  "results": [
                    {
                      "name": "String check-a2486074-d803-4445-b431-ad2262e85d47",
                      "sample": null,
                      "passed": true,
                      "score": 1.0
                    }
                  ],
                  "sample": {
                    "input": [
                      {
                        "role": "developer",
                        "content": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n",
                        "tool_call_id": null,
                        "tool_calls": null,
                        "function_call": null
                      },
                      {
                        "role": "user",
                        "content": "Stock Markets Rally After Positive Economic Data Released",
                        "tool_call_id": null,
                        "tool_calls": null,
                        "function_call": null
                      }
                    ],
                    "output": [
                      {
                        "role": "assistant",
                        "content": "Markets",
                        "tool_call_id": null,
                        "tool_calls": null,
                        "function_call": null
                      }
                    ],
                    "finish_reason": "stop",
                    "model": "gpt-4o-mini-2024-07-18",
                    "usage": {
                      "total_tokens": 325,
                      "completion_tokens": 2,
                      "prompt_tokens": 323,
                      "cached_tokens": 0
                    },
                    "error": null,
                    "temperature": 1.0,
                    "max_completion_tokens": 2048,
                    "top_p": 1.0,
                    "seed": 42
                  }
                }
              ],
              "first_id": "outputitem_67e5796c28e081909917bf79f6e6214d",
              "last_id": "outputitem_67e5796c28e081909917bf79f6e6214d",
              "has_more": true
            }
  /evals/{eval_id}/runs/{run_id}/output_items/{output_item_id}:
    get:
      operationId: getEvalRunOutputItem
      parameters:
      - description: The ID of the evaluation to retrieve runs for.
        explode: false
        in: path
        name: eval_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run to retrieve.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the output item to retrieve.
        explode: false
        in: path
        name: output_item_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/EvalRunOutputItem"
          description: The evaluation run output item
      summary: |
        Get an evaluation run output item by ID.
      tags:
      - Evals
      x-oaiMeta:
        name: Get an output item of an eval run
        group: evals
        returns: "The [EvalRunOutputItem](/docs/api-reference/evals/run-output-item-object)\
          \ object matching the specified ID."
        path: get
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7/output_items/outputitem_67abd55eb6548190bb580745d5644a33 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              output_item = client.evals.runs.output_items.retrieve(
                "eval_67abd54d9b0081909a86353f6fb9317a",
                "evalrun_67abd54d60ec8190832b46859da808f7",
                "outputitem_67abd55eb6548190bb580745d5644a33"
              )
              print(output_item)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const outputItem = await openai.evals.runs.outputItems.retrieve(
                "outputitem_67abd55eb6548190bb580745d5644a33",
                {
                  eval_id: "eval_67abd54d9b0081909a86353f6fb9317a",
                  run_id: "evalrun_67abd54d60ec8190832b46859da808f7",
                }
              );
              console.log(outputItem);
          response: |
            {
              "object": "eval.run.output_item",
              "id": "outputitem_67e5796c28e081909917bf79f6e6214d",
              "created_at": 1743092076,
              "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
              "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
              "status": "pass",
              "datasource_item_id": 5,
              "datasource_item": {
                "input": "Stock Markets Rally After Positive Economic Data Released",
                "ground_truth": "Markets"
              },
              "results": [
                {
                  "name": "String check-a2486074-d803-4445-b431-ad2262e85d47",
                  "sample": null,
                  "passed": true,
                  "score": 1.0
                }
              ],
              "sample": {
                "input": [
                  {
                    "role": "developer",
                    "content": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n",
                    "tool_call_id": null,
                    "tool_calls": null,
                    "function_call": null
                  },
                  {
                    "role": "user",
                    "content": "Stock Markets Rally After Positive Economic Data Released",
                    "tool_call_id": null,
                    "tool_calls": null,
                    "function_call": null
                  }
                ],
                "output": [
                  {
                    "role": "assistant",
                    "content": "Markets",
                    "tool_call_id": null,
                    "tool_calls": null,
                    "function_call": null
                  }
                ],
                "finish_reason": "stop",
                "model": "gpt-4o-mini-2024-07-18",
                "usage": {
                  "total_tokens": 325,
                  "completion_tokens": 2,
                  "prompt_tokens": 323,
                  "cached_tokens": 0
                },
                "error": null,
                "temperature": 1.0,
                "max_completion_tokens": 2048,
                "top_p": 1.0,
                "seed": 42
              }
            }
  /files:
    get:
      operationId: listFiles
      parameters:
      - description: Only return files with the given purpose.
        explode: true
        in: query
        name: purpose
        required: false
        schema:
          type: string
        style: form
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 10,000, and the default is 10,000.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 10000
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListFilesResponse"
          description: OK
      summary: Returns a list of files.
      tags:
      - Files
      x-oaiMeta:
        name: List files
        group: files
        returns: "A list of [File](/docs/api-reference/files/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.list()
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.files.list();

                for await (const file of list) {
                  console.log(file);
                }
              }

              main();
          response: |
            {
              "data": [
                {
                  "id": "file-abc123",
                  "object": "file",
                  "bytes": 175,
                  "created_at": 1613677385,
                  "filename": "salesOverview.pdf",
                  "purpose": "assistants",
                },
                {
                  "id": "file-abc123",
                  "object": "file",
                  "bytes": 140,
                  "created_at": 1613779121,
                  "filename": "puppy.jsonl",
                  "purpose": "fine-tune",
                }
              ],
              "object": "list"
            }
    post:
      operationId: createFile
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: "#/components/schemas/CreateFileRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/OpenAIFile"
          description: OK
      summary: |
        Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.

        The Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](/docs/assistants/tools) for details.

        The Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) models.

        The Batch API only supports `.jsonl` files up to 200 MB in size. The input also has a specific required [format](/docs/api-reference/batch/request-input).

        Please [contact us](https://help.openai.com/) if you need to increase these storage limits.
      tags:
      - Files
      x-oaiMeta:
        name: Upload file
        group: files
        returns: "The uploaded [File](/docs/api-reference/files/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F purpose="fine-tune" \
                -F file="@mydata.jsonl"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.create(
                file=open("mydata.jsonl", "rb"),
                purpose="fine-tune"
              )
            node.js: |-
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.create({
                  file: fs.createReadStream("mydata.jsonl"),
                  purpose: "fine-tune",
                });

                console.log(file);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "file",
              "bytes": 120000,
              "created_at": 1677610602,
              "filename": "mydata.jsonl",
              "purpose": "fine-tune",
            }
  /files/{file_id}:
    delete:
      operationId: deleteFile
      parameters:
      - description: The ID of the file to use for this request.
        explode: false
        in: path
        name: file_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteFileResponse"
          description: OK
      summary: Delete a file.
      tags:
      - Files
      x-oaiMeta:
        name: Delete file
        group: files
        returns: Deletion status.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files/file-abc123 \
                -X DELETE \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.delete("file-abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.delete("file-abc123");

                console.log(file);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "file",
              "deleted": true
            }
    get:
      operationId: retrieveFile
      parameters:
      - description: The ID of the file to use for this request.
        explode: false
        in: path
        name: file_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/OpenAIFile"
          description: OK
      summary: Returns information about a specific file.
      tags:
      - Files
      x-oaiMeta:
        name: Retrieve file
        group: files
        returns: "The [File](/docs/api-reference/files/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files/file-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.retrieve("file-abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.retrieve("file-abc123");

                console.log(file);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "file",
              "bytes": 120000,
              "created_at": 1677610602,
              "filename": "mydata.jsonl",
              "purpose": "fine-tune",
            }
  /files/{file_id}/content:
    get:
      operationId: downloadFile
      parameters:
      - description: The ID of the file to use for this request.
        explode: false
        in: path
        name: file_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                type: string
          description: OK
      summary: Returns the contents of the specified file.
      tags:
      - Files
      x-oaiMeta:
        name: Retrieve file content
        group: files
        returns: The file content.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files/file-abc123/content \
                -H "Authorization: Bearer $OPENAI_API_KEY" > file.jsonl
            python: |
              from openai import OpenAI
              client = OpenAI()

              content = client.files.content("file-abc123")
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.content("file-abc123");

                console.log(file);
              }

              main();
  /fine_tuning/alpha/graders/run:
    post:
      operationId: runGrader
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/RunGraderRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunGraderResponse"
          description: OK
      summary: |
        Run a grader.
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: Run grader
        beta: true
        group: graders
        returns: The results from the grader run.
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/fine_tuning/alpha/graders/run \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "grader": {
                    "type": "score_model",
                    "name": "Example score model grader",
                    "input": [
                      {
                        "role": "user",
                        "content": "Score how close the reference answer is to the model answer. Score 1.0 if they are the same and 0.0 if they are different. Return just a floating point score\n\nReference answer: {{item.reference_answer}}\n\nModel answer: {{sample.output_text}}"
                      }
                    ],
                    "model": "gpt-4o-2024-08-06",
                    "sampling_params": {
                      "temperature": 1,
                      "top_p": 1,
                      "seed": 42
                    }
                  },
                  "item": {
                    "reference_answer": "fuzzy wuzzy was a bear"
                  },
                  "model_sample": "fuzzy wuzzy was a bear"
                }'
          response: |
            {
              "reward": 1.0,
              "metadata": {
                "name": "Example score model grader",
                "type": "score_model",
                "errors": {
                  "formula_parse_error": false,
                  "sample_parse_error": false,
                  "truncated_observation_error": false,
                  "unresponsive_reward_error": false,
                  "invalid_variable_error": false,
                  "other_error": false,
                  "python_grader_server_error": false,
                  "python_grader_server_error_type": null,
                  "python_grader_runtime_error": false,
                  "python_grader_runtime_error_details": null,
                  "model_grader_server_error": false,
                  "model_grader_refusal_error": false,
                  "model_grader_parse_error": false,
                  "model_grader_server_error_details": null
                },
                "execution_time": 4.365238428115845,
                "scores": {},
                "token_usage": {
                  "prompt_tokens": 190,
                  "total_tokens": 324,
                  "completion_tokens": 134,
                  "cached_tokens": 0
                },
                "sampled_model_name": "gpt-4o-2024-08-06"
              },
              "sub_rewards": {},
              "model_grader_token_usage_per_model": {
                "gpt-4o-2024-08-06": {
                  "prompt_tokens": 190,
                  "total_tokens": 324,
                  "completion_tokens": 134,
                  "cached_tokens": 0
                }
              }
            }
  /fine_tuning/alpha/graders/validate:
    post:
      operationId: validateGrader
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ValidateGraderRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ValidateGraderResponse"
          description: OK
      summary: |
        Validate a grader.
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: Validate grader
        beta: true
        group: graders
        returns: The validated grader object.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/alpha/graders/validate \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "grader": {
                    "type": "string_check",
                    "name": "Example string check grader",
                    "input": "{{sample.output_text}}",
                    "reference": "{{item.label}}",
                    "operation": "eq"
                  }
                }'
          response: |
            {
              "grader": {
                "type": "string_check",
                "name": "Example string check grader",
                "input": "{{sample.output_text}}",
                "reference": "{{item.label}}",
                "operation": "eq"
              }
            }
  /fine_tuning/checkpoints/{fine_tuned_model_checkpoint}/permissions:
    get:
      operationId: listFineTuningCheckpointPermissions
      parameters:
      - description: |
          The ID of the fine-tuned model checkpoint to get permissions for.
        explode: false
        in: path
        name: fine_tuned_model_checkpoint
        required: true
        schema:
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          type: string
        style: simple
      - description: The ID of the project to get permissions for.
        explode: true
        in: query
        name: project_id
        required: false
        schema:
          type: string
        style: form
      - description: Identifier for the last permission ID from the previous pagination
          request.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: Number of permissions to retrieve.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 10
          type: integer
        style: form
      - description: The order in which to retrieve permissions.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: descending
          enum:
          - ascending
          - descending
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListFineTuningCheckpointPermissionResponse"
          description: OK
      summary: |
        **NOTE:** This endpoint requires an [admin API key](../admin-api-keys).

        Organization owners can use this endpoint to view all permissions for a fine-tuned model checkpoint.
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: List checkpoint permissions
        group: fine-tuning
        returns: "A list of fine-tuned model checkpoint [permission objects](/docs/api-reference/fine-tuning/permission-object)\
          \ for a fine-tuned model checkpoint."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "checkpoint.permission",
                  "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
                  "created_at": 1721764867,
                  "project_id": "proj_abGMw1llN8IrBb6SvvY5A1iH"
                },
                {
                  "object": "checkpoint.permission",
                  "id": "cp_enQCFmOTGj3syEpYVhBRLTSy",
                  "created_at": 1721764800,
                  "project_id": "proj_iqGMw1llN8IrBb6SvvY5A1oF"
                },
              ],
              "first_id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
              "last_id": "cp_enQCFmOTGj3syEpYVhBRLTSy",
              "has_more": false
            }
    post:
      operationId: createFineTuningCheckpointPermission
      parameters:
      - description: |
          The ID of the fine-tuned model checkpoint to create a permission for.
        explode: false
        in: path
        name: fine_tuned_model_checkpoint
        required: true
        schema:
          example: ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateFineTuningCheckpointPermissionRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListFineTuningCheckpointPermissionResponse"
          description: OK
      summary: |
        **NOTE:** Calling this endpoint requires an [admin API key](../admin-api-keys).

        This enables organization owners to share fine-tuned models with other projects in their organization.
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: Create checkpoint permissions
        group: fine-tuning
        returns: "A list of fine-tuned model checkpoint [permission objects](/docs/api-reference/fine-tuning/permission-object)\
          \ for a fine-tuned model checkpoint."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions \
                -H "Authorization: Bearer $OPENAI_API_KEY"
                -d '{"project_ids": ["proj_abGMw1llN8IrBb6SvvY5A1iH"]}'
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "checkpoint.permission",
                  "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
                  "created_at": 1721764867,
                  "project_id": "proj_abGMw1llN8IrBb6SvvY5A1iH"
                }
              ],
              "first_id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
              "last_id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
              "has_more": false
            }
  /fine_tuning/checkpoints/{fine_tuned_model_checkpoint}/permissions/{permission_id}:
    delete:
      operationId: deleteFineTuningCheckpointPermission
      parameters:
      - description: |
          The ID of the fine-tuned model checkpoint to delete a permission for.
        explode: false
        in: path
        name: fine_tuned_model_checkpoint
        required: true
        schema:
          example: ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd
          type: string
        style: simple
      - description: |
          The ID of the fine-tuned model checkpoint permission to delete.
        explode: false
        in: path
        name: permission_id
        required: true
        schema:
          example: cp_zc4Q7MP6XxulcVzj4MZdwsAB
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteFineTuningCheckpointPermissionResponse"
          description: OK
      summary: |
        **NOTE:** This endpoint requires an [admin API key](../admin-api-keys).

        Organization owners can use this endpoint to delete a permission for a fine-tuned model checkpoint.
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: Delete checkpoint permission
        group: fine-tuning
        returns: "The deletion status of the fine-tuned model checkpoint [permission\
          \ object](/docs/api-reference/fine-tuning/permission-object)."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions/cp_zc4Q7MP6XxulcVzj4MZdwsAB \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
              "object": "checkpoint.permission",
              "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
              "deleted": true
            }
  /fine_tuning/jobs:
    get:
      operationId: listPaginatedFineTuningJobs
      parameters:
      - description: Identifier for the last job from the previous pagination request.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: Number of fine-tuning jobs to retrieve.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Optional metadata filter. To filter, use the syntax `metadata[k]=v`. Alternatively, set `metadata=null` to indicate no metadata.
        explode: true
        in: query
        name: metadata
        required: false
        schema:
          additionalProperties:
            type: string
          nullable: true
        style: deepObject
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListPaginatedFineTuningJobsResponse"
          description: OK
      summary: |
        List your organization's fine-tuning jobs
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: List fine-tuning jobs
        group: fine-tuning
        returns: "A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs?limit=2&metadata[key]=value \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.list()
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.fineTuning.jobs.list();

                for await (const fineTune of list) {
                  console.log(fineTune);
                }
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "fine_tuning.job",
                  "id": "ftjob-abc123",
                  "model": "gpt-4o-mini-2024-07-18",
                  "created_at": 1721764800,
                  "fine_tuned_model": null,
                  "organization_id": "org-123",
                  "result_files": [],
                  "status": "queued",
                  "validation_file": null,
                  "training_file": "file-abc123",
                  "metadata": {
                    "key": "value"
                  }
                },
                { ... },
                { ... }
              ], "has_more": true
            }
    post:
      operationId: createFineTuningJob
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateFineTuningJobRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FineTuningJob"
          description: OK
      summary: |
        Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

        Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

        [Learn more about fine-tuning](/docs/guides/model-optimization)
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: Create fine-tuning job
        group: fine-tuning
        returns: "A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-BK7bzQj3FfZFXr7DbL6xJwfo",
                  "model": "gpt-4o-mini"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.create(
                training_file="file-abc123",
                model="gpt-4o-mini"
              )
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.create({
                  training_file: "file-abc123"
                });

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": null,
              "training_file": "file-abc123",
              "method": {
                "type": "supervised",
                "supervised": {
                  "hyperparameters": {
                    "batch_size": "auto",
                    "learning_rate_multiplier": "auto",
                    "n_epochs": "auto",
                  }
                }
              },
              "metadata": null
            }
        - title: Epochs
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-abc123",
                  "model": "gpt-4o-mini",
                  "method": {
                    "type": "supervised",
                    "supervised": {
                      "hyperparameters": {
                        "n_epochs": 2
                      }
                    }
                  }
                }'
            python: |
              from openai import OpenAI
              from openai.types.fine_tuning import SupervisedMethod, SupervisedHyperparameters

              client = OpenAI()

              client.fine_tuning.jobs.create(
                training_file="file-abc123",
                model="gpt-4o-mini",
                method={
                  "type": "supervised",
                  "supervised": SupervisedMethod(
                    hyperparameters=SupervisedHyperparameters(
                      n_epochs=2
                    )
                  )
                }
              )
            node.js: |
              import OpenAI from "openai";
              import { SupervisedMethod, SupervisedHyperparameters } from "openai/resources/fine-tuning/methods";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.create({
                  training_file: "file-abc123",
                  model: "gpt-4o-mini",
                  method: {
                    type: "supervised",
                    supervised: {
                      hyperparameters: {
                        n_epochs: 2
                      }
                    }
                  }
                });

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": null,
              "training_file": "file-abc123",
              "hyperparameters": {
                "batch_size": "auto",
                "learning_rate_multiplier": "auto",
                "n_epochs": 2
              },
              "method": {
                "type": "supervised",
                "supervised": {
                  "hyperparameters": {
                    "batch_size": "auto",
                    "learning_rate_multiplier": "auto",
                    "n_epochs": 2
                  }
                }
              },
              "metadata": null,
              "error": {
                "code": null,
                "message": null,
                "param": null
              },
              "finished_at": null,
              "seed": 683058546,
              "trained_tokens": null,
              "estimated_finish": null,
              "integrations": [],
              "user_provided_suffix": null,
              "usage_metrics": null,
              "shared_with_openai": false
            }
        - title: DPO
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-abc123",
                  "validation_file": "file-abc123",
                  "model": "gpt-4o-mini",
                  "method": {
                    "type": "dpo",
                    "dpo": {
                      "hyperparameters": {
                        "beta": 0.1
                      }
                    }
                  }
                }'
          python: |
            from openai import OpenAI
            from openai.types.fine_tuning import DpoMethod, DpoHyperparameters

            client = OpenAI()

            client.fine_tuning.jobs.create(
              training_file="file-abc",
              validation_file="file-123",
              model="gpt-4o-mini",
              method={
                "type": "dpo",
                "dpo": DpoMethod(
                  hyperparameters=DpoHyperparameters(beta=0.1)
                )
              }
            )
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc",
              "model": "gpt-4o-mini",
              "created_at": 1746130590,
              "fine_tuned_model": null,
              "organization_id": "org-abc",
              "result_files": [],
              "status": "queued",
              "validation_file": "file-123",
              "training_file": "file-abc",
              "method": {
                "type": "dpo",
                "dpo": {
                  "hyperparameters": {
                    "beta": 0.1,
                    "batch_size": "auto",
                    "learning_rate_multiplier": "auto",
                    "n_epochs": "auto"
                  }
                }
              },
              "metadata": null,
              "error": {
                "code": null,
                "message": null,
                "param": null
              },
              "finished_at": null,
              "hyperparameters": null,
              "seed": 1036326793,
              "estimated_finish": null,
              "integrations": [],
              "user_provided_suffix": null,
              "usage_metrics": null,
              "shared_with_openai": false
            }
        - title: Reinforcement
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-abc",
                  "validation_file": "file-123",
                  "model": "o4-mini",
                  "method": {
                    "type": "reinforcement",
                    "reinforcement": {
                      "grader": {
                        "type": "string_check",
                        "name": "Example string check grader",
                        "input": "{{sample.output_text}}",
                        "reference": "{{item.label}}",
                        "operation": "eq"
                      },
                      "hyperparameters": {
                        "reasoning_effort": "medium"
                      }
                    }
                  }
                }'
            python: "from openai import OpenAI\nfrom openai.types.fine_tuning import\
              \ ReinforcementMethod, ReinforcementHyperparameters\nfrom openai.types.graders\
              \ import StringCheckGrader\n\nclient = OpenAI()\n\nclient.fine_tuning.jobs.create(\n\
              \  training_file=\"file-abc\",\n  validation_file=\"file-123\",\n  model=\"\
              o4-mini\",\n  method={\n    \"type\": \"reinforcement\",\n    \"reinforcement\"\
              : ReinforcementMethod(\n      grader=StringCheckGrader(\n        name=\"\
              Example string check grader\",\n        type=\"string_check\",\n   \
              \     input=\"{{item.label}}\",\n        operation=\"eq\",\n       \
              \ reference=\"{{sample.output_text}}\"\n      ),\n      hyperparameters=ReinforcementHyperparameters(\n\
              \          reasoning_effort=\"medium\",\n      )\n    )\n  }, \n  seed=42,\n\
              )\n"
          response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\"\
            ,\n  \"model\": \"o4-mini\",\n  \"created_at\": 1721764800,\n  \"finished_at\"\
            : null,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\"\
            ,\n  \"result_files\": [],\n  \"status\": \"validating_files\",\n  \"\
            validation_file\": \"file-123\",\n  \"training_file\": \"file-abc\",\n\
            \  \"trained_tokens\": null,\n  \"error\": {},\n  \"user_provided_suffix\"\
            : null,\n  \"seed\": 950189191,\n  \"estimated_finish\": null,\n  \"integrations\"\
            : [],\n  \"method\": {\n    \"type\": \"reinforcement\",\n    \"reinforcement\"\
            : {\n      \"hyperparameters\": {\n        \"batch_size\": \"auto\",\n\
            \        \"learning_rate_multiplier\": \"auto\",\n        \"n_epochs\"\
            : \"auto\",\n        \"eval_interval\": \"auto\",\n        \"eval_samples\"\
            : \"auto\",\n        \"compute_multiplier\": \"auto\",\n        \"reasoning_effort\"\
            : \"medium\"\n      },\n      \"grader\": {\n        \"type\": \"string_check\"\
            ,\n        \"name\": \"Example string check grader\",\n        \"input\"\
            : \"{{sample.output_text}}\",\n        \"reference\": \"{{item.label}}\"\
            ,\n        \"operation\": \"eq\"\n      },\n      \"response_format\"\
            : null\n    }\n  },\n  \"metadata\": null,\n  \"usage_metrics\": null,\n\
            \  \"shared_with_openai\": false\n}\n      \n"
        - title: Validation file
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-abc123",
                  "validation_file": "file-abc123",
                  "model": "gpt-4o-mini"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.create(
                training_file="file-abc123",
                validation_file="file-def456",
                model="gpt-4o-mini"
              )
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.create({
                  training_file: "file-abc123",
                  validation_file: "file-abc123"
                });

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": "file-abc123",
              "training_file": "file-abc123",
              "method": {
                "type": "supervised",
                "supervised": {
                  "hyperparameters": {
                    "batch_size": "auto",
                    "learning_rate_multiplier": "auto",
                    "n_epochs": "auto",
                  }
                }
              },
              "metadata": null
            }
        - title: W&B Integration
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-abc123",
                  "validation_file": "file-abc123",
                  "model": "gpt-4o-mini",
                  "integrations": [
                    {
                      "type": "wandb",
                      "wandb": {
                        "project": "my-wandb-project",
                        "name": "ft-run-display-name"
                        "tags": [
                          "first-experiment", "v2"
                        ]
                      }
                    }
                  ]
                }'
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": "file-abc123",
              "training_file": "file-abc123",
              "integrations": [
                {
                  "type": "wandb",
                  "wandb": {
                    "project": "my-wandb-project",
                    "entity": None,
                    "run_id": "ftjob-abc123"
                  }
                }
              ],
              "method": {
                "type": "supervised",
                "supervised": {
                  "hyperparameters": {
                    "batch_size": "auto",
                    "learning_rate_multiplier": "auto",
                    "n_epochs": "auto",
                  }
                }
              },
              "metadata": null
            }
  /fine_tuning/jobs/{fine_tuning_job_id}:
    get:
      operationId: retrieveFineTuningJob
      parameters:
      - description: |
          The ID of the fine-tuning job.
        explode: false
        in: path
        name: fine_tuning_job_id
        required: true
        schema:
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FineTuningJob"
          description: OK
      summary: |
        Get info about a fine-tuning job.

        [Learn more about fine-tuning](/docs/guides/model-optimization)
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: Retrieve fine-tuning job
        group: fine-tuning
        returns: "The [fine-tuning](/docs/api-reference/fine-tuning/object) object\
          \ with the given ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.retrieve("ftjob-abc123")
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.retrieve("ftjob-abc123");

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "davinci-002",
              "created_at": 1692661014,
              "finished_at": 1692661190,
              "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
              "organization_id": "org-123",
              "result_files": [
                  "file-abc123"
              ],
              "status": "succeeded",
              "validation_file": null,
              "training_file": "file-abc123",
              "hyperparameters": {
                  "n_epochs": 4,
                  "batch_size": 1,
                  "learning_rate_multiplier": 1.0
              },
              "trained_tokens": 5768,
              "integrations": [],
              "seed": 0,
              "estimated_finish": 0,
              "method": {
                "type": "supervised",
                "supervised": {
                  "hyperparameters": {
                    "n_epochs": 4,
                    "batch_size": 1,
                    "learning_rate_multiplier": 1.0
                  }
                }
              }
            }
  /fine_tuning/jobs/{fine_tuning_job_id}/cancel:
    post:
      operationId: cancelFineTuningJob
      parameters:
      - description: |
          The ID of the fine-tuning job to cancel.
        explode: false
        in: path
        name: fine_tuning_job_id
        required: true
        schema:
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FineTuningJob"
          description: OK
      summary: |
        Immediately cancel a fine-tune job.
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: Cancel fine-tuning
        group: fine-tuning
        returns: "The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.cancel("ftjob-abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.cancel("ftjob-abc123");

                console.log(fineTune);
              }
              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "cancelled",
              "validation_file": "file-abc123",
              "training_file": "file-abc123"
            }
  /fine_tuning/jobs/{fine_tuning_job_id}/checkpoints:
    get:
      operationId: listFineTuningJobCheckpoints
      parameters:
      - description: |
          The ID of the fine-tuning job to get checkpoints for.
        explode: false
        in: path
        name: fine_tuning_job_id
        required: true
        schema:
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          type: string
        style: simple
      - description: Identifier for the last checkpoint ID from the previous pagination
          request.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: Number of checkpoints to retrieve.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 10
          type: integer
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListFineTuningJobCheckpointsResponse"
          description: OK
      summary: |
        List checkpoints for a fine-tuning job.
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: List fine-tuning checkpoints
        group: fine-tuning
        returns: "A list of fine-tuning [checkpoint objects](/docs/api-reference/fine-tuning/checkpoint-object)\
          \ for a fine-tuning job."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "fine_tuning.job.checkpoint",
                  "id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
                  "created_at": 1721764867,
                  "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000",
                  "metrics": {
                    "full_valid_loss": 0.134,
                    "full_valid_mean_token_accuracy": 0.874
                  },
                  "fine_tuning_job_id": "ftjob-abc123",
                  "step_number": 2000
                },
                {
                  "object": "fine_tuning.job.checkpoint",
                  "id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
                  "created_at": 1721764800,
                  "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000",
                  "metrics": {
                    "full_valid_loss": 0.167,
                    "full_valid_mean_token_accuracy": 0.781
                  },
                  "fine_tuning_job_id": "ftjob-abc123",
                  "step_number": 1000
                }
              ],
              "first_id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
              "last_id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
              "has_more": true
            }
  /fine_tuning/jobs/{fine_tuning_job_id}/events:
    get:
      operationId: listFineTuningEvents
      parameters:
      - description: |
          The ID of the fine-tuning job to get events for.
        explode: false
        in: path
        name: fine_tuning_job_id
        required: true
        schema:
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          type: string
        style: simple
      - description: Identifier for the last event from the previous pagination request.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: Number of events to retrieve.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListFineTuningJobEventsResponse"
          description: OK
      summary: |
        Get status updates for a fine-tuning job.
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: List fine-tuning events
        group: fine-tuning
        returns: A list of fine-tuning event objects.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.list_events(
                fine_tuning_job_id="ftjob-abc123",
                limit=2
              )
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.fineTuning.list_events(id="ftjob-abc123", limit=2);

                for await (const fineTune of list) {
                  console.log(fineTune);
                }
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "fine_tuning.job.event",
                  "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",
                  "created_at": 1721764800,
                  "level": "info",
                  "message": "Fine tuning job successfully completed",
                  "data": null,
                  "type": "message"
                },
                {
                  "object": "fine_tuning.job.event",
                  "id": "ft-event-tyiGuB72evQncpH87xe505Sv",
                  "created_at": 1721764800,
                  "level": "info",
                  "message": "New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel",
                  "data": null,
                  "type": "message"
                }
              ],
              "has_more": true
            }
  /fine_tuning/jobs/{fine_tuning_job_id}/pause:
    post:
      operationId: pauseFineTuningJob
      parameters:
      - description: |
          The ID of the fine-tuning job to pause.
        explode: false
        in: path
        name: fine_tuning_job_id
        required: true
        schema:
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FineTuningJob"
          description: OK
      summary: |
        Pause a fine-tune job.
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: Pause fine-tuning
        group: fine-tuning
        returns: "The paused [fine-tuning](/docs/api-reference/fine-tuning/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/pause \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.pause("ftjob-abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.pause("ftjob-abc123");

                console.log(fineTune);
              }
              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "paused",
              "validation_file": "file-abc123",
              "training_file": "file-abc123"
            }
  /fine_tuning/jobs/{fine_tuning_job_id}/resume:
    post:
      operationId: resumeFineTuningJob
      parameters:
      - description: |
          The ID of the fine-tuning job to resume.
        explode: false
        in: path
        name: fine_tuning_job_id
        required: true
        schema:
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FineTuningJob"
          description: OK
      summary: |
        Resume a fine-tune job.
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: Resume fine-tuning
        group: fine-tuning
        returns: "The resumed [fine-tuning](/docs/api-reference/fine-tuning/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/resume \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.resume("ftjob-abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.resume("ftjob-abc123");

                console.log(fineTune);
              }
              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": "file-abc123",
              "training_file": "file-abc123"
            }
  /images/edits:
    post:
      operationId: createImageEdit
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: "#/components/schemas/CreateImageEditRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImagesResponse"
          description: OK
      summary: Creates an edited or extended image given one or more source images
        and a prompt. This endpoint only supports `gpt-image-1` and `dall-e-2`.
      tags:
      - Images
      x-oaiMeta:
        name: Create image edit
        group: images
        returns: "Returns a list of [image](/docs/api-reference/images/object) objects."
        examples:
          request:
            curl: |
              curl -s -D >(grep -i x-request-id >&2) \
                -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png) \
                -X POST "https://api.openai.com/v1/images/edits" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F "model=gpt-image-1" \
                -F "image[]=@body-lotion.png" \
                -F "image[]=@bath-bomb.png" \
                -F "image[]=@incense-kit.png" \
                -F "image[]=@soap.png" \
                -F 'prompt=Create a lovely gift basket with these four items in it'
            python: "import base64\nfrom openai import OpenAI\nclient = OpenAI()\n\
              \nprompt = \"\"\"\nGenerate a photorealistic image of a gift basket\
              \ on a white background \nlabeled 'Relax & Unwind' with a ribbon and\
              \ handwriting-like font, \ncontaining all the items in the reference\
              \ pictures.\n\"\"\"\n\nresult = client.images.edit(\n    model=\"gpt-image-1\"\
              ,\n    image=[\n        open(\"body-lotion.png\", \"rb\"),\n       \
              \ open(\"bath-bomb.png\", \"rb\"),\n        open(\"incense-kit.png\"\
              , \"rb\"),\n        open(\"soap.png\", \"rb\"),\n    ],\n    prompt=prompt\n\
              )\n\nimage_base64 = result.data[0].b64_json\nimage_bytes = base64.b64decode(image_base64)\n\
              \n# Save the image to a file\nwith open(\"gift-basket.png\", \"wb\"\
              ) as f:\n    f.write(image_bytes)\n"
            node.js: |
              import fs from "fs";
              import OpenAI, { toFile } from "openai";

              const client = new OpenAI();

              const imageFiles = [
                  "bath-bomb.png",
                  "body-lotion.png",
                  "incense-kit.png",
                  "soap.png",
              ];

              const images = await Promise.all(
                  imageFiles.map(async (file) =>
                      await toFile(fs.createReadStream(file), null, {
                          type: "image/png",
                      })
                  ),
              );

              const rsp = await client.images.edit({
                  model: "gpt-image-1",
                  image: images,
                  prompt: "Create a lovely gift basket with these four items in it",
              });

              // Save the image to a file
              const image_base64 = rsp.data[0].b64_json;
              const image_bytes = Buffer.from(image_base64, "base64");
              fs.writeFileSync("basket.png", image_bytes);
          response: |
            {
              "created": 1713833628,
              "data": [
                {
                  "b64_json": "..."
                }
              ],
              "usage": {
                "total_tokens": 100,
                "input_tokens": 50,
                "output_tokens": 50,
                "input_tokens_details": {
                  "text_tokens": 10,
                  "image_tokens": 40
                }
              }
            }
  /images/generations:
    post:
      operationId: createImage
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateImageRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImagesResponse"
          description: OK
      summary: |
        Creates an image given a prompt. [Learn more](/docs/guides/images).
      tags:
      - Images
      x-oaiMeta:
        name: Create image
        group: images
        returns: "Returns a list of [image](/docs/api-reference/images/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/images/generations \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-image-1",
                  "prompt": "A cute baby sea otter",
                  "n": 1,
                  "size": "1024x1024"
                }'
            python: |
              import base64
              from openai import OpenAI
              client = OpenAI()

              img = client.images.generate(
                  model="gpt-image-1",
                  prompt="A cute baby sea otter",
                  n=1,
                  size="1024x1024"
              )

              image_bytes = base64.b64decode(img.data[0].b64_json)
              with open("output.png", "wb") as f:
                  f.write(image_bytes)
            node.js: |
              import OpenAI from "openai";
              import { writeFile } from "fs/promises";

              const client = new OpenAI();

              const img = await client.images.generate({
                model: "gpt-image-1",
                prompt: "A cute baby sea otter",
                n: 1,
                size: "1024x1024"
              });

              const imageBuffer = Buffer.from(img.data[0].b64_json, "base64");
              await writeFile("output.png", imageBuffer);
          response: |
            {
              "created": 1713833628,
              "data": [
                {
                  "b64_json": "..."
                }
              ],
              "usage": {
                "total_tokens": 100,
                "input_tokens": 50,
                "output_tokens": 50,
                "input_tokens_details": {
                  "text_tokens": 10,
                  "image_tokens": 40
                }
              }
            }
  /images/variations:
    post:
      operationId: createImageVariation
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: "#/components/schemas/CreateImageVariationRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImagesResponse"
          description: OK
      summary: Creates a variation of a given image. This endpoint only supports `dall-e-2`.
      tags:
      - Images
      x-oaiMeta:
        name: Create image variation
        group: images
        returns: "Returns a list of [image](/docs/api-reference/images/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/images/variations \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F image="@otter.png" \
                -F n=2 \
                -F size="1024x1024"
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.images.create_variation(
                image=open("image_edit_original.png", "rb"),
                n=2,
                size="1024x1024"
              )
            node.js: |-
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const image = await openai.images.createVariation({
                  image: fs.createReadStream("otter.png"),
                });

                console.log(image.data);
              }
              main();
            csharp: |
              using System;

              using OpenAI.Images;

              ImageClient client = new(
                  model: "dall-e-2",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              GeneratedImage image = client.GenerateImageVariation(imageFilePath: "otter.png");

              Console.WriteLine(image.ImageUri);
          response: |
            {
              "created": 1589478378,
              "data": [
                {
                  "url": "https://..."
                },
                {
                  "url": "https://..."
                }
              ]
            }
  /models:
    get:
      operationId: listModels
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListModelsResponse"
          description: OK
      summary: "Lists the currently available models, and provides basic information\
        \ about each one such as the owner and availability."
      tags:
      - Models
      x-oaiMeta:
        name: List models
        group: models
        returns: "A list of [model](/docs/api-reference/models/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/models \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.models.list()
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.models.list();

                for await (const model of list) {
                  console.log(model);
                }
              }
              main();
            csharp: |
              using System;

              using OpenAI.Models;

              OpenAIModelClient client = new(
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              foreach (var model in client.GetModels().Value)
              {
                  Console.WriteLine(model.Id);
              }
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "model-id-0",
                  "object": "model",
                  "created": 1686935002,
                  "owned_by": "organization-owner"
                },
                {
                  "id": "model-id-1",
                  "object": "model",
                  "created": 1686935002,
                  "owned_by": "organization-owner",
                },
                {
                  "id": "model-id-2",
                  "object": "model",
                  "created": 1686935002,
                  "owned_by": "openai"
                },
              ],
              "object": "list"
            }
  /models/{model}:
    delete:
      operationId: deleteModel
      parameters:
      - description: The model to delete
        explode: false
        in: path
        name: model
        required: true
        schema:
          example: ft:gpt-4o-mini:acemeco:suffix:abc123
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteModelResponse"
          description: OK
      summary: Delete a fine-tuned model. You must have the Owner role in your organization
        to delete a model.
      tags:
      - Models
      x-oaiMeta:
        name: Delete a fine-tuned model
        group: models
        returns: Deletion status.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/models/ft:gpt-4o-mini:acemeco:suffix:abc123 \
                -X DELETE \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.models.delete("ft:gpt-4o-mini:acemeco:suffix:abc123")
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const model = await openai.models.delete(\"\
              ft:gpt-4o-mini:acemeco:suffix:abc123\");\n  \n  console.log(model);\n\
              }\nmain();"
            csharp: |
              using System;
              using System.ClientModel;

              using OpenAI.Models;

              OpenAIModelClient client = new(
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              ClientResult success = client.DeleteModel("ft:gpt-4o-mini:acemeco:suffix:abc123");
              Console.WriteLine(success);
          response: |
            {
              "id": "ft:gpt-4o-mini:acemeco:suffix:abc123",
              "object": "model",
              "deleted": true
            }
    get:
      operationId: retrieveModel
      parameters:
      - description: The ID of the model to use for this request
        explode: false
        in: path
        name: model
        required: true
        schema:
          example: gpt-4o-mini
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Model"
          description: OK
      summary: "Retrieves a model instance, providing basic information about the\
        \ model such as the owner and permissioning."
      tags:
      - Models
      x-oaiMeta:
        name: Retrieve model
        group: models
        returns: "The [model](/docs/api-reference/models/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/models/VAR_chat_model_id \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.models.retrieve("VAR_chat_model_id")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const model = await openai.models.retrieve("VAR_chat_model_id");

                console.log(model);
              }

              main();
            csharp: |
              using System;
              using System.ClientModel;

              using OpenAI.Models;

                OpenAIModelClient client = new(
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              ClientResult<OpenAIModel> model = client.GetModel("babbage-002");
              Console.WriteLine(model.Value.Id);
          response: |
            {
              "id": "VAR_chat_model_id",
              "object": "model",
              "created": 1686935002,
              "owned_by": "openai"
            }
  /moderations:
    post:
      operationId: createModeration
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateModerationRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateModerationResponse"
          description: OK
      summary: |
        Classifies if text and/or image inputs are potentially harmful. Learn
        more in the [moderation guide](/docs/guides/moderation).
      tags:
      - Moderations
      x-oaiMeta:
        name: Create moderation
        group: moderations
        returns: "A [moderation](/docs/api-reference/moderations/object) object."
        examples:
        - title: Single string
          request:
            curl: |
              curl https://api.openai.com/v1/moderations \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "input": "I want to kill them."
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              moderation = client.moderations.create(input="I want to kill them.")
              print(moderation)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const moderation = await openai.moderations.create({ input: "I want to kill them." });

                console.log(moderation);
              }
              main();
            csharp: |
              using System;
              using System.ClientModel;

              using OpenAI.Moderations;

              ModerationClient client = new(
                  model: "omni-moderation-latest",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              ClientResult<ModerationResult> moderation = client.ClassifyText("I want to kill them.");
          response: |
            {
              "id": "modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR",
              "model": "text-moderation-007",
              "results": [
                {
                  "flagged": true,
                  "categories": {
                    "sexual": false,
                    "hate": false,
                    "harassment": true,
                    "self-harm": false,
                    "sexual/minors": false,
                    "hate/threatening": false,
                    "violence/graphic": false,
                    "self-harm/intent": false,
                    "self-harm/instructions": false,
                    "harassment/threatening": true,
                    "violence": true
                  },
                  "category_scores": {
                    "sexual": 0.000011726012417057063,
                    "hate": 0.22706663608551025,
                    "harassment": 0.5215635299682617,
                    "self-harm": 2.227119921371923e-6,
                    "sexual/minors": 7.107352217872176e-8,
                    "hate/threatening": 0.023547329008579254,
                    "violence/graphic": 0.00003391829886822961,
                    "self-harm/intent": 1.646940972932498e-6,
                    "self-harm/instructions": 1.1198755256458526e-9,
                    "harassment/threatening": 0.5694745779037476,
                    "violence": 0.9971134662628174
                  }
                }
              ]
            }
        - title: Image and text
          request:
            curl: |
              curl https://api.openai.com/v1/moderations \
                -X POST \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "omni-moderation-latest",
                  "input": [
                    { "type": "text", "text": "...text to classify goes here..." },
                    {
                      "type": "image_url",
                      "image_url": {
                        "url": "https://example.com/image.png"
                      }
                    }
                  ]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.moderations.create(
                  model="omni-moderation-latest",
                  input=[
                      {"type": "text", "text": "...text to classify goes here..."},
                      {
                          "type": "image_url",
                          "image_url": {
                              "url": "https://example.com/image.png",
                              # can also use base64 encoded image URLs
                              # "url": "data:image/jpeg;base64,abcdefg..."
                          }
                      },
                  ],
              )

              print(response)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              const moderation = await openai.moderations.create({
                  model: "omni-moderation-latest",
                  input: [
                      { type: "text", text: "...text to classify goes here..." },
                      {
                          type: "image_url",
                          image_url: {
                              url: "https://example.com/image.png"
                              // can also use base64 encoded image URLs
                              // url: "data:image/jpeg;base64,abcdefg..."
                          }
                      }
                  ],
              });

              console.log(moderation);
          response: |
            {
              "id": "modr-0d9740456c391e43c445bf0f010940c7",
              "model": "omni-moderation-latest",
              "results": [
                {
                  "flagged": true,
                  "categories": {
                    "harassment": true,
                    "harassment/threatening": true,
                    "sexual": false,
                    "hate": false,
                    "hate/threatening": false,
                    "illicit": false,
                    "illicit/violent": false,
                    "self-harm/intent": false,
                    "self-harm/instructions": false,
                    "self-harm": false,
                    "sexual/minors": false,
                    "violence": true,
                    "violence/graphic": true
                  },
                  "category_scores": {
                    "harassment": 0.8189693396524255,
                    "harassment/threatening": 0.804985420696006,
                    "sexual": 1.573112165348997e-6,
                    "hate": 0.007562942636942845,
                    "hate/threatening": 0.004208854591835476,
                    "illicit": 0.030535955153511665,
                    "illicit/violent": 0.008925306722380033,
                    "self-harm/intent": 0.00023023930975076432,
                    "self-harm/instructions": 0.0002293869201073356,
                    "self-harm": 0.012598046106750154,
                    "sexual/minors": 2.212566909570261e-8,
                    "violence": 0.9999992735124786,
                    "violence/graphic": 0.843064871157054
                  },
                  "category_applied_input_types": {
                    "harassment": [
                      "text"
                    ],
                    "harassment/threatening": [
                      "text"
                    ],
                    "sexual": [
                      "text",
                      "image"
                    ],
                    "hate": [
                      "text"
                    ],
                    "hate/threatening": [
                      "text"
                    ],
                    "illicit": [
                      "text"
                    ],
                    "illicit/violent": [
                      "text"
                    ],
                    "self-harm/intent": [
                      "text",
                      "image"
                    ],
                    "self-harm/instructions": [
                      "text",
                      "image"
                    ],
                    "self-harm": [
                      "text",
                      "image"
                    ],
                    "sexual/minors": [
                      "text"
                    ],
                    "violence": [
                      "text",
                      "image"
                    ],
                    "violence/graphic": [
                      "text",
                      "image"
                    ]
                  }
                }
              ]
            }
  /organization/admin_api_keys:
    get:
      description: Retrieve a paginated list of organization admin API keys.
      operationId: admin-api-keys-list
      parameters:
      - explode: true
        in: query
        name: after
        required: false
        schema:
          description: Return keys with IDs that come after this ID in the pagination
            order.
          type: string
          nullable: true
        style: form
      - explode: true
        in: query
        name: order
        required: false
        schema:
          default: asc
          description: "Order results by creation time, ascending or descending."
          enum:
          - asc
          - desc
          type: string
        style: form
      - explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          description: Maximum number of keys to return.
          type: integer
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ApiKeyList"
          description: A list of organization API keys.
      summary: List organization API keys
      x-oaiMeta:
        name: List all organization and project API keys.
        group: administration
        returns: A list of admin and project API key objects.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/admin_api_keys?after=key_abc&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "organization.admin_api_key",
                  "id": "key_abc",
                  "name": "Main Admin Key",
                  "redacted_value": "sk-admin...def",
                  "created_at": 1711471533,
                  "last_used_at": 1711471534,
                  "owner": {
                    "type": "service_account",
                    "object": "organization.service_account",
                    "id": "sa_456",
                    "name": "My Service Account",
                    "created_at": 1711471533,
                    "role": "member"
                  }
                }
              ],
              "first_id": "key_abc",
              "last_id": "key_abc",
              "has_more": false
            }
    post:
      description: Create a new admin-level API key for the organization.
      operationId: admin-api-keys-create
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/admin_api_keys_create_request"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AdminApiKey"
          description: The newly created admin API key.
      summary: Create an organization admin API key
      x-oaiMeta:
        name: Create admin API key
        group: administration
        returns: "The created [AdminApiKey](/docs/api-reference/admin-api-keys/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/admin_api_keys \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "name": "New Admin Key"
                }'
          response: |
            {
              "object": "organization.admin_api_key",
              "id": "key_xyz",
              "name": "New Admin Key",
              "redacted_value": "sk-admin...xyz",
              "created_at": 1711471533,
              "last_used_at": 1711471534,
              "owner": {
                "type": "user",
                "object": "organization.user",
                "id": "user_123",
                "name": "John Doe",
                "created_at": 1711471533,
                "role": "owner"
              },
              "value": "sk-admin-1234abcd"
            }
  /organization/admin_api_keys/{key_id}:
    delete:
      description: Delete the specified admin API key.
      operationId: admin-api-keys-delete
      parameters:
      - explode: false
        in: path
        name: key_id
        required: true
        schema:
          description: The ID of the API key to be deleted.
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/admin_api_keys_delete_200_response"
          description: Confirmation that the API key was deleted.
      summary: Delete an organization admin API key
      x-oaiMeta:
        name: Delete admin API key
        group: administration
        returns: A confirmation object indicating the key was deleted.
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/admin_api_keys/key_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "id": "key_abc",
              "object": "organization.admin_api_key.deleted",
              "deleted": true
            }
    get:
      description: Get details for a specific organization API key by its ID.
      operationId: admin-api-keys-get
      parameters:
      - explode: false
        in: path
        name: key_id
        required: true
        schema:
          description: The ID of the API key.
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AdminApiKey"
          description: Details of the requested API key.
      summary: Retrieve a single organization API key
      x-oaiMeta:
        name: Retrieve admin API key
        group: administration
        returns: "The requested [AdminApiKey](/docs/api-reference/admin-api-keys/object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/admin_api_keys/key_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "object": "organization.admin_api_key",
              "id": "key_abc",
              "name": "Main Admin Key",
              "redacted_value": "sk-admin...xyz",
              "created_at": 1711471533,
              "last_used_at": 1711471534,
              "owner": {
                "type": "user",
                "object": "organization.user",
                "id": "user_123",
                "name": "John Doe",
                "created_at": 1711471533,
                "role": "owner"
              }
            }
  /organization/audit_logs:
    get:
      operationId: list-audit-logs
      parameters:
      - description: Return only events whose `effective_at` (Unix seconds) is in
          this range.
        explode: true
        in: query
        name: effective_at
        required: false
        schema:
          $ref: "#/components/schemas/list_audit_logs_effective_at_parameter"
        style: form
      - description: Return only events for these projects.
        explode: true
        in: query
        name: "project_ids[]"
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: "Return only events with a `type` in one of these values. For\
          \ example, `project.created`. For all options, see the documentation for\
          \ the [audit log object](/docs/api-reference/audit-logs/object)."
        explode: true
        in: query
        name: "event_types[]"
        required: false
        schema:
          items:
            $ref: "#/components/schemas/AuditLogEventType"
          type: array
        style: form
      - description: "Return only events performed by these actors. Can be a user\
          \ ID, a service account ID, or an api key tracking ID."
        explode: true
        in: query
        name: "actor_ids[]"
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only events performed by users with these emails.
        explode: true
        in: query
        name: "actor_emails[]"
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: "Return only events performed on these targets. For example,\
          \ a project ID updated."
        explode: true
        in: query
        name: "resource_ids[]"
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListAuditLogsResponse"
          description: Audit logs listed successfully.
      summary: List user actions and configuration changes within this organization.
      tags:
      - Audit Logs
      x-oaiMeta:
        name: List audit logs
        group: audit-logs
        returns: "A list of paginated [Audit Log](/docs/api-reference/audit-logs/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/audit_logs \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "list",
                "data": [
                    {
                        "id": "audit_log-xxx_yyyymmdd",
                        "type": "project.archived",
                        "effective_at": 1722461446,
                        "actor": {
                            "type": "api_key",
                            "api_key": {
                                "type": "user",
                                "user": {
                                    "id": "user-xxx",
                                    "email": "user@example.com"
                                }
                            }
                        },
                        "project.archived": {
                            "id": "proj_abc"
                        },
                    },
                    {
                        "id": "audit_log-yyy__20240101",
                        "type": "api_key.updated",
                        "effective_at": 1720804190,
                        "actor": {
                            "type": "session",
                            "session": {
                                "user": {
                                    "id": "user-xxx",
                                    "email": "user@example.com"
                                },
                                "ip_address": "127.0.0.1",
                                "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
                                "ja3": "a497151ce4338a12c4418c44d375173e",
                                "ja4": "q13d0313h3_55b375c5d22e_c7319ce65786",
                                "ip_address_details": {
                                  "country": "US",
                                  "city": "San Francisco",
                                  "region": "California",
                                  "region_code": "CA",
                                  "asn": "1234",
                                  "latitude": "37.77490",
                                  "longitude": "-122.41940"
                                }
                            }
                        },
                        "api_key.updated": {
                            "id": "key_xxxx",
                            "data": {
                                "scopes": ["resource_2.operation_2"]
                            }
                        },
                    }
                ],
                "first_id": "audit_log-xxx__20240101",
                "last_id": "audit_log_yyy__20240101",
                "has_more": true
            }
  /organization/certificates:
    get:
      operationId: listOrganizationCertificates
      parameters:
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListCertificatesResponse"
          description: Certificates listed successfully.
      summary: List uploaded certificates for this organization.
      tags:
      - Certificates
      x-oaiMeta:
        name: List organization certificates
        group: administration
        returns: "A list of [Certificate](/docs/api-reference/certificates/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/certificates \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY"
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "organization.certificate",
                  "id": "cert_abc",
                  "name": "My Example Certificate",
                  "active": true,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
              ],
              "first_id": "cert_abc",
              "last_id": "cert_abc",
              "has_more": false
            }
    post:
      operationId: uploadCertificate
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/UploadCertificateRequest"
        description: The certificate upload payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Certificate"
          description: Certificate uploaded successfully.
      summary: |
        Upload a certificate to the organization. This does **not** automatically activate the certificate.

        Organizations can upload up to 50 certificates.
      tags:
      - Certificates
      x-oaiMeta:
        name: Upload certificate
        group: administration
        returns: "A single [Certificate](/docs/api-reference/certificates/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/certificates \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json" \
              -d '{
                "name": "My Example Certificate",
                "certificate": "-----BEGIN CERTIFICATE-----\\nMIIDeT...\\n-----END CERTIFICATE-----"
              }'
          response: |
            {
              "object": "certificate",
              "id": "cert_abc",
              "name": "My Example Certificate",
              "created_at": 1234567,
              "certificate_details": {
                "valid_at": 12345667,
                "expires_at": 12345678
              }
            }
  /organization/certificates/activate:
    post:
      operationId: activateOrganizationCertificates
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ToggleCertificatesRequest"
        description: The certificate activation payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListCertificatesResponse"
          description: Certificates activated successfully.
      summary: |
        Activate certificates at the organization level.

        You can atomically and idempotently activate up to 10 certificates at a time.
      tags:
      - Certificates
      x-oaiMeta:
        name: Activate certificates for organization
        group: administration
        returns: "A list of [Certificate](/docs/api-reference/certificates/object)\
          \ objects that were activated."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/certificates/activate \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json" \
              -d '{
                "data": ["cert_abc", "cert_def"]
              }'
          response: |
            {
              "object": "organization.certificate.activation",
              "data": [
                {
                  "object": "organization.certificate",
                  "id": "cert_abc",
                  "name": "My Example Certificate",
                  "active": true,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
                {
                  "object": "organization.certificate",
                  "id": "cert_def",
                  "name": "My Example Certificate 2",
                  "active": true,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
              ],
            }
  /organization/certificates/deactivate:
    post:
      operationId: deactivateOrganizationCertificates
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ToggleCertificatesRequest"
        description: The certificate deactivation payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListCertificatesResponse"
          description: Certificates deactivated successfully.
      summary: |
        Deactivate certificates at the organization level.

        You can atomically and idempotently deactivate up to 10 certificates at a time.
      tags:
      - Certificates
      x-oaiMeta:
        name: Deactivate certificates for organization
        group: administration
        returns: "A list of [Certificate](/docs/api-reference/certificates/object)\
          \ objects that were deactivated."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/certificates/deactivate \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json" \
              -d '{
                "data": ["cert_abc", "cert_def"]
              }'
          response: |
            {
              "object": "organization.certificate.deactivation",
              "data": [
                {
                  "object": "organization.certificate",
                  "id": "cert_abc",
                  "name": "My Example Certificate",
                  "active": false,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
                {
                  "object": "organization.certificate",
                  "id": "cert_def",
                  "name": "My Example Certificate 2",
                  "active": false,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
              ],
            }
  /organization/certificates/{certificate_id}:
    delete:
      operationId: deleteCertificate
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteCertificateResponse"
          description: Certificate deleted successfully.
      summary: |
        Delete a certificate from the organization.

        The certificate must be inactive for the organization and all projects.
      tags:
      - Certificates
      x-oaiMeta:
        name: Delete certificate
        group: administration
        returns: A confirmation object indicating the certificate was deleted.
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/certificates/cert_abc \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY"
          response: |
            {
              "object": "certificate.deleted",
              "id": "cert_abc"
            }
    get:
      operationId: getCertificate
      parameters:
      - description: Unique ID of the certificate to retrieve.
        explode: false
        in: path
        name: certificate_id
        required: true
        schema:
          type: string
        style: simple
      - description: A list of additional fields to include in the response. Currently
          the only supported value is `content` to fetch the PEM content of the certificate.
        explode: true
        in: query
        name: include
        required: false
        schema:
          items:
            enum:
            - content
            type: string
          type: array
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Certificate"
          description: Certificate retrieved successfully.
      summary: |
        Get a certificate that has been uploaded to the organization.

        You can get a certificate regardless of whether it is active or not.
      tags:
      - Certificates
      x-oaiMeta:
        name: Get certificate
        group: administration
        returns: "A single [Certificate](/docs/api-reference/certificates/object)\
          \ object."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/certificates/cert_abc?include[]=content" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY"
          response: |
            {
              "object": "certificate",
              "id": "cert_abc",
              "name": "My Example Certificate",
              "created_at": 1234567,
              "certificate_details": {
                "valid_at": 1234567,
                "expires_at": 12345678,
                "content": "-----BEGIN CERTIFICATE-----MIIDeT...-----END CERTIFICATE-----"
              }
            }
    post:
      operationId: modifyCertificate
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ModifyCertificateRequest"
        description: The certificate modification payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Certificate"
          description: Certificate modified successfully.
      summary: |
        Modify a certificate. Note that only the name can be modified.
      tags:
      - Certificates
      x-oaiMeta:
        name: Modify certificate
        group: administration
        returns: "The updated [Certificate](/docs/api-reference/certificates/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/certificates/cert_abc \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json" \
              -d '{
                "name": "Renamed Certificate"
              }'
          response: |
            {
              "object": "certificate",
              "id": "cert_abc",
              "name": "Renamed Certificate",
              "created_at": 1234567,
              "certificate_details": {
                "valid_at": 12345667,
                "expires_at": 12345678
              }
            }
  /organization/costs:
    get:
      operationId: usage-costs
      parameters:
      - description: "Start time (Unix seconds) of the query time range, inclusive."
        explode: true
        in: query
        name: start_time
        required: true
        schema:
          type: integer
        style: form
      - description: "End time (Unix seconds) of the query time range, exclusive."
        explode: true
        in: query
        name: end_time
        required: false
        schema:
          type: integer
        style: form
      - description: "Width of each time bucket in response. Currently only `1d` is\
          \ supported, default to `1d`."
        explode: true
        in: query
        name: bucket_width
        required: false
        schema:
          default: 1d
          enum:
          - 1d
          type: string
        style: form
      - description: Return only costs for these projects.
        explode: true
        in: query
        name: project_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: "Group the costs by the specified fields. Support fields include\
          \ `project_id`, `line_item` and any combination of them."
        explode: true
        in: query
        name: group_by
        required: false
        schema:
          items:
            enum:
            - project_id
            - line_item
            type: string
          type: array
        style: form
      - description: |
          A limit on the number of buckets to be returned. Limit can range between 1 and 180, and the default is 7.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 7
          type: integer
        style: form
      - description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response.
        explode: true
        in: query
        name: page
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/UsageResponse"
          description: Costs data retrieved successfully.
      summary: Get costs details for the organization.
      tags:
      - Usage
      x-oaiMeta:
        name: Costs
        group: usage-costs
        returns: "A list of paginated, time bucketed [Costs](/docs/api-reference/usage/costs_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/costs?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.costs.result",
                                "amount": {
                                    "value": 0.06,
                                    "currency": "usd"
                                },
                                "line_item": null,
                                "project_id": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/invites:
    get:
      operationId: list-invites
      parameters:
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InviteListResponse"
          description: Invites listed successfully.
      summary: Returns a list of invites in the organization.
      tags:
      - Invites
      x-oaiMeta:
        name: List invites
        group: administration
        returns: "A list of [Invite](/docs/api-reference/invite/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "organization.invite",
                  "id": "invite-abc",
                  "email": "user@example.com",
                  "role": "owner",
                  "status": "accepted",
                  "invited_at": 1711471533,
                  "expires_at": 1711471533,
                  "accepted_at": 1711471533
                }
              ],
              "first_id": "invite-abc",
              "last_id": "invite-abc",
              "has_more": false
            }
    post:
      operationId: inviteUser
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/InviteRequest"
        description: The invite request payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Invite"
          description: User invited successfully.
      summary: Create an invite for a user to the organization. The invite must be
        accepted by the user before they have access to the organization.
      tags:
      - Invites
      x-oaiMeta:
        name: Create invite
        group: administration
        returns: "The created [Invite](/docs/api-reference/invite/object) object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/invites \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "email": "anotheruser@example.com",
                    "role": "reader",
                    "projects": [
                      {
                        "id": "project-xyz",
                        "role": "member"
                      },
                      {
                        "id": "project-abc",
                        "role": "owner"
                      }
                    ]
                }'
          response: |
            {
              "object": "organization.invite",
              "id": "invite-def",
              "email": "anotheruser@example.com",
              "role": "reader",
              "status": "pending",
              "invited_at": 1711471533,
              "expires_at": 1711471533,
              "accepted_at": null,
              "projects": [
                {
                  "id": "project-xyz",
                  "role": "member"
                },
                {
                  "id": "project-abc",
                  "role": "owner"
                }
              ]
            }
  /organization/invites/{invite_id}:
    delete:
      operationId: delete-invite
      parameters:
      - description: The ID of the invite to delete.
        explode: false
        in: path
        name: invite_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InviteDeleteResponse"
          description: Invite deleted successfully.
      summary: "Delete an invite. If the invite has already been accepted, it cannot\
        \ be deleted."
      tags:
      - Invites
      x-oaiMeta:
        name: Delete invite
        group: administration
        returns: Confirmation that the invite has been deleted
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.invite.deleted",
                "id": "invite-abc",
                "deleted": true
            }
    get:
      operationId: retrieve-invite
      parameters:
      - description: The ID of the invite to retrieve.
        explode: false
        in: path
        name: invite_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Invite"
          description: Invite retrieved successfully.
      summary: Retrieves an invite.
      tags:
      - Invites
      x-oaiMeta:
        name: Retrieve invite
        group: administration
        returns: "The [Invite](/docs/api-reference/invite/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/invites/invite-abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.invite",
                "id": "invite-abc",
                "email": "user@example.com",
                "role": "owner",
                "status": "accepted",
                "invited_at": 1711471533,
                "expires_at": 1711471533,
                "accepted_at": 1711471533
            }
  /organization/projects:
    get:
      operationId: list-projects
      parameters:
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: If `true` returns all projects including those that have been
          `archived`. Archived projects are not included by default.
        explode: true
        in: query
        name: include_archived
        required: false
        schema:
          default: false
          type: boolean
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProjectListResponse"
          description: Projects listed successfully.
      summary: Returns a list of projects.
      tags:
      - Projects
      x-oaiMeta:
        name: List projects
        group: administration
        returns: "A list of [Project](/docs/api-reference/projects/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "list",
                "data": [
                    {
                        "id": "proj_abc",
                        "object": "organization.project",
                        "name": "Project example",
                        "created_at": 1711471533,
                        "archived_at": null,
                        "status": "active"
                    }
                ],
                "first_id": "proj-abc",
                "last_id": "proj-xyz",
                "has_more": false
            }
    post:
      operationId: create-project
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ProjectCreateRequest"
        description: The project create request payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Project"
          description: Project created successfully.
      summary: "Create a new project in the organization. Projects can be created\
        \ and archived, but cannot be deleted."
      tags:
      - Projects
      x-oaiMeta:
        name: Create project
        group: administration
        returns: "The created [Project](/docs/api-reference/projects/object) object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "name": "Project ABC"
                }'
          response: |
            {
                "id": "proj_abc",
                "object": "organization.project",
                "name": "Project ABC",
                "created_at": 1711471533,
                "archived_at": null,
                "status": "active"
            }
  /organization/projects/{project_id}:
    get:
      operationId: retrieve-project
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Project"
          description: Project retrieved successfully.
      summary: Retrieves a project.
      tags:
      - Projects
      x-oaiMeta:
        name: Retrieve project
        group: administration
        description: Retrieve a project.
        returns: "The [Project](/docs/api-reference/projects/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "id": "proj_abc",
                "object": "organization.project",
                "name": "Project example",
                "created_at": 1711471533,
                "archived_at": null,
                "status": "active"
            }
    post:
      operationId: modify-project
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ProjectUpdateRequest"
        description: The project update request payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Project"
          description: Project updated successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorResponse"
          description: Error response when updating the default project.
      summary: Modifies a project in the organization.
      tags:
      - Projects
      x-oaiMeta:
        name: Modify project
        group: administration
        returns: "The updated [Project](/docs/api-reference/projects/object) object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "name": "Project DEF"
                }'
  /organization/projects/{project_id}/api_keys:
    get:
      operationId: list-project-api-keys
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProjectApiKeyListResponse"
          description: Project API keys listed successfully.
      summary: Returns a list of API keys in the project.
      tags:
      - Projects
      x-oaiMeta:
        name: List project API keys
        group: administration
        returns: "A list of [ProjectApiKey](/docs/api-reference/project-api-keys/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "list",
                "data": [
                    {
                        "object": "organization.project.api_key",
                        "redacted_value": "sk-abc...def",
                        "name": "My API Key",
                        "created_at": 1711471533,
                        "last_used_at": 1711471534,
                        "id": "key_abc",
                        "owner": {
                            "type": "user",
                            "user": {
                                "object": "organization.project.user",
                                "id": "user_abc",
                                "name": "First Last",
                                "email": "user@example.com",
                                "role": "owner",
                                "added_at": 1711471533
                            }
                        }
                    }
                ],
                "first_id": "key_abc",
                "last_id": "key_xyz",
                "has_more": false
            }
  /organization/projects/{project_id}/api_keys/{key_id}:
    delete:
      operationId: delete-project-api-key
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the API key.
        explode: false
        in: path
        name: key_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProjectApiKeyDeleteResponse"
          description: Project API key deleted successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorResponse"
          description: Error response for various conditions.
      summary: Deletes an API key from the project.
      tags:
      - Projects
      x-oaiMeta:
        name: Delete project API key
        group: administration
        returns: Confirmation of the key's deletion or an error if the key belonged
          to a service account
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.project.api_key.deleted",
                "id": "key_abc",
                "deleted": true
            }
    get:
      operationId: retrieve-project-api-key
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the API key.
        explode: false
        in: path
        name: key_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProjectApiKey"
          description: Project API key retrieved successfully.
      summary: Retrieves an API key in the project.
      tags:
      - Projects
      x-oaiMeta:
        name: Retrieve project API key
        group: administration
        returns: "The [ProjectApiKey](/docs/api-reference/project-api-keys/object)\
          \ object matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.project.api_key",
                "redacted_value": "sk-abc...def",
                "name": "My API Key",
                "created_at": 1711471533,
                "last_used_at": 1711471534,
                "id": "key_abc",
                "owner": {
                    "type": "user",
                    "user": {
                        "object": "organization.project.user",
                        "id": "user_abc",
                        "name": "First Last",
                        "email": "user@example.com",
                        "role": "owner",
                        "added_at": 1711471533
                    }
                }
            }
  /organization/projects/{project_id}/archive:
    post:
      operationId: archive-project
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Project"
          description: Project archived successfully.
      summary: Archives a project in the organization. Archived projects cannot be
        used or updated.
      tags:
      - Projects
      x-oaiMeta:
        name: Archive project
        group: administration
        returns: "The archived [Project](/docs/api-reference/projects/object) object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "id": "proj_abc",
                "object": "organization.project",
                "name": "Project DEF",
                "created_at": 1711471533,
                "archived_at": 1711471533,
                "status": "archived"
            }
  /organization/projects/{project_id}/certificates:
    get:
      operationId: listProjectCertificates
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListCertificatesResponse"
          description: Certificates listed successfully.
      summary: List certificates for this project.
      tags:
      - Certificates
      x-oaiMeta:
        name: List project certificates
        group: administration
        returns: "A list of [Certificate](/docs/api-reference/certificates/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/certificates \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY"
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "organization.project.certificate",
                  "id": "cert_abc",
                  "name": "My Example Certificate",
                  "active": true,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
              ],
              "first_id": "cert_abc",
              "last_id": "cert_abc",
              "has_more": false
            }
  /organization/projects/{project_id}/certificates/activate:
    post:
      operationId: activateProjectCertificates
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ToggleCertificatesRequest"
        description: The certificate activation payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListCertificatesResponse"
          description: Certificates activated successfully.
      summary: |
        Activate certificates at the project level.

        You can atomically and idempotently activate up to 10 certificates at a time.
      tags:
      - Certificates
      x-oaiMeta:
        name: Activate certificates for project
        group: administration
        returns: "A list of [Certificate](/docs/api-reference/certificates/object)\
          \ objects that were activated."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/certificates/activate \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json" \
              -d '{
                "data": ["cert_abc", "cert_def"]
              }'
          response: |
            {
              "object": "organization.project.certificate.activation",
              "data": [
                {
                  "object": "organization.project.certificate",
                  "id": "cert_abc",
                  "name": "My Example Certificate",
                  "active": true,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
                {
                  "object": "organization.project.certificate",
                  "id": "cert_def",
                  "name": "My Example Certificate 2",
                  "active": true,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
              ],
            }
  /organization/projects/{project_id}/certificates/deactivate:
    post:
      operationId: deactivateProjectCertificates
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ToggleCertificatesRequest"
        description: The certificate deactivation payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListCertificatesResponse"
          description: Certificates deactivated successfully.
      summary: "Deactivate certificates at the project level. You can atomically and\
        \ \nidempotently deactivate up to 10 certificates at a time.\n"
      tags:
      - Certificates
      x-oaiMeta:
        name: Deactivate certificates for project
        group: administration
        returns: "A list of [Certificate](/docs/api-reference/certificates/object)\
          \ objects that were deactivated."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/certificates/deactivate \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json" \
              -d '{
                "data": ["cert_abc", "cert_def"]
              }'
          response: |
            {
              "object": "organization.project.certificate.deactivation",
              "data": [
                {
                  "object": "organization.project.certificate",
                  "id": "cert_abc",
                  "name": "My Example Certificate",
                  "active": false,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
                {
                  "object": "organization.project.certificate",
                  "id": "cert_def",
                  "name": "My Example Certificate 2",
                  "active": false,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
              ],
            }
  /organization/projects/{project_id}/rate_limits:
    get:
      operationId: list-project-rate-limits
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. The default is 100.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 100
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, beginning with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProjectRateLimitListResponse"
          description: Project rate limits listed successfully.
      summary: Returns the rate limits per model for a project.
      tags:
      - Projects
      x-oaiMeta:
        name: List project rate limits
        group: administration
        returns: "A list of [ProjectRateLimit](/docs/api-reference/project-rate-limits/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/rate_limits?after=rl_xxx&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "list",
                "data": [
                    {
                      "object": "project.rate_limit",
                      "id": "rl-ada",
                      "model": "ada",
                      "max_requests_per_1_minute": 600,
                      "max_tokens_per_1_minute": 150000,
                      "max_images_per_1_minute": 10
                    }
                ],
                "first_id": "rl-ada",
                "last_id": "rl-ada",
                "has_more": false
            }
          error_response: |
            {
                "code": 404,
                "message": "The project {project_id} was not found"
            }
  /organization/projects/{project_id}/rate_limits/{rate_limit_id}:
    post:
      operationId: update-project-rate-limits
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the rate limit.
        explode: false
        in: path
        name: rate_limit_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ProjectRateLimitUpdateRequest"
        description: The project rate limit update request payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProjectRateLimit"
          description: Project rate limit updated successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorResponse"
          description: Error response for various conditions.
      summary: Updates a project rate limit.
      tags:
      - Projects
      x-oaiMeta:
        name: Modify project rate limit
        group: administration
        returns: "The updated [ProjectRateLimit](/docs/api-reference/project-rate-limits/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/rate_limits/rl_xxx \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "max_requests_per_1_minute": 500
                }'
          response: |
            {
                "object": "project.rate_limit",
                "id": "rl-ada",
                "model": "ada",
                "max_requests_per_1_minute": 600,
                "max_tokens_per_1_minute": 150000,
                "max_images_per_1_minute": 10
              }
          error_response: |
            {
                "code": 404,
                "message": "The project {project_id} was not found"
            }
  /organization/projects/{project_id}/service_accounts:
    get:
      operationId: list-project-service-accounts
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProjectServiceAccountListResponse"
          description: Project service accounts listed successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorResponse"
          description: Error response when project is archived.
      summary: Returns a list of service accounts in the project.
      tags:
      - Projects
      x-oaiMeta:
        name: List project service accounts
        group: administration
        returns: "A list of [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "list",
                "data": [
                    {
                        "object": "organization.project.service_account",
                        "id": "svc_acct_abc",
                        "name": "Service Account",
                        "role": "owner",
                        "created_at": 1711471533
                    }
                ],
                "first_id": "svc_acct_abc",
                "last_id": "svc_acct_xyz",
                "has_more": false
            }
    post:
      operationId: create-project-service-account
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ProjectServiceAccountCreateRequest"
        description: The project service account create request payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProjectServiceAccountCreateResponse"
          description: Project service account created successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorResponse"
          description: Error response when project is archived.
      summary: Creates a new service account in the project. This also returns an
        unredacted API key for the service account.
      tags:
      - Projects
      x-oaiMeta:
        name: Create project service account
        group: administration
        returns: "The created [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "name": "Production App"
                }'
          response: |
            {
                "object": "organization.project.service_account",
                "id": "svc_acct_abc",
                "name": "Production App",
                "role": "member",
                "created_at": 1711471533,
                "api_key": {
                    "object": "organization.project.service_account.api_key",
                    "value": "sk-abcdefghijklmnop123",
                    "name": "Secret Key",
                    "created_at": 1711471533,
                    "id": "key_abc"
                }
            }
  /organization/projects/{project_id}/service_accounts/{service_account_id}:
    delete:
      operationId: delete-project-service-account
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the service account.
        explode: false
        in: path
        name: service_account_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProjectServiceAccountDeleteResponse"
          description: Project service account deleted successfully.
      summary: Deletes a service account from the project.
      tags:
      - Projects
      x-oaiMeta:
        name: Delete project service account
        group: administration
        returns: "Confirmation of service account being deleted, or an error in case\
          \ of an archived project, which has no service accounts"
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.project.service_account.deleted",
                "id": "svc_acct_abc",
                "deleted": true
            }
    get:
      operationId: retrieve-project-service-account
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the service account.
        explode: false
        in: path
        name: service_account_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProjectServiceAccount"
          description: Project service account retrieved successfully.
      summary: Retrieves a service account in the project.
      tags:
      - Projects
      x-oaiMeta:
        name: Retrieve project service account
        group: administration
        returns: "The [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object)\
          \ object matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.project.service_account",
                "id": "svc_acct_abc",
                "name": "Service Account",
                "role": "owner",
                "created_at": 1711471533
            }
  /organization/projects/{project_id}/users:
    get:
      operationId: list-project-users
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProjectUserListResponse"
          description: Project users listed successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorResponse"
          description: Error response when project is archived.
      summary: Returns a list of users in the project.
      tags:
      - Projects
      x-oaiMeta:
        name: List project users
        group: administration
        returns: "A list of [ProjectUser](/docs/api-reference/project-users/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "list",
                "data": [
                    {
                        "object": "organization.project.user",
                        "id": "user_abc",
                        "name": "First Last",
                        "email": "user@example.com",
                        "role": "owner",
                        "added_at": 1711471533
                    }
                ],
                "first_id": "user-abc",
                "last_id": "user-xyz",
                "has_more": false
            }
    post:
      operationId: create-project-user
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ProjectUserCreateRequest"
        description: The project user create request payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProjectUser"
          description: User added to project successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorResponse"
          description: Error response for various conditions.
      summary: Adds a user to the project. Users must already be members of the organization
        to be added to a project.
      tags:
      - Projects
      x-oaiMeta:
        name: Create project user
        group: administration
        returns: "The created [ProjectUser](/docs/api-reference/project-users/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "user_id": "user_abc",
                    "role": "member"
                }'
          response: |
            {
                "object": "organization.project.user",
                "id": "user_abc",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
  /organization/projects/{project_id}/users/{user_id}:
    delete:
      operationId: delete-project-user
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the user.
        explode: false
        in: path
        name: user_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProjectUserDeleteResponse"
          description: Project user deleted successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorResponse"
          description: Error response for various conditions.
      summary: Deletes a user from the project.
      tags:
      - Projects
      x-oaiMeta:
        name: Delete project user
        group: administration
        returns: "Confirmation that project has been deleted or an error in case of\
          \ an archived project, which has no users"
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.project.user.deleted",
                "id": "user_abc",
                "deleted": true
            }
    get:
      operationId: retrieve-project-user
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the user.
        explode: false
        in: path
        name: user_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProjectUser"
          description: Project user retrieved successfully.
      summary: Retrieves a user in the project.
      tags:
      - Projects
      x-oaiMeta:
        name: Retrieve project user
        group: administration
        returns: "The [ProjectUser](/docs/api-reference/project-users/object) object\
          \ matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.project.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
    post:
      operationId: modify-project-user
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the user.
        explode: false
        in: path
        name: user_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ProjectUserUpdateRequest"
        description: The project user update request payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProjectUser"
          description: Project user's role updated successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorResponse"
          description: Error response for various conditions.
      summary: Modifies a user's role in the project.
      tags:
      - Projects
      x-oaiMeta:
        name: Modify project user
        group: administration
        returns: "The updated [ProjectUser](/docs/api-reference/project-users/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "role": "owner"
                }'
          response: |
            {
                "object": "organization.project.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
  /organization/usage/audio_speeches:
    get:
      operationId: usage-audio-speeches
      parameters:
      - description: "Start time (Unix seconds) of the query time range, inclusive."
        explode: true
        in: query
        name: start_time
        required: true
        schema:
          type: integer
        style: form
      - description: "End time (Unix seconds) of the query time range, exclusive."
        explode: true
        in: query
        name: end_time
        required: false
        schema:
          type: integer
        style: form
      - description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`."
        explode: true
        in: query
        name: bucket_width
        required: false
        schema:
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
          type: string
        style: form
      - description: Return only usage for these projects.
        explode: true
        in: query
        name: project_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these users.
        explode: true
        in: query
        name: user_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these API keys.
        explode: true
        in: query
        name: api_key_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these models.
        explode: true
        in: query
        name: models
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: "Group the usage data by the specified fields. Support fields\
          \ include `project_id`, `user_id`, `api_key_id`, `model` or any combination\
          \ of them."
        explode: true
        in: query
        name: group_by
        required: false
        schema:
          items:
            enum:
            - project_id
            - user_id
            - api_key_id
            - model
            type: string
          type: array
        style: form
      - description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        explode: true
        in: query
        name: limit
        required: false
        schema:
          type: integer
        style: form
      - description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response.
        explode: true
        in: query
        name: page
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/UsageResponse"
          description: Usage data retrieved successfully.
      summary: Get audio speeches usage details for the organization.
      tags:
      - Usage
      x-oaiMeta:
        name: Audio speeches
        group: usage-audio-speeches
        returns: "A list of paginated, time bucketed [Audio speeches usage](/docs/api-reference/usage/audio_speeches_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.audio_speeches.result",
                                "characters": 45,
                                "num_model_requests": 1,
                                "project_id": null,
                                "user_id": null,
                                "api_key_id": null,
                                "model": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/usage/audio_transcriptions:
    get:
      operationId: usage-audio-transcriptions
      parameters:
      - description: "Start time (Unix seconds) of the query time range, inclusive."
        explode: true
        in: query
        name: start_time
        required: true
        schema:
          type: integer
        style: form
      - description: "End time (Unix seconds) of the query time range, exclusive."
        explode: true
        in: query
        name: end_time
        required: false
        schema:
          type: integer
        style: form
      - description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`."
        explode: true
        in: query
        name: bucket_width
        required: false
        schema:
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
          type: string
        style: form
      - description: Return only usage for these projects.
        explode: true
        in: query
        name: project_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these users.
        explode: true
        in: query
        name: user_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these API keys.
        explode: true
        in: query
        name: api_key_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these models.
        explode: true
        in: query
        name: models
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: "Group the usage data by the specified fields. Support fields\
          \ include `project_id`, `user_id`, `api_key_id`, `model` or any combination\
          \ of them."
        explode: true
        in: query
        name: group_by
        required: false
        schema:
          items:
            enum:
            - project_id
            - user_id
            - api_key_id
            - model
            type: string
          type: array
        style: form
      - description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        explode: true
        in: query
        name: limit
        required: false
        schema:
          type: integer
        style: form
      - description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response.
        explode: true
        in: query
        name: page
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/UsageResponse"
          description: Usage data retrieved successfully.
      summary: Get audio transcriptions usage details for the organization.
      tags:
      - Usage
      x-oaiMeta:
        name: Audio transcriptions
        group: usage-audio-transcriptions
        returns: "A list of paginated, time bucketed [Audio transcriptions usage](/docs/api-reference/usage/audio_transcriptions_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/audio_transcriptions?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.audio_transcriptions.result",
                                "seconds": 20,
                                "num_model_requests": 1,
                                "project_id": null,
                                "user_id": null,
                                "api_key_id": null,
                                "model": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/usage/code_interpreter_sessions:
    get:
      operationId: usage-code-interpreter-sessions
      parameters:
      - description: "Start time (Unix seconds) of the query time range, inclusive."
        explode: true
        in: query
        name: start_time
        required: true
        schema:
          type: integer
        style: form
      - description: "End time (Unix seconds) of the query time range, exclusive."
        explode: true
        in: query
        name: end_time
        required: false
        schema:
          type: integer
        style: form
      - description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`."
        explode: true
        in: query
        name: bucket_width
        required: false
        schema:
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
          type: string
        style: form
      - description: Return only usage for these projects.
        explode: true
        in: query
        name: project_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Group the usage data by the specified fields. Support fields
          include `project_id`.
        explode: true
        in: query
        name: group_by
        required: false
        schema:
          items:
            enum:
            - project_id
            type: string
          type: array
        style: form
      - description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        explode: true
        in: query
        name: limit
        required: false
        schema:
          type: integer
        style: form
      - description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response.
        explode: true
        in: query
        name: page
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/UsageResponse"
          description: Usage data retrieved successfully.
      summary: Get code interpreter sessions usage details for the organization.
      tags:
      - Usage
      x-oaiMeta:
        name: Code interpreter sessions
        group: usage-code-interpreter-sessions
        returns: "A list of paginated, time bucketed [Code interpreter sessions usage](/docs/api-reference/usage/code_interpreter_sessions_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.code_interpreter_sessions.result",
                                "num_sessions": 1,
                                "project_id": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/usage/completions:
    get:
      operationId: usage-completions
      parameters:
      - description: "Start time (Unix seconds) of the query time range, inclusive."
        explode: true
        in: query
        name: start_time
        required: true
        schema:
          type: integer
        style: form
      - description: "End time (Unix seconds) of the query time range, exclusive."
        explode: true
        in: query
        name: end_time
        required: false
        schema:
          type: integer
        style: form
      - description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`."
        explode: true
        in: query
        name: bucket_width
        required: false
        schema:
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
          type: string
        style: form
      - description: Return only usage for these projects.
        explode: true
        in: query
        name: project_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these users.
        explode: true
        in: query
        name: user_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these API keys.
        explode: true
        in: query
        name: api_key_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these models.
        explode: true
        in: query
        name: models
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: |
          If `true`, return batch jobs only. If `false`, return non-batch jobs only. By default, return both.
        explode: true
        in: query
        name: batch
        required: false
        schema:
          type: boolean
        style: form
      - description: "Group the usage data by the specified fields. Support fields\
          \ include `project_id`, `user_id`, `api_key_id`, `model`, `batch` or any\
          \ combination of them."
        explode: true
        in: query
        name: group_by
        required: false
        schema:
          items:
            enum:
            - project_id
            - user_id
            - api_key_id
            - model
            - batch
            type: string
          type: array
        style: form
      - description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        explode: true
        in: query
        name: limit
        required: false
        schema:
          type: integer
        style: form
      - description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response.
        explode: true
        in: query
        name: page
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/UsageResponse"
          description: Usage data retrieved successfully.
      summary: Get completions usage details for the organization.
      tags:
      - Usage
      x-oaiMeta:
        name: Completions
        group: usage-completions
        returns: "A list of paginated, time bucketed [Completions usage](/docs/api-reference/usage/completions_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/completions?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.completions.result",
                                "input_tokens": 1000,
                                "output_tokens": 500,
                                "input_cached_tokens": 800,
                                "input_audio_tokens": 0,
                                "output_audio_tokens": 0,
                                "num_model_requests": 5,
                                "project_id": null,
                                "user_id": null,
                                "api_key_id": null,
                                "model": null,
                                "batch": null
                            }
                        ]
                    }
                ],
                "has_more": true,
                "next_page": "page_AAAAAGdGxdEiJdKOAAAAAGcqsYA="
            }
  /organization/usage/embeddings:
    get:
      operationId: usage-embeddings
      parameters:
      - description: "Start time (Unix seconds) of the query time range, inclusive."
        explode: true
        in: query
        name: start_time
        required: true
        schema:
          type: integer
        style: form
      - description: "End time (Unix seconds) of the query time range, exclusive."
        explode: true
        in: query
        name: end_time
        required: false
        schema:
          type: integer
        style: form
      - description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`."
        explode: true
        in: query
        name: bucket_width
        required: false
        schema:
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
          type: string
        style: form
      - description: Return only usage for these projects.
        explode: true
        in: query
        name: project_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these users.
        explode: true
        in: query
        name: user_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these API keys.
        explode: true
        in: query
        name: api_key_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these models.
        explode: true
        in: query
        name: models
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: "Group the usage data by the specified fields. Support fields\
          \ include `project_id`, `user_id`, `api_key_id`, `model` or any combination\
          \ of them."
        explode: true
        in: query
        name: group_by
        required: false
        schema:
          items:
            enum:
            - project_id
            - user_id
            - api_key_id
            - model
            type: string
          type: array
        style: form
      - description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        explode: true
        in: query
        name: limit
        required: false
        schema:
          type: integer
        style: form
      - description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response.
        explode: true
        in: query
        name: page
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/UsageResponse"
          description: Usage data retrieved successfully.
      summary: Get embeddings usage details for the organization.
      tags:
      - Usage
      x-oaiMeta:
        name: Embeddings
        group: usage-embeddings
        returns: "A list of paginated, time bucketed [Embeddings usage](/docs/api-reference/usage/embeddings_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/embeddings?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.embeddings.result",
                                "input_tokens": 16,
                                "num_model_requests": 2,
                                "project_id": null,
                                "user_id": null,
                                "api_key_id": null,
                                "model": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/usage/images:
    get:
      operationId: usage-images
      parameters:
      - description: "Start time (Unix seconds) of the query time range, inclusive."
        explode: true
        in: query
        name: start_time
        required: true
        schema:
          type: integer
        style: form
      - description: "End time (Unix seconds) of the query time range, exclusive."
        explode: true
        in: query
        name: end_time
        required: false
        schema:
          type: integer
        style: form
      - description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`."
        explode: true
        in: query
        name: bucket_width
        required: false
        schema:
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
          type: string
        style: form
      - description: "Return only usages for these sources. Possible values are `image.generation`,\
          \ `image.edit`, `image.variation` or any combination of them."
        explode: true
        in: query
        name: sources
        required: false
        schema:
          items:
            enum:
            - image.generation
            - image.edit
            - image.variation
            type: string
          type: array
        style: form
      - description: "Return only usages for these image sizes. Possible values are\
          \ `256x256`, `512x512`, `1024x1024`, `1792x1792`, `1024x1792` or any combination\
          \ of them."
        explode: true
        in: query
        name: sizes
        required: false
        schema:
          items:
            enum:
            - 256x256
            - 512x512
            - 1024x1024
            - 1792x1792
            - 1024x1792
            type: string
          type: array
        style: form
      - description: Return only usage for these projects.
        explode: true
        in: query
        name: project_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these users.
        explode: true
        in: query
        name: user_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these API keys.
        explode: true
        in: query
        name: api_key_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these models.
        explode: true
        in: query
        name: models
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: "Group the usage data by the specified fields. Support fields\
          \ include `project_id`, `user_id`, `api_key_id`, `model`, `size`, `source`\
          \ or any combination of them."
        explode: true
        in: query
        name: group_by
        required: false
        schema:
          items:
            enum:
            - project_id
            - user_id
            - api_key_id
            - model
            - size
            - source
            type: string
          type: array
        style: form
      - description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        explode: true
        in: query
        name: limit
        required: false
        schema:
          type: integer
        style: form
      - description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response.
        explode: true
        in: query
        name: page
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/UsageResponse"
          description: Usage data retrieved successfully.
      summary: Get images usage details for the organization.
      tags:
      - Usage
      x-oaiMeta:
        name: Images
        group: usage-images
        returns: "A list of paginated, time bucketed [Images usage](/docs/api-reference/usage/images_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/images?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.images.result",
                                "images": 2,
                                "num_model_requests": 2,
                                "size": null,
                                "source": null,
                                "project_id": null,
                                "user_id": null,
                                "api_key_id": null,
                                "model": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/usage/moderations:
    get:
      operationId: usage-moderations
      parameters:
      - description: "Start time (Unix seconds) of the query time range, inclusive."
        explode: true
        in: query
        name: start_time
        required: true
        schema:
          type: integer
        style: form
      - description: "End time (Unix seconds) of the query time range, exclusive."
        explode: true
        in: query
        name: end_time
        required: false
        schema:
          type: integer
        style: form
      - description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`."
        explode: true
        in: query
        name: bucket_width
        required: false
        schema:
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
          type: string
        style: form
      - description: Return only usage for these projects.
        explode: true
        in: query
        name: project_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these users.
        explode: true
        in: query
        name: user_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these API keys.
        explode: true
        in: query
        name: api_key_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only usage for these models.
        explode: true
        in: query
        name: models
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: "Group the usage data by the specified fields. Support fields\
          \ include `project_id`, `user_id`, `api_key_id`, `model` or any combination\
          \ of them."
        explode: true
        in: query
        name: group_by
        required: false
        schema:
          items:
            enum:
            - project_id
            - user_id
            - api_key_id
            - model
            type: string
          type: array
        style: form
      - description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        explode: true
        in: query
        name: limit
        required: false
        schema:
          type: integer
        style: form
      - description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response.
        explode: true
        in: query
        name: page
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/UsageResponse"
          description: Usage data retrieved successfully.
      summary: Get moderations usage details for the organization.
      tags:
      - Usage
      x-oaiMeta:
        name: Moderations
        group: usage-moderations
        returns: "A list of paginated, time bucketed [Moderations usage](/docs/api-reference/usage/moderations_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/moderations?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.moderations.result",
                                "input_tokens": 16,
                                "num_model_requests": 2,
                                "project_id": null,
                                "user_id": null,
                                "api_key_id": null,
                                "model": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/usage/vector_stores:
    get:
      operationId: usage-vector-stores
      parameters:
      - description: "Start time (Unix seconds) of the query time range, inclusive."
        explode: true
        in: query
        name: start_time
        required: true
        schema:
          type: integer
        style: form
      - description: "End time (Unix seconds) of the query time range, exclusive."
        explode: true
        in: query
        name: end_time
        required: false
        schema:
          type: integer
        style: form
      - description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`."
        explode: true
        in: query
        name: bucket_width
        required: false
        schema:
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
          type: string
        style: form
      - description: Return only usage for these projects.
        explode: true
        in: query
        name: project_ids
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Group the usage data by the specified fields. Support fields
          include `project_id`.
        explode: true
        in: query
        name: group_by
        required: false
        schema:
          items:
            enum:
            - project_id
            type: string
          type: array
        style: form
      - description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        explode: true
        in: query
        name: limit
        required: false
        schema:
          type: integer
        style: form
      - description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response.
        explode: true
        in: query
        name: page
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/UsageResponse"
          description: Usage data retrieved successfully.
      summary: Get vector stores usage details for the organization.
      tags:
      - Usage
      x-oaiMeta:
        name: Vector stores
        group: usage-vector-stores
        returns: "A list of paginated, time bucketed [Vector stores usage](/docs/api-reference/usage/vector_stores_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/vector_stores?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.vector_stores.result",
                                "usage_bytes": 1024,
                                "project_id": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/users:
    get:
      operationId: list-users
      parameters:
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: Filter by the email address of users.
        explode: true
        in: query
        name: emails
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/UserListResponse"
          description: Users listed successfully.
      summary: Lists all of the users in the organization.
      tags:
      - Users
      x-oaiMeta:
        name: List users
        group: administration
        returns: "A list of [User](/docs/api-reference/users/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "list",
                "data": [
                    {
                        "object": "organization.user",
                        "id": "user_abc",
                        "name": "First Last",
                        "email": "user@example.com",
                        "role": "owner",
                        "added_at": 1711471533
                    }
                ],
                "first_id": "user-abc",
                "last_id": "user-xyz",
                "has_more": false
            }
  /organization/users/{user_id}:
    delete:
      operationId: delete-user
      parameters:
      - description: The ID of the user.
        explode: false
        in: path
        name: user_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/UserDeleteResponse"
          description: User deleted successfully.
      summary: Deletes a user from the organization.
      tags:
      - Users
      x-oaiMeta:
        name: Delete user
        group: administration
        returns: Confirmation of the deleted user
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.user.deleted",
                "id": "user_abc",
                "deleted": true
            }
    get:
      operationId: retrieve-user
      parameters:
      - description: The ID of the user.
        explode: false
        in: path
        name: user_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/User"
          description: User retrieved successfully.
      summary: Retrieves a user by their identifier.
      tags:
      - Users
      x-oaiMeta:
        name: Retrieve user
        group: administration
        returns: "The [User](/docs/api-reference/users/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
    post:
      operationId: modify-user
      parameters:
      - description: The ID of the user.
        explode: false
        in: path
        name: user_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/UserRoleUpdateRequest"
        description: The new user role to modify. This must be one of `owner` or `member`.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/User"
          description: User role updated successfully.
      summary: Modifies a user's role in the organization.
      tags:
      - Users
      x-oaiMeta:
        name: Modify user
        group: administration
        returns: "The updated [User](/docs/api-reference/users/object) object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "role": "owner"
                }'
          response: |
            {
                "object": "organization.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
  /realtime/sessions:
    post:
      operationId: create-realtime-session
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/RealtimeSessionCreateRequest"
        description: Create an ephemeral API key with the given session configuration.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RealtimeSessionCreateResponse"
          description: Session created successfully.
      summary: |
        Create an ephemeral API token for use in client-side applications with the
        Realtime API. Can be configured with the same session parameters as the
        `session.update` client event.

        It responds with a session object, plus a `client_secret` key which contains
        a usable ephemeral API token that can be used to authenticate browser clients
        for the Realtime API.
      tags:
      - Realtime
      x-oaiMeta:
        name: Create session
        group: realtime
        returns: "The created Realtime session object, plus an ephemeral key"
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/realtime/sessions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "model": "gpt-4o-realtime-preview",
                  "modalities": ["audio", "text"],
                  "instructions": "You are a friendly assistant."
                }'
          response: "{\n  \"id\": \"sess_001\",\n  \"object\": \"realtime.session\"\
            ,\n  \"model\": \"gpt-4o-realtime-preview\",\n  \"modalities\": [\"audio\"\
            , \"text\"],\n  \"instructions\": \"You are a friendly assistant.\",\n\
            \  \"voice\": \"alloy\",\n  \"input_audio_format\": \"pcm16\",\n  \"output_audio_format\"\
            : \"pcm16\",\n  \"input_audio_transcription\": {\n      \"model\": \"\
            whisper-1\"\n  },\n  \"turn_detection\": null,\n  \"tools\": [],\n  \"\
            tool_choice\": \"none\",\n  \"temperature\": 0.7,\n  \"max_response_output_tokens\"\
            : 200,\n  \"speed\": 1.1,\n  \"tracing\": \"auto\",\n  \"client_secret\"\
            : {\n    \"value\": \"ek_abc123\", \n    \"expires_at\": 1234567890\n\
            \  }\n}\n"
  /realtime/transcription_sessions:
    post:
      operationId: create-realtime-transcription-session
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/RealtimeTranscriptionSessionCreateRequest"
        description: Create an ephemeral API key with the given session configuration.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RealtimeTranscriptionSessionCreateResponse"
          description: Session created successfully.
      summary: "Create an ephemeral API token for use in client-side applications\
        \ with the\nRealtime API specifically for realtime transcriptions. \nCan be\
        \ configured with the same session parameters as the `transcription_session.update`\
        \ client event.\n\nIt responds with a session object, plus a `client_secret`\
        \ key which contains\na usable ephemeral API token that can be used to authenticate\
        \ browser clients\nfor the Realtime API.\n"
      tags:
      - Realtime
      x-oaiMeta:
        name: Create transcription session
        group: realtime
        returns: "The created [Realtime transcription session object](/docs/api-reference/realtime-sessions/transcription_session_object),\
          \ plus an ephemeral key"
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/realtime/transcription_sessions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{}'
          response: |
            {
              "id": "sess_BBwZc7cFV3XizEyKGDCGL",
              "object": "realtime.transcription_session",
              "modalities": ["audio", "text"],
              "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 200
              },
              "input_audio_format": "pcm16",
              "input_audio_transcription": {
                "model": "gpt-4o-transcribe",
                "language": null,
                "prompt": ""
              },
              "client_secret": null
            }
  /responses:
    post:
      operationId: createResponse
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateResponse"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Response"
            text/event-stream:
              schema:
                $ref: "#/components/schemas/ResponseStreamEvent"
          description: OK
      summary: |
        Creates a model response. Provide [text](/docs/guides/text) or
        [image](/docs/guides/images) inputs to generate [text](/docs/guides/text)
        or [JSON](/docs/guides/structured-outputs) outputs. Have the model call
        your own [custom code](/docs/guides/function-calling) or use built-in
        [tools](/docs/guides/tools) like [web search](/docs/guides/tools-web-search)
        or [file search](/docs/guides/tools-file-search) to use your own data
        as input for the model's response.
      tags:
      - Responses
      x-oaiMeta:
        name: Create a model response
        group: responses
        returns: |
          Returns a [Response](/docs/api-reference/responses/object) object.
        path: create
        examples:
        - title: Text input
          request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4.1",
                  "input": "Tell me a three sentence bedtime story about a unicorn."
                }'
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "gpt-4.1",
                  input: "Tell me a three sentence bedtime story about a unicorn."
              });

              console.log(response);
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.responses.create(
                model="gpt-4.1",
                input="Tell me a three sentence bedtime story about a unicorn."
              )

              print(response)
            csharp: |
              using System;
              using OpenAI.Responses;

              OpenAIResponseClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              OpenAIResponse response = client.CreateResponse("Tell me a three sentence bedtime story about a unicorn.");

              Console.WriteLine(response.GetOutputText());
          response: |
            {
              "id": "resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b",
              "object": "response",
              "created_at": 1741476542,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4.1-2025-04-14",
              "output": [
                {
                  "type": "message",
                  "id": "msg_67ccd2bf17f0819081ff3bb2cf6508e60bb6a6b452d3795b",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "In a peaceful grove beneath a silver moon, a unicorn named Lumina discovered a hidden pool that reflected the stars. As she dipped her horn into the water, the pool began to shimmer, revealing a pathway to a magical realm of endless night skies. Filled with wonder, Lumina whispered a wish for all who dream to find their own hidden magic, and as she glanced back, her hoofprints sparkled like stardust.",
                      "annotations": []
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 36,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 87,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 123
              },
              "user": null,
              "metadata": {}
            }
        - title: Image input
          request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4.1",
                  "input": [
                    {
                      "role": "user",
                      "content": [
                        {"type": "input_text", "text": "what is in this image?"},
                        {
                          "type": "input_image",
                          "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                        }
                      ]
                    }
                  ]
                }'
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "gpt-4.1",
                  input: [
                      {
                          role: "user",
                          content: [
                              { type: "input_text", text: "what is in this image?" },
                              {
                                  type: "input_image",
                                  image_url:
                                      "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                              },
                          ],
                      },
                  ],
              });

              console.log(response);
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.responses.create(
                  model="gpt-4.1",
                  input=[
                      {
                          "role": "user",
                          "content": [
                              { "type": "input_text", "text": "what is in this image?" },
                              {
                                  "type": "input_image",
                                  "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                              }
                          ]
                      }
                  ]
              )

              print(response)
            csharp: |
              using System;
              using System.Collections.Generic;

              using OpenAI.Responses;

              OpenAIResponseClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              List<ResponseItem> inputItems =
              [
                  ResponseItem.CreateUserMessageItem(
                      [
                          ResponseContentPart.CreateInputTextPart("What is in this image?"),
                          ResponseContentPart.CreateInputImagePart(new Uri("https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"))
                      ]
                  )
              ];

              OpenAIResponse response = client.CreateResponse(inputItems);

              Console.WriteLine(response.GetOutputText());
          response: |
            {
              "id": "resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41",
              "object": "response",
              "created_at": 1741476777,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4.1-2025-04-14",
              "output": [
                {
                  "type": "message",
                  "id": "msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "The image depicts a scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue sky with some clouds. The setting suggests a peaceful natural area, possibly a park or nature reserve. There are trees and shrubs in the background.",
                      "annotations": []
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 328,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 52,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 380
              },
              "user": null,
              "metadata": {}
            }
        - title: Web search
          request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4.1",
                  "tools": [{ "type": "web_search_preview" }],
                  "input": "What was a positive news story from today?"
                }'
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "gpt-4.1",
                  tools: [{ type: "web_search_preview" }],
                  input: "What was a positive news story from today?",
              });

              console.log(response);
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.responses.create(
                  model="gpt-4.1",
                  tools=[{ "type": "web_search_preview" }],
                  input="What was a positive news story from today?",
              )

              print(response)
            csharp: |
              using System;

              using OpenAI.Responses;

              OpenAIResponseClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              string userInputText = "What was a positive news story from today?";

              ResponseCreationOptions options = new()
              {
                  Tools =
                  {
                      ResponseTool.CreateWebSearchTool()
                  },
              };

              OpenAIResponse response = client.CreateResponse(userInputText, options);

              Console.WriteLine(response.GetOutputText());
          response: |
            {
              "id": "resp_67ccf18ef5fc8190b16dbee19bc54e5f087bb177ab789d5c",
              "object": "response",
              "created_at": 1741484430,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4.1-2025-04-14",
              "output": [
                {
                  "type": "web_search_call",
                  "id": "ws_67ccf18f64008190a39b619f4c8455ef087bb177ab789d5c",
                  "status": "completed"
                },
                {
                  "type": "message",
                  "id": "msg_67ccf190ca3881909d433c50b1f6357e087bb177ab789d5c",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "As of today, March 9, 2025, one notable positive news story...",
                      "annotations": [
                        {
                          "type": "url_citation",
                          "start_index": 442,
                          "end_index": 557,
                          "url": "https://.../?utm_source=chatgpt.com",
                          "title": "..."
                        },
                        {
                          "type": "url_citation",
                          "start_index": 962,
                          "end_index": 1077,
                          "url": "https://.../?utm_source=chatgpt.com",
                          "title": "..."
                        },
                        {
                          "type": "url_citation",
                          "start_index": 1336,
                          "end_index": 1451,
                          "url": "https://.../?utm_source=chatgpt.com",
                          "title": "..."
                        }
                      ]
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [
                {
                  "type": "web_search_preview",
                  "domains": [],
                  "search_context_size": "medium",
                  "user_location": {
                    "type": "approximate",
                    "city": null,
                    "country": "US",
                    "region": null,
                    "timezone": null
                  }
                }
              ],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 328,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 356,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 684
              },
              "user": null,
              "metadata": {}
            }
        - title: File search
          request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4.1",
                  "tools": [{
                    "type": "file_search",
                    "vector_store_ids": ["vs_1234567890"],
                    "max_num_results": 20
                  }],
                  "input": "What are the attributes of an ancient brown dragon?"
                }'
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "gpt-4.1",
                  tools: [{
                    type: "file_search",
                    vector_store_ids: ["vs_1234567890"],
                    max_num_results: 20
                  }],
                  input: "What are the attributes of an ancient brown dragon?",
              });

              console.log(response);
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.responses.create(
                  model="gpt-4.1",
                  tools=[{
                    "type": "file_search",
                    "vector_store_ids": ["vs_1234567890"],
                    "max_num_results": 20
                  }],
                  input="What are the attributes of an ancient brown dragon?",
              )

              print(response)
            csharp: |
              using System;

              using OpenAI.Responses;

              OpenAIResponseClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              string userInputText = "What are the attributes of an ancient brown dragon?";

              ResponseCreationOptions options = new()
              {
                  Tools =
                  {
                      ResponseTool.CreateFileSearchTool(
                          vectorStoreIds: ["vs_1234567890"],
                          maxResultCount: 20
                      )
                  },
              };

              OpenAIResponse response = client.CreateResponse(userInputText, options);

              Console.WriteLine(response.GetOutputText());
          response: "{\n  \"id\": \"resp_67ccf4c55fc48190b71bd0463ad3306d09504fb6872380d7\"\
            ,\n  \"object\": \"response\",\n  \"created_at\": 1741485253,\n  \"status\"\
            : \"completed\",\n  \"error\": null,\n  \"incomplete_details\": null,\n\
            \  \"instructions\": null,\n  \"max_output_tokens\": null,\n  \"model\"\
            : \"gpt-4.1-2025-04-14\",\n  \"output\": [\n    {\n      \"type\": \"\
            file_search_call\",\n      \"id\": \"fs_67ccf4c63cd08190887ef6464ba5681609504fb6872380d7\"\
            ,\n      \"status\": \"completed\",\n      \"queries\": [\n        \"\
            attributes of an ancient brown dragon\"\n      ],\n      \"results\":\
            \ null\n    },\n    {\n      \"type\": \"message\",\n      \"id\": \"\
            msg_67ccf4c93e5c81909d595b369351a9d309504fb6872380d7\",\n      \"status\"\
            : \"completed\",\n      \"role\": \"assistant\",\n      \"content\": [\n\
            \        {\n          \"type\": \"output_text\",\n          \"text\":\
            \ \"The attributes of an ancient brown dragon include...\",\n        \
            \  \"annotations\": [\n            {\n              \"type\": \"file_citation\"\
            ,\n              \"index\": 320,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 576,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 815,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 815,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 1030,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 1030,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 1156,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 1225,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            }\n      \
            \    ]\n        }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\": true,\n\
            \  \"previous_response_id\": null,\n  \"reasoning\": {\n    \"effort\"\
            : null,\n    \"summary\": null\n  },\n  \"store\": true,\n  \"temperature\"\
            : 1.0,\n  \"text\": {\n    \"format\": {\n      \"type\": \"text\"\n \
            \   }\n  },\n  \"tool_choice\": \"auto\",\n  \"tools\": [\n    {\n   \
            \   \"type\": \"file_search\",\n      \"filters\": null,\n      \"max_num_results\"\
            : 20,\n      \"ranking_options\": {\n        \"ranker\": \"auto\",\n \
            \       \"score_threshold\": 0.0\n      },\n      \"vector_store_ids\"\
            : [\n        \"vs_1234567890\"\n      ]\n    }\n  ],\n  \"top_p\": 1.0,\n\
            \  \"truncation\": \"disabled\",\n  \"usage\": {\n    \"input_tokens\"\
            : 18307,\n    \"input_tokens_details\": {\n      \"cached_tokens\": 0\n\
            \    },\n    \"output_tokens\": 348,\n    \"output_tokens_details\": {\n\
            \      \"reasoning_tokens\": 0\n    },\n    \"total_tokens\": 18655\n\
            \  },\n  \"user\": null,\n  \"metadata\": {}\n}      \n"
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4.1",
                  "instructions": "You are a helpful assistant.",
                  "input": "Hello!",
                  "stream": true
                }'
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.responses.create(
                model="gpt-4.1",
                instructions="You are a helpful assistant.",
                input="Hello!",
                stream=True
              )

              for event in response:
                print(event)
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "gpt-4.1",
                  instructions: "You are a helpful assistant.",
                  input: "Hello!",
                  stream: true,
              });

              for await (const event of response) {
                  console.log(event);
              }
            csharp: |
              using System;
              using System.ClientModel;
              using System.Threading.Tasks;

              using OpenAI.Responses;

              OpenAIResponseClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              string userInputText = "Hello!";

              ResponseCreationOptions options = new()
              {
                  Instructions = "You are a helpful assistant.",
              };

              AsyncCollectionResult<StreamingResponseUpdate> responseUpdates = client.CreateResponseStreamingAsync(userInputText, options);

              await foreach (StreamingResponseUpdate responseUpdate in responseUpdates)
              {
                  if (responseUpdate is StreamingResponseOutputTextDeltaUpdate outputTextDeltaUpdate)
                  {
                      Console.Write(outputTextDeltaUpdate.Delta);
                  }
              }
          response: |
            event: response.created
            data: {"type":"response.created","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"in_progress","error":null,"incomplete_details":null,"instructions":"You are a helpful assistant.","max_output_tokens":null,"model":"gpt-4.1-2025-04-14","output":[],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":null,"user":null,"metadata":{}}}

            event: response.in_progress
            data: {"type":"response.in_progress","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"in_progress","error":null,"incomplete_details":null,"instructions":"You are a helpful assistant.","max_output_tokens":null,"model":"gpt-4.1-2025-04-14","output":[],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":null,"user":null,"metadata":{}}}

            event: response.output_item.added
            data: {"type":"response.output_item.added","output_index":0,"item":{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"in_progress","role":"assistant","content":[]}}

            event: response.content_part.added
            data: {"type":"response.content_part.added","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"part":{"type":"output_text","text":"","annotations":[]}}

            event: response.output_text.delta
            data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"Hi"}

            ...

            event: response.output_text.done
            data: {"type":"response.output_text.done","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"text":"Hi there! How can I assist you today?"}

            event: response.content_part.done
            data: {"type":"response.content_part.done","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"part":{"type":"output_text","text":"Hi there! How can I assist you today?","annotations":[]}}

            event: response.output_item.done
            data: {"type":"response.output_item.done","output_index":0,"item":{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"completed","role":"assistant","content":[{"type":"output_text","text":"Hi there! How can I assist you today?","annotations":[]}]}}

            event: response.completed
            data: {"type":"response.completed","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"completed","error":null,"incomplete_details":null,"instructions":"You are a helpful assistant.","max_output_tokens":null,"model":"gpt-4.1-2025-04-14","output":[{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"completed","role":"assistant","content":[{"type":"output_text","text":"Hi there! How can I assist you today?","annotations":[]}]}],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":{"input_tokens":37,"output_tokens":11,"output_tokens_details":{"reasoning_tokens":0},"total_tokens":48},"user":null,"metadata":{}}}
        - title: Functions
          request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4.1",
                  "input": "What is the weather like in Boston today?",
                  "tools": [
                    {
                      "type": "function",
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA"
                          },
                          "unit": {
                            "type": "string",
                            "enum": ["celsius", "fahrenheit"]
                          }
                        },
                        "required": ["location", "unit"]
                      }
                    }
                  ],
                  "tool_choice": "auto"
                }'
            python: |
              from openai import OpenAI

              client = OpenAI()

              tools = [
                  {
                      "type": "function",
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                            "location": {
                                "type": "string",
                                "description": "The city and state, e.g. San Francisco, CA",
                            },
                            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                        },
                        "required": ["location", "unit"],
                      }
                  }
              ]

              response = client.responses.create(
                model="gpt-4.1",
                tools=tools,
                input="What is the weather like in Boston today?",
                tool_choice="auto"
              )

              print(response)
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const tools = [
                  {
                      type: "function",
                      name: "get_current_weather",
                      description: "Get the current weather in a given location",
                      parameters: {
                          type: "object",
                          properties: {
                              location: {
                                  type: "string",
                                  description: "The city and state, e.g. San Francisco, CA",
                              },
                              unit: { type: "string", enum: ["celsius", "fahrenheit"] },
                          },
                          required: ["location", "unit"],
                      },
                  },
              ];

              const response = await openai.responses.create({
                  model: "gpt-4.1",
                  tools: tools,
                  input: "What is the weather like in Boston today?",
                  tool_choice: "auto",
              });

              console.log(response);
            csharp: |
              using System;
              using OpenAI.Responses;

              OpenAIResponseClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              ResponseTool getCurrentWeatherFunctionTool = ResponseTool.CreateFunctionTool(
                  functionName: "get_current_weather",
                  functionDescription: "Get the current weather in a given location",
                  functionParameters: BinaryData.FromString("""
                      {
                          "type": "object",
                          "properties": {
                              "location": {
                                  "type": "string",
                                  "description": "The city and state, e.g. San Francisco, CA"
                              },
                              "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
                          },
                          "required": ["location", "unit"]
                      }
                      """
                  )
              );

              string userInputText = "What is the weather like in Boston today?";

              ResponseCreationOptions options = new()
              {
                  Tools =
                  {
                      getCurrentWeatherFunctionTool
                  },
                  ToolChoice = ResponseToolChoice.CreateAutoChoice(),
              };

              OpenAIResponse response = client.CreateResponse(userInputText, options);
          response: |
            {
              "id": "resp_67ca09c5efe0819096d0511c92b8c890096610f474011cc0",
              "object": "response",
              "created_at": 1741294021,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4.1-2025-04-14",
              "output": [
                {
                  "type": "function_call",
                  "id": "fc_67ca09c6bedc8190a7abfec07b1a1332096610f474011cc0",
                  "call_id": "call_unLAR8MvFNptuiZK6K6HCy5k",
                  "name": "get_current_weather",
                  "arguments": "{\"location\":\"Boston, MA\",\"unit\":\"celsius\"}",
                  "status": "completed"
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [
                {
                  "type": "function",
                  "description": "Get the current weather in a given location",
                  "name": "get_current_weather",
                  "parameters": {
                    "type": "object",
                    "properties": {
                      "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA"
                      },
                      "unit": {
                        "type": "string",
                        "enum": [
                          "celsius",
                          "fahrenheit"
                        ]
                      }
                    },
                    "required": [
                      "location",
                      "unit"
                    ]
                  },
                  "strict": true
                }
              ],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 291,
                "output_tokens": 23,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 314
              },
              "user": null,
              "metadata": {}
            }
        - title: Reasoning
          request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "o3-mini",
                  "input": "How much wood would a woodchuck chuck?",
                  "reasoning": {
                    "effort": "high"
                  }
                }'
            javascript: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "o3-mini",
                  input: "How much wood would a woodchuck chuck?",
                  reasoning: {
                    effort: "high"
                  }
              });

              console.log(response);
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.responses.create(
                  model="o3-mini",
                  input="How much wood would a woodchuck chuck?",
                  reasoning={
                      "effort": "high"
                  }
              )

              print(response)
            csharp: |
              using System;
              using OpenAI.Responses;

              OpenAIResponseClient client = new(
                  model: "o3-mini",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              string userInputText = "How much wood would a woodchuck chuck?";

              ResponseCreationOptions options = new()
              {
                  ReasoningOptions = new()
                  {
                      ReasoningEffortLevel = ResponseReasoningEffortLevel.High,
                  },
              };

              OpenAIResponse response = client.CreateResponse(userInputText, options);

              Console.WriteLine(response.GetOutputText());
          response: |
            {
              "id": "resp_67ccd7eca01881908ff0b5146584e408072912b2993db808",
              "object": "response",
              "created_at": 1741477868,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "o1-2024-12-17",
              "output": [
                {
                  "type": "message",
                  "id": "msg_67ccd7f7b5848190a6f3e95d809f6b44072912b2993db808",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "The classic tongue twister...",
                      "annotations": []
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": "high",
                "summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 81,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 1035,
                "output_tokens_details": {
                  "reasoning_tokens": 832
                },
                "total_tokens": 1116
              },
              "user": null,
              "metadata": {}
            }
  /responses/{response_id}:
    delete:
      operationId: deleteResponse
      parameters:
      - description: The ID of the response to delete.
        explode: false
        in: path
        name: response_id
        required: true
        schema:
          example: resp_677efb5139a88190b512bc3fef8e535d
          type: string
        style: simple
      responses:
        "200":
          description: OK
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Error"
          description: Not Found
      summary: |
        Deletes a model response with the given ID.
      tags:
      - Responses
      x-oaiMeta:
        name: Delete a model response
        group: responses
        returns: |
          A success message.
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/responses/resp_123 \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY"
            javascript: |
              import OpenAI from "openai";
              const client = new OpenAI();

              const response = await client.responses.delete("resp_123");
              console.log(response);
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.responses.delete("resp_123")
              print(response)
          response: |
            {
              "id": "resp_6786a1bec27481909a17d673315b29f6",
              "object": "response",
              "deleted": true
            }
    get:
      operationId: getResponse
      parameters:
      - description: The ID of the response to retrieve.
        explode: false
        in: path
        name: response_id
        required: true
        schema:
          example: resp_677efb5139a88190b512bc3fef8e535d
          type: string
        style: simple
      - description: |
          Additional fields to include in the response. See the `include`
          parameter for Response creation above for more information.
        explode: true
        in: query
        name: include
        required: false
        schema:
          items:
            $ref: "#/components/schemas/Includable"
          type: array
        style: form
      - description: |
          If set to true, the model response data will be streamed to the client
          as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).
          See the [Streaming section below](/docs/api-reference/responses-streaming)
          for more information.
        explode: true
        in: query
        name: stream
        required: false
        schema:
          type: boolean
        style: form
      - description: |
          The sequence number of the event after which to start streaming.
        explode: true
        in: query
        name: starting_after
        required: false
        schema:
          type: integer
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Response"
          description: OK
      summary: |
        Retrieves a model response with the given ID.
      tags:
      - Responses
      x-oaiMeta:
        name: Get a model response
        group: responses
        returns: |
          The [Response](/docs/api-reference/responses/object) object matching the
          specified ID.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/responses/resp_123 \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY"
            javascript: |
              import OpenAI from "openai";
              const client = new OpenAI();

              const response = await client.responses.retrieve("resp_123");
              console.log(response);
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.responses.retrieve("resp_123")
              print(response)
          response: |
            {
              "id": "resp_67cb71b351908190a308f3859487620d06981a8637e6bc44",
              "object": "response",
              "created_at": 1741386163,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [
                {
                  "type": "message",
                  "id": "msg_67cb71b3c2b0819084d481baaaf148f206981a8637e6bc44",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "Silent circuits hum,  \nThoughts emerge in data streams  \nDigital dawn breaks.",
                      "annotations": []
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 32,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 18,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 50
              },
              "user": null,
              "metadata": {}
            }
  /responses/{response_id}/cancel:
    post:
      operationId: cancelResponse
      parameters:
      - description: The ID of the response to cancel.
        explode: false
        in: path
        name: response_id
        required: true
        schema:
          example: resp_677efb5139a88190b512bc3fef8e535d
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Response"
          description: OK
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Error"
          description: Not Found
      summary: "Cancels a model response with the given ID. Only responses created\
        \ with\nthe `background` parameter set to `true` can be cancelled. \n[Learn\
        \ more](/docs/guides/background).\n"
      tags:
      - Responses
      x-oaiMeta:
        name: Cancel a response
        group: responses
        returns: |
          A [Response](/docs/api-reference/responses/object) object.
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/responses/resp_123/cancel \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\
              \nconst response = await client.responses.cancel(\"resp_123\");\nconsole.log(response);\
              \  \n"
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.responses.cancel("resp_123")
              print(response)
          response: |
            {
              "id": "resp_67cb71b351908190a308f3859487620d06981a8637e6bc44",
              "object": "response",
              "created_at": 1741386163,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [
                {
                  "type": "message",
                  "id": "msg_67cb71b3c2b0819084d481baaaf148f206981a8637e6bc44",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "Silent circuits hum,  \nThoughts emerge in data streams  \nDigital dawn breaks.",
                      "annotations": []
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 32,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 18,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 50
              },
              "user": null,
              "metadata": {}
            }
  /responses/{response_id}/input_items:
    get:
      operationId: listInputItems
      parameters:
      - description: The ID of the response to retrieve input items for.
        explode: false
        in: path
        name: response_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between
          1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          The order to return the input items in. Default is `desc`.
          - `asc`: Return the input items in ascending order.
          - `desc`: Return the input items in descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          An item ID to list items after, used in pagination.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          An item ID to list items before, used in pagination.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      - description: |
          Additional fields to include in the response. See the `include`
          parameter for Response creation above for more information.
        explode: true
        in: query
        name: include
        required: false
        schema:
          items:
            $ref: "#/components/schemas/Includable"
          type: array
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResponseItemList"
          description: OK
      summary: Returns a list of input items for a given response.
      tags:
      - Responses
      x-oaiMeta:
        name: List input items
        group: responses
        returns: A list of input item objects.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/responses/resp_abc123/input_items \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\
              \nconst response = await client.responses.inputItems.list(\"resp_123\"\
              );\nconsole.log(response.data);  \n"
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.responses.input_items.list("resp_123")
              print(response.data)
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "msg_abc123",
                  "type": "message",
                  "role": "user",
                  "content": [
                    {
                      "type": "input_text",
                      "text": "Tell me a three sentence bedtime story about a unicorn."
                    }
                  ]
                }
              ],
              "first_id": "msg_abc123",
              "last_id": "msg_abc123",
              "has_more": false
            }
  /threads:
    post:
      operationId: createThread
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateThreadRequest"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThreadObject"
          description: OK
      summary: Create a thread.
      tags:
      - Assistants
      x-oaiMeta:
        name: Create thread
        group: threads
        beta: true
        returns: "A [thread](/docs/api-reference/threads) object."
        examples:
        - title: Empty
          request:
            curl: |
              curl https://api.openai.com/v1/threads \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d ''
            python: |
              from openai import OpenAI
              client = OpenAI()

              empty_thread = client.beta.threads.create()
              print(empty_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const emptyThread = await openai.beta.threads.create();

                console.log(emptyThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699012949,
              "metadata": {},
              "tool_resources": {}
            }
        - title: Messages
          request:
            curl: |
              curl https://api.openai.com/v1/threads \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $OPENAI_API_KEY" \
              -H "OpenAI-Beta: assistants=v2" \
              -d '{
                  "messages": [{
                    "role": "user",
                    "content": "Hello, what is AI?"
                  }, {
                    "role": "user",
                    "content": "How does AI work? Explain it in simple terms."
                  }]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              message_thread = client.beta.threads.create(
                messages=[
                  {
                    "role": "user",
                    "content": "Hello, what is AI?"
                  },
                  {
                    "role": "user",
                    "content": "How does AI work? Explain it in simple terms."
                  },
                ]
              )

              print(message_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const messageThread = await openai.beta.threads.create({
                  messages: [
                    {
                      role: "user",
                      content: "Hello, what is AI?"
                    },
                    {
                      role: "user",
                      content: "How does AI work? Explain it in simple terms.",
                    },
                  ],
                });

                console.log(messageThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {},
              "tool_resources": {}
            }
  /threads/runs:
    post:
      operationId: createThreadAndRun
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateThreadAndRunRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
          description: OK
      summary: Create a thread and run it in one request.
      tags:
      - Assistants
      x-oaiMeta:
        name: Create thread and run
        group: threads
        beta: true
        returns: "A [run](/docs/api-reference/runs/object) object."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/threads/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "assistant_id": "asst_abc123",
                    "thread": {
                      "messages": [
                        {"role": "user", "content": "Explain deep learning to a 5 year old."}
                      ]
                    }
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.create_and_run(
                assistant_id="asst_abc123",
                thread={
                  "messages": [
                    {"role": "user", "content": "Explain deep learning to a 5 year old."}
                  ]
                }
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.createAndRun({
                  assistant_id: "asst_abc123",
                  thread: {
                    messages: [
                      { role: "user", content: "Explain deep learning to a 5 year old." },
                    ],
                  },
                });

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699076792,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "queued",
              "started_at": null,
              "expires_at": 1699077392,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": null,
              "required_action": null,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": "You are a helpful assistant.",
              "tools": [],
              "tool_resources": {},
              "metadata": {},
              "temperature": 1.0,
              "top_p": 1.0,
              "max_completion_tokens": null,
              "max_prompt_tokens": null,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "incomplete_details": null,
              "usage": null,
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/threads/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_123",
                  "thread": {
                    "messages": [
                      {"role": "user", "content": "Hello"}
                    ]
                  },
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              stream = client.beta.threads.create_and_run(
                assistant_id="asst_123",
                thread={
                  "messages": [
                    {"role": "user", "content": "Hello"}
                  ]
                },
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.beta.threads.createAndRun({
                    assistant_id: "asst_123",
                    thread: {
                      messages: [
                        { role: "user", content: "Hello" },
                      ],
                    },
                    stream: true
                });

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.created
            data: {"id":"thread_123","object":"thread","created_at":1710348075,"metadata":{}}

            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[], "metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[], "metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" today"}}]}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}

            event: thread.message.completed
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710348077,"role":"assistant","content":[{"type":"text","text":{"value":"Hello! How can I assist you today?","annotations":[]}}], "metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710348077,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}

            event: thread.run.completed
            {"id":"run_123","object":"thread.run","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1713226836,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1713226837,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":345,"completion_tokens":11,"total_tokens":356},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: done
            data: [DONE]
        - title: Streaming with Functions
          request:
            curl: |
              curl https://api.openai.com/v1/threads/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_abc123",
                  "thread": {
                    "messages": [
                      {"role": "user", "content": "What is the weather like in San Francisco?"}
                    ]
                  },
                  "tools": [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA"
                            },
                            "unit": {
                              "type": "string",
                              "enum": ["celsius", "fahrenheit"]
                            }
                          },
                          "required": ["location"]
                        }
                      }
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              tools = [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA",
                        },
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                      },
                      "required": ["location"],
                    },
                  }
                }
              ]

              stream = client.beta.threads.create_and_run(
                thread={
                    "messages": [
                      {"role": "user", "content": "What is the weather like in San Francisco?"}
                    ]
                },
                assistant_id="asst_abc123",
                tools=tools,
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const tools = [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA",
                          },
                          "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                        },
                        "required": ["location"],
                      },
                    }
                  }
              ];

              async function main() {
                const stream = await openai.beta.threads.createAndRun({
                  assistant_id: "asst_123",
                  thread: {
                    messages: [
                      { role: "user", content: "What is the weather like in San Francisco?" },
                    ],
                  },
                  tools: tools,
                  stream: true
                });

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.created
            data: {"id":"thread_123","object":"thread","created_at":1710351818,"metadata":{}}

            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710351818,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710351819,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710352418,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[]},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710351819,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710352418,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[]},"usage":null}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"id":"call_XXNp8YGaFrjrSjgqxtC8JJ1B","type":"function","function":{"name":"get_current_weather","arguments":"","output":null}}]}}}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"{\""}}]}}}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"location"}}]}}}

            ...

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"ahrenheit"}}]}}}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"\"}"}}]}}}

            event: thread.run.requires_action
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"requires_action","started_at":1710351818,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":{"type":"submit_tool_outputs","submit_tool_outputs":{"tool_calls":[{"id":"call_XXNp8YGaFrjrSjgqxtC8JJ1B","type":"function","function":{"name":"get_current_weather","arguments":"{\"location\":\"San Francisco, CA\",\"unit\":\"fahrenheit\"}"}}]}},"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":345,"completion_tokens":11,"total_tokens":356},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
  /threads/{thread_id}:
    delete:
      operationId: deleteThread
      parameters:
      - description: The ID of the thread to delete.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteThreadResponse"
          description: OK
      summary: Delete a thread.
      tags:
      - Assistants
      x-oaiMeta:
        name: Delete thread
        group: threads
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.beta.threads.delete("thread_abc123")
              print(response)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.beta.threads.delete("thread_abc123");

                console.log(response);
              }
              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread.deleted",
              "deleted": true
            }
    get:
      operationId: getThread
      parameters:
      - description: The ID of the thread to retrieve.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThreadObject"
          description: OK
      summary: Retrieves a thread.
      tags:
      - Assistants
      x-oaiMeta:
        name: Retrieve thread
        group: threads
        beta: true
        returns: "The [thread](/docs/api-reference/threads/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_thread = client.beta.threads.retrieve("thread_abc123")
              print(my_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myThread = await openai.beta.threads.retrieve(
                  "thread_abc123"
                );

                console.log(myThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {},
              "tool_resources": {
                "code_interpreter": {
                  "file_ids": []
                }
              }
            }
    post:
      operationId: modifyThread
      parameters:
      - description: The ID of the thread to modify. Only the `metadata` can be modified.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ModifyThreadRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThreadObject"
          description: OK
      summary: Modifies a thread.
      tags:
      - Assistants
      x-oaiMeta:
        name: Modify thread
        group: threads
        beta: true
        returns: "The modified [thread](/docs/api-reference/threads/object) object\
          \ matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "metadata": {
                      "modified": "true",
                      "user": "abc123"
                    }
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_updated_thread = client.beta.threads.update(
                "thread_abc123",
                metadata={
                  "modified": "true",
                  "user": "abc123"
                }
              )
              print(my_updated_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const updatedThread = await openai.beta.threads.update(
                  "thread_abc123",
                  {
                    metadata: { modified: "true", user: "abc123" },
                  }
                );

                console.log(updatedThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {
                "modified": "true",
                "user": "abc123"
              },
              "tool_resources": {}
            }
  /threads/{thread_id}/messages:
    get:
      operationId: listMessages
      parameters:
      - description: "The ID of the [thread](/docs/api-reference/threads) the messages\
          \ belong to."
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      - description: |
          Filter messages by the run ID that generated them.
        explode: true
        in: query
        name: run_id
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListMessagesResponse"
          description: OK
      summary: Returns a list of messages for a given thread.
      tags:
      - Assistants
      x-oaiMeta:
        name: List messages
        group: threads
        beta: true
        returns: "A list of [message](/docs/api-reference/messages) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              thread_messages = client.beta.threads.messages.list("thread_abc123")
              print(thread_messages.data)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const threadMessages = await openai.beta.threads.messages.list(
                  "thread_abc123"
                );

                console.log(threadMessages.data);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "msg_abc123",
                  "object": "thread.message",
                  "created_at": 1699016383,
                  "assistant_id": null,
                  "thread_id": "thread_abc123",
                  "run_id": null,
                  "role": "user",
                  "content": [
                    {
                      "type": "text",
                      "text": {
                        "value": "How does AI work? Explain it in simple terms.",
                        "annotations": []
                      }
                    }
                  ],
                  "attachments": [],
                  "metadata": {}
                },
                {
                  "id": "msg_abc456",
                  "object": "thread.message",
                  "created_at": 1699016383,
                  "assistant_id": null,
                  "thread_id": "thread_abc123",
                  "run_id": null,
                  "role": "user",
                  "content": [
                    {
                      "type": "text",
                      "text": {
                        "value": "Hello, what is AI?",
                        "annotations": []
                      }
                    }
                  ],
                  "attachments": [],
                  "metadata": {}
                }
              ],
              "first_id": "msg_abc123",
              "last_id": "msg_abc456",
              "has_more": false
            }
    post:
      operationId: createMessage
      parameters:
      - description: "The ID of the [thread](/docs/api-reference/threads) to create\
          \ a message for."
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateMessageRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/MessageObject"
          description: OK
      summary: Create a message.
      tags:
      - Assistants
      x-oaiMeta:
        name: Create message
        group: threads
        beta: true
        returns: "A [message](/docs/api-reference/messages/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "role": "user",
                    "content": "How does AI work? Explain it in simple terms."
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              thread_message = client.beta.threads.messages.create(
                "thread_abc123",
                role="user",
                content="How does AI work? Explain it in simple terms.",
              )
              print(thread_message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const threadMessages = await openai.beta.threads.messages.create(
                  "thread_abc123",
                  { role: "user", content: "How does AI work? Explain it in simple terms." }
                );

                console.log(threadMessages);
              }

              main();
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1713226573,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "attachments": [],
              "metadata": {}
            }
  /threads/{thread_id}/messages/{message_id}:
    delete:
      operationId: deleteMessage
      parameters:
      - description: The ID of the thread to which this message belongs.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the message to delete.
        explode: false
        in: path
        name: message_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteMessageResponse"
          description: OK
      summary: Deletes a message.
      tags:
      - Assistants
      x-oaiMeta:
        name: Delete message
        group: threads
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_message = client.beta.threads.messages.delete(
                message_id="msg_abc12",
                thread_id="thread_abc123",
              )
              print(deleted_message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const deletedMessage = await openai.beta.threads.messages.delete(
                  "msg_abc123",
                  { thread_id: "thread_abc123" }
                );

                console.log(deletedMessage);
              }
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message.deleted",
              "deleted": true
            }
    get:
      operationId: getMessage
      parameters:
      - description: "The ID of the [thread](/docs/api-reference/threads) to which\
          \ this message belongs."
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the message to retrieve.
        explode: false
        in: path
        name: message_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/MessageObject"
          description: OK
      summary: Retrieve a message.
      tags:
      - Assistants
      x-oaiMeta:
        name: Retrieve message
        group: threads
        beta: true
        returns: "The [message](/docs/api-reference/messages/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              message = client.beta.threads.messages.retrieve(
                message_id="msg_abc123",
                thread_id="thread_abc123",
              )
              print(message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const message = await openai.beta.threads.messages.retrieve(
                  "msg_abc123",
                  { thread_id: "thread_abc123" }
                );

                console.log(message);
              }

              main();
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1699017614,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "attachments": [],
              "metadata": {}
            }
    post:
      operationId: modifyMessage
      parameters:
      - description: The ID of the thread to which this message belongs.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the message to modify.
        explode: false
        in: path
        name: message_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ModifyMessageRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/MessageObject"
          description: OK
      summary: Modifies a message.
      tags:
      - Assistants
      x-oaiMeta:
        name: Modify message
        group: threads
        beta: true
        returns: "The modified [message](/docs/api-reference/messages/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "metadata": {
                      "modified": "true",
                      "user": "abc123"
                    }
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              message = client.beta.threads.messages.update(
                message_id="msg_abc12",
                thread_id="thread_abc123",
                metadata={
                  "modified": "true",
                  "user": "abc123",
                },
              )
              print(message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const message = await openai.beta.threads.messages.update(
                  "thread_abc123",
                  "msg_abc123",
                  {
                    metadata: {
                      modified: "true",
                      user: "abc123",
                    },
                  }
                }'
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1699017614,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "file_ids": [],
              "metadata": {
                "modified": "true",
                "user": "abc123"
              }
            }
  /threads/{thread_id}/runs:
    get:
      operationId: listRuns
      parameters:
      - description: The ID of the thread the run belongs to.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListRunsResponse"
          description: OK
      summary: Returns a list of runs belonging to a thread.
      tags:
      - Assistants
      x-oaiMeta:
        name: List runs
        group: threads
        beta: true
        returns: "A list of [run](/docs/api-reference/runs/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              runs = client.beta.threads.runs.list(
                "thread_abc123"
              )

              print(runs)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const runs = await openai.beta.threads.runs.list(
                  "thread_abc123"
                );

                console.log(runs);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "run_abc123",
                  "object": "thread.run",
                  "created_at": 1699075072,
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "status": "completed",
                  "started_at": 1699075072,
                  "expires_at": null,
                  "cancelled_at": null,
                  "failed_at": null,
                  "completed_at": 1699075073,
                  "last_error": null,
                  "model": "gpt-4o",
                  "instructions": null,
                  "incomplete_details": null,
                  "tools": [
                    {
                      "type": "code_interpreter"
                    }
                  ],
                  "tool_resources": {
                    "code_interpreter": {
                      "file_ids": [
                        "file-abc123",
                        "file-abc456"
                      ]
                    }
                  },
                  "metadata": {},
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  },
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_prompt_tokens": 1000,
                  "max_completion_tokens": 1000,
                  "truncation_strategy": {
                    "type": "auto",
                    "last_messages": null
                  },
                  "response_format": "auto",
                  "tool_choice": "auto",
                  "parallel_tool_calls": true
                },
                {
                  "id": "run_abc456",
                  "object": "thread.run",
                  "created_at": 1699063290,
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "status": "completed",
                  "started_at": 1699063290,
                  "expires_at": null,
                  "cancelled_at": null,
                  "failed_at": null,
                  "completed_at": 1699063291,
                  "last_error": null,
                  "model": "gpt-4o",
                  "instructions": null,
                  "incomplete_details": null,
                  "tools": [
                    {
                      "type": "code_interpreter"
                    }
                  ],
                  "tool_resources": {
                    "code_interpreter": {
                      "file_ids": [
                        "file-abc123",
                        "file-abc456"
                      ]
                    }
                  },
                  "metadata": {},
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  },
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_prompt_tokens": 1000,
                  "max_completion_tokens": 1000,
                  "truncation_strategy": {
                    "type": "auto",
                    "last_messages": null
                  },
                  "response_format": "auto",
                  "tool_choice": "auto",
                  "parallel_tool_calls": true
                }
              ],
              "first_id": "run_abc123",
              "last_id": "run_abc456",
              "has_more": false
            }
    post:
      operationId: createRun
      parameters:
      - description: The ID of the thread to run.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

          See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.
        explode: true
        in: query
        name: "include[]"
        required: false
        schema:
          items:
            enum:
            - "step_details.tool_calls[*].file_search.results[*].content"
            type: string
          type: array
        style: form
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateRunRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
          description: OK
      summary: Create a run.
      tags:
      - Assistants
      x-oaiMeta:
        name: Create run
        group: threads
        beta: true
        returns: "A [run](/docs/api-reference/runs/object) object."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_abc123"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.create(
                thread_id="thread_abc123",
                assistant_id="asst_abc123"
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.create(
                  "thread_abc123",
                  { assistant_id: "asst_abc123" }
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699063290,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "queued",
              "started_at": 1699063290,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699063291,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "metadata": {},
              "usage": null,
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_123",
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              stream = client.beta.threads.runs.create(
                thread_id="thread_123",
                assistant_id="asst_123",
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.beta.threads.runs.create(
                  "thread_123",
                  { assistant_id: "asst_123", stream: true }
                );

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710330641,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" today"}}]}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}

            event: thread.message.completed
            data: {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710330642,"role":"assistant","content":[{"type":"text","text":{"value":"Hello! How can I assist you today?","annotations":[]}}],"metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710330642,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}

            event: thread.run.completed
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710330641,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710330642,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
        - title: Streaming with Functions
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_abc123",
                  "tools": [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA"
                            },
                            "unit": {
                              "type": "string",
                              "enum": ["celsius", "fahrenheit"]
                            }
                          },
                          "required": ["location"]
                        }
                      }
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              tools = [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA",
                        },
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                      },
                      "required": ["location"],
                    },
                  }
                }
              ]

              stream = client.beta.threads.runs.create(
                thread_id="thread_abc123",
                assistant_id="asst_abc123",
                tools=tools,
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const tools = [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA",
                          },
                          "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                        },
                        "required": ["location"],
                      },
                    }
                  }
              ];

              async function main() {
                const stream = await openai.beta.threads.runs.create(
                  "thread_abc123",
                  {
                    assistant_id: "asst_abc123",
                    tools: tools,
                    stream: true
                  }
                );

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710348075,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" today"}}]}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}

            event: thread.message.completed
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710348077,"role":"assistant","content":[{"type":"text","text":{"value":"Hello! How can I assist you today?","annotations":[]}}],"metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710348077,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}

            event: thread.run.completed
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710348075,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710348077,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
  /threads/{thread_id}/runs/{run_id}:
    get:
      operationId: getRun
      parameters:
      - description: "The ID of the [thread](/docs/api-reference/threads) that was\
          \ run."
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run to retrieve.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
          description: OK
      summary: Retrieves a run.
      tags:
      - Assistants
      x-oaiMeta:
        name: Retrieve run
        group: threads
        beta: true
        returns: "The [run](/docs/api-reference/runs/object) object matching the specified\
          \ ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.retrieve(
                thread_id="thread_abc123",
                run_id="run_abc123"
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.retrieve(
                  "run_abc123",
                  { thread_id: "thread_abc123" }
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699075072,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "completed",
              "started_at": 1699075072,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699075073,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "metadata": {},
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              },
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
    post:
      operationId: modifyRun
      parameters:
      - description: "The ID of the [thread](/docs/api-reference/threads) that was\
          \ run."
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run to modify.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ModifyRunRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
          description: OK
      summary: Modifies a run.
      tags:
      - Assistants
      x-oaiMeta:
        name: Modify run
        group: threads
        beta: true
        returns: "The modified [run](/docs/api-reference/runs/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "metadata": {
                    "user_id": "user_abc123"
                  }
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.update(
                thread_id="thread_abc123",
                run_id="run_abc123",
                metadata={"user_id": "user_abc123"},
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.update(
                  "run_abc123",
                  {
                    thread_id: "thread_abc123",
                    metadata: {
                      user_id: "user_abc123",
                    },
                  }
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699075072,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "completed",
              "started_at": 1699075072,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699075073,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "tool_resources": {
                "code_interpreter": {
                  "file_ids": [
                    "file-abc123",
                    "file-abc456"
                  ]
                }
              },
              "metadata": {
                "user_id": "user_abc123"
              },
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              },
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
  /threads/{thread_id}/runs/{run_id}/cancel:
    post:
      operationId: cancelRun
      parameters:
      - description: The ID of the thread to which this run belongs.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run to cancel.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
          description: OK
      summary: Cancels a run that is `in_progress`.
      tags:
      - Assistants
      x-oaiMeta:
        name: Cancel a run
        group: threads
        beta: true
        returns: "The modified [run](/docs/api-reference/runs/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X POST
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.cancel(
                thread_id="thread_abc123",
                run_id="run_abc123"
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.cancel(
                  "run_abc123",
                  { thread_id: "thread_abc123" }
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699076126,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "cancelling",
              "started_at": 1699076126,
              "expires_at": 1699076726,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": null,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": "You summarize books.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "tool_resources": {
                "file_search": {
                  "vector_store_ids": ["vs_123"]
                }
              },
              "metadata": {},
              "usage": null,
              "temperature": 1.0,
              "top_p": 1.0,
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
  /threads/{thread_id}/runs/{run_id}/steps:
    get:
      operationId: listRunSteps
      parameters:
      - description: The ID of the thread the run and run steps belong to.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run the run steps belong to.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      - description: |
          A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

          See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.
        explode: true
        in: query
        name: "include[]"
        required: false
        schema:
          items:
            enum:
            - "step_details.tool_calls[*].file_search.results[*].content"
            type: string
          type: array
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListRunStepsResponse"
          description: OK
      summary: Returns a list of run steps belonging to a run.
      tags:
      - Assistants
      x-oaiMeta:
        name: List run steps
        group: threads
        beta: true
        returns: "A list of [run step](/docs/api-reference/run-steps/step-object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              run_steps = client.beta.threads.runs.steps.list(
                  thread_id="thread_abc123",
                  run_id="run_abc123"
              )

              print(run_steps)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const runStep = await openai.beta.threads.runs.steps.list(
                  "run_abc123",
                  { thread_id: "thread_abc123" }
                );
                console.log(runStep);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "step_abc123",
                  "object": "thread.run.step",
                  "created_at": 1699063291,
                  "run_id": "run_abc123",
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "type": "message_creation",
                  "status": "completed",
                  "cancelled_at": null,
                  "completed_at": 1699063291,
                  "expired_at": null,
                  "failed_at": null,
                  "last_error": null,
                  "step_details": {
                    "type": "message_creation",
                    "message_creation": {
                      "message_id": "msg_abc123"
                    }
                  },
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  }
                }
              ],
              "first_id": "step_abc123",
              "last_id": "step_abc456",
              "has_more": false
            }
  /threads/{thread_id}/runs/{run_id}/steps/{step_id}:
    get:
      operationId: getRunStep
      parameters:
      - description: The ID of the thread to which the run and run step belongs.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run to which the run step belongs.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run step to retrieve.
        explode: false
        in: path
        name: step_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

          See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.
        explode: true
        in: query
        name: "include[]"
        required: false
        schema:
          items:
            enum:
            - "step_details.tool_calls[*].file_search.results[*].content"
            type: string
          type: array
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunStepObject"
          description: OK
      summary: Retrieves a run step.
      tags:
      - Assistants
      x-oaiMeta:
        name: Retrieve run step
        group: threads
        beta: true
        returns: "The [run step](/docs/api-reference/run-steps/step-object) object\
          \ matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              run_step = client.beta.threads.runs.steps.retrieve(
                  thread_id="thread_abc123",
                  run_id="run_abc123",
                  step_id="step_abc123"
              )

              print(run_step)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const runStep = await openai.beta.threads.runs.steps.retrieve(
                  "step_abc123",
                  { thread_id: "thread_abc123", run_id: "run_abc123" }
                );
                console.log(runStep);
              }

              main();
          response: |
            {
              "id": "step_abc123",
              "object": "thread.run.step",
              "created_at": 1699063291,
              "run_id": "run_abc123",
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "type": "message_creation",
              "status": "completed",
              "cancelled_at": null,
              "completed_at": 1699063291,
              "expired_at": null,
              "failed_at": null,
              "last_error": null,
              "step_details": {
                "type": "message_creation",
                "message_creation": {
                  "message_id": "msg_abc123"
                }
              },
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              }
            }
  /threads/{thread_id}/runs/{run_id}/submit_tool_outputs:
    post:
      operationId: submitToolOuputsToRun
      parameters:
      - description: "The ID of the [thread](/docs/api-reference/threads) to which\
          \ this run belongs."
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run that requires the tool output submission.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/SubmitToolOutputsRunRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
          description: OK
      summary: |
        When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.
      tags:
      - Assistants
      x-oaiMeta:
        name: Submit tool outputs to run
        group: threads
        beta: true
        returns: "The modified [run](/docs/api-reference/runs/object) object matching\
          \ the specified ID."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "tool_outputs": [
                    {
                      "tool_call_id": "call_001",
                      "output": "70 degrees and sunny."
                    }
                  ]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.submit_tool_outputs(
                thread_id="thread_123",
                run_id="run_123",
                tool_outputs=[
                  {
                    "tool_call_id": "call_001",
                    "output": "70 degrees and sunny."
                  }
                ]
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.submitToolOutputs(
                  "run_123",
                  {
                    thread_id: "thread_123",
                    tool_outputs: [
                      {
                        tool_call_id: "call_001",
                        output: "70 degrees and sunny.",
                      },
                    ],
                  }
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_123",
              "object": "thread.run",
              "created_at": 1699075592,
              "assistant_id": "asst_123",
              "thread_id": "thread_123",
              "status": "queued",
              "started_at": 1699075592,
              "expires_at": 1699076192,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": null,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": null,
              "tools": [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA"
                        },
                        "unit": {
                          "type": "string",
                          "enum": ["celsius", "fahrenheit"]
                        }
                      },
                      "required": ["location"]
                    }
                  }
                }
              ],
              "metadata": {},
              "usage": null,
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "tool_outputs": [
                    {
                      "tool_call_id": "call_001",
                      "output": "70 degrees and sunny."
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              stream = client.beta.threads.runs.submit_tool_outputs(
                thread_id="thread_123",
                run_id="run_123",
                tool_outputs=[
                  {
                    "tool_call_id": "call_001",
                    "output": "70 degrees and sunny."
                  }
                ],
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.beta.threads.runs.submitToolOutputs(
                  "run_123",
                  {
                    thread_id: "thread_123",
                    tool_outputs: [
                      {
                        tool_call_id: "call_001",
                        output: "70 degrees and sunny.",
                      },
                    ],
                  }
                );

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710352449,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"completed","cancelled_at":null,"completed_at":1710352475,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[{"id":"call_iWr0kQ2EaYMaxNdl0v3KYkx7","type":"function","function":{"name":"get_current_weather","arguments":"{\"location\":\"San Francisco, CA\",\"unit\":\"fahrenheit\"}","output":"70 degrees and sunny."}}]},"usage":{"prompt_tokens":291,"completion_tokens":24,"total_tokens":315}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":1710352448,"expires_at":1710353047,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710352475,"expires_at":1710353047,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"The","annotations":[]}}]}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" current"}}]}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" weather"}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" sunny"}}]}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"."}}]}}

            event: thread.message.completed
            data: {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710352477,"role":"assistant","content":[{"type":"text","text":{"value":"The current weather in San Francisco, CA is 70 degrees Fahrenheit and sunny.","annotations":[]}}],"metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710352477,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":{"prompt_tokens":329,"completion_tokens":18,"total_tokens":347}}

            event: thread.run.completed
            data: {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710352475,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710352477,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
  /uploads:
    post:
      operationId: createUpload
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateUploadRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Upload"
          description: OK
      summary: "Creates an intermediate [Upload](/docs/api-reference/uploads/object)\
        \ object\nthat you can add [Parts](/docs/api-reference/uploads/part-object)\
        \ to.\nCurrently, an Upload can accept at most 8 GB in total and expires after\
        \ an\nhour after you create it.\n\nOnce you complete the Upload, we will create\
        \ a\n[File](/docs/api-reference/files/object) object that contains all the\
        \ parts\nyou uploaded. This File is usable in the rest of our platform as\
        \ a regular\nFile object.\n\nFor certain `purpose` values, the correct `mime_type`\
        \ must be specified. \nPlease refer to documentation for the \n[supported\
        \ MIME types for your use case](/docs/assistants/tools/file-search#supported-files).\n\
        \nFor guidance on the proper filename extensions for each purpose, please\n\
        follow the documentation on [creating a\nFile](/docs/api-reference/files/create).\n"
      tags:
      - Uploads
      x-oaiMeta:
        name: Create upload
        group: uploads
        returns: "The [Upload](/docs/api-reference/uploads/object) object with status\
          \ `pending`."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "purpose": "fine-tune",
                  "filename": "training_examples.jsonl",
                  "bytes": 2147483648,
                  "mime_type": "text/jsonl"
                }'
          response: |
            {
              "id": "upload_abc123",
              "object": "upload",
              "bytes": 2147483648,
              "created_at": 1719184911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
              "status": "pending",
              "expires_at": 1719127296
            }
  /uploads/{upload_id}/cancel:
    post:
      operationId: cancelUpload
      parameters:
      - description: |
          The ID of the Upload.
        explode: false
        in: path
        name: upload_id
        required: true
        schema:
          example: upload_abc123
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Upload"
          description: OK
      summary: |
        Cancels the Upload. No Parts may be added after an Upload is cancelled.
      tags:
      - Uploads
      x-oaiMeta:
        name: Cancel upload
        group: uploads
        returns: "The [Upload](/docs/api-reference/uploads/object) object with status\
          \ `cancelled`."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads/upload_abc123/cancel
          response: |
            {
              "id": "upload_abc123",
              "object": "upload",
              "bytes": 2147483648,
              "created_at": 1719184911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
              "status": "cancelled",
              "expires_at": 1719127296
            }
  /uploads/{upload_id}/complete:
    post:
      operationId: completeUpload
      parameters:
      - description: |
          The ID of the Upload.
        explode: false
        in: path
        name: upload_id
        required: true
        schema:
          example: upload_abc123
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CompleteUploadRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Upload"
          description: OK
      summary: "Completes the [Upload](/docs/api-reference/uploads/object). \n\nWithin\
        \ the returned Upload object, there is a nested [File](/docs/api-reference/files/object)\
        \ object that is ready to use in the rest of the platform.\n\nYou can specify\
        \ the order of the Parts by passing in an ordered list of the Part IDs.\n\n\
        The number of bytes uploaded upon completion must match the number of bytes\
        \ initially specified when creating the Upload object. No Parts may be added\
        \ after an Upload is completed.\n"
      tags:
      - Uploads
      x-oaiMeta:
        name: Complete upload
        group: uploads
        returns: "The [Upload](/docs/api-reference/uploads/object) object with status\
          \ `completed` with an additional `file` property containing the created\
          \ usable File object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads/upload_abc123/complete
                -d '{
                  "part_ids": ["part_def456", "part_ghi789"]
                }'
          response: |
            {
              "id": "upload_abc123",
              "object": "upload",
              "bytes": 2147483648,
              "created_at": 1719184911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
              "status": "completed",
              "expires_at": 1719127296,
              "file": {
                "id": "file-xyz321",
                "object": "file",
                "bytes": 2147483648,
                "created_at": 1719186911,
                "filename": "training_examples.jsonl",
                "purpose": "fine-tune",
              }
            }
  /uploads/{upload_id}/parts:
    post:
      operationId: addUploadPart
      parameters:
      - description: |
          The ID of the Upload.
        explode: false
        in: path
        name: upload_id
        required: true
        schema:
          example: upload_abc123
          type: string
        style: simple
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: "#/components/schemas/AddUploadPartRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/UploadPart"
          description: OK
      summary: "Adds a [Part](/docs/api-reference/uploads/part-object) to an [Upload](/docs/api-reference/uploads/object)\
        \ object. A Part represents a chunk of bytes from the file you are trying\
        \ to upload. \n\nEach Part can be at most 64 MB, and you can add Parts until\
        \ you hit the Upload maximum of 8 GB.\n\nIt is possible to add multiple Parts\
        \ in parallel. You can decide the intended order of the Parts when you [complete\
        \ the Upload](/docs/api-reference/uploads/complete).\n"
      tags:
      - Uploads
      x-oaiMeta:
        name: Add upload part
        group: uploads
        returns: "The upload [Part](/docs/api-reference/uploads/part-object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads/upload_abc123/parts
                -F data="aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz..."
          response: |
            {
              "id": "part_def456",
              "object": "upload.part",
              "created_at": 1719185911,
              "upload_id": "upload_abc123"
            }
  /vector_stores:
    get:
      operationId: listVectorStores
      parameters:
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListVectorStoresResponse"
          description: OK
      summary: Returns a list of vector stores.
      tags:
      - Vector stores
      x-oaiMeta:
        name: List vector stores
        group: vector_stores
        returns: "A list of [vector store](/docs/api-reference/vector-stores/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_stores = client.vector_stores.list()
              print(vector_stores)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStores = await openai.vectorStores.list();
                console.log(vectorStores);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "vs_abc123",
                  "object": "vector_store",
                  "created_at": 1699061776,
                  "name": "Support FAQ",
                  "bytes": 139920,
                  "file_counts": {
                    "in_progress": 0,
                    "completed": 3,
                    "failed": 0,
                    "cancelled": 0,
                    "total": 3
                  }
                },
                {
                  "id": "vs_abc456",
                  "object": "vector_store",
                  "created_at": 1699061776,
                  "name": "Support FAQ v2",
                  "bytes": 139920,
                  "file_counts": {
                    "in_progress": 0,
                    "completed": 3,
                    "failed": 0,
                    "cancelled": 0,
                    "total": 3
                  }
                }
              ],
              "first_id": "vs_abc123",
              "last_id": "vs_abc456",
              "has_more": false
            }
    post:
      operationId: createVectorStore
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateVectorStoreRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreObject"
          description: OK
      summary: Create a vector store.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Create vector store
        group: vector_stores
        returns: "A [vector store](/docs/api-reference/vector-stores/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "name": "Support FAQ"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store = client.vector_stores.create(
                name="Support FAQ"
              )
              print(vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStore = await openai.vectorStores.create({
                  name: "Support FAQ"
                });
                console.log(vectorStore);
              }

              main();
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776,
              "name": "Support FAQ",
              "bytes": 139920,
              "file_counts": {
                "in_progress": 0,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 3
              }
            }
  /vector_stores/{vector_store_id}:
    delete:
      operationId: deleteVectorStore
      parameters:
      - description: The ID of the vector store to delete.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteVectorStoreResponse"
          description: OK
      summary: Delete a vector store.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Delete vector store
        group: vector_stores
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_vector_store = client.vector_stores.delete(
                vector_store_id="vs_abc123"
              )
              print(deleted_vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const deletedVectorStore = await openai.vectorStores.delete(
                  "vs_abc123"
                );
                console.log(deletedVectorStore);
              }

              main();
          response: |
            {
              id: "vs_abc123",
              object: "vector_store.deleted",
              deleted: true
            }
    get:
      operationId: getVectorStore
      parameters:
      - description: The ID of the vector store to retrieve.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreObject"
          description: OK
      summary: Retrieves a vector store.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Retrieve vector store
        group: vector_stores
        returns: "The [vector store](/docs/api-reference/vector-stores/object) object\
          \ matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store = client.vector_stores.retrieve(
                vector_store_id="vs_abc123"
              )
              print(vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStore = await openai.vectorStores.retrieve(
                  "vs_abc123"
                );
                console.log(vectorStore);
              }

              main();
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776
            }
    post:
      operationId: modifyVectorStore
      parameters:
      - description: The ID of the vector store to modify.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/UpdateVectorStoreRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreObject"
          description: OK
      summary: Modifies a vector store.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Modify vector store
        group: vector_stores
        returns: "The modified [vector store](/docs/api-reference/vector-stores/object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
                -d '{
                  "name": "Support FAQ"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store = client.vector_stores.update(
                vector_store_id="vs_abc123",
                name="Support FAQ"
              )
              print(vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStore = await openai.vectorStores.update(
                  "vs_abc123",
                  {
                    name: "Support FAQ"
                  }
                );
                console.log(vectorStore);
              }

              main();
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776,
              "name": "Support FAQ",
              "bytes": 139920,
              "file_counts": {
                "in_progress": 0,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 3
              }
            }
  /vector_stores/{vector_store_id}/file_batches:
    post:
      operationId: createVectorStoreFileBatch
      parameters:
      - description: |
          The ID of the vector store for which to create a File Batch.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          example: vs_abc123
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateVectorStoreFileBatchRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreFileBatchObject"
          description: OK
      summary: Create a vector store file batch.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Create vector store file batch
        group: vector_stores
        returns: "A [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "file_ids": ["file-abc123", "file-abc456"]
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file_batch = client.vector_stores.file_batches.create(
                vector_store_id="vs_abc123",
                file_ids=["file-abc123", "file-abc456"]
              )
              print(vector_store_file_batch)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const myVectorStoreFileBatch = await openai.vectorStores.fileBatches.create(
                  "vs_abc123",
                  {
                    file_ids: ["file-abc123", "file-abc456"]
                  }
                );
                console.log(myVectorStoreFileBatch);
              }

              main();
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "in_progress",
              "file_counts": {
                "in_progress": 1,
                "completed": 1,
                "failed": 0,
                "cancelled": 0,
                "total": 0,
              }
            }
  /vector_stores/{vector_store_id}/file_batches/{batch_id}:
    get:
      operationId: getVectorStoreFileBatch
      parameters:
      - description: The ID of the vector store that the file batch belongs to.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          example: vs_abc123
          type: string
        style: simple
      - description: The ID of the file batch being retrieved.
        explode: false
        in: path
        name: batch_id
        required: true
        schema:
          example: vsfb_abc123
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreFileBatchObject"
          description: OK
      summary: Retrieves a vector store file batch.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Retrieve vector store file batch
        group: vector_stores
        returns: "The [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file_batch = client.vector_stores.file_batches.retrieve(
                vector_store_id="vs_abc123",
                batch_id="vsfb_abc123"
              )
              print(vector_store_file_batch)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFileBatch = await openai.vectorStores.fileBatches.retrieve(
                  "vsfb_abc123",
                  { vector_store_id: "vs_abc123" }
                );
                console.log(vectorStoreFileBatch);
              }

              main();
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "in_progress",
              "file_counts": {
                "in_progress": 1,
                "completed": 1,
                "failed": 0,
                "cancelled": 0,
                "total": 0,
              }
            }
  /vector_stores/{vector_store_id}/file_batches/{batch_id}/cancel:
    post:
      operationId: cancelVectorStoreFileBatch
      parameters:
      - description: The ID of the vector store that the file batch belongs to.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the file batch to cancel.
        explode: false
        in: path
        name: batch_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreFileBatchObject"
          description: OK
      summary: Cancel a vector store file batch. This attempts to cancel the processing
        of files in this batch as soon as possible.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Cancel vector store file batch
        group: vector_stores
        returns: The modified vector store file batch object.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X POST
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_vector_store_file_batch = client.vector_stores.file_batches.cancel(
                  vector_store_id="vs_abc123",
                  file_batch_id="vsfb_abc123"
              )
              print(deleted_vector_store_file_batch)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const deletedVectorStoreFileBatch = await openai.vectorStores.fileBatches.cancel(
                  "vsfb_abc123",
                  { vector_store_id: "vs_abc123" }
                );
                console.log(deletedVectorStoreFileBatch);
              }

              main();
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "in_progress",
              "file_counts": {
                "in_progress": 12,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 15,
              }
            }
  /vector_stores/{vector_store_id}/file_batches/{batch_id}/files:
    get:
      operationId: listFilesInVectorStoreBatch
      parameters:
      - description: The ID of the vector store that the files belong to.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the file batch that the files belong to.
        explode: false
        in: path
        name: batch_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      - description: "Filter by file status. One of `in_progress`, `completed`, `failed`,\
          \ `cancelled`."
        explode: true
        in: query
        name: filter
        required: false
        schema:
          enum:
          - in_progress
          - completed
          - failed
          - cancelled
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListVectorStoreFilesResponse"
          description: OK
      summary: Returns a list of vector store files in a batch.
      tags:
      - Vector stores
      x-oaiMeta:
        name: List vector store files in a batch
        group: vector_stores
        returns: "A list of [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_files = client.vector_stores.file_batches.list_files(
                vector_store_id="vs_abc123",
                batch_id="vsfb_abc123"
              )
              print(vector_store_files)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFiles = await openai.vectorStores.fileBatches.listFiles(
                  "vsfb_abc123",
                  { vector_store_id: "vs_abc123" }
                );
                console.log(vectorStoreFiles);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "file-abc123",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                },
                {
                  "id": "file-abc456",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                }
              ],
              "first_id": "file-abc123",
              "last_id": "file-abc456",
              "has_more": false
            }
  /vector_stores/{vector_store_id}/files:
    get:
      operationId: listVectorStoreFiles
      parameters:
      - description: The ID of the vector store that the files belong to.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      - description: "Filter by file status. One of `in_progress`, `completed`, `failed`,\
          \ `cancelled`."
        explode: true
        in: query
        name: filter
        required: false
        schema:
          enum:
          - in_progress
          - completed
          - failed
          - cancelled
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListVectorStoreFilesResponse"
          description: OK
      summary: Returns a list of vector store files.
      tags:
      - Vector stores
      x-oaiMeta:
        name: List vector store files
        group: vector_stores
        returns: "A list of [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_files = client.vector_stores.files.list(
                vector_store_id="vs_abc123"
              )
              print(vector_store_files)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFiles = await openai.vectorStores.files.list(
                  "vs_abc123"
                );
                console.log(vectorStoreFiles);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "file-abc123",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                },
                {
                  "id": "file-abc456",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                }
              ],
              "first_id": "file-abc123",
              "last_id": "file-abc456",
              "has_more": false
            }
    post:
      operationId: createVectorStoreFile
      parameters:
      - description: |
          The ID of the vector store for which to create a File.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          example: vs_abc123
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateVectorStoreFileRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreFileObject"
          description: OK
      summary: "Create a vector store file by attaching a [File](/docs/api-reference/files)\
        \ to a [vector store](/docs/api-reference/vector-stores/object)."
      tags:
      - Vector stores
      x-oaiMeta:
        name: Create vector store file
        group: vector_stores
        returns: "A [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "file_id": "file-abc123"
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file = client.vector_stores.files.create(
                vector_store_id="vs_abc123",
                file_id="file-abc123"
              )
              print(vector_store_file)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const myVectorStoreFile = await openai.vectorStores.files.create(
                  "vs_abc123",
                  {
                    file_id: "file-abc123"
                  }
                );
                console.log(myVectorStoreFile);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "vector_store.file",
              "created_at": 1699061776,
              "usage_bytes": 1234,
              "vector_store_id": "vs_abcd",
              "status": "completed",
              "last_error": null
            }
  /vector_stores/{vector_store_id}/files/{file_id}:
    delete:
      operationId: deleteVectorStoreFile
      parameters:
      - description: The ID of the vector store that the file belongs to.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the file to delete.
        explode: false
        in: path
        name: file_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteVectorStoreFileResponse"
          description: OK
      summary: "Delete a vector store file. This will remove the file from the vector\
        \ store but the file itself will not be deleted. To delete the file, use the\
        \ [delete file](/docs/api-reference/files/delete) endpoint."
      tags:
      - Vector stores
      x-oaiMeta:
        name: Delete vector store file
        group: vector_stores
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_vector_store_file = client.vector_stores.files.delete(
                  vector_store_id="vs_abc123",
                  file_id="file-abc123"
              )
              print(deleted_vector_store_file)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const deletedVectorStoreFile = await openai.vectorStores.files.delete(
                  "file-abc123",
                  { vector_store_id: "vs_abc123" }
                );
                console.log(deletedVectorStoreFile);
              }

              main();
          response: |
            {
              id: "file-abc123",
              object: "vector_store.file.deleted",
              deleted: true
            }
    get:
      operationId: getVectorStoreFile
      parameters:
      - description: The ID of the vector store that the file belongs to.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          example: vs_abc123
          type: string
        style: simple
      - description: The ID of the file being retrieved.
        explode: false
        in: path
        name: file_id
        required: true
        schema:
          example: file-abc123
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreFileObject"
          description: OK
      summary: Retrieves a vector store file.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Retrieve vector store file
        group: vector_stores
        returns: "The [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file = client.vector_stores.files.retrieve(
                vector_store_id="vs_abc123",
                file_id="file-abc123"
              )
              print(vector_store_file)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFile = await openai.vectorStores.files.retrieve(
                  "file-abc123",
                  { vector_store_id: "vs_abc123" }
                );
                console.log(vectorStoreFile);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "vector_store.file",
              "created_at": 1699061776,
              "vector_store_id": "vs_abcd",
              "status": "completed",
              "last_error": null
            }
    post:
      operationId: updateVectorStoreFileAttributes
      parameters:
      - description: The ID of the vector store the file belongs to.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          example: vs_abc123
          type: string
        style: simple
      - description: The ID of the file to update attributes.
        explode: false
        in: path
        name: file_id
        required: true
        schema:
          example: file-abc123
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/UpdateVectorStoreFileAttributesRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreFileObject"
          description: OK
      summary: Update attributes on a vector store file.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Update vector store file attributes
        group: vector_stores
        returns: "The updated [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id} \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{"attributes": {"key1": "value1", "key2": 2}}'
          response: |
            {
              "id": "file-abc123",
              "object": "vector_store.file",
              "usage_bytes": 1234,
              "created_at": 1699061776,
              "vector_store_id": "vs_abcd",
              "status": "completed",
              "last_error": null,
              "chunking_strategy": {...},
              "attributes": {"key1": "value1", "key2": 2}
            }
  /vector_stores/{vector_store_id}/files/{file_id}/content:
    get:
      operationId: retrieveVectorStoreFileContent
      parameters:
      - description: The ID of the vector store.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          example: vs_abc123
          type: string
        style: simple
      - description: The ID of the file within the vector store.
        explode: false
        in: path
        name: file_id
        required: true
        schema:
          example: file-abc123
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreFileContentResponse"
          description: OK
      summary: Retrieve the parsed contents of a vector store file.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Retrieve vector store file content
        group: vector_stores
        returns: The parsed contents of the specified vector store file.
        examples:
          request:
            curl: |
              curl \
              https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123/content \
              -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
              "file_id": "file-abc123",
              "filename": "example.txt",
              "attributes": {"key": "value"},
              "content": [
                {"type": "text", "text": "..."},
                ...
              ]
            }
  /vector_stores/{vector_store_id}/search:
    post:
      operationId: searchVectorStore
      parameters:
      - description: The ID of the vector store to search.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          example: vs_abc123
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/VectorStoreSearchRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreSearchResultsPage"
          description: OK
      summary: Search a vector store for relevant chunks based on a query and file
        attributes filter.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Search vector store
        group: vector_stores
        returns: A page of search results from the vector store.
        examples:
          request:
            curl: |
              curl -X POST \
              https://api.openai.com/v1/vector_stores/vs_abc123/search \
              -H "Authorization: Bearer $OPENAI_API_KEY" \
              -H "Content-Type: application/json" \
              -d '{"query": "What is the return policy?", "filters": {...}}'
          response: |
            {
              "object": "vector_store.search_results.page",
              "search_query": "What is the return policy?",
              "data": [
                {
                  "file_id": "file_123",
                  "filename": "document.pdf",
                  "score": 0.95,
                  "attributes": {
                    "author": "John Doe",
                    "date": "2023-01-01"
                  },
                  "content": [
                    {
                      "type": "text",
                      "text": "Relevant chunk"
                    }
                  ]
                },
                {
                  "file_id": "file_456",
                  "filename": "notes.txt",
                  "score": 0.89,
                  "attributes": {
                    "author": "Jane Smith",
                    "date": "2023-01-02"
                  },
                  "content": [
                    {
                      "type": "text",
                      "text": "Sample text content from the vector store."
                    }
                  ]
                }
              ],
              "has_more": false,
              "next_page": null
            }
components:
  schemas:
    AddUploadPartRequest:
      additionalProperties: true
      properties:
        data:
          description: |
            The chunk of bytes for this Part.
          format: binary
          type: string
      required:
      - data
    AdminApiKey:
      description: Represents an individual Admin API key in an org.
      example:
        owner:
          role: owner
          name: My Service Account
          created_at: 1711471533
          id: sa_456
          type: user
          object: organization.user
        last_used_at: 1711471534
        name: Administration Key
        created_at: 1711471533
        id: key_abc
        redacted_value: sk-admin...def
        value: sk-admin-1234abcd
        object: organization.admin_api_key
      properties:
        object:
          description: "The object type, which is always `organization.admin_api_key`"
          example: organization.admin_api_key
          type: string
          x-stainless-const: true
        id:
          description: "The identifier, which can be referenced in API endpoints"
          example: key_abc
          type: string
        name:
          description: The name of the API key
          example: Administration Key
          type: string
        redacted_value:
          description: The redacted value of the API key
          example: sk-admin...def
          type: string
        value:
          description: The value of the API key. Only shown on create.
          example: sk-admin-1234abcd
          type: string
        created_at:
          description: The Unix timestamp (in seconds) of when the API key was created
          example: 1711471533
          format: int64
          type: integer
        last_used_at:
          description: The Unix timestamp (in seconds) of when the API key was last
            used
          example: 1711471534
          format: int64
          type: integer
          nullable: true
        owner:
          $ref: "#/components/schemas/AdminApiKey_owner"
      required:
      - created_at
      - id
      - last_used_at
      - name
      - object
      - owner
      - redacted_value
      x-oaiMeta:
        name: The admin API key object
        example: |
          {
            "object": "organization.admin_api_key",
            "id": "key_abc",
            "name": "Main Admin Key",
            "redacted_value": "sk-admin...xyz",
            "created_at": 1711471533,
            "last_used_at": 1711471534,
            "owner": {
              "type": "user",
              "object": "organization.user",
              "id": "user_123",
              "name": "John Doe",
              "created_at": 1711471533,
              "role": "owner"
            }
          }
    ApiKeyList:
      example:
        first_id: key_abc
        data:
        - owner:
            role: owner
            name: My Service Account
            created_at: 1711471533
            id: sa_456
            type: user
            object: organization.user
          last_used_at: 1711471534
          name: Administration Key
          created_at: 1711471533
          id: key_abc
          redacted_value: sk-admin...def
          value: sk-admin-1234abcd
          object: organization.admin_api_key
        - owner:
            role: owner
            name: My Service Account
            created_at: 1711471533
            id: sa_456
            type: user
            object: organization.user
          last_used_at: 1711471534
          name: Administration Key
          created_at: 1711471533
          id: key_abc
          redacted_value: sk-admin...def
          value: sk-admin-1234abcd
          object: organization.admin_api_key
        last_id: key_xyz
        has_more: false
        object: list
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: "#/components/schemas/AdminApiKey"
          type: array
        has_more:
          example: false
          type: boolean
        first_id:
          example: key_abc
          type: string
        last_id:
          example: key_xyz
          type: string
    AssistantObject:
      description: Represents an `assistant` that can call the model and use tools.
      example:
        instructions: instructions
        tool_resources:
          code_interpreter:
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
          file_search:
            vector_store_ids:
            - vector_store_ids
        metadata:
          key: metadata
        created_at: 0
        description: description
        tools:
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        top_p: 1
        response_format: auto
        name: name
        temperature: 1
        model: model
        id: id
        object: assistant
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `assistant`."
          enum:
          - assistant
          type: string
          x-stainless-const: true
        created_at:
          description: The Unix timestamp (in seconds) for when the assistant was
            created.
          type: integer
        name:
          description: |
            The name of the assistant. The maximum length is 256 characters.
          maxLength: 256
          type: string
          nullable: true
        description:
          description: |
            The description of the assistant. The maximum length is 512 characters.
          maxLength: 512
          type: string
          nullable: true
        model:
          description: |
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.
          type: string
        instructions:
          description: |
            The system instructions that the assistant uses. The maximum length is 256,000 characters.
          maxLength: 256000
          type: string
          nullable: true
        tools:
          default: []
          description: |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: "#/components/schemas/AssistantObject_tools_inner"
          maxItems: 128
          type: array
        tool_resources:
          $ref: "#/components/schemas/AssistantObject_tool_resources"
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          example: 1
          maximum: 2
          minimum: 0
          type: number
          nullable: true
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
          example: 1
          maximum: 1
          minimum: 0
          type: number
          nullable: true
        response_format:
          $ref: "#/components/schemas/AssistantsApiResponseFormatOption"
      required:
      - created_at
      - description
      - id
      - instructions
      - metadata
      - model
      - name
      - object
      - tools
      title: Assistant
      x-oaiMeta:
        name: The assistant object
        beta: true
        example: |
          {
            "id": "asst_abc123",
            "object": "assistant",
            "created_at": 1698984975,
            "name": "Math Tutor",
            "description": null,
            "model": "gpt-4o",
            "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
            "tools": [
              {
                "type": "code_interpreter"
              }
            ],
            "metadata": {},
            "top_p": 1.0,
            "temperature": 1.0,
            "response_format": "auto"
          }
    AssistantStreamEvent:
      description: |
        Represents an event emitted when streaming a Run.

        Each event in a server-sent events stream has an `event` and `data` property:

        ```
        event: thread.created
        data: {"id": "thread_123", "object": "thread", ...}
        ```

        We emit events whenever a new object is created, transitions to a new state, or is being
        streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
        is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
        to create a message during a run, we emit a `thread.message.created event`, a
        `thread.message.in_progress` event, many `thread.message.delta` events, and finally a
        `thread.message.completed` event.

        We may add additional events over time, so we recommend handling unknown events gracefully
        in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
        integrate the Assistants API with streaming.
      oneOf:
      - $ref: "#/components/schemas/ThreadStreamEvent"
      - $ref: "#/components/schemas/RunStreamEvent"
      - $ref: "#/components/schemas/RunStepStreamEvent"
      - $ref: "#/components/schemas/MessageStreamEvent"
      - $ref: "#/components/schemas/ErrorEvent"
      - $ref: "#/components/schemas/DoneEvent"
      x-oaiMeta:
        name: Assistant stream events
        beta: true
    AssistantSupportedModels:
      enum:
      - gpt-4.1
      - gpt-4.1-mini
      - gpt-4.1-nano
      - gpt-4.1-2025-04-14
      - gpt-4.1-mini-2025-04-14
      - gpt-4.1-nano-2025-04-14
      - o3-mini
      - o3-mini-2025-01-31
      - o1
      - o1-2024-12-17
      - gpt-4o
      - gpt-4o-2024-11-20
      - gpt-4o-2024-08-06
      - gpt-4o-2024-05-13
      - gpt-4o-mini
      - gpt-4o-mini-2024-07-18
      - gpt-4.5-preview
      - gpt-4.5-preview-2025-02-27
      - gpt-4-turbo
      - gpt-4-turbo-2024-04-09
      - gpt-4-0125-preview
      - gpt-4-turbo-preview
      - gpt-4-1106-preview
      - gpt-4-vision-preview
      - gpt-4
      - gpt-4-0314
      - gpt-4-0613
      - gpt-4-32k
      - gpt-4-32k-0314
      - gpt-4-32k-0613
      - gpt-3.5-turbo
      - gpt-3.5-turbo-16k
      - gpt-3.5-turbo-0613
      - gpt-3.5-turbo-1106
      - gpt-3.5-turbo-0125
      - gpt-3.5-turbo-16k-0613
      type: string
    AssistantToolsCode:
      example:
        type: code_interpreter
      properties:
        type:
          description: "The type of tool being defined: `code_interpreter`"
          enum:
          - code_interpreter
          type: string
          x-stainless-const: true
      required:
      - type
      title: Code interpreter tool
    AssistantToolsFileSearch:
      properties:
        type:
          description: "The type of tool being defined: `file_search`"
          enum:
          - file_search
          type: string
          x-stainless-const: true
        file_search:
          $ref: "#/components/schemas/AssistantToolsFileSearch_file_search"
      required:
      - type
      title: FileSearch tool
    AssistantToolsFileSearchTypeOnly:
      properties:
        type:
          description: "The type of tool being defined: `file_search`"
          enum:
          - file_search
          type: string
          x-stainless-const: true
      required:
      - type
      title: FileSearch tool
    AssistantToolsFunction:
      properties:
        type:
          description: "The type of tool being defined: `function`"
          enum:
          - function
          type: string
          x-stainless-const: true
        function:
          $ref: "#/components/schemas/FunctionObject"
      required:
      - function
      - type
      title: Function tool
    AssistantsApiResponseFormatOption:
      description: |
        Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

        Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

        Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

        **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.
      oneOf:
      - description: |
          `auto` is the default value
        enum:
        - auto
        type: string
        x-stainless-const: true
      - $ref: "#/components/schemas/ResponseFormatText"
      - $ref: "#/components/schemas/ResponseFormatJsonObject"
      - $ref: "#/components/schemas/ResponseFormatJsonSchema"
    AssistantsApiToolChoiceOption:
      description: |
        Controls which (if any) tool is called by the model.
        `none` means the model will not call any tools and instead generates a message.
        `auto` is the default value and means the model can pick between generating a message or calling one or more tools.
        `required` means the model must call one or more tools before responding to the user.
        Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.
      oneOf:
      - description: |
          `none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user.
        enum:
        - none
        - auto
        - required
        type: string
      - $ref: "#/components/schemas/AssistantsNamedToolChoice"
    AssistantsNamedToolChoice:
      description: Specifies a tool the model should use. Use to force the model to
        call a specific tool.
      properties:
        type:
          description: "The type of the tool. If type is `function`, the function\
            \ name must be set"
          enum:
          - function
          - code_interpreter
          - file_search
          type: string
        function:
          $ref: "#/components/schemas/AssistantsNamedToolChoice_function"
      required:
      - type
    AudioResponseFormat:
      default: json
      description: |
        The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`. For `gpt-4o-transcribe` and `gpt-4o-mini-transcribe`, the only supported format is `json`.
      enum:
      - json
      - text
      - srt
      - verbose_json
      - vtt
      type: string
    AuditLog:
      description: A log of a user action or configuration change within this organization.
      example:
        rate_limit.updated:
          changes_requested:
            batch_1_day_max_input_tokens: 7
            max_tokens_per_1_minute: 1
            max_images_per_1_minute: 5
            max_audio_megabytes_per_1_minute: 5
            max_requests_per_1_minute: 6
            max_requests_per_1_day: 2
          id: id
        user.updated:
          changes_requested:
            role: role
          id: id
        project:
          name: name
          id: id
        certificate.deleted:
          name: name
          certificate: certificate
          id: id
        service_account.deleted:
          id: id
        type: api_key.created
        logout.failed:
          error_message: error_message
          error_code: error_code
        certificate.updated:
          name: name
          id: id
        login.failed:
          error_message: error_message
          error_code: error_code
        service_account.updated:
          changes_requested:
            role: role
          id: id
        rate_limit.deleted:
          id: id
        id: id
        project.created:
          data:
            name: name
            title: title
          id: id
        certificate.created:
          name: name
          id: id
        checkpoint_permission.created:
          data:
            project_id: project_id
            fine_tuned_model_checkpoint: fine_tuned_model_checkpoint
          id: id
        organization.updated:
          changes_requested:
            threads_ui_visibility: threads_ui_visibility
            usage_dashboard_visibility: usage_dashboard_visibility
            api_call_logging: api_call_logging
            name: name
            description: description
            title: title
            api_call_logging_project_ids: api_call_logging_project_ids
          id: id
        project.updated:
          changes_requested:
            title: title
          id: id
        project.archived:
          id: id
        user.added:
          data:
            role: role
          id: id
        invite.accepted:
          id: id
        invite.deleted:
          id: id
        actor:
          api_key:
            service_account:
              id: id
            id: id
            type: user
            user:
              id: id
              email: email
          session:
            ip_address: ip_address
            user:
              id: id
              email: email
          type: session
        effective_at: 0
        checkpoint_permission.deleted:
          id: id
        invite.sent:
          data:
            role: role
            email: email
          id: id
        certificates.deactivated:
          certificates:
          - name: name
            id: id
          - name: name
            id: id
        service_account.created:
          data:
            role: role
          id: id
        api_key.created:
          data:
            scopes:
            - scopes
            - scopes
          id: id
        user.deleted:
          id: id
        api_key.deleted:
          id: id
        certificates.activated:
          certificates:
          - name: name
            id: id
          - name: name
            id: id
        api_key.updated:
          changes_requested:
            scopes:
            - scopes
            - scopes
          id: id
      properties:
        id:
          description: The ID of this log.
          type: string
        type:
          $ref: "#/components/schemas/AuditLogEventType"
        effective_at:
          description: The Unix timestamp (in seconds) of the event.
          type: integer
        project:
          $ref: "#/components/schemas/AuditLog_project"
        actor:
          $ref: "#/components/schemas/AuditLogActor"
        api_key.created:
          $ref: "#/components/schemas/AuditLog_api_key_created"
        api_key.updated:
          $ref: "#/components/schemas/AuditLog_api_key_updated"
        api_key.deleted:
          $ref: "#/components/schemas/AuditLog_api_key_deleted"
        checkpoint_permission.created:
          $ref: "#/components/schemas/AuditLog_checkpoint_permission_created"
        checkpoint_permission.deleted:
          $ref: "#/components/schemas/AuditLog_checkpoint_permission_deleted"
        invite.sent:
          $ref: "#/components/schemas/AuditLog_invite_sent"
        invite.accepted:
          $ref: "#/components/schemas/AuditLog_invite_accepted"
        invite.deleted:
          $ref: "#/components/schemas/AuditLog_invite_accepted"
        login.failed:
          $ref: "#/components/schemas/AuditLog_login_failed"
        logout.failed:
          $ref: "#/components/schemas/AuditLog_login_failed"
        organization.updated:
          $ref: "#/components/schemas/AuditLog_organization_updated"
        project.created:
          $ref: "#/components/schemas/AuditLog_project_created"
        project.updated:
          $ref: "#/components/schemas/AuditLog_project_updated"
        project.archived:
          $ref: "#/components/schemas/AuditLog_project_archived"
        rate_limit.updated:
          $ref: "#/components/schemas/AuditLog_rate_limit_updated"
        rate_limit.deleted:
          $ref: "#/components/schemas/AuditLog_rate_limit_deleted"
        service_account.created:
          $ref: "#/components/schemas/AuditLog_service_account_created"
        service_account.updated:
          $ref: "#/components/schemas/AuditLog_service_account_updated"
        service_account.deleted:
          $ref: "#/components/schemas/AuditLog_service_account_deleted"
        user.added:
          $ref: "#/components/schemas/AuditLog_user_added"
        user.updated:
          $ref: "#/components/schemas/AuditLog_user_updated"
        user.deleted:
          $ref: "#/components/schemas/AuditLog_user_deleted"
        certificate.created:
          $ref: "#/components/schemas/AuditLog_certificate_created"
        certificate.updated:
          $ref: "#/components/schemas/AuditLog_certificate_created"
        certificate.deleted:
          $ref: "#/components/schemas/AuditLog_certificate_deleted"
        certificates.activated:
          $ref: "#/components/schemas/AuditLog_certificates_activated"
        certificates.deactivated:
          $ref: "#/components/schemas/AuditLog_certificates_activated"
      required:
      - actor
      - effective_at
      - id
      - type
      x-oaiMeta:
        name: The audit log object
        example: |
          {
              "id": "req_xxx_20240101",
              "type": "api_key.created",
              "effective_at": 1720804090,
              "actor": {
                  "type": "session",
                  "session": {
                      "user": {
                          "id": "user-xxx",
                          "email": "user@example.com"
                      },
                      "ip_address": "127.0.0.1",
                      "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
                  }
              },
              "api_key.created": {
                  "id": "key_xxxx",
                  "data": {
                      "scopes": ["resource.operation"]
                  }
              }
          }
    AuditLogActor:
      description: The actor who performed the audit logged action.
      example:
        api_key:
          service_account:
            id: id
          id: id
          type: user
          user:
            id: id
            email: email
        session:
          ip_address: ip_address
          user:
            id: id
            email: email
        type: session
      properties:
        type:
          description: The type of actor. Is either `session` or `api_key`.
          enum:
          - session
          - api_key
          type: string
        session:
          $ref: "#/components/schemas/AuditLogActorSession"
        api_key:
          $ref: "#/components/schemas/AuditLogActorApiKey"
    AuditLogActorApiKey:
      description: The API Key used to perform the audit logged action.
      example:
        service_account:
          id: id
        id: id
        type: user
        user:
          id: id
          email: email
      properties:
        id:
          description: The tracking id of the API key.
          type: string
        type:
          description: The type of API key. Can be either `user` or `service_account`.
          enum:
          - user
          - service_account
          type: string
        user:
          $ref: "#/components/schemas/AuditLogActorUser"
        service_account:
          $ref: "#/components/schemas/AuditLogActorServiceAccount"
    AuditLogActorServiceAccount:
      description: The service account that performed the audit logged action.
      example:
        id: id
      properties:
        id:
          description: The service account id.
          type: string
    AuditLogActorSession:
      description: The session in which the audit logged action was performed.
      example:
        ip_address: ip_address
        user:
          id: id
          email: email
      properties:
        user:
          $ref: "#/components/schemas/AuditLogActorUser"
        ip_address:
          description: The IP address from which the action was performed.
          type: string
    AuditLogActorUser:
      description: The user who performed the audit logged action.
      example:
        id: id
        email: email
      properties:
        id:
          description: The user id.
          type: string
        email:
          description: The user email.
          type: string
    AuditLogEventType:
      description: The event type.
      enum:
      - api_key.created
      - api_key.updated
      - api_key.deleted
      - checkpoint_permission.created
      - checkpoint_permission.deleted
      - invite.sent
      - invite.accepted
      - invite.deleted
      - login.succeeded
      - login.failed
      - logout.succeeded
      - logout.failed
      - organization.updated
      - project.created
      - project.updated
      - project.archived
      - service_account.created
      - service_account.updated
      - service_account.deleted
      - rate_limit.updated
      - rate_limit.deleted
      - user.added
      - user.updated
      - user.deleted
      type: string
    AutoChunkingStrategyRequestParam:
      additionalProperties: true
      description: The default strategy. This strategy currently uses a `max_chunk_size_tokens`
        of `800` and `chunk_overlap_tokens` of `400`.
      example:
        type: auto
      properties:
        type:
          description: Always `auto`.
          enum:
          - auto
          type: string
          x-stainless-const: true
      required:
      - type
      title: Auto Chunking Strategy
    Batch:
      example:
        cancelled_at: 2
        metadata:
          key: metadata
        request_counts:
          total: 4
          completed: 7
          failed: 1
        input_file_id: input_file_id
        output_file_id: output_file_id
        error_file_id: error_file_id
        created_at: 6
        in_progress_at: 1
        expired_at: 9
        finalizing_at: 5
        completed_at: 2
        endpoint: endpoint
        expires_at: 5
        cancelling_at: 3
        completion_window: completion_window
        id: id
        failed_at: 7
        errors:
          data:
          - code: code
            param: param
            line: 0
            message: message
          - code: code
            param: param
            line: 0
            message: message
          object: object
        object: batch
        status: validating
      properties:
        id:
          type: string
        object:
          description: "The object type, which is always `batch`."
          enum:
          - batch
          type: string
          x-stainless-const: true
        endpoint:
          description: The OpenAI API endpoint used by the batch.
          type: string
        errors:
          $ref: "#/components/schemas/Batch_errors"
        input_file_id:
          description: The ID of the input file for the batch.
          type: string
        completion_window:
          description: The time frame within which the batch should be processed.
          type: string
        status:
          description: The current status of the batch.
          enum:
          - validating
          - failed
          - in_progress
          - finalizing
          - completed
          - expired
          - cancelling
          - cancelled
          type: string
        output_file_id:
          description: The ID of the file containing the outputs of successfully executed
            requests.
          type: string
        error_file_id:
          description: The ID of the file containing the outputs of requests with
            errors.
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the batch was created.
          type: integer
        in_progress_at:
          description: The Unix timestamp (in seconds) for when the batch started
            processing.
          type: integer
        expires_at:
          description: The Unix timestamp (in seconds) for when the batch will expire.
          type: integer
        finalizing_at:
          description: The Unix timestamp (in seconds) for when the batch started
            finalizing.
          type: integer
        completed_at:
          description: The Unix timestamp (in seconds) for when the batch was completed.
          type: integer
        failed_at:
          description: The Unix timestamp (in seconds) for when the batch failed.
          type: integer
        expired_at:
          description: The Unix timestamp (in seconds) for when the batch expired.
          type: integer
        cancelling_at:
          description: The Unix timestamp (in seconds) for when the batch started
            cancelling.
          type: integer
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the batch was cancelled.
          type: integer
        request_counts:
          $ref: "#/components/schemas/Batch_request_counts"
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
      required:
      - completion_window
      - created_at
      - endpoint
      - id
      - input_file_id
      - object
      - status
      x-oaiMeta:
        name: The batch object
        example: |
          {
            "id": "batch_abc123",
            "object": "batch",
            "endpoint": "/v1/completions",
            "errors": null,
            "input_file_id": "file-abc123",
            "completion_window": "24h",
            "status": "completed",
            "output_file_id": "file-cvaTdG",
            "error_file_id": "file-HOWS94",
            "created_at": 1711471533,
            "in_progress_at": 1711471538,
            "expires_at": 1711557933,
            "finalizing_at": 1711493133,
            "completed_at": 1711493163,
            "failed_at": null,
            "expired_at": null,
            "cancelling_at": null,
            "cancelled_at": null,
            "request_counts": {
              "total": 100,
              "completed": 95,
              "failed": 5
            },
            "metadata": {
              "customer_id": "user_123456789",
              "batch_description": "Nightly eval job",
            }
          }
    BatchRequestInput:
      description: The per-line object of the batch input file
      properties:
        custom_id:
          description: A developer-provided per-request id that will be used to match
            outputs to inputs. Must be unique for each request in a batch.
          type: string
        method:
          description: The HTTP method to be used for the request. Currently only
            `POST` is supported.
          enum:
          - POST
          type: string
          x-stainless-const: true
        url:
          description: "The OpenAI API relative URL to be used for the request. Currently\
            \ `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are\
            \ supported."
          type: string
      x-oaiMeta:
        name: The request input object
        example: |
          {"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}
    BatchRequestOutput:
      description: The per-line object of the batch output and error files
      properties:
        id:
          type: string
        custom_id:
          description: A developer-provided per-request id that will be used to match
            outputs to inputs.
          type: string
        response:
          $ref: "#/components/schemas/BatchRequestOutput_response"
        error:
          $ref: "#/components/schemas/BatchRequestOutput_error"
      x-oaiMeta:
        name: The request output object
        example: |
          {"id": "batch_req_wnaDys", "custom_id": "request-2", "response": {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054, "model": "gpt-4o-mini", "choices": [{"index": 0, "message": {"role": "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}}, "error": null}
    Certificate:
      description: Represents an individual `certificate` uploaded to the organization.
      example:
        name: name
        created_at: 0
        active: true
        id: id
        certificate_details:
          expires_at: 1
          content: content
          valid_at: 6
        object: certificate
      properties:
        object:
          description: |
            The object type.

            - If creating, updating, or getting a specific certificate, the object type is `certificate`.
            - If listing, activating, or deactivating certificates for the organization, the object type is `organization.certificate`.
            - If listing, activating, or deactivating certificates for a project, the object type is `organization.project.certificate`.
          enum:
          - certificate
          - organization.certificate
          - organization.project.certificate
          type: string
          x-stainless-const: true
        id:
          description: "The identifier, which can be referenced in API endpoints"
          type: string
        name:
          description: The name of the certificate.
          type: string
        created_at:
          description: The Unix timestamp (in seconds) of when the certificate was
            uploaded.
          type: integer
        certificate_details:
          $ref: "#/components/schemas/Certificate_certificate_details"
        active:
          description: Whether the certificate is currently active at the specified
            scope. Not returned when getting details for a specific certificate.
          type: boolean
      required:
      - certificate_details
      - created_at
      - id
      - name
      - object
      x-oaiMeta:
        name: The certificate object
        example: |
          {
            "object": "certificate",
            "id": "cert_abc",
            "name": "My Certificate",
            "created_at": 1234567,
            "certificate_details": {
              "valid_at": 1234567,
              "expires_at": 12345678,
              "content": "-----BEGIN CERTIFICATE----- MIIGAjCCA...6znFlOW+ -----END CERTIFICATE-----"
            }
          }
    ChatCompletionDeleted:
      example:
        deleted: true
        id: id
        object: chat.completion.deleted
      properties:
        object:
          description: The type of object being deleted.
          enum:
          - chat.completion.deleted
          type: string
          x-stainless-const: true
        id:
          description: The ID of the chat completion that was deleted.
          type: string
        deleted:
          description: Whether the chat completion was deleted.
          type: boolean
      required:
      - deleted
      - id
      - object
    ChatCompletionFunctionCallOption:
      description: |
        Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.
      properties:
        name:
          description: The name of the function to call.
          type: string
      required:
      - name
    ChatCompletionFunctions:
      deprecated: true
      example:
        name: name
        description: description
        parameters:
          key: ""
      properties:
        description:
          description: "A description of what the function does, used by the model\
            \ to choose when and how to call the function."
          type: string
        name:
          description: "The name of the function to be called. Must be a-z, A-Z, 0-9,\
            \ or contain underscores and dashes, with a maximum length of 64."
          type: string
        parameters:
          additionalProperties: true
          description: "The parameters the functions accepts, described as a JSON\
            \ Schema object. See the [guide](/docs/guides/function-calling) for examples,\
            \ and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/)\
            \ for documentation about the format. \n\nOmitting `parameters` defines\
            \ a function with an empty parameter list."
          type: object
      required:
      - name
    ChatCompletionList:
      description: |
        An object representing a list of Chat Completions.
      example:
        first_id: first_id
        data:
        - created: 3
          usage:
            completion_tokens: 2
            prompt_tokens: 4
            completion_tokens_details:
              accepted_prediction_tokens: 1
              audio_tokens: 1
              reasoning_tokens: 1
              rejected_prediction_tokens: 6
            prompt_tokens_details:
              audio_tokens: 7
              cached_tokens: 1
            total_tokens: 7
          model: model
          service_tier: auto
          id: id
          choices:
          - finish_reason: stop
            index: 0
            message:
              role: assistant
              function_call:
                name: name
                arguments: arguments
              refusal: refusal
              annotations:
              - type: url_citation
                url_citation:
                  start_index: 1
                  end_index: 6
                  title: title
                  url: url
              - type: url_citation
                url_citation:
                  start_index: 1
                  end_index: 6
                  title: title
                  url: url
              tool_calls:
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
              audio:
                expires_at: 5
                transcript: transcript
                data: data
                id: id
              content: content
            logprobs:
              refusal:
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              content:
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
          - finish_reason: stop
            index: 0
            message:
              role: assistant
              function_call:
                name: name
                arguments: arguments
              refusal: refusal
              annotations:
              - type: url_citation
                url_citation:
                  start_index: 1
                  end_index: 6
                  title: title
                  url: url
              - type: url_citation
                url_citation:
                  start_index: 1
                  end_index: 6
                  title: title
                  url: url
              tool_calls:
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
              audio:
                expires_at: 5
                transcript: transcript
                data: data
                id: id
              content: content
            logprobs:
              refusal:
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              content:
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
          system_fingerprint: system_fingerprint
          object: chat.completion
        - created: 3
          usage:
            completion_tokens: 2
            prompt_tokens: 4
            completion_tokens_details:
              accepted_prediction_tokens: 1
              audio_tokens: 1
              reasoning_tokens: 1
              rejected_prediction_tokens: 6
            prompt_tokens_details:
              audio_tokens: 7
              cached_tokens: 1
            total_tokens: 7
          model: model
          service_tier: auto
          id: id
          choices:
          - finish_reason: stop
            index: 0
            message:
              role: assistant
              function_call:
                name: name
                arguments: arguments
              refusal: refusal
              annotations:
              - type: url_citation
                url_citation:
                  start_index: 1
                  end_index: 6
                  title: title
                  url: url
              - type: url_citation
                url_citation:
                  start_index: 1
                  end_index: 6
                  title: title
                  url: url
              tool_calls:
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
              audio:
                expires_at: 5
                transcript: transcript
                data: data
                id: id
              content: content
            logprobs:
              refusal:
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              content:
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
          - finish_reason: stop
            index: 0
            message:
              role: assistant
              function_call:
                name: name
                arguments: arguments
              refusal: refusal
              annotations:
              - type: url_citation
                url_citation:
                  start_index: 1
                  end_index: 6
                  title: title
                  url: url
              - type: url_citation
                url_citation:
                  start_index: 1
                  end_index: 6
                  title: title
                  url: url
              tool_calls:
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
              audio:
                expires_at: 5
                transcript: transcript
                data: data
                id: id
              content: content
            logprobs:
              refusal:
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              content:
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - top_logprobs:
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                - logprob: 7.061401241503109
                  bytes:
                  - 9
                  - 9
                  token: token
                logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
          system_fingerprint: system_fingerprint
          object: chat.completion
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          default: list
          description: |
            The type of this object. It is always set to "list".
          enum:
          - list
          type: string
          x-stainless-const: true
        data:
          description: |
            An array of chat completion objects.
          items:
            $ref: "#/components/schemas/CreateChatCompletionResponse"
          type: array
        first_id:
          description: The identifier of the first chat completion in the data array.
          type: string
        last_id:
          description: The identifier of the last chat completion in the data array.
          type: string
        has_more:
          description: Indicates whether there are more Chat Completions available.
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      title: ChatCompletionList
      x-oaiMeta:
        name: The chat completion list object
        group: chat
        example: |
          {
            "object": "list",
            "data": [
              {
                "object": "chat.completion",
                "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
                "model": "gpt-4o-2024-08-06",
                "created": 1738960610,
                "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
                "tool_choice": null,
                "usage": {
                  "total_tokens": 31,
                  "completion_tokens": 18,
                  "prompt_tokens": 13
                },
                "seed": 4944116822809979520,
                "top_p": 1.0,
                "temperature": 1.0,
                "presence_penalty": 0.0,
                "frequency_penalty": 0.0,
                "system_fingerprint": "fp_50cad350e4",
                "input_user": null,
                "service_tier": "default",
                "tools": null,
                "metadata": {},
                "choices": [
                  {
                    "index": 0,
                    "message": {
                      "content": "Mind of circuits hum,  \nLearning patterns in silence  \nFuture's quiet spark.",
                      "role": "assistant",
                      "tool_calls": null,
                      "function_call": null
                    },
                    "finish_reason": "stop",
                    "logprobs": null
                  }
                ],
                "response_format": null
              }
            ],
            "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
            "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
            "has_more": false
          }
    ChatCompletionMessageList:
      description: |
        An object representing a list of chat completion messages.
      example:
        first_id: first_id
        data:
        - role: assistant
          function_call:
            name: name
            arguments: arguments
          refusal: refusal
          annotations:
          - type: url_citation
            url_citation:
              start_index: 1
              end_index: 6
              title: title
              url: url
          - type: url_citation
            url_citation:
              start_index: 1
              end_index: 6
              title: title
              url: url
          tool_calls:
          - function:
              name: name
              arguments: arguments
            id: id
            type: function
          - function:
              name: name
              arguments: arguments
            id: id
            type: function
          audio:
            expires_at: 5
            transcript: transcript
            data: data
            id: id
          id: id
          content: content
        - role: assistant
          function_call:
            name: name
            arguments: arguments
          refusal: refusal
          annotations:
          - type: url_citation
            url_citation:
              start_index: 1
              end_index: 6
              title: title
              url: url
          - type: url_citation
            url_citation:
              start_index: 1
              end_index: 6
              title: title
              url: url
          tool_calls:
          - function:
              name: name
              arguments: arguments
            id: id
            type: function
          - function:
              name: name
              arguments: arguments
            id: id
            type: function
          audio:
            expires_at: 5
            transcript: transcript
            data: data
            id: id
          id: id
          content: content
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          default: list
          description: |
            The type of this object. It is always set to "list".
          enum:
          - list
          type: string
          x-stainless-const: true
        data:
          description: |
            An array of chat completion message objects.
          items:
            $ref: "#/components/schemas/ChatCompletionMessageList_data_inner"
          type: array
        first_id:
          description: The identifier of the first chat message in the data array.
          type: string
        last_id:
          description: The identifier of the last chat message in the data array.
          type: string
        has_more:
          description: Indicates whether there are more chat messages available.
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      title: ChatCompletionMessageList
      x-oaiMeta:
        name: The chat completion message list object
        group: chat
        example: |
          {
            "object": "list",
            "data": [
              {
                "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
                "role": "user",
                "content": "write a haiku about ai",
                "name": null,
                "content_parts": null
              }
            ],
            "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
            "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
            "has_more": false
          }
    ChatCompletionMessageToolCall:
      example:
        function:
          name: name
          arguments: arguments
        id: id
        type: function
      properties:
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: "The type of the tool. Currently, only `function` is supported."
          enum:
          - function
          type: string
          x-stainless-const: true
        function:
          $ref: "#/components/schemas/ChatCompletionMessageToolCall_function"
      required:
      - function
      - id
      - type
    ChatCompletionMessageToolCallChunk:
      properties:
        index:
          type: integer
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: "The type of the tool. Currently, only `function` is supported."
          enum:
          - function
          type: string
          x-stainless-const: true
        function:
          $ref: "#/components/schemas/ChatCompletionMessageToolCallChunk_function"
      required:
      - index
    ChatCompletionMessageToolCalls:
      description: "The tool calls generated by the model, such as function calls."
      items:
        $ref: "#/components/schemas/ChatCompletionMessageToolCall"
      type: array
    ChatCompletionModalities:
      description: |
        Output types that you would like the model to generate for this request.
        Most models are capable of generating text, which is the default:

        `["text"]`

        The `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To
        request that this model generate both text and audio responses, you can
        use:

        `["text", "audio"]`
      items:
        enum:
        - text
        - audio
        type: string
      type: array
      nullable: true
    ChatCompletionNamedToolChoice:
      description: Specifies a tool the model should use. Use to force the model to
        call a specific function.
      properties:
        type:
          description: "The type of the tool. Currently, only `function` is supported."
          enum:
          - function
          type: string
          x-stainless-const: true
        function:
          $ref: "#/components/schemas/AssistantsNamedToolChoice_function"
      required:
      - function
      - type
    ChatCompletionRequestAssistantMessage:
      description: |
        Messages sent by the model in response to user messages.
      properties:
        content:
          $ref: "#/components/schemas/ChatCompletionRequestAssistantMessage_content"
        refusal:
          description: The refusal message by the assistant.
          type: string
          nullable: true
        role:
          description: "The role of the messages author, in this case `assistant`."
          enum:
          - assistant
          type: string
          x-stainless-const: true
        name:
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role.
          type: string
        audio:
          $ref: "#/components/schemas/ChatCompletionRequestAssistantMessage_audio"
        tool_calls:
          description: "The tool calls generated by the model, such as function calls."
          items:
            $ref: "#/components/schemas/ChatCompletionMessageToolCall"
          type: array
        function_call:
          $ref: "#/components/schemas/ChatCompletionRequestAssistantMessage_function_call"
      required:
      - role
      title: Assistant message
    ChatCompletionRequestAssistantMessageContentPart:
      oneOf:
      - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartText"
      - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartRefusal"
    ChatCompletionRequestDeveloperMessage:
      description: |
        Developer-provided instructions that the model should follow, regardless of
        messages sent by the user. With o1 models and newer, `developer` messages
        replace the previous `system` messages.
      example:
        role: developer
        name: name
        content: ChatCompletionRequestDeveloperMessage_content
      properties:
        content:
          $ref: "#/components/schemas/ChatCompletionRequestDeveloperMessage_content"
        role:
          description: "The role of the messages author, in this case `developer`."
          enum:
          - developer
          type: string
          x-stainless-const: true
        name:
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role.
          type: string
      required:
      - content
      - role
      title: Developer message
    ChatCompletionRequestFunctionMessage:
      deprecated: true
      properties:
        role:
          description: "The role of the messages author, in this case `function`."
          enum:
          - function
          type: string
          x-stainless-const: true
        content:
          description: The contents of the function message.
          type: string
          nullable: true
        name:
          description: The name of the function to call.
          type: string
      required:
      - content
      - name
      - role
      title: Function message
    ChatCompletionRequestMessage:
      oneOf:
      - $ref: "#/components/schemas/ChatCompletionRequestDeveloperMessage"
      - $ref: "#/components/schemas/ChatCompletionRequestSystemMessage"
      - $ref: "#/components/schemas/ChatCompletionRequestUserMessage"
      - $ref: "#/components/schemas/ChatCompletionRequestAssistantMessage"
      - $ref: "#/components/schemas/ChatCompletionRequestToolMessage"
      - $ref: "#/components/schemas/ChatCompletionRequestFunctionMessage"
    ChatCompletionRequestMessageContentPartAudio:
      description: |
        Learn about [audio inputs](/docs/guides/audio).
      properties:
        type:
          description: The type of the content part. Always `input_audio`.
          enum:
          - input_audio
          type: string
          x-stainless-const: true
        input_audio:
          $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartAudio_input_audio"
      required:
      - input_audio
      - type
      title: Audio content part
    ChatCompletionRequestMessageContentPartFile:
      description: |
        Learn about [file inputs](/docs/guides/text) for text generation.
      properties:
        type:
          description: The type of the content part. Always `file`.
          enum:
          - file
          type: string
          x-stainless-const: true
        file:
          $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartFile_file"
      required:
      - file
      - type
      title: File content part
    ChatCompletionRequestMessageContentPartImage:
      description: |
        Learn about [image inputs](/docs/guides/vision).
      properties:
        type:
          description: The type of the content part.
          enum:
          - image_url
          type: string
          x-stainless-const: true
        image_url:
          $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartImage_image_url"
      required:
      - image_url
      - type
      title: Image content part
    ChatCompletionRequestMessageContentPartRefusal:
      properties:
        type:
          description: The type of the content part.
          enum:
          - refusal
          type: string
          x-stainless-const: true
        refusal:
          description: The refusal message generated by the model.
          type: string
      required:
      - refusal
      - type
      title: Refusal content part
    ChatCompletionRequestMessageContentPartText:
      description: |
        Learn about [text inputs](/docs/guides/text-generation).
      properties:
        type:
          description: The type of the content part.
          enum:
          - text
          type: string
          x-stainless-const: true
        text:
          description: The text content.
          type: string
      required:
      - text
      - type
      title: Text content part
    ChatCompletionRequestSystemMessage:
      description: |
        Developer-provided instructions that the model should follow, regardless of
        messages sent by the user. With o1 models and newer, use `developer` messages
        for this purpose instead.
      properties:
        content:
          $ref: "#/components/schemas/ChatCompletionRequestSystemMessage_content"
        role:
          description: "The role of the messages author, in this case `system`."
          enum:
          - system
          type: string
          x-stainless-const: true
        name:
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role.
          type: string
      required:
      - content
      - role
      title: System message
    ChatCompletionRequestSystemMessageContentPart:
      $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartText"
    ChatCompletionRequestToolMessage:
      properties:
        role:
          description: "The role of the messages author, in this case `tool`."
          enum:
          - tool
          type: string
          x-stainless-const: true
        content:
          $ref: "#/components/schemas/ChatCompletionRequestToolMessage_content"
        tool_call_id:
          description: Tool call that this message is responding to.
          type: string
      required:
      - content
      - role
      - tool_call_id
      title: Tool message
    ChatCompletionRequestToolMessageContentPart:
      $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartText"
    ChatCompletionRequestUserMessage:
      description: |
        Messages sent by an end user, containing prompts or additional context
        information.
      properties:
        content:
          $ref: "#/components/schemas/ChatCompletionRequestUserMessage_content"
        role:
          description: "The role of the messages author, in this case `user`."
          enum:
          - user
          type: string
          x-stainless-const: true
        name:
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role.
          type: string
      required:
      - content
      - role
      title: User message
    ChatCompletionRequestUserMessageContentPart:
      oneOf:
      - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartText"
      - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartImage"
      - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartAudio"
      - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartFile"
    ChatCompletionResponseMessage:
      description: A chat completion message generated by the model.
      example:
        role: assistant
        function_call:
          name: name
          arguments: arguments
        refusal: refusal
        annotations:
        - type: url_citation
          url_citation:
            start_index: 1
            end_index: 6
            title: title
            url: url
        - type: url_citation
          url_citation:
            start_index: 1
            end_index: 6
            title: title
            url: url
        tool_calls:
        - function:
            name: name
            arguments: arguments
          id: id
          type: function
        - function:
            name: name
            arguments: arguments
          id: id
          type: function
        audio:
          expires_at: 5
          transcript: transcript
          data: data
          id: id
        content: content
      properties:
        content:
          description: The contents of the message.
          type: string
          nullable: true
        refusal:
          description: The refusal message generated by the model.
          type: string
          nullable: true
        tool_calls:
          description: "The tool calls generated by the model, such as function calls."
          items:
            $ref: "#/components/schemas/ChatCompletionMessageToolCall"
          type: array
        annotations:
          description: |
            Annotations for the message, when applicable, as when using the
            [web search tool](/docs/guides/tools-web-search?api-mode=chat).
          items:
            $ref: "#/components/schemas/ChatCompletionResponseMessage_annotations_inner"
          type: array
        role:
          description: The role of the author of this message.
          enum:
          - assistant
          type: string
          x-stainless-const: true
        function_call:
          $ref: "#/components/schemas/ChatCompletionResponseMessage_function_call"
        audio:
          $ref: "#/components/schemas/ChatCompletionResponseMessage_audio"
      required:
      - content
      - refusal
      - role
    ChatCompletionRole:
      description: The role of the author of a message
      enum:
      - developer
      - system
      - user
      - assistant
      - tool
      - function
      type: string
    ChatCompletionStreamOptions:
      description: |
        Options for streaming response. Only set this when you set `stream: true`.
      example:
        include_usage: true
      properties:
        include_usage:
          description: "If set, an additional chunk will be streamed before the `data:\
            \ [DONE]`\nmessage. The `usage` field on this chunk shows the token usage\
            \ statistics\nfor the entire request, and the `choices` field will always\
            \ be an empty\narray. \n\nAll other chunks will also include a `usage`\
            \ field, but with a null\nvalue. **NOTE:** If the stream is interrupted,\
            \ you may not receive the\nfinal usage chunk which contains the total\
            \ token usage for the request.\n"
          type: boolean
      nullable: true
    ChatCompletionStreamResponseDelta:
      description: A chat completion delta generated by streamed model responses.
      properties:
        content:
          description: The contents of the chunk message.
          type: string
          nullable: true
        function_call:
          $ref: "#/components/schemas/ChatCompletionStreamResponseDelta_function_call"
        tool_calls:
          items:
            $ref: "#/components/schemas/ChatCompletionMessageToolCallChunk"
          type: array
        role:
          description: The role of the author of this message.
          enum:
          - developer
          - system
          - user
          - assistant
          - tool
          type: string
        refusal:
          description: The refusal message generated by the model.
          type: string
          nullable: true
    ChatCompletionTokenLogprob:
      example:
        top_logprobs:
        - logprob: 7.061401241503109
          bytes:
          - 9
          - 9
          token: token
        - logprob: 7.061401241503109
          bytes:
          - 9
          - 9
          token: token
        logprob: 5.637376656633329
        bytes:
        - 2
        - 2
        token: token
      properties:
        token:
          description: The token.
          type: string
        logprob:
          description: "The log probability of this token, if it is within the top\
            \ 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify\
            \ that the token is very unlikely."
          type: number
        bytes:
          description: A list of integers representing the UTF-8 bytes representation
            of the token. Useful in instances where characters are represented by
            multiple tokens and their byte representations must be combined to generate
            the correct text representation. Can be `null` if there is no bytes representation
            for the token.
          items:
            type: integer
          type: array
          nullable: true
        top_logprobs:
          description: "List of the most likely tokens and their log probability,\
            \ at this token position. In rare cases, there may be fewer than the number\
            \ of requested `top_logprobs` returned."
          items:
            $ref: "#/components/schemas/ChatCompletionTokenLogprob_top_logprobs_inner"
          type: array
      required:
      - bytes
      - logprob
      - token
      - top_logprobs
    ChatCompletionTool:
      example:
        function:
          name: name
          description: description
          strict: false
          parameters:
            key: ""
        type: function
      properties:
        type:
          description: "The type of the tool. Currently, only `function` is supported."
          enum:
          - function
          type: string
          x-stainless-const: true
        function:
          $ref: "#/components/schemas/FunctionObject"
      required:
      - function
      - type
    ChatCompletionToolChoiceOption:
      description: |
        Controls which (if any) tool is called by the model.
        `none` means the model will not call any tool and instead generates a message.
        `auto` means the model can pick between generating a message or calling one or more tools.
        `required` means the model must call one or more tools.
        Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

        `none` is the default when no tools are present. `auto` is the default if tools are present.
      oneOf:
      - description: |
          `none` means the model will not call any tool and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools.
        enum:
        - none
        - auto
        - required
        type: string
      - $ref: "#/components/schemas/ChatCompletionNamedToolChoice"
    ChunkingStrategyRequestParam:
      description: "The chunking strategy used to chunk the file(s). If not set, will\
        \ use the `auto` strategy."
      oneOf:
      - $ref: "#/components/schemas/AutoChunkingStrategyRequestParam"
      - $ref: "#/components/schemas/StaticChunkingStrategyRequestParam"
    Click:
      description: |
        A click action.
      properties:
        type:
          default: click
          description: "Specifies the event type. For a click action, this property\
            \ is \nalways set to `click`.\n"
          enum:
          - click
          type: string
          x-stainless-const: true
        button:
          description: |
            Indicates which mouse button was pressed during the click. One of `left`, `right`, `wheel`, `back`, or `forward`.
          enum:
          - left
          - right
          - wheel
          - back
          - forward
          type: string
        x:
          description: |
            The x-coordinate where the click occurred.
          type: integer
        "y":
          description: |
            The y-coordinate where the click occurred.
          type: integer
      required:
      - button
      - type
      - x
      - "y"
      title: Click
    CodeInterpreterFileOutput:
      description: |
        The output of a code interpreter tool call that is a file.
      properties:
        type:
          description: |
            The type of the code interpreter file output. Always `files`.
          enum:
          - files
          type: string
          x-stainless-const: true
        files:
          items:
            $ref: "#/components/schemas/CodeInterpreterFileOutput_files_inner"
          type: array
      required:
      - files
      - type
      title: Code interpreter file output
    CodeInterpreterOutputImage:
      description: |
        The image output from the code interpreter.
      properties:
        type:
          default: image
          description: The type of the output. Always 'image'.
          enum:
          - image
          type: string
          x-stainless-const: true
        url:
          description: The URL of the image output from the code interpreter.
          type: string
      required:
      - type
      - url
      title: Code interpreter output image
    CodeInterpreterOutputLogs:
      description: |
        The logs output from the code interpreter.
      properties:
        type:
          default: logs
          description: The type of the output. Always 'logs'.
          enum:
          - logs
          type: string
          x-stainless-const: true
        logs:
          description: The logs output from the code interpreter.
          type: string
      required:
      - logs
      - type
      title: Code interpreter output logs
    CodeInterpreterTextOutput:
      description: |
        The output of a code interpreter tool call that is text.
      properties:
        type:
          description: |
            The type of the code interpreter text output. Always `logs`.
          enum:
          - logs
          type: string
          x-stainless-const: true
        logs:
          description: |
            The logs of the code interpreter tool call.
          type: string
      required:
      - logs
      - type
      title: Code interpreter text output
    CodeInterpreterTool:
      description: |
        A tool that runs Python code to help generate a response to a prompt.
      properties:
        type:
          description: |
            The type of the code interpreter tool. Always `code_interpreter`.
          enum:
          - code_interpreter
          type: string
          x-stainless-const: true
        container:
          $ref: "#/components/schemas/CodeInterpreterTool_container"
      required:
      - container
      - type
      title: Code interpreter
    CodeInterpreterToolAuto:
      description: |
        Configuration for a code interpreter container. Optionally specify the IDs
        of the files to run the code on.
      properties:
        type:
          description: Always `auto`.
          enum:
          - auto
          type: string
          x-stainless-const: true
        file_ids:
          description: |
            An optional list of uploaded files to make available to your code.
          items:
            type: string
          type: array
      required:
      - type
      title: CodeInterpreterContainerAuto
    CodeInterpreterToolCall:
      description: |
        A tool call to run code.
      properties:
        type:
          default: code_interpreter_call
          description: |
            The type of the code interpreter tool call. Always `code_interpreter_call`.
          enum:
          - code_interpreter_call
          type: string
          x-stainless-const: true
        id:
          description: |
            The unique ID of the code interpreter tool call.
          type: string
        status:
          description: |
            The status of the code interpreter tool call.
          enum:
          - in_progress
          - completed
          - incomplete
          - interpreting
          - failed
          type: string
        container_id:
          description: |
            The ID of the container used to run the code.
          type: string
        code:
          description: |
            The code to run, or null if not available.
          type: string
          nullable: true
        outputs:
          description: "The outputs generated by the code interpreter, such as logs\
            \ or images. \nCan be null if no outputs are available.\n"
          items:
            $ref: "#/components/schemas/CodeInterpreterToolCall_outputs_inner"
          type: array
          nullable: true
      required:
      - code
      - container_id
      - id
      - outputs
      - status
      - type
      title: Code interpreter tool call
    ComparisonFilter:
      additionalProperties: true
      description: |
        A filter used to compare a specified attribute key to a given value using a defined comparison operation.
      example:
        type: eq
        value: ComparisonFilter_value
        key: key
      properties:
        type:
          default: eq
          description: |
            Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`.
            - `eq`: equals
            - `ne`: not equal
            - `gt`: greater than
            - `gte`: greater than or equal
            - `lt`: less than
            - `lte`: less than or equal
          enum:
          - eq
          - ne
          - gt
          - gte
          - lt
          - lte
          type: string
        key:
          description: The key to compare against the value.
          type: string
        value:
          $ref: "#/components/schemas/ComparisonFilter_value"
      required:
      - key
      - type
      - value
      title: Comparison Filter
      x-oaiMeta:
        name: ComparisonFilter
    CompleteUploadRequest:
      additionalProperties: true
      example:
        part_ids:
        - part_ids
        - part_ids
        md5: md5
      properties:
        part_ids:
          description: |
            The ordered list of Part IDs.
          items:
            type: string
          type: array
        md5:
          description: |
            The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect.
          type: string
      required:
      - part_ids
    CompletionUsage:
      description: Usage statistics for the completion request.
      example:
        completion_tokens: 2
        prompt_tokens: 4
        completion_tokens_details:
          accepted_prediction_tokens: 1
          audio_tokens: 1
          reasoning_tokens: 1
          rejected_prediction_tokens: 6
        prompt_tokens_details:
          audio_tokens: 7
          cached_tokens: 1
        total_tokens: 7
      properties:
        completion_tokens:
          default: 0
          description: Number of tokens in the generated completion.
          type: integer
        prompt_tokens:
          default: 0
          description: Number of tokens in the prompt.
          type: integer
        total_tokens:
          default: 0
          description: Total number of tokens used in the request (prompt + completion).
          type: integer
        completion_tokens_details:
          $ref: "#/components/schemas/CompletionUsage_completion_tokens_details"
        prompt_tokens_details:
          $ref: "#/components/schemas/CompletionUsage_prompt_tokens_details"
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
    CompoundFilter:
      additionalProperties: true
      description: Combine multiple filters using `and` or `or`.
      properties:
        type:
          description: "Type of operation: `and` or `or`."
          enum:
          - and
          - or
          type: string
        filters:
          description: Array of filters to combine. Items can be `ComparisonFilter`
            or `CompoundFilter`.
          items:
            $ref: "#/components/schemas/ComparisonFilter"
          type: array
      required:
      - filters
      - type
      title: Compound Filter
      x-oaiMeta:
        name: CompoundFilter
      $recursiveAnchor: true
    ComputerAction:
      oneOf:
      - $ref: "#/components/schemas/Click"
      - $ref: "#/components/schemas/DoubleClick"
      - $ref: "#/components/schemas/Drag"
      - $ref: "#/components/schemas/KeyPress"
      - $ref: "#/components/schemas/Move"
      - $ref: "#/components/schemas/Screenshot"
      - $ref: "#/components/schemas/Scroll"
      - $ref: "#/components/schemas/Type"
      - $ref: "#/components/schemas/Wait"
    ComputerScreenshotImage:
      description: |
        A computer screenshot image used with the computer use tool.
      properties:
        type:
          default: computer_screenshot
          description: "Specifies the event type. For a computer screenshot, this\
            \ property is \nalways set to `computer_screenshot`.\n"
          enum:
          - computer_screenshot
          type: string
          x-stainless-const: true
        image_url:
          description: The URL of the screenshot image.
          type: string
        file_id:
          description: The identifier of an uploaded file that contains the screenshot.
          type: string
      required:
      - type
    ComputerToolCall:
      description: "A tool call to a computer use tool. See the \n[computer use guide](/docs/guides/tools-computer-use)\
        \ for more information.\n"
      properties:
        type:
          default: computer_call
          description: The type of the computer call. Always `computer_call`.
          enum:
          - computer_call
          type: string
        id:
          description: The unique ID of the computer call.
          type: string
        call_id:
          description: |
            An identifier used when responding to the tool call with output.
          type: string
        action:
          $ref: "#/components/schemas/ComputerAction"
        pending_safety_checks:
          description: |
            The pending safety checks for the computer call.
          items:
            $ref: "#/components/schemas/ComputerToolCallSafetyCheck"
          type: array
        status:
          description: |
            The status of the item. One of `in_progress`, `completed`, or
            `incomplete`. Populated when items are returned via API.
          enum:
          - in_progress
          - completed
          - incomplete
          type: string
      required:
      - action
      - call_id
      - id
      - pending_safety_checks
      - status
      - type
      title: Computer tool call
    ComputerToolCallOutput:
      description: |
        The output of a computer tool call.
      properties:
        type:
          default: computer_call_output
          description: |
            The type of the computer tool call output. Always `computer_call_output`.
          enum:
          - computer_call_output
          type: string
          x-stainless-const: true
        id:
          description: |
            The ID of the computer tool call output.
          type: string
        call_id:
          description: |
            The ID of the computer tool call that produced the output.
          type: string
        acknowledged_safety_checks:
          description: "The safety checks reported by the API that have been acknowledged\
            \ by the \ndeveloper.\n"
          items:
            $ref: "#/components/schemas/ComputerToolCallSafetyCheck"
          type: array
        output:
          $ref: "#/components/schemas/ComputerScreenshotImage"
        status:
          description: |
            The status of the message input. One of `in_progress`, `completed`, or
            `incomplete`. Populated when input items are returned via API.
          enum:
          - in_progress
          - completed
          - incomplete
          type: string
      required:
      - call_id
      - output
      - type
      title: Computer tool call output
    ComputerToolCallOutputResource:
      allOf:
      - $ref: "#/components/schemas/ComputerToolCallOutput"
      - properties:
          id:
            description: |
              The unique ID of the computer call tool output.
            type: string
        required:
        - id
    ComputerToolCallSafetyCheck:
      description: |
        A pending safety check for the computer call.
      properties:
        id:
          description: The ID of the pending safety check.
          type: string
        code:
          description: The type of the pending safety check.
          type: string
        message:
          description: Details about the pending safety check.
          type: string
      required:
      - code
      - id
      - message
    ContainerFileListResource:
      example:
        first_id: first_id
        data:
        - path: path
          bytes: 6
          created_at: 0
          id: id
          source: source
          container_id: container_id
          object: object
        - path: path
          bytes: 6
          created_at: 0
          id: id
          source: source
          container_id: container_id
          object: object
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          description: "The type of object returned, must be 'list'."
          enum:
          - list
          type: string
        data:
          description: A list of container files.
          items:
            $ref: "#/components/schemas/ContainerFileResource"
          type: array
        first_id:
          description: The ID of the first file in the list.
          type: string
        last_id:
          description: The ID of the last file in the list.
          type: string
        has_more:
          description: Whether there are more files available.
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ContainerFileResource:
      example:
        path: path
        bytes: 6
        created_at: 0
        id: id
        source: source
        container_id: container_id
        object: object
      properties:
        id:
          description: Unique identifier for the file.
          type: string
        object:
          description: The type of this object (`container.file`).
          type: string
        container_id:
          description: The container this file belongs to.
          type: string
        created_at:
          description: Unix timestamp (in seconds) when the file was created.
          type: integer
        bytes:
          description: Size of the file in bytes.
          type: integer
        path:
          description: Path of the file in the container.
          type: string
        source:
          description: "Source of the file (e.g., `user`, `assistant`)."
          type: string
      required:
      - bytes
      - container_id
      - created_at
      - id
      - object
      - path
      - source
      title: The container file object
      x-oaiMeta:
        name: The container file object
        example: |
          {
              "id": "cfile_682e0e8a43c88191a7978f477a09bdf5",
              "object": "container.file",
              "created_at": 1747848842,
              "bytes": 880,
              "container_id": "cntr_682e0e7318108198aa783fd921ff305e08e78805b9fdbb04",
              "path": "/mnt/data/88e12fa445d32636f190a0b33daed6cb-tsconfig.json",
              "source": "user"
          }
    ContainerListResource:
      example:
        first_id: first_id
        data:
        - expires_after:
            minutes: 6
            anchor: last_active_at
          name: name
          created_at: 0
          id: id
          object: object
          status: status
        - expires_after:
            minutes: 6
            anchor: last_active_at
          name: name
          created_at: 0
          id: id
          object: object
          status: status
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          description: "The type of object returned, must be 'list'."
          enum:
          - list
          type: string
        data:
          description: A list of containers.
          items:
            $ref: "#/components/schemas/ContainerResource"
          type: array
        first_id:
          description: The ID of the first container in the list.
          type: string
        last_id:
          description: The ID of the last container in the list.
          type: string
        has_more:
          description: Whether there are more containers available.
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ContainerResource:
      example:
        expires_after:
          minutes: 6
          anchor: last_active_at
        name: name
        created_at: 0
        id: id
        object: object
        status: status
      properties:
        id:
          description: Unique identifier for the container.
          type: string
        object:
          description: The type of this object.
          type: string
        name:
          description: Name of the container.
          type: string
        created_at:
          description: Unix timestamp (in seconds) when the container was created.
          type: integer
        status:
          description: "Status of the container (e.g., active, deleted)."
          type: string
        expires_after:
          $ref: "#/components/schemas/ContainerResource_expires_after"
      required:
      - created_at
      - created_at
      - id
      - id
      - name
      - name
      - object
      - status
      - status
      title: The container object
      x-oaiMeta:
        name: The container object
        example: |
          {
             "id": "cntr_682dfebaacac8198bbfe9c2474fb6f4a085685cbe3cb5863",
             "object": "container",
             "created_at": 1747844794,
             "status": "running",
             "expires_after": {
               "anchor": "last_active_at",
               "minutes": 20
             },
             "last_active_at": 1747844794,
             "name": "My Container"
          }
    Content:
      description: |
        Multi-modal input and output contents.
      oneOf:
      - $ref: "#/components/schemas/InputContent"
      - $ref: "#/components/schemas/OutputContent"
    Coordinate:
      description: |
        An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.
      properties:
        x:
          description: |
            The x-coordinate.
          type: integer
        "y":
          description: |
            The y-coordinate.
          type: integer
      required:
      - x
      - "y"
      title: Coordinate
    CostsResult:
      description: The aggregated costs details of the specific time bucket.
      properties:
        object:
          enum:
          - organization.costs.result
          type: string
          x-stainless-const: true
        amount:
          $ref: "#/components/schemas/CostsResult_amount"
        line_item:
          description: "When `group_by=line_item`, this field provides the line item\
            \ of the grouped costs result."
          type: string
          nullable: true
        project_id:
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped costs result."
          type: string
          nullable: true
      required:
      - object
      x-oaiMeta:
        name: Costs object
        example: |
          {
              "object": "organization.costs.result",
              "amount": {
                "value": 0.06,
                "currency": "usd"
              },
              "line_item": "Image models",
              "project_id": "proj_abc"
          }
    CreateAssistantRequest:
      additionalProperties: {}
      example:
        reasoning_effort: medium
        top_p: 1
        instructions: instructions
        tool_resources:
          code_interpreter:
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
          file_search:
            vector_store_ids:
            - vector_store_ids
            vector_stores:
            - chunking_strategy:
                type: auto
              metadata:
                key: metadata
              file_ids:
              - file_ids
              - file_ids
              - file_ids
              - file_ids
              - file_ids
        metadata:
          key: metadata
        response_format: auto
        name: name
        temperature: 1
        description: description
        model: gpt-4o
        tools:
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
      properties:
        model:
          $ref: "#/components/schemas/CreateAssistantRequest_model"
        name:
          description: |
            The name of the assistant. The maximum length is 256 characters.
          maxLength: 256
          nullable: true
        description:
          description: |
            The description of the assistant. The maximum length is 512 characters.
          maxLength: 512
          nullable: true
        instructions:
          description: |
            The system instructions that the assistant uses. The maximum length is 256,000 characters.
          maxLength: 256000
          nullable: true
        reasoning_effort:
          $ref: "#/components/schemas/ReasoningEffort"
        tools:
          default: []
          description: |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: "#/components/schemas/AssistantObject_tools_inner"
          maxItems: 128
        tool_resources:
          $ref: "#/components/schemas/CreateAssistantRequest_tool_resources"
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          example: 1
          maximum: 2
          minimum: 0
          nullable: true
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
          example: 1
          maximum: 1
          minimum: 0
          nullable: true
        response_format:
          $ref: "#/components/schemas/AssistantsApiResponseFormatOption"
      required:
      - model
    CreateChatCompletionRequest:
      allOf:
      - $ref: "#/components/schemas/CreateModelResponseProperties"
      - properties:
          messages:
            description: |
              A list of messages comprising the conversation so far. Depending on the
              [model](/docs/models) you use, different message types (modalities) are
              supported, like [text](/docs/guides/text-generation),
              [images](/docs/guides/vision), and [audio](/docs/guides/audio).
            items:
              $ref: "#/components/schemas/ChatCompletionRequestMessage"
            minItems: 1
            type: array
          model:
            $ref: "#/components/schemas/ModelIdsShared"
          modalities:
            $ref: "#/components/schemas/ResponseModalities"
          reasoning_effort:
            $ref: "#/components/schemas/ReasoningEffort"
          max_completion_tokens:
            description: |
              An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).
            type: integer
            nullable: true
          frequency_penalty:
            default: 0
            description: |
              Number between -2.0 and 2.0. Positive values penalize new tokens based on
              their existing frequency in the text so far, decreasing the model's
              likelihood to repeat the same line verbatim.
            maximum: 2
            minimum: -2
            type: number
            nullable: true
          presence_penalty:
            default: 0
            description: |
              Number between -2.0 and 2.0. Positive values penalize new tokens based on
              whether they appear in the text so far, increasing the model's likelihood
              to talk about new topics.
            maximum: 2
            minimum: -2
            type: number
            nullable: true
          web_search_options:
            $ref: "#/components/schemas/Web_search"
          top_logprobs:
            description: |
              An integer between 0 and 20 specifying the number of most likely tokens to
              return at each token position, each with an associated log probability.
              `logprobs` must be set to `true` if this parameter is used.
            maximum: 20
            minimum: 0
            type: integer
            nullable: true
          response_format:
            $ref: "#/components/schemas/CreateChatCompletionRequest_allOf_response_format"
          audio:
            $ref: "#/components/schemas/CreateChatCompletionRequest_allOf_audio"
          store:
            default: false
            description: "Whether or not to store the output of this chat completion\
              \ request for \nuse in our [model distillation](/docs/guides/distillation)\
              \ or\n[evals](/docs/guides/evals) products. \n\nSupports text and image\
              \ inputs. Note: image inputs over 10MB will be dropped.\n"
            type: boolean
            nullable: true
          stream:
            default: false
            description: |
              If set to true, the model response data will be streamed to the client
              as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).
              See the [Streaming section below](/docs/api-reference/chat/streaming)
              for more information, along with the [streaming responses](/docs/guides/streaming-responses)
              guide for more information on how to handle the streaming events.
            type: boolean
            nullable: true
          stop:
            $ref: "#/components/schemas/StopConfiguration"
          logit_bias:
            additionalProperties:
              type: integer
            description: |
              Modify the likelihood of specified tokens appearing in the completion.

              Accepts a JSON object that maps tokens (specified by their token ID in the
              tokenizer) to an associated bias value from -100 to 100. Mathematically,
              the bias is added to the logits generated by the model prior to sampling.
              The exact effect will vary per model, but values between -1 and 1 should
              decrease or increase likelihood of selection; values like -100 or 100
              should result in a ban or exclusive selection of the relevant token.
            x-oaiTypeLabel: map
            nullable: true
          logprobs:
            default: false
            description: |
              Whether to return log probabilities of the output tokens or not. If true,
              returns the log probabilities of each output token returned in the
              `content` of `message`.
            type: boolean
            nullable: true
          max_tokens:
            deprecated: true
            description: |
              The maximum number of [tokens](/tokenizer) that can be generated in the
              chat completion. This value can be used to control
              [costs](https://openai.com/api/pricing/) for text generated via API.

              This value is now deprecated in favor of `max_completion_tokens`, and is
              not compatible with [o-series models](/docs/guides/reasoning).
            type: integer
            nullable: true
          "n":
            default: 1
            description: How many chat completion choices to generate for each input
              message. Note that you will be charged based on the number of generated
              tokens across all of the choices. Keep `n` as `1` to minimize costs.
            example: 1
            maximum: 128
            minimum: 1
            type: integer
            nullable: true
          prediction:
            $ref: "#/components/schemas/PredictionContent"
          seed:
            description: |
              This feature is in Beta.
              If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
              Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
            maximum: 9223372036854776000
            minimum: -9223372036854776000
            type: integer
            x-oaiMeta:
              beta: true
            nullable: true
          stream_options:
            $ref: "#/components/schemas/ChatCompletionStreamOptions"
          tools:
            description: |
              A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.
            items:
              $ref: "#/components/schemas/ChatCompletionTool"
            type: array
          tool_choice:
            $ref: "#/components/schemas/ChatCompletionToolChoiceOption"
          parallel_tool_calls:
            $ref: "#/components/schemas/ParallelToolCalls"
          function_call:
            $ref: "#/components/schemas/CreateChatCompletionRequest_allOf_function_call"
          functions:
            description: |
              Deprecated in favor of `tools`.

              A list of functions the model may generate JSON inputs for.
            items:
              $ref: "#/components/schemas/ChatCompletionFunctions"
            maxItems: 128
            minItems: 1
            type: array
        required:
        - messages
        - model
      example:
        top_logprobs: 4
        reasoning_effort: medium
        metadata:
          key: metadata
        logit_bias:
          key: 7
        seed: -2147483648
        functions:
        - name: name
          description: description
          parameters:
            key: ""
        - name: name
          description: description
          parameters:
            key: ""
        - name: name
          description: description
          parameters:
            key: ""
        - name: name
          description: description
          parameters:
            key: ""
        - name: name
          description: description
          parameters:
            key: ""
        function_call: none
        presence_penalty: 0.25495066265333133
        tools:
        - function:
            name: name
            description: description
            strict: false
            parameters:
              key: ""
          type: function
        - function:
            name: name
            description: description
            strict: false
            parameters:
              key: ""
          type: function
        web_search_options:
          search_context_size: medium
          user_location:
            approximate:
              country: country
              city: city
              timezone: timezone
              region: region
            type: approximate
        logprobs: false
        top_p: 1
        max_completion_tokens: 1
        modalities:
        - text
        - text
        frequency_penalty: 0.38485356667327286
        response_format:
          type: text
        stream: false
        temperature: 1
        tool_choice: none
        service_tier: auto
        model: gpt-4o
        audio:
          voice: ash
          format: wav
        max_tokens: 9
        store: false
        "n": 1
        stop: |2+

        parallel_tool_calls: null
        prediction:
          type: content
          content: PredictionContent_content
        messages:
        - role: developer
          name: name
          content: ChatCompletionRequestDeveloperMessage_content
        - role: developer
          name: name
          content: ChatCompletionRequestDeveloperMessage_content
        stream_options:
          include_usage: true
        user: user-1234
    CreateChatCompletionResponse:
      description: "Represents a chat completion response returned by model, based\
        \ on the provided input."
      example:
        created: 3
        usage:
          completion_tokens: 2
          prompt_tokens: 4
          completion_tokens_details:
            accepted_prediction_tokens: 1
            audio_tokens: 1
            reasoning_tokens: 1
            rejected_prediction_tokens: 6
          prompt_tokens_details:
            audio_tokens: 7
            cached_tokens: 1
          total_tokens: 7
        model: model
        service_tier: auto
        id: id
        choices:
        - finish_reason: stop
          index: 0
          message:
            role: assistant
            function_call:
              name: name
              arguments: arguments
            refusal: refusal
            annotations:
            - type: url_citation
              url_citation:
                start_index: 1
                end_index: 6
                title: title
                url: url
            - type: url_citation
              url_citation:
                start_index: 1
                end_index: 6
                title: title
                url: url
            tool_calls:
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
            audio:
              expires_at: 5
              transcript: transcript
              data: data
              id: id
            content: content
          logprobs:
            refusal:
            - top_logprobs:
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
            - top_logprobs:
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
            content:
            - top_logprobs:
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
            - top_logprobs:
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
        - finish_reason: stop
          index: 0
          message:
            role: assistant
            function_call:
              name: name
              arguments: arguments
            refusal: refusal
            annotations:
            - type: url_citation
              url_citation:
                start_index: 1
                end_index: 6
                title: title
                url: url
            - type: url_citation
              url_citation:
                start_index: 1
                end_index: 6
                title: title
                url: url
            tool_calls:
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
            audio:
              expires_at: 5
              transcript: transcript
              data: data
              id: id
            content: content
          logprobs:
            refusal:
            - top_logprobs:
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
            - top_logprobs:
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
            content:
            - top_logprobs:
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
            - top_logprobs:
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              - logprob: 7.061401241503109
                bytes:
                - 9
                - 9
                token: token
              logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
        system_fingerprint: system_fingerprint
        object: chat.completion
      properties:
        id:
          description: A unique identifier for the chat completion.
          type: string
        choices:
          description: A list of chat completion choices. Can be more than one if
            `n` is greater than 1.
          items:
            $ref: "#/components/schemas/CreateChatCompletionResponse_choices_inner"
          type: array
        created:
          description: The Unix timestamp (in seconds) of when the chat completion
            was created.
          type: integer
        model:
          description: The model used for the chat completion.
          type: string
        service_tier:
          $ref: "#/components/schemas/ServiceTier"
        system_fingerprint:
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
          type: string
        object:
          description: "The object type, which is always `chat.completion`."
          enum:
          - chat.completion
          type: string
          x-stainless-const: true
        usage:
          $ref: "#/components/schemas/CompletionUsage"
      required:
      - choices
      - created
      - id
      - model
      - object
      x-oaiMeta:
        name: The chat completion object
        group: chat
        example: |
          {
            "id": "chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG",
            "object": "chat.completion",
            "created": 1741570283,
            "model": "gpt-4o-2024-08-06",
            "choices": [
              {
                "index": 0,
                "message": {
                  "role": "assistant",
                  "content": "The image shows a wooden boardwalk path running through a lush green field or meadow. The sky is bright blue with some scattered clouds, giving the scene a serene and peaceful atmosphere. Trees and shrubs are visible in the background.",
                  "refusal": null,
                  "annotations": []
                },
                "logprobs": null,
                "finish_reason": "stop"
              }
            ],
            "usage": {
              "prompt_tokens": 1117,
              "completion_tokens": 46,
              "total_tokens": 1163,
              "prompt_tokens_details": {
                "cached_tokens": 0,
                "audio_tokens": 0
              },
              "completion_tokens_details": {
                "reasoning_tokens": 0,
                "audio_tokens": 0,
                "accepted_prediction_tokens": 0,
                "rejected_prediction_tokens": 0
              }
            },
            "service_tier": "default",
            "system_fingerprint": "fp_fc9f1d7035"
          }
    CreateChatCompletionStreamResponse:
      description: "Represents a streamed chunk of a chat completion response returned\n\
        by the model, based on the provided input. \n[Learn more](/docs/guides/streaming-responses).\n"
      properties:
        id:
          description: A unique identifier for the chat completion. Each chunk has
            the same ID.
          type: string
        choices:
          description: |
            A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
            last chunk if you set `stream_options: {"include_usage": true}`.
          items:
            $ref: "#/components/schemas/CreateChatCompletionStreamResponse_choices_inner"
          type: array
        created:
          description: The Unix timestamp (in seconds) of when the chat completion
            was created. Each chunk has the same timestamp.
          type: integer
        model:
          description: The model to generate the completion.
          type: string
        service_tier:
          $ref: "#/components/schemas/ServiceTier"
        system_fingerprint:
          description: |
            This fingerprint represents the backend configuration that the model runs with.
            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
          type: string
        object:
          description: "The object type, which is always `chat.completion.chunk`."
          enum:
          - chat.completion.chunk
          type: string
          x-stainless-const: true
        usage:
          $ref: "#/components/schemas/CompletionUsage"
      required:
      - choices
      - created
      - id
      - model
      - object
      x-oaiMeta:
        name: The chat completion chunk object
        group: chat
        example: |
          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

          ....

          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
    CreateCompletionRequest:
      example:
        logit_bias:
          key: 1
        seed: 2
        max_tokens: 16
        presence_penalty: 0.25495066265333133
        echo: false
        suffix: test.
        "n": 1
        logprobs: 2
        top_p: 1
        frequency_penalty: 0.4109824732281613
        best_of: 1
        stop: |2+

        stream: false
        temperature: 1
        model: CreateCompletionRequest_model
        stream_options:
          include_usage: true
        prompt: This is a test.
        user: user-1234
      properties:
        model:
          $ref: "#/components/schemas/CreateCompletionRequest_model"
        prompt:
          $ref: "#/components/schemas/CreateCompletionRequest_prompt"
        best_of:
          default: 1
          description: |
            Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

            When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return  `best_of` must be greater than `n`.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
          maximum: 20
          minimum: 0
          type: integer
          nullable: true
        echo:
          default: false
          description: |
            Echo back the prompt in addition to the completion
          type: boolean
          nullable: true
        frequency_penalty:
          default: 0
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation)
          maximum: 2
          minimum: -2
          type: number
          nullable: true
        logit_bias:
          additionalProperties:
            type: integer
          description: |
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

            As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated.
          x-oaiTypeLabel: map
          nullable: true
        logprobs:
          description: |
            Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

            The maximum value for `logprobs` is 5.
          maximum: 5
          minimum: 0
          type: integer
          nullable: true
        max_tokens:
          default: 16
          description: |
            The maximum number of [tokens](/tokenizer) that can be generated in the completion.

            The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
          example: 16
          minimum: 0
          type: integer
          nullable: true
        "n":
          default: 1
          description: |
            How many completions to generate for each prompt.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
          example: 1
          maximum: 128
          minimum: 1
          type: integer
          nullable: true
        presence_penalty:
          default: 0
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation)
          maximum: 2
          minimum: -2
          type: number
          nullable: true
        seed:
          description: |
            If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

            Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
          format: int64
          type: integer
          nullable: true
        stop:
          $ref: "#/components/schemas/StopConfiguration"
        stream:
          default: false
          description: |
            Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
          type: boolean
          nullable: true
        stream_options:
          $ref: "#/components/schemas/ChatCompletionStreamOptions"
        suffix:
          description: |
            The suffix that comes after a completion of inserted text.

            This parameter is only supported for `gpt-3.5-turbo-instruct`.
          example: test.
          type: string
          nullable: true
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

            We generally recommend altering this or `top_p` but not both.
          example: 1
          maximum: 2
          minimum: 0
          type: number
          nullable: true
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or `temperature` but not both.
          example: 1
          maximum: 1
          minimum: 0
          type: number
          nullable: true
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).
          example: user-1234
          type: string
      required:
      - model
      - prompt
    CreateCompletionResponse:
      description: |
        Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).
      example:
        created: 5
        usage:
          completion_tokens: 2
          prompt_tokens: 4
          completion_tokens_details:
            accepted_prediction_tokens: 1
            audio_tokens: 1
            reasoning_tokens: 1
            rejected_prediction_tokens: 6
          prompt_tokens_details:
            audio_tokens: 7
            cached_tokens: 1
          total_tokens: 7
        model: model
        id: id
        choices:
        - finish_reason: stop
          index: 0
          text: text
          logprobs:
            top_logprobs:
            - key: 5.962133916683182
            - key: 5.962133916683182
            token_logprobs:
            - 1.4658129805029452
            - 1.4658129805029452
            tokens:
            - tokens
            - tokens
            text_offset:
            - 6
            - 6
        - finish_reason: stop
          index: 0
          text: text
          logprobs:
            top_logprobs:
            - key: 5.962133916683182
            - key: 5.962133916683182
            token_logprobs:
            - 1.4658129805029452
            - 1.4658129805029452
            tokens:
            - tokens
            - tokens
            text_offset:
            - 6
            - 6
        system_fingerprint: system_fingerprint
        object: text_completion
      properties:
        id:
          description: A unique identifier for the completion.
          type: string
        choices:
          description: The list of completion choices the model generated for the
            input prompt.
          items:
            $ref: "#/components/schemas/CreateCompletionResponse_choices_inner"
          type: array
        created:
          description: The Unix timestamp (in seconds) of when the completion was
            created.
          type: integer
        model:
          description: The model used for completion.
          type: string
        system_fingerprint:
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
          type: string
        object:
          description: "The object type, which is always \"text_completion\""
          enum:
          - text_completion
          type: string
          x-stainless-const: true
        usage:
          $ref: "#/components/schemas/CompletionUsage"
      required:
      - choices
      - created
      - id
      - model
      - object
      x-oaiMeta:
        name: The completion object
        legacy: true
        example: |
          {
            "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
            "object": "text_completion",
            "created": 1589478378,
            "model": "gpt-4-turbo",
            "choices": [
              {
                "text": "\n\nThis is indeed a test",
                "index": 0,
                "logprobs": null,
                "finish_reason": "length"
              }
            ],
            "usage": {
              "prompt_tokens": 5,
              "completion_tokens": 7,
              "total_tokens": 12
            }
          }
    CreateContainerBody:
      example:
        expires_after:
          minutes: 0
          anchor: last_active_at
        name: name
        file_ids:
        - file_ids
        - file_ids
      properties:
        name:
          description: Name of the container to create.
          type: string
        file_ids:
          description: IDs of files to copy to the container.
          items:
            type: string
          type: array
        expires_after:
          $ref: "#/components/schemas/CreateContainerBody_expires_after"
      required:
      - name
    CreateContainerFileBody:
      properties:
        file_id:
          description: Name of the file to create.
          type: string
        file:
          description: |
            The File object (not file name) to be uploaded.
          format: binary
          type: string
    CreateEmbeddingRequest:
      additionalProperties: true
      example:
        input: The quick brown fox jumped over the lazy dog
        encoding_format: float
        model: text-embedding-3-small
        user: user-1234
        dimensions: 1
      properties:
        input:
          $ref: "#/components/schemas/CreateEmbeddingRequest_input"
        model:
          $ref: "#/components/schemas/CreateEmbeddingRequest_model"
        encoding_format:
          default: float
          description: "The format to return the embeddings in. Can be either `float`\
            \ or [`base64`](https://pypi.org/project/pybase64/)."
          enum:
          - float
          - base64
          example: float
          type: string
        dimensions:
          description: |
            The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.
          minimum: 1
          type: integer
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).
          example: user-1234
          type: string
      required:
      - input
      - model
    CreateEmbeddingResponse:
      example:
        data:
        - index: 0
          embedding:
          - 6.0274563
          - 6.0274563
          object: embedding
        - index: 0
          embedding:
          - 6.0274563
          - 6.0274563
          object: embedding
        usage:
          prompt_tokens: 1
          total_tokens: 5
        model: model
        object: list
      properties:
        data:
          description: The list of embeddings generated by the model.
          items:
            $ref: "#/components/schemas/Embedding"
          type: array
        model:
          description: The name of the model used to generate the embedding.
          type: string
        object:
          description: "The object type, which is always \"list\"."
          enum:
          - list
          type: string
          x-stainless-const: true
        usage:
          $ref: "#/components/schemas/CreateEmbeddingResponse_usage"
      required:
      - data
      - model
      - object
      - usage
    CreateEvalCompletionsRunDataSource:
      description: |
        A CompletionsRunDataSource object describing a model sampling configuration.
      properties:
        type:
          default: completions
          description: The type of run data source. Always `completions`.
          enum:
          - completions
          type: string
        input_messages:
          $ref: "#/components/schemas/CreateEvalCompletionsRunDataSource_input_messages"
        sampling_params:
          $ref: "#/components/schemas/CreateEvalCompletionsRunDataSource_sampling_params"
        model:
          description: The name of the model to use for generating completions (e.g.
            "o3-mini").
          type: string
        source:
          $ref: "#/components/schemas/CreateEvalCompletionsRunDataSource_source"
      required:
      - source
      - type
      title: CompletionsRunDataSource
      x-oaiMeta:
        name: The completions data source object used to configure an individual run
        group: eval runs
        example: |
          {
            "name": "gpt-4o-mini-2024-07-18",
            "data_source": {
              "type": "completions",
              "input_messages": {
                "type": "item_reference",
                "item_reference": "item.input"
              },
              "model": "gpt-4o-mini-2024-07-18",
              "source": {
                "type": "stored_completions",
                "model": "gpt-4o-mini-2024-07-18"
              }
            }
          }
    CreateEvalCustomDataSourceConfig:
      description: |
        A CustomDataSourceConfig object that defines the schema for the data source used for the evaluation runs.
        This schema is used to define the shape of the data that will be:
        - Used to define your testing criteria and
        - What data is required when creating a run
      example:
        item_schema: |
          {
            "type": "object",
            "properties": {
              "name": {"type": "string"},
              "age": {"type": "integer"}
            },
            "required": ["name", "age"]
          }
        include_sample_schema: false
        type: custom
      properties:
        type:
          default: custom
          description: The type of data source. Always `custom`.
          enum:
          - custom
          type: string
          x-stainless-const: true
        item_schema:
          additionalProperties: true
          description: The json schema for each row in the data source.
          example: |
            {
              "type": "object",
              "properties": {
                "name": {"type": "string"},
                "age": {"type": "integer"}
              },
              "required": ["name", "age"]
            }
          type: object
        include_sample_schema:
          default: false
          description: "Whether the eval should expect you to populate the sample\
            \ namespace (ie, by generating responses off of your data source)"
          type: boolean
      required:
      - item_schema
      - type
      title: CustomDataSourceConfig
      x-oaiMeta:
        name: The eval file data source config object
        group: evals
        example: |
          {
            "type": "custom",
            "item_schema": {
              "type": "object",
              "properties": {
                "name": {"type": "string"},
                "age": {"type": "integer"}
              },
              "required": ["name", "age"]
            },
            "include_sample_schema": true
          }
    CreateEvalItem:
      description: "A chat message that makes up the prompt or context. May include\
        \ variable references to the `item` namespace, ie {{item.name}}."
      oneOf:
      - $ref: "#/components/schemas/SimpleInputMessage"
      - $ref: "#/components/schemas/EvalItem"
      title: CreateEvalItem
      x-oaiMeta:
        name: The chat message object used to configure an individual run
    CreateEvalJsonlRunDataSource:
      description: "A JsonlRunDataSource object with that specifies a JSONL file that\
        \ matches the eval \n"
      example:
        source:
          type: file_content
          content:
          - item:
              key: ""
            sample:
              key: ""
          - item:
              key: ""
            sample:
              key: ""
        type: jsonl
      properties:
        type:
          default: jsonl
          description: The type of data source. Always `jsonl`.
          enum:
          - jsonl
          type: string
          x-stainless-const: true
        source:
          $ref: "#/components/schemas/CreateEvalJsonlRunDataSource_source"
      required:
      - source
      - type
      title: JsonlRunDataSource
      x-oaiMeta:
        name: The file data source object for the eval run configuration
        group: evals
        example: |
          {
           "type": "jsonl",
           "source": {
             "type": "file_id",
             "id": "file-9GYS6xbkWgWhmE7VoLUWFg"
           }
          }
    CreateEvalLabelModelGrader:
      description: |
        A LabelModelGrader object which uses a model to assign labels to each item
        in the evaluation.
      example:
        input:
        - role: role
          content: content
        - role: role
          content: content
        name: name
        model: model
        passing_labels:
        - passing_labels
        - passing_labels
        type: label_model
        labels:
        - labels
        - labels
      properties:
        type:
          description: "The object type, which is always `label_model`."
          enum:
          - label_model
          type: string
          x-stainless-const: true
        name:
          description: The name of the grader.
          type: string
        model:
          description: The model to use for the evaluation. Must support structured
            outputs.
          type: string
        input:
          description: "A list of chat messages forming the prompt or context. May\
            \ include variable references to the `item` namespace, ie {{item.name}}."
          items:
            $ref: "#/components/schemas/CreateEvalItem"
          type: array
        labels:
          description: The labels to classify to each item in the evaluation.
          items:
            type: string
          type: array
        passing_labels:
          description: The labels that indicate a passing result. Must be a subset
            of labels.
          items:
            type: string
          type: array
      required:
      - input
      - labels
      - model
      - name
      - passing_labels
      - type
      title: LabelModelGrader
      x-oaiMeta:
        name: The eval label model grader object
        group: evals
        example: |
          {
            "type": "label_model",
            "model": "gpt-4o-2024-08-06",
            "input": [
              {
                "role": "system",
                "content": "Classify the sentiment of the following statement as one of 'positive', 'neutral', or 'negative'"
              },
              {
                "role": "user",
                "content": "Statement: {{item.response}}"
              }
            ],
            "passing_labels": ["positive"],
            "labels": ["positive", "neutral", "negative"],
            "name": "Sentiment label grader"
          }
    CreateEvalLogsDataSourceConfig:
      description: |
        A data source config which specifies the metadata property of your logs query.
        This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc.
      properties:
        type:
          default: logs
          description: The type of data source. Always `logs`.
          enum:
          - logs
          type: string
          x-stainless-const: true
        metadata:
          additionalProperties: true
          description: Metadata filters for the logs data source.
          example: |
            {
              "use_case": "customer_support_agent"
            }
          type: object
      required:
      - type
      title: LogsDataSourceConfig
      x-oaiMeta:
        name: The logs data source object for evals
        group: evals
        example: |
          {
            "type": "logs",
            "metadata": {
              "use_case": "customer_support_agent"
            }
          }
    CreateEvalRequest:
      example:
        metadata:
          key: metadata
        name: name
        testing_criteria:
        - input:
          - role: role
            content: content
          - role: role
            content: content
          name: name
          model: model
          passing_labels:
          - passing_labels
          - passing_labels
          type: label_model
          labels:
          - labels
          - labels
        - input:
          - role: role
            content: content
          - role: role
            content: content
          name: name
          model: model
          passing_labels:
          - passing_labels
          - passing_labels
          type: label_model
          labels:
          - labels
          - labels
        data_source_config:
          item_schema: |
            {
              "type": "object",
              "properties": {
                "name": {"type": "string"},
                "age": {"type": "integer"}
              },
              "required": ["name", "age"]
            }
          include_sample_schema: false
          type: custom
      properties:
        name:
          description: The name of the evaluation.
          type: string
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        data_source_config:
          $ref: "#/components/schemas/CreateEvalRequest_data_source_config"
        testing_criteria:
          description: "A list of graders for all eval runs in this group. Graders\
            \ can reference variables in the data source using double curly braces\
            \ notation, like `{{item.variable_name}}`. To reference the model's output,\
            \ use the `sample` namespace (ie, `{{sample.output_text}}`)."
          items:
            $ref: "#/components/schemas/CreateEvalRequest_testing_criteria_inner"
          type: array
      required:
      - data_source_config
      - testing_criteria
      title: CreateEvalRequest
    CreateEvalResponsesRunDataSource:
      description: |
        A ResponsesRunDataSource object describing a model sampling configuration.
      properties:
        type:
          default: responses
          description: The type of run data source. Always `responses`.
          enum:
          - responses
          type: string
        input_messages:
          $ref: "#/components/schemas/CreateEvalResponsesRunDataSource_input_messages"
        sampling_params:
          $ref: "#/components/schemas/CreateEvalResponsesRunDataSource_sampling_params"
        model:
          description: The name of the model to use for generating completions (e.g.
            "o3-mini").
          type: string
        source:
          $ref: "#/components/schemas/CreateEvalResponsesRunDataSource_source"
      required:
      - source
      - type
      title: ResponsesRunDataSource
      x-oaiMeta:
        name: The completions data source object used to configure an individual run
        group: eval runs
        example: |
          {
            "name": "gpt-4o-mini-2024-07-18",
            "data_source": {
              "type": "responses",
              "input_messages": {
                "type": "item_reference",
                "item_reference": "item.input"
              },
              "model": "gpt-4o-mini-2024-07-18",
              "source": {
                "type": "responses",
                "model": "gpt-4o-mini-2024-07-18"
              }
            }
          }
    CreateEvalRunRequest:
      example:
        metadata:
          key: metadata
        name: name
        data_source:
          source:
            type: file_content
            content:
            - item:
                key: ""
              sample:
                key: ""
            - item:
                key: ""
              sample:
                key: ""
          type: jsonl
      properties:
        name:
          description: The name of the run.
          type: string
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        data_source:
          $ref: "#/components/schemas/CreateEvalRunRequest_data_source"
      required:
      - data_source
      title: CreateEvalRunRequest
    CreateEvalStoredCompletionsDataSourceConfig:
      deprecated: true
      description: |
        Deprecated in favor of LogsDataSourceConfig.
      properties:
        type:
          default: stored_completions
          description: The type of data source. Always `stored_completions`.
          enum:
          - stored_completions
          type: string
          x-stainless-const: true
        metadata:
          additionalProperties: true
          description: Metadata filters for the stored completions data source.
          example: |
            {
              "use_case": "customer_support_agent"
            }
          type: object
      required:
      - type
      title: StoredCompletionsDataSourceConfig
      x-oaiMeta:
        name: The stored completions data source object for evals
        group: evals
        example: |
          {
            "type": "stored_completions",
            "metadata": {
              "use_case": "customer_support_agent"
            }
          }
    CreateFileRequest:
      additionalProperties: true
      properties:
        file:
          description: |
            The File object (not file name) to be uploaded.
          format: binary
          type: string
        purpose:
          description: |
            The intended purpose of the uploaded file. One of: - `assistants`: Used in the Assistants API - `batch`: Used in the Batch API - `fine-tune`: Used for fine-tuning - `vision`: Images used for vision fine-tuning - `user_data`: Flexible file type for any purpose - `evals`: Used for eval data sets
          enum:
          - assistants
          - batch
          - fine-tune
          - vision
          - user_data
          - evals
          type: string
      required:
      - file
      - purpose
    CreateFineTuningCheckpointPermissionRequest:
      additionalProperties: true
      example:
        project_ids:
        - project_ids
        - project_ids
      properties:
        project_ids:
          description: The project identifiers to grant access to.
          items:
            type: string
          type: array
      required:
      - project_ids
    CreateFineTuningJobRequest:
      example:
        training_file: file-abc123
        metadata:
          key: metadata
        seed: 42
        method:
          supervised:
            hyperparameters:
              batch_size: auto
              n_epochs: auto
              learning_rate_multiplier: auto
          dpo:
            hyperparameters:
              batch_size: null
              n_epochs: null
              beta: auto
              learning_rate_multiplier: null
          reinforcement:
            hyperparameters:
              reasoning_effort: default
              batch_size: null
              n_epochs: null
              eval_interval: auto
              compute_multiplier: auto
              eval_samples: auto
              learning_rate_multiplier: null
            grader:
              reference: reference
              input: input
              name: name
              type: string_check
              operation: eq
          type: supervised
        validation_file: file-abc123
        hyperparameters:
          batch_size: auto
          n_epochs: auto
          learning_rate_multiplier: auto
        model: gpt-4o-mini
        suffix: suffix
        integrations:
        - wandb:
            name: name
            project: my-wandb-project
            entity: entity
            tags:
            - custom-tag
            - custom-tag
          type: wandb
        - wandb:
            name: name
            project: my-wandb-project
            entity: entity
            tags:
            - custom-tag
            - custom-tag
          type: wandb
      properties:
        model:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_model"
        training_file:
          description: |
            The ID of an uploaded file that contains training data.

            See [upload file](/docs/api-reference/files/create) for how to upload a file.

            Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

            The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input), [completions](/docs/api-reference/fine-tuning/completions-input) format, or if the fine-tuning method uses the [preference](/docs/api-reference/fine-tuning/preference-input) format.

            See the [fine-tuning guide](/docs/guides/model-optimization) for more details.
          example: file-abc123
          type: string
        hyperparameters:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_hyperparameters"
        suffix:
          description: |
            A string of up to 64 characters that will be added to your fine-tuned model name.

            For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.
          maxLength: 64
          minLength: 1
          type: string
          nullable: true
        validation_file:
          description: |
            The ID of an uploaded file that contains validation data.

            If you provide this file, the data is used to generate validation
            metrics periodically during fine-tuning. These metrics can be viewed in
            the fine-tuning results file.
            The same data should not be present in both train and validation files.

            Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

            See the [fine-tuning guide](/docs/guides/model-optimization) for more details.
          example: file-abc123
          type: string
          nullable: true
        integrations:
          description: A list of integrations to enable for your fine-tuning job.
          items:
            $ref: "#/components/schemas/CreateFineTuningJobRequest_integrations_inner"
          type: array
          nullable: true
        seed:
          description: |
            The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
            If a seed is not specified, one will be generated for you.
          example: 42
          maximum: 2147483647
          minimum: 0
          type: integer
          nullable: true
        method:
          $ref: "#/components/schemas/FineTuneMethod"
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
      required:
      - model
      - training_file
    CreateImageEditRequest:
      properties:
        image:
          $ref: "#/components/schemas/CreateImageEditRequest_image"
        prompt:
          description: "A text description of the desired image(s). The maximum length\
            \ is 1000 characters for `dall-e-2`, and 32000 characters for `gpt-image-1`."
          example: A cute baby sea otter wearing a beret
          type: string
        mask:
          description: "An additional image whose fully transparent areas (e.g. where\
            \ alpha is zero) indicate where `image` should be edited. If there are\
            \ multiple images provided, the mask will be applied on the first image.\
            \ Must be a valid PNG file, less than 4MB, and have the same dimensions\
            \ as `image`."
          format: binary
          type: string
        background:
          default: auto
          description: "Allows to set transparency for the background of the generated\
            \ image(s). \nThis parameter is only supported for `gpt-image-1`. Must\
            \ be one of \n`transparent`, `opaque` or `auto` (default value). When\
            \ `auto` is used, the \nmodel will automatically determine the best background\
            \ for the image.\n\nIf `transparent`, the output format needs to support\
            \ transparency, so it \nshould be set to either `png` (default value)\
            \ or `webp`.\n"
          enum:
          - transparent
          - opaque
          - auto
          example: transparent
          type: string
          nullable: true
        model:
          $ref: "#/components/schemas/CreateImageEditRequest_model"
        "n":
          default: 1
          description: The number of images to generate. Must be between 1 and 10.
          example: 1
          maximum: 10
          minimum: 1
          type: integer
          nullable: true
        size:
          default: 1024x1024
          description: "The size of the generated images. Must be one of `1024x1024`,\
            \ `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default\
            \ value) for `gpt-image-1`, and one of `256x256`, `512x512`, or `1024x1024`\
            \ for `dall-e-2`."
          enum:
          - 256x256
          - 512x512
          - 1024x1024
          - 1536x1024
          - 1024x1536
          - auto
          example: 1024x1024
          type: string
          nullable: true
        response_format:
          default: url
          description: "The format in which the generated images are returned. Must\
            \ be one of `url` or `b64_json`. URLs are only valid for 60 minutes after\
            \ the image has been generated. This parameter is only supported for `dall-e-2`,\
            \ as `gpt-image-1` will always return base64-encoded images."
          enum:
          - url
          - b64_json
          example: url
          type: string
          nullable: true
        output_format:
          default: png
          description: |
            The format in which the generated images are returned. This parameter is
            only supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.
            The default value is `png`.
          enum:
          - png
          - jpeg
          - webp
          example: png
          type: string
          nullable: true
        output_compression:
          default: 100
          description: "The compression level (0-100%) for the generated images. This\
            \ parameter \nis only supported for `gpt-image-1` with the `webp` or `jpeg`\
            \ output \nformats, and defaults to 100.\n"
          example: 100
          type: integer
          nullable: true
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).
          example: user-1234
          type: string
        quality:
          default: auto
          description: |
            The quality of the image that will be generated. `high`, `medium` and `low` are only supported for `gpt-image-1`. `dall-e-2` only supports `standard` quality. Defaults to `auto`.
          enum:
          - standard
          - low
          - medium
          - high
          - auto
          example: high
          type: string
          nullable: true
      required:
      - image
      - prompt
    CreateImageRequest:
      example:
        response_format: url
        output_format: png
        size: 1024x1024
        output_compression: 100
        background: transparent
        moderation: low
        model: gpt-image-1
        style: vivid
        prompt: A cute baby sea otter
        user: user-1234
        "n": 1
        quality: medium
      properties:
        prompt:
          description: "A text description of the desired image(s). The maximum length\
            \ is 32000 characters for `gpt-image-1`, 1000 characters for `dall-e-2`\
            \ and 4000 characters for `dall-e-3`."
          example: A cute baby sea otter
          type: string
        model:
          $ref: "#/components/schemas/CreateImageRequest_model"
        "n":
          default: 1
          description: "The number of images to generate. Must be between 1 and 10.\
            \ For `dall-e-3`, only `n=1` is supported."
          example: 1
          maximum: 10
          minimum: 1
          type: integer
          nullable: true
        quality:
          default: auto
          description: "The quality of the image that will be generated. \n\n- `auto`\
            \ (default value) will automatically select the best quality for the given\
            \ model.\n- `high`, `medium` and `low` are supported for `gpt-image-1`.\n\
            - `hd` and `standard` are supported for `dall-e-3`.\n- `standard` is the\
            \ only option for `dall-e-2`.\n"
          enum:
          - standard
          - hd
          - low
          - medium
          - high
          - auto
          example: medium
          type: string
          nullable: true
        response_format:
          default: url
          description: The format in which generated images with `dall-e-2` and `dall-e-3`
            are returned. Must be one of `url` or `b64_json`. URLs are only valid
            for 60 minutes after the image has been generated. This parameter isn't
            supported for `gpt-image-1` which will always return base64-encoded images.
          enum:
          - url
          - b64_json
          example: url
          type: string
          nullable: true
        output_format:
          default: png
          description: "The format in which the generated images are returned. This\
            \ parameter is only supported for `gpt-image-1`. Must be one of `png`,\
            \ `jpeg`, or `webp`."
          enum:
          - png
          - jpeg
          - webp
          example: png
          type: string
          nullable: true
        output_compression:
          default: 100
          description: "The compression level (0-100%) for the generated images. This\
            \ parameter is only supported for `gpt-image-1` with the `webp` or `jpeg`\
            \ output formats, and defaults to 100."
          example: 100
          type: integer
          nullable: true
        size:
          default: auto
          description: "The size of the generated images. Must be one of `1024x1024`,\
            \ `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default\
            \ value) for `gpt-image-1`, one of `256x256`, `512x512`, or `1024x1024`\
            \ for `dall-e-2`, and one of `1024x1024`, `1792x1024`, or `1024x1792`\
            \ for `dall-e-3`."
          enum:
          - auto
          - 1024x1024
          - 1536x1024
          - 1024x1536
          - 256x256
          - 512x512
          - 1792x1024
          - 1024x1792
          example: 1024x1024
          type: string
          nullable: true
        moderation:
          default: auto
          description: Control the content-moderation level for images generated by
            `gpt-image-1`. Must be either `low` for less restrictive filtering or
            `auto` (default value).
          enum:
          - low
          - auto
          example: low
          type: string
          nullable: true
        background:
          default: auto
          description: "Allows to set transparency for the background of the generated\
            \ image(s). \nThis parameter is only supported for `gpt-image-1`. Must\
            \ be one of \n`transparent`, `opaque` or `auto` (default value). When\
            \ `auto` is used, the \nmodel will automatically determine the best background\
            \ for the image.\n\nIf `transparent`, the output format needs to support\
            \ transparency, so it \nshould be set to either `png` (default value)\
            \ or `webp`.\n"
          enum:
          - transparent
          - opaque
          - auto
          example: transparent
          type: string
          nullable: true
        style:
          default: vivid
          description: "The style of the generated images. This parameter is only\
            \ supported for `dall-e-3`. Must be one of `vivid` or `natural`. Vivid\
            \ causes the model to lean towards generating hyper-real and dramatic\
            \ images. Natural causes the model to produce more natural, less hyper-real\
            \ looking images."
          enum:
          - vivid
          - natural
          example: vivid
          type: string
          nullable: true
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).
          example: user-1234
          type: string
      required:
      - prompt
    CreateImageVariationRequest:
      properties:
        image:
          description: "The image to use as the basis for the variation(s). Must be\
            \ a valid PNG file, less than 4MB, and square."
          format: binary
          type: string
        model:
          $ref: "#/components/schemas/CreateImageVariationRequest_model"
        "n":
          default: 1
          description: The number of images to generate. Must be between 1 and 10.
          example: 1
          maximum: 10
          minimum: 1
          type: integer
          nullable: true
        response_format:
          default: url
          description: The format in which the generated images are returned. Must
            be one of `url` or `b64_json`. URLs are only valid for 60 minutes after
            the image has been generated.
          enum:
          - url
          - b64_json
          example: url
          type: string
          nullable: true
        size:
          default: 1024x1024
          description: "The size of the generated images. Must be one of `256x256`,\
            \ `512x512`, or `1024x1024`."
          enum:
          - 256x256
          - 512x512
          - 1024x1024
          example: 1024x1024
          type: string
          nullable: true
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).
          example: user-1234
          type: string
      required:
      - image
    CreateMessageRequest:
      additionalProperties: true
      example:
        metadata:
          key: metadata
        role: user
        attachments:
        - file_id: file_id
          tools:
          - type: code_interpreter
          - type: code_interpreter
        - file_id: file_id
          tools:
          - type: code_interpreter
          - type: code_interpreter
        content: CreateMessageRequest_content
      properties:
        role:
          description: |
            The role of the entity that is creating the message. Allowed values include:
            - `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
            - `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.
          enum:
          - user
          - assistant
          type: string
        content:
          $ref: "#/components/schemas/CreateMessageRequest_content"
        attachments:
          description: "A list of files attached to the message, and the tools they\
            \ should be added to."
          items:
            $ref: "#/components/schemas/CreateMessageRequest_attachments_inner"
          type: array
          nullable: true
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
      required:
      - content
      - role
    CreateModelResponseProperties:
      allOf:
      - $ref: "#/components/schemas/ModelResponseProperties"
      - properties:
          top_logprobs:
            description: |
              An integer between 0 and 20 specifying the number of most likely tokens to
              return at each token position, each with an associated log probability.
            maximum: 20
            minimum: 0
            type: integer
    CreateModerationRequest:
      example:
        input: I want to kill them.
        model: omni-moderation-2024-09-26
      properties:
        input:
          $ref: "#/components/schemas/CreateModerationRequest_input"
        model:
          $ref: "#/components/schemas/CreateModerationRequest_model"
      required:
      - input
    CreateModerationResponse:
      description: Represents if a given text input is potentially harmful.
      example:
        model: model
        id: id
        results:
        - category_scores:
            illicit/violent: 2.3021358869347655
            self-harm/instructions: 3.616076749251911
            harassment: 1.4658129805029452
            violence/graphic: 1.2315135367772556
            illicit: 5.637376656633329
            self-harm/intent: 9.301444243932576
            hate/threatening: 6.027456183070403
            sexual/minors: 4.145608029883936
            harassment/threatening: 5.962133916683182
            hate: 0.8008281904610115
            self-harm: 7.061401241503109
            sexual: 2.027123023002322
            violence: 7.386281948385884
          flagged: true
          category_applied_input_types:
            illicit/violent:
            - text
            - text
            self-harm/instructions:
            - text
            - text
            harassment:
            - text
            - text
            violence/graphic:
            - text
            - text
            illicit:
            - text
            - text
            self-harm/intent:
            - text
            - text
            hate/threatening:
            - text
            - text
            sexual/minors:
            - text
            - text
            harassment/threatening:
            - text
            - text
            hate:
            - text
            - text
            self-harm:
            - text
            - text
            sexual:
            - text
            - text
            violence:
            - text
            - text
          categories:
            illicit/violent: true
            self-harm/instructions: true
            harassment: true
            violence/graphic: true
            illicit: true
            self-harm/intent: true
            hate/threatening: true
            sexual/minors: true
            harassment/threatening: true
            hate: true
            self-harm: true
            sexual: true
            violence: true
        - category_scores:
            illicit/violent: 2.3021358869347655
            self-harm/instructions: 3.616076749251911
            harassment: 1.4658129805029452
            violence/graphic: 1.2315135367772556
            illicit: 5.637376656633329
            self-harm/intent: 9.301444243932576
            hate/threatening: 6.027456183070403
            sexual/minors: 4.145608029883936
            harassment/threatening: 5.962133916683182
            hate: 0.8008281904610115
            self-harm: 7.061401241503109
            sexual: 2.027123023002322
            violence: 7.386281948385884
          flagged: true
          category_applied_input_types:
            illicit/violent:
            - text
            - text
            self-harm/instructions:
            - text
            - text
            harassment:
            - text
            - text
            violence/graphic:
            - text
            - text
            illicit:
            - text
            - text
            self-harm/intent:
            - text
            - text
            hate/threatening:
            - text
            - text
            sexual/minors:
            - text
            - text
            harassment/threatening:
            - text
            - text
            hate:
            - text
            - text
            self-harm:
            - text
            - text
            sexual:
            - text
            - text
            violence:
            - text
            - text
          categories:
            illicit/violent: true
            self-harm/instructions: true
            harassment: true
            violence/graphic: true
            illicit: true
            self-harm/intent: true
            hate/threatening: true
            sexual/minors: true
            harassment/threatening: true
            hate: true
            self-harm: true
            sexual: true
            violence: true
      properties:
        id:
          description: The unique identifier for the moderation request.
          type: string
        model:
          description: The model used to generate the moderation results.
          type: string
        results:
          description: A list of moderation objects.
          items:
            $ref: "#/components/schemas/CreateModerationResponse_results_inner"
          type: array
      required:
      - id
      - model
      - results
      x-oaiMeta:
        name: The moderation object
        example: |
          {
            "id": "modr-0d9740456c391e43c445bf0f010940c7",
            "model": "omni-moderation-latest",
            "results": [
              {
                "flagged": true,
                "categories": {
                  "harassment": true,
                  "harassment/threatening": true,
                  "sexual": false,
                  "hate": false,
                  "hate/threatening": false,
                  "illicit": false,
                  "illicit/violent": false,
                  "self-harm/intent": false,
                  "self-harm/instructions": false,
                  "self-harm": false,
                  "sexual/minors": false,
                  "violence": true,
                  "violence/graphic": true
                },
                "category_scores": {
                  "harassment": 0.8189693396524255,
                  "harassment/threatening": 0.804985420696006,
                  "sexual": 1.573112165348997e-6,
                  "hate": 0.007562942636942845,
                  "hate/threatening": 0.004208854591835476,
                  "illicit": 0.030535955153511665,
                  "illicit/violent": 0.008925306722380033,
                  "self-harm/intent": 0.00023023930975076432,
                  "self-harm/instructions": 0.0002293869201073356,
                  "self-harm": 0.012598046106750154,
                  "sexual/minors": 2.212566909570261e-8,
                  "violence": 0.9999992735124786,
                  "violence/graphic": 0.843064871157054
                },
                "category_applied_input_types": {
                  "harassment": [
                    "text"
                  ],
                  "harassment/threatening": [
                    "text"
                  ],
                  "sexual": [
                    "text",
                    "image"
                  ],
                  "hate": [
                    "text"
                  ],
                  "hate/threatening": [
                    "text"
                  ],
                  "illicit": [
                    "text"
                  ],
                  "illicit/violent": [
                    "text"
                  ],
                  "self-harm/intent": [
                    "text",
                    "image"
                  ],
                  "self-harm/instructions": [
                    "text",
                    "image"
                  ],
                  "self-harm": [
                    "text",
                    "image"
                  ],
                  "sexual/minors": [
                    "text"
                  ],
                  "violence": [
                    "text",
                    "image"
                  ],
                  "violence/graphic": [
                    "text",
                    "image"
                  ]
                }
              }
            ]
          }
    CreateResponse:
      allOf:
      - $ref: "#/components/schemas/CreateModelResponseProperties"
      - $ref: "#/components/schemas/ResponseProperties"
      - properties:
          input:
            $ref: "#/components/schemas/CreateResponse_allOf_input"
          include:
            description: |
              Specify additional output data to include in the model response. Currently
              supported values are:
              - `code_interpreter_call.outputs`: Includes the outputs of python code execution
                in code interpreter tool call items.
              - `computer_call_output.output.image_url`: Include image urls from the computer call output.
              - `file_search_call.results`: Include the search results of
                the file search tool call.
              - `message.input_image.image_url`: Include image urls from the input message.
              - `message.output_text.logprobs`: Include logprobs with assistant messages.
              - `reasoning.encrypted_content`: Includes an encrypted version of reasoning
                tokens in reasoning item outputs. This enables reasoning items to be used in
                multi-turn conversations when using the Responses API statelessly (like
                when the `store` parameter is set to `false`, or when an organization is
                enrolled in the zero data retention program).
            items:
              $ref: "#/components/schemas/Includable"
            type: array
            nullable: true
          parallel_tool_calls:
            default: true
            description: |
              Whether to allow the model to run tool calls in parallel.
            type: boolean
            nullable: true
          store:
            default: true
            description: |
              Whether to store the generated model response for later retrieval via
              API.
            type: boolean
            nullable: true
          instructions:
            description: |
              A system (or developer) message inserted into the model's context.

              When using along with `previous_response_id`, the instructions from a previous
              response will not be carried over to the next response. This makes it simple
              to swap out system (or developer) messages in new responses.
            type: string
            nullable: true
          stream:
            default: false
            description: |
              If set to true, the model response data will be streamed to the client
              as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).
              See the [Streaming section below](/docs/api-reference/responses-streaming)
              for more information.
            type: boolean
            nullable: true
      example:
        top_logprobs: 12
        include:
        - code_interpreter_call.outputs
        - code_interpreter_call.outputs
        instructions: instructions
        metadata:
          key: metadata
        max_tool_calls: 5
        reasoning:
          summary: auto
          effort: medium
          generate_summary: auto
        store: true
        tools:
        - name: name
          description: description
          type: function
          strict: true
          parameters:
            key: ""
        - name: name
          description: description
          type: function
          strict: true
          parameters:
            key: ""
        top_p: 1
        input: CreateResponse_allOf_input
        previous_response_id: previous_response_id
        parallel_tool_calls: true
        stream: false
        background: false
        temperature: 1
        tool_choice: none
        service_tier: auto
        model: gpt-4o
        text:
          format:
            type: text
        user: user-1234
        prompt:
          variables:
            key: ResponsePromptVariables_value
          id: id
          version: version
        truncation: disabled
        max_output_tokens: 1
    CreateRunRequest:
      additionalProperties: true
      example:
        reasoning_effort: medium
        instructions: instructions
        additional_instructions: additional_instructions
        metadata:
          key: metadata
        assistant_id: assistant_id
        additional_messages:
        - metadata:
            key: metadata
          role: user
          attachments:
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          content: CreateMessageRequest_content
        - metadata:
            key: metadata
          role: user
          attachments:
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          content: CreateMessageRequest_content
        tools:
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        truncation_strategy: ""
        top_p: 1
        max_completion_tokens: 256
        response_format: auto
        parallel_tool_calls: true
        stream: true
        temperature: 1
        tool_choice: ""
        model: gpt-4o
        max_prompt_tokens: 256
      properties:
        assistant_id:
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ to use to execute this run."
          type: string
        model:
          $ref: "#/components/schemas/CreateRunRequest_model"
        reasoning_effort:
          $ref: "#/components/schemas/ReasoningEffort"
        instructions:
          description: "Overrides the [instructions](/docs/api-reference/assistants/createAssistant)\
            \ of the assistant. This is useful for modifying the behavior on a per-run\
            \ basis."
          type: string
          nullable: true
        additional_instructions:
          description: Appends additional instructions at the end of the instructions
            for the run. This is useful for modifying the behavior on a per-run basis
            without overriding other instructions.
          type: string
          nullable: true
        additional_messages:
          description: Adds additional messages to the thread before creating the
            run.
          items:
            $ref: "#/components/schemas/CreateMessageRequest"
          type: array
          nullable: true
        tools:
          description: Override the tools the assistant can use for this run. This
            is useful for modifying the behavior on a per-run basis.
          items:
            $ref: "#/components/schemas/AssistantObject_tools_inner"
          maxItems: 20
          type: array
          nullable: true
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          example: 1
          maximum: 2
          minimum: 0
          type: number
          nullable: true
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
          example: 1
          maximum: 1
          minimum: 0
          type: number
          nullable: true
        stream:
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.
          type: boolean
          nullable: true
        max_prompt_tokens:
          description: |
            The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
          type: integer
          nullable: true
        max_completion_tokens:
          description: |
            The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
          type: integer
          nullable: true
        truncation_strategy:
          allOf:
          - $ref: "#/components/schemas/TruncationObject"
          nullable: true
        tool_choice:
          allOf:
          - $ref: "#/components/schemas/AssistantsApiToolChoiceOption"
          nullable: true
        parallel_tool_calls:
          default: true
          description: "Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling)\
            \ during tool use."
          type: boolean
        response_format:
          $ref: "#/components/schemas/AssistantsApiResponseFormatOption"
      required:
      - assistant_id
    CreateSpeechRequest:
      additionalProperties: true
      example:
        voice: ash
        input: input
        instructions: instructions
        response_format: mp3
        model: CreateSpeechRequest_model
        stream_format: audio
        speed: 0.5503105714228793
      properties:
        model:
          $ref: "#/components/schemas/CreateSpeechRequest_model"
        input:
          description: The text to generate audio for. The maximum length is 4096
            characters.
          maxLength: 4096
          type: string
        instructions:
          description: Control the voice of your generated audio with additional instructions.
            Does not work with `tts-1` or `tts-1-hd`.
          maxLength: 4096
          type: string
        voice:
          $ref: "#/components/schemas/VoiceIdsShared"
        response_format:
          default: mp3
          description: "The format to audio in. Supported formats are `mp3`, `opus`,\
            \ `aac`, `flac`, `wav`, and `pcm`."
          enum:
          - mp3
          - opus
          - aac
          - flac
          - wav
          - pcm
          type: string
        speed:
          default: 1
          description: The speed of the generated audio. Select a value from `0.25`
            to `4.0`. `1.0` is the default.
          maximum: 4
          minimum: 0.25
          type: number
        stream_format:
          default: audio
          description: The format to stream the audio in. Supported formats are `sse`
            and `audio`. `sse` is not supported for `tts-1` or `tts-1-hd`.
          enum:
          - sse
          - audio
          type: string
      required:
      - input
      - model
      - voice
    CreateSpeechResponseStreamEvent:
      anyOf:
      - $ref: "#/components/schemas/SpeechAudioDeltaEvent"
      - $ref: "#/components/schemas/SpeechAudioDoneEvent"
      discriminator:
        propertyName: type
    CreateThreadAndRunRequest:
      additionalProperties: true
      example:
        instructions: instructions
        tool_resources:
          code_interpreter:
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
          file_search:
            vector_store_ids:
            - vector_store_ids
        metadata:
          key: metadata
        assistant_id: assistant_id
        thread:
          tool_resources:
            code_interpreter:
              file_ids:
              - file_ids
              - file_ids
              - file_ids
              - file_ids
              - file_ids
            file_search:
              vector_store_ids:
              - vector_store_ids
              vector_stores:
              - chunking_strategy:
                  type: auto
                metadata:
                  key: metadata
                file_ids:
                - file_ids
                - file_ids
                - file_ids
                - file_ids
                - file_ids
          metadata:
            key: metadata
          messages:
          - metadata:
              key: metadata
            role: user
            attachments:
            - file_id: file_id
              tools:
              - type: code_interpreter
              - type: code_interpreter
            - file_id: file_id
              tools:
              - type: code_interpreter
              - type: code_interpreter
            content: CreateMessageRequest_content
          - metadata:
              key: metadata
            role: user
            attachments:
            - file_id: file_id
              tools:
              - type: code_interpreter
              - type: code_interpreter
            - file_id: file_id
              tools:
              - type: code_interpreter
              - type: code_interpreter
            content: CreateMessageRequest_content
        tools:
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        truncation_strategy: ""
        top_p: 1
        max_completion_tokens: 256
        response_format: auto
        parallel_tool_calls: true
        stream: true
        temperature: 1
        tool_choice: ""
        model: gpt-4o
        max_prompt_tokens: 256
      properties:
        assistant_id:
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ to use to execute this run."
          type: string
        thread:
          $ref: "#/components/schemas/CreateThreadRequest"
        model:
          $ref: "#/components/schemas/CreateThreadAndRunRequest_model"
        instructions:
          description: Override the default system message of the assistant. This
            is useful for modifying the behavior on a per-run basis.
          type: string
          nullable: true
        tools:
          description: Override the tools the assistant can use for this run. This
            is useful for modifying the behavior on a per-run basis.
          items:
            $ref: "#/components/schemas/AssistantObject_tools_inner"
          maxItems: 20
          type: array
          nullable: true
        tool_resources:
          $ref: "#/components/schemas/CreateThreadAndRunRequest_tool_resources"
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          example: 1
          maximum: 2
          minimum: 0
          type: number
          nullable: true
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
          example: 1
          maximum: 1
          minimum: 0
          type: number
          nullable: true
        stream:
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.
          type: boolean
          nullable: true
        max_prompt_tokens:
          description: |
            The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
          type: integer
          nullable: true
        max_completion_tokens:
          description: |
            The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
          type: integer
          nullable: true
        truncation_strategy:
          allOf:
          - $ref: "#/components/schemas/TruncationObject"
          nullable: true
        tool_choice:
          allOf:
          - $ref: "#/components/schemas/AssistantsApiToolChoiceOption"
          nullable: true
        parallel_tool_calls:
          default: true
          description: "Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling)\
            \ during tool use."
          type: boolean
        response_format:
          $ref: "#/components/schemas/AssistantsApiResponseFormatOption"
      required:
      - assistant_id
    CreateThreadRequest:
      additionalProperties: {}
      description: "Options to create a new thread. If no thread is provided when\
        \ running a \nrequest, an empty thread will be created.\n"
      example:
        tool_resources:
          code_interpreter:
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
          file_search:
            vector_store_ids:
            - vector_store_ids
            vector_stores:
            - chunking_strategy:
                type: auto
              metadata:
                key: metadata
              file_ids:
              - file_ids
              - file_ids
              - file_ids
              - file_ids
              - file_ids
        metadata:
          key: metadata
        messages:
        - metadata:
            key: metadata
          role: user
          attachments:
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          content: CreateMessageRequest_content
        - metadata:
            key: metadata
          role: user
          attachments:
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          content: CreateMessageRequest_content
      properties:
        messages:
          description: "A list of [messages](/docs/api-reference/messages) to start\
            \ the thread with."
          items:
            $ref: "#/components/schemas/CreateMessageRequest"
        tool_resources:
          $ref: "#/components/schemas/CreateThreadRequest_tool_resources"
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
    CreateTranscriptionRequest:
      additionalProperties: true
      properties:
        file:
          description: |
            The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
          format: binary
          type: string
          x-oaiTypeLabel: file
        model:
          $ref: "#/components/schemas/CreateTranscriptionRequest_model"
        language:
          description: |
            The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format will improve accuracy and latency.
          type: string
        prompt:
          description: |
            An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should match the audio language.
          type: string
        response_format:
          $ref: "#/components/schemas/AudioResponseFormat"
        temperature:
          default: 0
          description: |
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.
          type: number
        include[]:
          description: "Additional information to include in the transcription response.\
            \ \n`logprobs` will return the log probabilities of the tokens in the\
            \ \nresponse to understand the model's confidence in the transcription.\
            \ \n`logprobs` only works with response_format set to `json` and only\
            \ with \nthe models `gpt-4o-transcribe` and `gpt-4o-mini-transcribe`.\n"
          items:
            $ref: "#/components/schemas/TranscriptionInclude"
          type: array
        timestamp_granularities[]:
          default:
          - segment
          description: |
            The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.
          items:
            enum:
            - word
            - segment
            type: string
          type: array
        stream:
          default: false
          description: "If set to true, the model response data will be streamed to\
            \ the client\nas it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\
            \ \nSee the [Streaming section of the Speech-to-Text guide](/docs/guides/speech-to-text?lang=curl#streaming-transcriptions)\n\
            for more information.\n\nNote: Streaming is not supported for the `whisper-1`\
            \ model and will be ignored.\n"
          type: boolean
          nullable: true
        chunking_strategy:
          $ref: "#/components/schemas/CreateTranscriptionRequest_chunking_strategy"
      required:
      - file
      - model
    CreateTranscriptionResponseJson:
      description: "Represents a transcription response returned by model, based on\
        \ the provided input."
      example:
        usage:
          total_tokens: 7
          input_token_details:
            audio_tokens: 5
            text_tokens: 5
          output_tokens: 2
          type: tokens
          input_tokens: 1
        text: text
        logprobs:
        - logprob: 0.8008281904610115
          bytes:
          - 6.027456183070403
          - 6.027456183070403
          token: token
        - logprob: 0.8008281904610115
          bytes:
          - 6.027456183070403
          - 6.027456183070403
          token: token
      properties:
        text:
          description: The transcribed text.
          type: string
        logprobs:
          description: |
            The log probabilities of the tokens in the transcription. Only returned with the models `gpt-4o-transcribe` and `gpt-4o-mini-transcribe` if `logprobs` is added to the `include` array.
          items:
            $ref: "#/components/schemas/CreateTranscriptionResponseJson_logprobs_inner"
          type: array
          optional: true
        usage:
          $ref: "#/components/schemas/CreateTranscriptionResponseJson_usage"
      required:
      - text
      x-oaiMeta:
        name: The transcription object (JSON)
        group: audio
        example: |
          {
            "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that.",
            "usage": {
              "type": "tokens",
              "input_tokens": 14,
              "input_token_details": {
                "text_tokens": 10,
                "audio_tokens": 4
              },
              "output_tokens": 101,
              "total_tokens": 115
            }
          }
    CreateTranscriptionResponseStreamEvent:
      anyOf:
      - $ref: "#/components/schemas/TranscriptTextDeltaEvent"
      - $ref: "#/components/schemas/TranscriptTextDoneEvent"
      discriminator:
        propertyName: type
    CreateTranscriptionResponseVerboseJson:
      description: "Represents a verbose json transcription response returned by model,\
        \ based on the provided input."
      properties:
        language:
          description: The language of the input audio.
          type: string
        duration:
          description: The duration of the input audio.
          type: number
        text:
          description: The transcribed text.
          type: string
        words:
          description: Extracted words and their corresponding timestamps.
          items:
            $ref: "#/components/schemas/TranscriptionWord"
          type: array
        segments:
          description: Segments of the transcribed text and their corresponding details.
          items:
            $ref: "#/components/schemas/TranscriptionSegment"
          type: array
        usage:
          $ref: "#/components/schemas/TranscriptTextUsageDuration"
      required:
      - duration
      - language
      - text
      x-oaiMeta:
        name: The transcription object (Verbose JSON)
        group: audio
        example: |
          {
            "task": "transcribe",
            "language": "english",
            "duration": 8.470000267028809,
            "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
            "segments": [
              {
                "id": 0,
                "seek": 0,
                "start": 0.0,
                "end": 3.319999933242798,
                "text": " The beach was a popular spot on a hot summer day.",
                "tokens": [
                  50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530
                ],
                "temperature": 0.0,
                "avg_logprob": -0.2860786020755768,
                "compression_ratio": 1.2363636493682861,
                "no_speech_prob": 0.00985979475080967
              },
              ...
            ],
            "usage": {
              "type": "duration",
              "seconds": 9
            }
          }
    CreateTranslationRequest:
      additionalProperties: true
      properties:
        file:
          description: |
            The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
          format: binary
          type: string
          x-oaiTypeLabel: file
        model:
          $ref: "#/components/schemas/CreateTranslationRequest_model"
        prompt:
          description: |
            An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should be in English.
          type: string
        response_format:
          default: json
          description: |
            The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.
          enum:
          - json
          - text
          - srt
          - verbose_json
          - vtt
          type: string
        temperature:
          default: 0
          description: |
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.
          type: number
      required:
      - file
      - model
    CreateTranslationResponseJson:
      example:
        text: text
      properties:
        text:
          type: string
      required:
      - text
    CreateTranslationResponseVerboseJson:
      properties:
        language:
          description: The language of the output translation (always `english`).
          type: string
        duration:
          description: The duration of the input audio.
          type: number
        text:
          description: The translated text.
          type: string
        segments:
          description: Segments of the translated text and their corresponding details.
          items:
            $ref: "#/components/schemas/TranscriptionSegment"
          type: array
      required:
      - duration
      - language
      - text
    CreateUploadRequest:
      additionalProperties: true
      example:
        filename: filename
        purpose: assistants
        mime_type: mime_type
        bytes: 0
      properties:
        filename:
          description: |
            The name of the file to upload.
          type: string
        purpose:
          description: |
            The intended purpose of the uploaded file.

            See the [documentation on File purposes](/docs/api-reference/files/create#files-create-purpose).
          enum:
          - assistants
          - batch
          - fine-tune
          - vision
          type: string
        bytes:
          description: |
            The number of bytes in the file you are uploading.
          type: integer
        mime_type:
          description: |
            The MIME type of the file.

            This must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision.
          type: string
      required:
      - bytes
      - filename
      - mime_type
      - purpose
    CreateVectorStoreFileBatchRequest:
      additionalProperties: true
      example:
        chunking_strategy:
          type: auto
        file_ids:
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        attributes:
          key: VectorStoreFileAttributes_value
      properties:
        file_ids:
          description: "A list of [File](/docs/api-reference/files) IDs that the vector\
            \ store should use. Useful for tools like `file_search` that can access\
            \ files."
          items:
            type: string
          maxItems: 500
          minItems: 1
          type: array
        chunking_strategy:
          $ref: "#/components/schemas/ChunkingStrategyRequestParam"
        attributes:
          additionalProperties:
            $ref: "#/components/schemas/VectorStoreFileAttributes_value"
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be \nuseful for storing additional information about the object\
            \ in a structured \nformat, and querying for objects via API or the dashboard.\
            \ Keys are strings \nwith a maximum length of 64 characters. Values are\
            \ strings with a maximum \nlength of 512 characters, booleans, or numbers.\n"
          maxProperties: 16
          x-oaiTypeLabel: map
          nullable: true
      required:
      - file_ids
    CreateVectorStoreFileRequest:
      additionalProperties: true
      example:
        chunking_strategy:
          type: auto
        file_id: file_id
        attributes:
          key: VectorStoreFileAttributes_value
      properties:
        file_id:
          description: "A [File](/docs/api-reference/files) ID that the vector store\
            \ should use. Useful for tools like `file_search` that can access files."
          type: string
        chunking_strategy:
          $ref: "#/components/schemas/ChunkingStrategyRequestParam"
        attributes:
          additionalProperties:
            $ref: "#/components/schemas/VectorStoreFileAttributes_value"
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be \nuseful for storing additional information about the object\
            \ in a structured \nformat, and querying for objects via API or the dashboard.\
            \ Keys are strings \nwith a maximum length of 64 characters. Values are\
            \ strings with a maximum \nlength of 512 characters, booleans, or numbers.\n"
          maxProperties: 16
          x-oaiTypeLabel: map
          nullable: true
      required:
      - file_id
    CreateVectorStoreRequest:
      additionalProperties: true
      example:
        chunking_strategy:
          type: auto
        metadata:
          key: metadata
        expires_after:
          anchor: last_active_at
          days: 339
        file_ids:
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        name: name
      properties:
        file_ids:
          description: "A list of [File](/docs/api-reference/files) IDs that the vector\
            \ store should use. Useful for tools like `file_search` that can access\
            \ files."
          items:
            type: string
          maxItems: 500
          type: array
        name:
          description: The name of the vector store.
          type: string
        expires_after:
          $ref: "#/components/schemas/VectorStoreExpirationAfter"
        chunking_strategy:
          $ref: "#/components/schemas/CreateVectorStoreRequest_chunking_strategy"
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
    DeleteAssistantResponse:
      example:
        deleted: true
        id: id
        object: assistant.deleted
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
          - assistant.deleted
          type: string
          x-stainless-const: true
      required:
      - deleted
      - id
      - object
    DeleteCertificateResponse:
      example:
        id: id
        object: certificate.deleted
      properties:
        object:
          description: "The object type, must be `certificate.deleted`."
          enum:
          - certificate.deleted
          type: string
          x-stainless-const: true
        id:
          description: The ID of the certificate that was deleted.
          type: string
      required:
      - id
      - object
    DeleteFileResponse:
      example:
        deleted: true
        id: id
        object: file
      properties:
        id:
          type: string
        object:
          enum:
          - file
          type: string
          x-stainless-const: true
        deleted:
          type: boolean
      required:
      - deleted
      - id
      - object
    DeleteFineTuningCheckpointPermissionResponse:
      example:
        deleted: true
        id: id
        object: checkpoint.permission
      properties:
        id:
          description: The ID of the fine-tuned model checkpoint permission that was
            deleted.
          type: string
        object:
          description: "The object type, which is always \"checkpoint.permission\"\
            ."
          enum:
          - checkpoint.permission
          type: string
          x-stainless-const: true
        deleted:
          description: Whether the fine-tuned model checkpoint permission was successfully
            deleted.
          type: boolean
      required:
      - deleted
      - id
      - object
    DeleteMessageResponse:
      example:
        deleted: true
        id: id
        object: thread.message.deleted
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
          - thread.message.deleted
          type: string
          x-stainless-const: true
      required:
      - deleted
      - id
      - object
    DeleteModelResponse:
      example:
        deleted: true
        id: id
        object: object
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          type: string
      required:
      - deleted
      - id
      - object
    DeleteThreadResponse:
      example:
        deleted: true
        id: id
        object: thread.deleted
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
          - thread.deleted
          type: string
          x-stainless-const: true
      required:
      - deleted
      - id
      - object
    DeleteVectorStoreFileResponse:
      example:
        deleted: true
        id: id
        object: vector_store.file.deleted
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
          - vector_store.file.deleted
          type: string
          x-stainless-const: true
      required:
      - deleted
      - id
      - object
    DeleteVectorStoreResponse:
      example:
        deleted: true
        id: id
        object: vector_store.deleted
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
          - vector_store.deleted
          type: string
          x-stainless-const: true
      required:
      - deleted
      - id
      - object
    DoneEvent:
      description: Occurs when a stream ends.
      properties:
        event:
          enum:
          - done
          type: string
          x-stainless-const: true
        data:
          enum:
          - "[DONE]"
          type: string
          x-stainless-const: true
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is `[DONE]`"
    DoubleClick:
      description: |
        A double click action.
      properties:
        type:
          default: double_click
          description: "Specifies the event type. For a double click action, this\
            \ property is \nalways set to `double_click`.\n"
          enum:
          - double_click
          type: string
          x-stainless-const: true
        x:
          description: |
            The x-coordinate where the double click occurred.
          type: integer
        "y":
          description: |
            The y-coordinate where the double click occurred.
          type: integer
      required:
      - type
      - x
      - "y"
      title: DoubleClick
    Drag:
      description: |
        A drag action.
      properties:
        type:
          default: drag
          description: "Specifies the event type. For a drag action, this property\
            \ is \nalways set to `drag`.\n"
          enum:
          - drag
          type: string
          x-stainless-const: true
        path:
          description: |
            An array of coordinates representing the path of the drag action. Coordinates will appear as an array
            of objects, eg
            ```
            [
              { x: 100, y: 200 },
              { x: 200, y: 300 }
            ]
            ```
          items:
            $ref: "#/components/schemas/Coordinate"
          type: array
      required:
      - path
      - type
      title: Drag
    EasyInputMessage:
      description: |
        A message input to the model with a role indicating instruction following
        hierarchy. Instructions given with the `developer` or `system` role take
        precedence over instructions given with the `user` role. Messages with the
        `assistant` role are presumed to have been generated by the model in previous
        interactions.
      properties:
        role:
          description: |
            The role of the message input. One of `user`, `assistant`, `system`, or
            `developer`.
          enum:
          - user
          - assistant
          - system
          - developer
          type: string
        content:
          $ref: "#/components/schemas/EasyInputMessage_content"
        type:
          description: |
            The type of the message input. Always `message`.
          enum:
          - message
          type: string
          x-stainless-const: true
      required:
      - content
      - role
      title: Input message
    Embedding:
      description: |
        Represents an embedding vector returned by embedding endpoint.
      example:
        index: 0
        embedding:
        - 6.0274563
        - 6.0274563
        object: embedding
      properties:
        index:
          description: The index of the embedding in the list of embeddings.
          type: integer
        embedding:
          description: |
            The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings).
          items:
            format: float
            type: number
          type: array
        object:
          description: "The object type, which is always \"embedding\"."
          enum:
          - embedding
          type: string
          x-stainless-const: true
      required:
      - embedding
      - index
      - object
      x-oaiMeta:
        name: The embedding object
        example: |
          {
            "object": "embedding",
            "embedding": [
              0.0023064255,
              -0.009327292,
              .... (1536 floats total for ada-002)
              -0.0028842222,
            ],
            "index": 0
          }
    Error:
      example:
        code: code
        param: param
        message: message
        type: type
      properties:
        code:
          type: string
          nullable: true
        message:
          type: string
          nullable: false
        param:
          type: string
          nullable: true
        type:
          type: string
          nullable: false
      required:
      - code
      - message
      - param
      - type
    ErrorEvent:
      description: "Occurs when an [error](/docs/guides/error-codes#api-errors) occurs.\
        \ This can happen due to an internal server error or a timeout."
      properties:
        event:
          enum:
          - error
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/Error"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is an [error](/docs/guides/error-codes#api-errors)"
    ErrorResponse:
      example:
        error:
          code: code
          param: param
          message: message
          type: type
      properties:
        error:
          $ref: "#/components/schemas/Error"
      required:
      - error
    Eval:
      description: |
        An Eval object with a data source config and testing criteria.
        An Eval represents a task to be done for your LLM integration.
        Like:
         - Improve the quality of my chatbot
         - See how well my chatbot handles customer support
         - Check if o4-mini is better at my usecase than gpt-4o
      example:
        metadata:
          key: metadata
        name: Chatbot effectiveness Evaluation
        testing_criteria:
        - input:
          - role: user
            type: message
            content: EvalItem_content
          - role: user
            type: message
            content: EvalItem_content
          name: name
          model: model
          passing_labels:
          - passing_labels
          - passing_labels
          type: label_model
          labels:
          - labels
          - labels
        - input:
          - role: user
            type: message
            content: EvalItem_content
          - role: user
            type: message
            content: EvalItem_content
          name: name
          model: model
          passing_labels:
          - passing_labels
          - passing_labels
          type: label_model
          labels:
          - labels
          - labels
        created_at: 0
        id: id
        data_source_config:
          schema: |
            {
              "type": "object",
              "properties": {
                "item": {
                  "type": "object",
                  "properties": {
                    "label": {"type": "string"},
                  },
                  "required": ["label"]
                }
              },
              "required": ["item"]
            }
          type: custom
        object: eval
      properties:
        object:
          default: eval
          description: The object type.
          enum:
          - eval
          type: string
          x-stainless-const: true
        id:
          description: Unique identifier for the evaluation.
          type: string
        name:
          description: The name of the evaluation.
          example: Chatbot effectiveness Evaluation
          type: string
        data_source_config:
          $ref: "#/components/schemas/Eval_data_source_config"
        testing_criteria:
          default: eval
          description: A list of testing criteria.
          items:
            $ref: "#/components/schemas/Eval_testing_criteria_inner"
          type: array
        created_at:
          description: The Unix timestamp (in seconds) for when the eval was created.
          type: integer
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
      required:
      - created_at
      - data_source_config
      - id
      - metadata
      - name
      - object
      - testing_criteria
      title: Eval
      x-oaiMeta:
        name: The eval object
        group: evals
        example: |
          {
            "object": "eval",
            "id": "eval_67abd54d9b0081909a86353f6fb9317a",
            "data_source_config": {
              "type": "custom",
              "item_schema": {
                "type": "object",
                "properties": {
                  "label": {"type": "string"},
                },
                "required": ["label"]
              },
              "include_sample_schema": true
            },
            "testing_criteria": [
              {
                "name": "My string check grader",
                "type": "string_check",
                "input": "{{sample.output_text}}",
                "reference": "{{item.label}}",
                "operation": "eq",
              }
            ],
            "name": "External Data Eval",
            "created_at": 1739314509,
            "metadata": {
              "test": "synthetics",
            }
          }
    EvalApiError:
      description: |
        An object representing an error response from the Eval API.
      example:
        code: code
        message: message
      properties:
        code:
          description: The error code.
          type: string
        message:
          description: The error message.
          type: string
      required:
      - code
      - message
      title: EvalApiError
      x-oaiMeta:
        name: The API error object
        group: evals
        example: |
          {
            "code": "internal_error",
            "message": "The eval run failed due to an internal error."
          }
    EvalCustomDataSourceConfig:
      description: |
        A CustomDataSourceConfig which specifies the schema of your `item` and optionally `sample` namespaces.
        The response schema defines the shape of the data that will be:
        - Used to define your testing criteria and
        - What data is required when creating a run
      example:
        schema: |
          {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "label": {"type": "string"},
                },
                "required": ["label"]
              }
            },
            "required": ["item"]
          }
        type: custom
      properties:
        type:
          default: custom
          description: The type of data source. Always `custom`.
          enum:
          - custom
          type: string
          x-stainless-const: true
        schema:
          additionalProperties: true
          description: |
            The json schema for the run data source items.
            Learn how to build JSON schemas [here](https://json-schema.org/).
          example: |
            {
              "type": "object",
              "properties": {
                "item": {
                  "type": "object",
                  "properties": {
                    "label": {"type": "string"},
                  },
                  "required": ["label"]
                }
              },
              "required": ["item"]
            }
          type: object
      required:
      - schema
      - type
      title: CustomDataSourceConfig
      x-oaiMeta:
        name: The eval custom data source config object
        group: evals
        example: |
          {
            "type": "custom",
            "schema": {
              "type": "object",
              "properties": {
                "item": {
                  "type": "object",
                  "properties": {
                    "label": {"type": "string"},
                  },
                  "required": ["label"]
                }
              },
              "required": ["item"]
            }
          }
    EvalGraderLabelModel:
      allOf:
      - $ref: "#/components/schemas/GraderLabelModel"
      example:
        input:
        - role: user
          type: message
          content: EvalItem_content
        - role: user
          type: message
          content: EvalItem_content
        name: name
        model: model
        passing_labels:
        - passing_labels
        - passing_labels
        type: label_model
        labels:
        - labels
        - labels
      title: LabelModelGrader
    EvalGraderPython:
      allOf:
      - $ref: "#/components/schemas/GraderPython"
      - properties:
          pass_threshold:
            description: The threshold for the score.
            type: number
        x-oaiMeta:
          name: Eval Python Grader
          group: graders
          example: |
            {
              "type": "python",
              "name": "Example python grader",
              "image_tag": "2025-05-08",
              "source": """
            def grade(sample: dict, item: dict) -> float:
                \"""
                Returns 1.0 if `output_text` equals `label`, otherwise 0.0.
                \"""
                output = sample.get("output_text")
                label = item.get("label")
                return 1.0 if output == label else 0.0
            """,
              "pass_threshold": 0.8
            }
      title: PythonGrader
    EvalGraderScoreModel:
      allOf:
      - $ref: "#/components/schemas/GraderScoreModel"
      - properties:
          pass_threshold:
            description: The threshold for the score.
            type: number
      title: ScoreModelGrader
    EvalGraderStringCheck:
      allOf:
      - $ref: "#/components/schemas/GraderStringCheck"
      title: StringCheckGrader
    EvalGraderTextSimilarity:
      allOf:
      - $ref: "#/components/schemas/GraderTextSimilarity"
      - properties:
          pass_threshold:
            description: The threshold for the score.
            type: number
        required:
        - pass_threshold
        x-oaiMeta:
          name: Text Similarity Grader
          group: graders
          example: |
            {
              "type": "text_similarity",
              "name": "Example text similarity grader",
              "input": "{{sample.output_text}}",
              "reference": "{{item.label}}",
              "pass_threshold": 0.8,
              "evaluation_metric": "fuzzy_match"
            }
      title: TextSimilarityGrader
    EvalItem:
      description: |
        A message input to the model with a role indicating instruction following
        hierarchy. Instructions given with the `developer` or `system` role take
        precedence over instructions given with the `user` role. Messages with the
        `assistant` role are presumed to have been generated by the model in previous
        interactions.
      example:
        role: user
        type: message
        content: EvalItem_content
      properties:
        role:
          description: |
            The role of the message input. One of `user`, `assistant`, `system`, or
            `developer`.
          enum:
          - user
          - assistant
          - system
          - developer
          type: string
        content:
          $ref: "#/components/schemas/EvalItem_content"
        type:
          description: |
            The type of the message input. Always `message`.
          enum:
          - message
          type: string
          x-stainless-const: true
      required:
      - content
      - role
      title: Eval message object
    EvalJsonlFileContentSource:
      example:
        type: file_content
        content:
        - item:
            key: ""
          sample:
            key: ""
        - item:
            key: ""
          sample:
            key: ""
      properties:
        type:
          default: file_content
          description: The type of jsonl source. Always `file_content`.
          enum:
          - file_content
          type: string
          x-stainless-const: true
        content:
          description: The content of the jsonl file.
          items:
            $ref: "#/components/schemas/EvalJsonlFileContentSource_content_inner"
          type: array
      required:
      - content
      - type
      title: EvalJsonlFileContentSource
    EvalJsonlFileIdSource:
      properties:
        type:
          default: file_id
          description: The type of jsonl source. Always `file_id`.
          enum:
          - file_id
          type: string
          x-stainless-const: true
        id:
          description: The identifier of the file.
          type: string
      required:
      - id
      - type
      title: EvalJsonlFileIdSource
    EvalList:
      description: |
        An object representing a list of evals.
      example:
        first_id: first_id
        data:
        - metadata:
            key: metadata
          name: Chatbot effectiveness Evaluation
          testing_criteria:
          - input:
            - role: user
              type: message
              content: EvalItem_content
            - role: user
              type: message
              content: EvalItem_content
            name: name
            model: model
            passing_labels:
            - passing_labels
            - passing_labels
            type: label_model
            labels:
            - labels
            - labels
          - input:
            - role: user
              type: message
              content: EvalItem_content
            - role: user
              type: message
              content: EvalItem_content
            name: name
            model: model
            passing_labels:
            - passing_labels
            - passing_labels
            type: label_model
            labels:
            - labels
            - labels
          created_at: 0
          id: id
          data_source_config:
            schema: |
              {
                "type": "object",
                "properties": {
                  "item": {
                    "type": "object",
                    "properties": {
                      "label": {"type": "string"},
                    },
                    "required": ["label"]
                  }
                },
                "required": ["item"]
              }
            type: custom
          object: eval
        - metadata:
            key: metadata
          name: Chatbot effectiveness Evaluation
          testing_criteria:
          - input:
            - role: user
              type: message
              content: EvalItem_content
            - role: user
              type: message
              content: EvalItem_content
            name: name
            model: model
            passing_labels:
            - passing_labels
            - passing_labels
            type: label_model
            labels:
            - labels
            - labels
          - input:
            - role: user
              type: message
              content: EvalItem_content
            - role: user
              type: message
              content: EvalItem_content
            name: name
            model: model
            passing_labels:
            - passing_labels
            - passing_labels
            type: label_model
            labels:
            - labels
            - labels
          created_at: 0
          id: id
          data_source_config:
            schema: |
              {
                "type": "object",
                "properties": {
                  "item": {
                    "type": "object",
                    "properties": {
                      "label": {"type": "string"},
                    },
                    "required": ["label"]
                  }
                },
                "required": ["item"]
              }
            type: custom
          object: eval
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          default: list
          description: |
            The type of this object. It is always set to "list".
          enum:
          - list
          type: string
          x-stainless-const: true
        data:
          description: |
            An array of eval objects.
          items:
            $ref: "#/components/schemas/Eval"
          type: array
        first_id:
          description: The identifier of the first eval in the data array.
          type: string
        last_id:
          description: The identifier of the last eval in the data array.
          type: string
        has_more:
          description: Indicates whether there are more evals available.
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      title: EvalList
      x-oaiMeta:
        name: The eval list object
        group: evals
        example: |
          {
            "object": "list",
            "data": [
              {
                "object": "eval",
                "id": "eval_67abd54d9b0081909a86353f6fb9317a",
                "data_source_config": {
                  "type": "custom",
                  "schema": {
                    "type": "object",
                    "properties": {
                      "item": {
                        "type": "object",
                        "properties": {
                          "input": {
                            "type": "string"
                          },
                          "ground_truth": {
                            "type": "string"
                          }
                        },
                        "required": [
                          "input",
                          "ground_truth"
                        ]
                      }
                    },
                    "required": [
                      "item"
                    ]
                  }
                },
                "testing_criteria": [
                  {
                    "name": "String check",
                    "id": "String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2",
                    "type": "string_check",
                    "input": "{{item.input}}",
                    "reference": "{{item.ground_truth}}",
                    "operation": "eq"
                  }
                ],
                "name": "External Data Eval",
                "created_at": 1739314509,
                "metadata": {},
              }
            ],
            "first_id": "eval_67abd54d9b0081909a86353f6fb9317a",
            "last_id": "eval_67abd54d9b0081909a86353f6fb9317a",
            "has_more": true
          }
    EvalLogsDataSourceConfig:
      description: |
        A LogsDataSourceConfig which specifies the metadata property of your logs query.
        This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc.
        The schema returned by this data source config is used to defined what variables are available in your evals.
        `item` and `sample` are both defined when using this data source config.
      properties:
        type:
          default: logs
          description: The type of data source. Always `logs`.
          enum:
          - logs
          type: string
          x-stainless-const: true
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        schema:
          additionalProperties: true
          description: |
            The json schema for the run data source items.
            Learn how to build JSON schemas [here](https://json-schema.org/).
          type: object
      required:
      - schema
      - type
      title: LogsDataSourceConfig
      x-oaiMeta:
        name: The logs data source object for evals
        group: evals
        example: |
          {
            "type": "logs",
            "metadata": {
              "language": "english"
            },
            "schema": {
              "type": "object",
              "properties": {
                "item": {
                  "type": "object"
                },
                "sample": {
                  "type": "object"
                }
              },
              "required": [
                "item",
                "sample"
              }
          }
    EvalResponsesSource:
      description: |
        A EvalResponsesSource object describing a run data source configuration.
      properties:
        type:
          description: The type of run data source. Always `responses`.
          enum:
          - responses
          type: string
        metadata:
          description: Metadata filter for the responses. This is a query parameter
            used to select responses.
          type: object
          nullable: true
        model:
          description: The name of the model to find responses for. This is a query
            parameter used to select responses.
          type: string
          nullable: true
        instructions_search:
          description: Optional string to search the 'instructions' field. This is
            a query parameter used to select responses.
          type: string
          nullable: true
        created_after:
          description: Only include items created after this timestamp (inclusive).
            This is a query parameter used to select responses.
          minimum: 0
          type: integer
          nullable: true
        created_before:
          description: Only include items created before this timestamp (inclusive).
            This is a query parameter used to select responses.
          minimum: 0
          type: integer
          nullable: true
        reasoning_effort:
          $ref: "#/components/schemas/ReasoningEffort"
        temperature:
          description: Sampling temperature. This is a query parameter used to select
            responses.
          type: number
          nullable: true
        top_p:
          description: Nucleus sampling parameter. This is a query parameter used
            to select responses.
          type: number
          nullable: true
        users:
          description: List of user identifiers. This is a query parameter used to
            select responses.
          items:
            type: string
          type: array
          nullable: true
        tools:
          description: List of tool names. This is a query parameter used to select
            responses.
          items:
            type: string
          type: array
          nullable: true
      required:
      - type
      title: EvalResponsesSource
      x-oaiMeta:
        name: The run data source object used to configure an individual run
        group: eval runs
        example: |
          {
            "type": "responses",
            "model": "gpt-4o-mini-2024-07-18",
            "temperature": 0.7,
            "top_p": 1.0,
            "users": ["user1", "user2"],
            "tools": ["tool1", "tool2"],
            "instructions_search": "You are a coding assistant"
          }
    EvalRun:
      description: |
        A schema representing an evaluation run.
      example:
        per_testing_criteria_results:
        - testing_criteria: testing_criteria
          passed: 4
          failed: 7
        - testing_criteria: testing_criteria
          passed: 4
          failed: 7
        metadata:
          key: metadata
        eval_id: eval_id
        report_url: report_url
        created_at: 0
        error:
          code: code
          message: message
        data_source:
          source:
            type: file_content
            content:
            - item:
                key: ""
              sample:
                key: ""
            - item:
                key: ""
              sample:
                key: ""
          type: jsonl
        result_counts:
          total: 6
          failed: 5
          passed: 5
          errored: 1
        name: name
        model: model
        id: id
        per_model_usage:
        - completion_tokens: 9
          prompt_tokens: 7
          model_name: model_name
          total_tokens: 3
          invocation_count: 2
          cached_tokens: 2
        - completion_tokens: 9
          prompt_tokens: 7
          model_name: model_name
          total_tokens: 3
          invocation_count: 2
          cached_tokens: 2
        object: eval.run
        status: status
      properties:
        object:
          default: eval.run
          description: The type of the object. Always "eval.run".
          enum:
          - eval.run
          type: string
          x-stainless-const: true
        id:
          description: Unique identifier for the evaluation run.
          type: string
        eval_id:
          description: The identifier of the associated evaluation.
          type: string
        status:
          description: The status of the evaluation run.
          type: string
        model:
          description: "The model that is evaluated, if applicable."
          type: string
        name:
          description: The name of the evaluation run.
          type: string
        created_at:
          description: Unix timestamp (in seconds) when the evaluation run was created.
          type: integer
        report_url:
          description: The URL to the rendered evaluation run report on the UI dashboard.
          type: string
        result_counts:
          $ref: "#/components/schemas/EvalRun_result_counts"
        per_model_usage:
          description: Usage statistics for each model during the evaluation run.
          items:
            $ref: "#/components/schemas/EvalRun_per_model_usage_inner"
          type: array
        per_testing_criteria_results:
          description: Results per testing criteria applied during the evaluation
            run.
          items:
            $ref: "#/components/schemas/EvalRun_per_testing_criteria_results_inner"
          type: array
        data_source:
          $ref: "#/components/schemas/EvalRun_data_source"
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        error:
          $ref: "#/components/schemas/EvalApiError"
      required:
      - created_at
      - data_source
      - error
      - eval_id
      - id
      - metadata
      - model
      - name
      - object
      - per_model_usage
      - per_testing_criteria_results
      - report_url
      - result_counts
      - status
      title: EvalRun
      x-oaiMeta:
        name: The eval run object
        group: evals
        example: |
          {
            "object": "eval.run",
            "id": "evalrun_67e57965b480819094274e3a32235e4c",
            "eval_id": "eval_67e579652b548190aaa83ada4b125f47",
            "report_url": "https://platform.openai.com/evaluations/eval_67e579652b548190aaa83ada4b125f47?run_id=evalrun_67e57965b480819094274e3a32235e4c",
            "status": "queued",
            "model": "gpt-4o-mini",
            "name": "gpt-4o-mini",
            "created_at": 1743092069,
            "result_counts": {
              "total": 0,
              "errored": 0,
              "failed": 0,
              "passed": 0
            },
            "per_model_usage": null,
            "per_testing_criteria_results": null,
            "data_source": {
              "type": "completions",
              "source": {
                "type": "file_content",
                "content": [
                  {
                    "item": {
                      "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                      "ground_truth": "Technology"
                    }
                  },
                  {
                    "item": {
                      "input": "Central Bank Increases Interest Rates Amid Inflation Concerns",
                      "ground_truth": "Markets"
                    }
                  },
                  {
                    "item": {
                      "input": "International Summit Addresses Climate Change Strategies",
                      "ground_truth": "World"
                    }
                  },
                  {
                    "item": {
                      "input": "Major Retailer Reports Record-Breaking Holiday Sales",
                      "ground_truth": "Business"
                    }
                  },
                  {
                    "item": {
                      "input": "National Team Qualifies for World Championship Finals",
                      "ground_truth": "Sports"
                    }
                  },
                  {
                    "item": {
                      "input": "Stock Markets Rally After Positive Economic Data Released",
                      "ground_truth": "Markets"
                    }
                  },
                  {
                    "item": {
                      "input": "Global Manufacturer Announces Merger with Competitor",
                      "ground_truth": "Business"
                    }
                  },
                  {
                    "item": {
                      "input": "Breakthrough in Renewable Energy Technology Unveiled",
                      "ground_truth": "Technology"
                    }
                  },
                  {
                    "item": {
                      "input": "World Leaders Sign Historic Climate Agreement",
                      "ground_truth": "World"
                    }
                  },
                  {
                    "item": {
                      "input": "Professional Athlete Sets New Record in Championship Event",
                      "ground_truth": "Sports"
                    }
                  },
                  {
                    "item": {
                      "input": "Financial Institutions Adapt to New Regulatory Requirements",
                      "ground_truth": "Business"
                    }
                  },
                  {
                    "item": {
                      "input": "Tech Conference Showcases Advances in Artificial Intelligence",
                      "ground_truth": "Technology"
                    }
                  },
                  {
                    "item": {
                      "input": "Global Markets Respond to Oil Price Fluctuations",
                      "ground_truth": "Markets"
                    }
                  },
                  {
                    "item": {
                      "input": "International Cooperation Strengthened Through New Treaty",
                      "ground_truth": "World"
                    }
                  },
                  {
                    "item": {
                      "input": "Sports League Announces Revised Schedule for Upcoming Season",
                      "ground_truth": "Sports"
                    }
                  }
                ]
              },
              "input_messages": {
                "type": "template",
                "template": [
                  {
                    "type": "message",
                    "role": "developer",
                    "content": {
                      "type": "input_text",
                      "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
                    }
                  },
                  {
                    "type": "message",
                    "role": "user",
                    "content": {
                      "type": "input_text",
                      "text": "{{item.input}}"
                    }
                  }
                ]
              },
              "model": "gpt-4o-mini",
              "sampling_params": {
                "seed": 42,
                "temperature": 1.0,
                "top_p": 1.0,
                "max_completions_tokens": 2048
              }
            },
            "error": null,
            "metadata": {}
          }
    EvalRunList:
      description: |
        An object representing a list of runs for an evaluation.
      example:
        first_id: first_id
        data:
        - per_testing_criteria_results:
          - testing_criteria: testing_criteria
            passed: 4
            failed: 7
          - testing_criteria: testing_criteria
            passed: 4
            failed: 7
          metadata:
            key: metadata
          eval_id: eval_id
          report_url: report_url
          created_at: 0
          error:
            code: code
            message: message
          data_source:
            source:
              type: file_content
              content:
              - item:
                  key: ""
                sample:
                  key: ""
              - item:
                  key: ""
                sample:
                  key: ""
            type: jsonl
          result_counts:
            total: 6
            failed: 5
            passed: 5
            errored: 1
          name: name
          model: model
          id: id
          per_model_usage:
          - completion_tokens: 9
            prompt_tokens: 7
            model_name: model_name
            total_tokens: 3
            invocation_count: 2
            cached_tokens: 2
          - completion_tokens: 9
            prompt_tokens: 7
            model_name: model_name
            total_tokens: 3
            invocation_count: 2
            cached_tokens: 2
          object: eval.run
          status: status
        - per_testing_criteria_results:
          - testing_criteria: testing_criteria
            passed: 4
            failed: 7
          - testing_criteria: testing_criteria
            passed: 4
            failed: 7
          metadata:
            key: metadata
          eval_id: eval_id
          report_url: report_url
          created_at: 0
          error:
            code: code
            message: message
          data_source:
            source:
              type: file_content
              content:
              - item:
                  key: ""
                sample:
                  key: ""
              - item:
                  key: ""
                sample:
                  key: ""
            type: jsonl
          result_counts:
            total: 6
            failed: 5
            passed: 5
            errored: 1
          name: name
          model: model
          id: id
          per_model_usage:
          - completion_tokens: 9
            prompt_tokens: 7
            model_name: model_name
            total_tokens: 3
            invocation_count: 2
            cached_tokens: 2
          - completion_tokens: 9
            prompt_tokens: 7
            model_name: model_name
            total_tokens: 3
            invocation_count: 2
            cached_tokens: 2
          object: eval.run
          status: status
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          default: list
          description: |
            The type of this object. It is always set to "list".
          enum:
          - list
          type: string
          x-stainless-const: true
        data:
          description: |
            An array of eval run objects.
          items:
            $ref: "#/components/schemas/EvalRun"
          type: array
        first_id:
          description: The identifier of the first eval run in the data array.
          type: string
        last_id:
          description: The identifier of the last eval run in the data array.
          type: string
        has_more:
          description: Indicates whether there are more evals available.
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      title: EvalRunList
      x-oaiMeta:
        name: The eval run list object
        group: evals
        example: |
          {
            "object": "list",
            "data": [
              {
                "object": "eval.run",
                "id": "evalrun_67b7fbdad46c819092f6fe7a14189620",
                "eval_id": "eval_67b7fa9a81a88190ab4aa417e397ea21",
                "report_url": "https://platform.openai.com/evaluations/eval_67b7fa9a81a88190ab4aa417e397ea21?run_id=evalrun_67b7fbdad46c819092f6fe7a14189620",
                "status": "completed",
                "model": "o3-mini",
                "name": "Academic Assistant",
                "created_at": 1740110812,
                "result_counts": {
                  "total": 171,
                  "errored": 0,
                  "failed": 80,
                  "passed": 91
                },
                "per_model_usage": null,
                "per_testing_criteria_results": [
                  {
                    "testing_criteria": "String check grader",
                    "passed": 91,
                    "failed": 80
                  }
                ],
                "run_data_source": {
                  "type": "completions",
                  "template_messages": [
                    {
                      "type": "message",
                      "role": "system",
                      "content": {
                        "type": "input_text",
                        "text": "You are a helpful assistant."
                      }
                    },
                    {
                      "type": "message",
                      "role": "user",
                      "content": {
                        "type": "input_text",
                        "text": "Hello, can you help me with my homework?"
                      }
                    }
                  ],
                  "datasource_reference": null,
                  "model": "o3-mini",
                  "max_completion_tokens": null,
                  "seed": null,
                  "temperature": null,
                  "top_p": null
                },
                "error": null,
                "metadata": {"test": "synthetics"}
              }
            ],
            "first_id": "evalrun_67abd54d60ec8190832b46859da808f7",
            "last_id": "evalrun_67abd54d60ec8190832b46859da808f7",
            "has_more": false
          }
    EvalRunOutputItem:
      description: |
        A schema representing an evaluation run output item.
      example:
        datasource_item:
          key: ""
        run_id: run_id
        eval_id: eval_id
        created_at: 0
        datasource_item_id: 6
        id: id
        results:
        - key: ""
        - key: ""
        sample:
          output:
          - role: role
            content: content
          - role: role
            content: content
          top_p: 3.616076749251911
          input:
          - role: role
            content: content
          - role: role
            content: content
          max_completion_tokens: 9
          finish_reason: finish_reason
          seed: 2
          usage:
            completion_tokens: 5
            prompt_tokens: 5
            total_tokens: 1
            cached_tokens: 2
          temperature: 7.061401241503109
          model: model
          error:
            code: code
            message: message
        object: eval.run.output_item
        status: status
      properties:
        object:
          default: eval.run.output_item
          description: The type of the object. Always "eval.run.output_item".
          enum:
          - eval.run.output_item
          type: string
          x-stainless-const: true
        id:
          description: Unique identifier for the evaluation run output item.
          type: string
        run_id:
          description: The identifier of the evaluation run associated with this output
            item.
          type: string
        eval_id:
          description: The identifier of the evaluation group.
          type: string
        created_at:
          description: Unix timestamp (in seconds) when the evaluation run was created.
          type: integer
        status:
          description: The status of the evaluation run.
          type: string
        datasource_item_id:
          description: The identifier for the data source item.
          type: integer
        datasource_item:
          additionalProperties: true
          description: Details of the input data source item.
          type: object
        results:
          description: A list of results from the evaluation run.
          items:
            additionalProperties: true
            description: A result object.
            type: object
          type: array
        sample:
          $ref: "#/components/schemas/EvalRunOutputItem_sample"
      required:
      - created_at
      - datasource_item
      - datasource_item_id
      - eval_id
      - id
      - object
      - results
      - run_id
      - sample
      - status
      title: EvalRunOutputItem
      x-oaiMeta:
        name: The eval run output item object
        group: evals
        example: |
          {
            "object": "eval.run.output_item",
            "id": "outputitem_67abd55eb6548190bb580745d5644a33",
            "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
            "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
            "created_at": 1739314509,
            "status": "pass",
            "datasource_item_id": 137,
            "datasource_item": {
                "teacher": "To grade essays, I only check for style, content, and grammar.",
                "student": "I am a student who is trying to write the best essay."
            },
            "results": [
              {
                "name": "String Check Grader",
                "type": "string-check-grader",
                "score": 1.0,
                "passed": true,
              }
            ],
            "sample": {
              "input": [
                {
                  "role": "system",
                  "content": "You are an evaluator bot..."
                },
                {
                  "role": "user",
                  "content": "You are assessing..."
                }
              ],
              "output": [
                {
                  "role": "assistant",
                  "content": "The rubric is not clear nor concise."
                }
              ],
              "finish_reason": "stop",
              "model": "gpt-4o-2024-08-06",
              "usage": {
                "total_tokens": 521,
                "completion_tokens": 2,
                "prompt_tokens": 519,
                "cached_tokens": 0
              },
              "error": null,
              "temperature": 1.0,
              "max_completion_tokens": 2048,
              "top_p": 1.0,
              "seed": 42
            }
          }
    EvalRunOutputItemList:
      description: |
        An object representing a list of output items for an evaluation run.
      example:
        first_id: first_id
        data:
        - datasource_item:
            key: ""
          run_id: run_id
          eval_id: eval_id
          created_at: 0
          datasource_item_id: 6
          id: id
          results:
          - key: ""
          - key: ""
          sample:
            output:
            - role: role
              content: content
            - role: role
              content: content
            top_p: 3.616076749251911
            input:
            - role: role
              content: content
            - role: role
              content: content
            max_completion_tokens: 9
            finish_reason: finish_reason
            seed: 2
            usage:
              completion_tokens: 5
              prompt_tokens: 5
              total_tokens: 1
              cached_tokens: 2
            temperature: 7.061401241503109
            model: model
            error:
              code: code
              message: message
          object: eval.run.output_item
          status: status
        - datasource_item:
            key: ""
          run_id: run_id
          eval_id: eval_id
          created_at: 0
          datasource_item_id: 6
          id: id
          results:
          - key: ""
          - key: ""
          sample:
            output:
            - role: role
              content: content
            - role: role
              content: content
            top_p: 3.616076749251911
            input:
            - role: role
              content: content
            - role: role
              content: content
            max_completion_tokens: 9
            finish_reason: finish_reason
            seed: 2
            usage:
              completion_tokens: 5
              prompt_tokens: 5
              total_tokens: 1
              cached_tokens: 2
            temperature: 7.061401241503109
            model: model
            error:
              code: code
              message: message
          object: eval.run.output_item
          status: status
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          default: list
          description: |
            The type of this object. It is always set to "list".
          enum:
          - list
          type: string
          x-stainless-const: true
        data:
          description: |
            An array of eval run output item objects.
          items:
            $ref: "#/components/schemas/EvalRunOutputItem"
          type: array
        first_id:
          description: The identifier of the first eval run output item in the data
            array.
          type: string
        last_id:
          description: The identifier of the last eval run output item in the data
            array.
          type: string
        has_more:
          description: Indicates whether there are more eval run output items available.
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      title: EvalRunOutputItemList
      x-oaiMeta:
        name: The eval run output item list object
        group: evals
        example: |
          {
            "object": "list",
            "data": [
              {
                "object": "eval.run.output_item",
                "id": "outputitem_67abd55eb6548190bb580745d5644a33",
                "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
                "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
                "created_at": 1739314509,
                "status": "pass",
                "datasource_item_id": 137,
                "datasource_item": {
                    "teacher": "To grade essays, I only check for style, content, and grammar.",
                    "student": "I am a student who is trying to write the best essay."
                },
                "results": [
                  {
                    "name": "String Check Grader",
                    "type": "string-check-grader",
                    "score": 1.0,
                    "passed": true,
                  }
                ],
                "sample": {
                  "input": [
                    {
                      "role": "system",
                      "content": "You are an evaluator bot..."
                    },
                    {
                      "role": "user",
                      "content": "You are assessing..."
                    }
                  ],
                  "output": [
                    {
                      "role": "assistant",
                      "content": "The rubric is not clear nor concise."
                    }
                  ],
                  "finish_reason": "stop",
                  "model": "gpt-4o-2024-08-06",
                  "usage": {
                    "total_tokens": 521,
                    "completion_tokens": 2,
                    "prompt_tokens": 519,
                    "cached_tokens": 0
                  },
                  "error": null,
                  "temperature": 1.0,
                  "max_completion_tokens": 2048,
                  "top_p": 1.0,
                  "seed": 42
                }
              },
            ],
            "first_id": "outputitem_67abd55eb6548190bb580745d5644a33",
            "last_id": "outputitem_67abd55eb6548190bb580745d5644a33",
            "has_more": false
          }
    EvalStoredCompletionsDataSourceConfig:
      deprecated: true
      description: |
        Deprecated in favor of LogsDataSourceConfig.
      properties:
        type:
          default: stored_completions
          description: The type of data source. Always `stored_completions`.
          enum:
          - stored_completions
          type: string
          x-stainless-const: true
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        schema:
          additionalProperties: true
          description: |
            The json schema for the run data source items.
            Learn how to build JSON schemas [here](https://json-schema.org/).
          type: object
      required:
      - schema
      - type
      title: StoredCompletionsDataSourceConfig
      x-oaiMeta:
        name: The stored completions data source object for evals
        group: evals
        example: |
          {
            "type": "stored_completions",
            "metadata": {
              "language": "english"
            },
            "schema": {
              "type": "object",
              "properties": {
                "item": {
                  "type": "object"
                },
                "sample": {
                  "type": "object"
                }
              },
              "required": [
                "item",
                "sample"
              }
          }
    EvalStoredCompletionsSource:
      description: |
        A StoredCompletionsRunDataSource configuration describing a set of filters
      properties:
        type:
          default: stored_completions
          description: The type of source. Always `stored_completions`.
          enum:
          - stored_completions
          type: string
          x-stainless-const: true
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        model:
          description: "An optional model to filter by (e.g., 'gpt-4o')."
          type: string
          nullable: true
        created_after:
          description: An optional Unix timestamp to filter items created after this
            time.
          type: integer
          nullable: true
        created_before:
          description: An optional Unix timestamp to filter items created before this
            time.
          type: integer
          nullable: true
        limit:
          description: An optional maximum number of items to return.
          type: integer
          nullable: true
      required:
      - type
      title: StoredCompletionsRunDataSource
      x-oaiMeta:
        name: The stored completions data source object used to configure an individual
          run
        group: eval runs
        example: |
          {
            "type": "stored_completions",
            "model": "gpt-4o",
            "created_after": 1668124800,
            "created_before": 1668124900,
            "limit": 100,
            "metadata": {}
          }
    FilePath:
      description: |
        A path to a file.
      properties:
        type:
          description: |
            The type of the file path. Always `file_path`.
          enum:
          - file_path
          type: string
          x-stainless-const: true
        file_id:
          description: |
            The ID of the file.
          type: string
        index:
          description: |
            The index of the file in the list of files.
          type: integer
      required:
      - file_id
      - index
      - type
      title: File path
    FileSearchRanker:
      description: The ranker to use for the file search. If not specified will use
        the `auto` ranker.
      enum:
      - auto
      - default_2024_08_21
      type: string
    FileSearchRankingOptions:
      description: |
        The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.

        See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.
      properties:
        ranker:
          $ref: "#/components/schemas/FileSearchRanker"
        score_threshold:
          description: The score threshold for the file search. All values must be
            a floating point number between 0 and 1.
          maximum: 1
          minimum: 0
          type: number
      required:
      - score_threshold
      title: File search tool call ranking options
    FileSearchToolCall:
      description: "The results of a file search tool call. See the \n[file search\
        \ guide](/docs/guides/tools-file-search) for more information.\n"
      properties:
        id:
          description: |
            The unique ID of the file search tool call.
          type: string
        type:
          description: |
            The type of the file search tool call. Always `file_search_call`.
          enum:
          - file_search_call
          type: string
          x-stainless-const: true
        status:
          description: "The status of the file search tool call. One of `in_progress`,\
            \ \n`searching`, `incomplete` or `failed`,\n"
          enum:
          - in_progress
          - searching
          - completed
          - incomplete
          - failed
          type: string
        queries:
          description: |
            The queries used to search for files.
          items:
            type: string
          type: array
        results:
          description: |
            The results of the file search tool call.
          items:
            $ref: "#/components/schemas/FileSearchToolCall_results_inner"
          type: array
          nullable: true
      required:
      - id
      - queries
      - status
      - type
      title: File search tool call
    FineTuneChatCompletionRequestAssistantMessage:
      allOf:
      - deprecated: false
        properties:
          weight:
            description: Controls whether the assistant message is trained against
              (0 or 1)
            enum:
            - 0
            - 1
            type: integer
        title: Assistant message
      - $ref: "#/components/schemas/ChatCompletionRequestAssistantMessage"
      required:
      - role
    FineTuneChatRequestInput:
      description: |
        The per-line training example of a fine-tuning input file for chat models using the supervised method.
        Input messages may contain text or image content only. Audio and file input messages
        are not currently supported for fine-tuning.
      properties:
        messages:
          items:
            $ref: "#/components/schemas/FineTuneChatRequestInput_messages_inner"
          minItems: 1
          type: array
        tools:
          description: A list of tools the model may generate JSON inputs for.
          items:
            $ref: "#/components/schemas/ChatCompletionTool"
          type: array
        parallel_tool_calls:
          default: true
          description: "Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling)\
            \ during tool use."
          type: boolean
        functions:
          description: A list of functions the model may generate JSON inputs for.
          items:
            $ref: "#/components/schemas/ChatCompletionFunctions"
          maxItems: 128
          minItems: 1
          type: array
      x-oaiMeta:
        name: Training format for chat models using the supervised method
        example: |
          {
            "messages": [
              { "role": "user", "content": "What is the weather in San Francisco?" },
              {
                "role": "assistant",
                "tool_calls": [
                  {
                    "id": "call_id",
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "arguments": "{\"location\": \"San Francisco, USA\", \"format\": \"celsius\"}"
                    }
                  }
                ]
              }
            ],
            "parallel_tool_calls": false,
            "tools": [
              {
                "type": "function",
                "function": {
                  "name": "get_current_weather",
                  "description": "Get the current weather",
                  "parameters": {
                    "type": "object",
                    "properties": {
                      "location": {
                          "type": "string",
                          "description": "The city and country, eg. San Francisco, USA"
                      },
                      "format": { "type": "string", "enum": ["celsius", "fahrenheit"] }
                    },
                    "required": ["location", "format"]
                  }
                }
              }
            ]
          }
    FineTuneDPOHyperparameters:
      description: The hyperparameters used for the DPO fine-tuning job.
      example:
        batch_size: null
        n_epochs: null
        beta: auto
        learning_rate_multiplier: null
      properties:
        beta:
          $ref: "#/components/schemas/FineTuneDPOHyperparameters_beta"
        batch_size:
          $ref: "#/components/schemas/FineTuneDPOHyperparameters_batch_size"
        learning_rate_multiplier:
          $ref: "#/components/schemas/FineTuneDPOHyperparameters_learning_rate_multiplier"
        n_epochs:
          $ref: "#/components/schemas/FineTuneDPOHyperparameters_n_epochs"
    FineTuneDPOMethod:
      description: Configuration for the DPO fine-tuning method.
      example:
        hyperparameters:
          batch_size: null
          n_epochs: null
          beta: auto
          learning_rate_multiplier: null
      properties:
        hyperparameters:
          $ref: "#/components/schemas/FineTuneDPOHyperparameters"
    FineTuneMethod:
      description: The method used for fine-tuning.
      example:
        supervised:
          hyperparameters:
            batch_size: auto
            n_epochs: auto
            learning_rate_multiplier: auto
        dpo:
          hyperparameters:
            batch_size: null
            n_epochs: null
            beta: auto
            learning_rate_multiplier: null
        reinforcement:
          hyperparameters:
            reasoning_effort: default
            batch_size: null
            n_epochs: null
            eval_interval: auto
            compute_multiplier: auto
            eval_samples: auto
            learning_rate_multiplier: null
          grader:
            reference: reference
            input: input
            name: name
            type: string_check
            operation: eq
        type: supervised
      properties:
        type:
          description: "The type of method. Is either `supervised`, `dpo`, or `reinforcement`."
          enum:
          - supervised
          - dpo
          - reinforcement
          type: string
        supervised:
          $ref: "#/components/schemas/FineTuneSupervisedMethod"
        dpo:
          $ref: "#/components/schemas/FineTuneDPOMethod"
        reinforcement:
          $ref: "#/components/schemas/FineTuneReinforcementMethod"
      required:
      - type
    FineTunePreferenceRequestInput:
      description: |
        The per-line training example of a fine-tuning input file for chat models using the dpo method.
        Input messages may contain text or image content only. Audio and file input messages
        are not currently supported for fine-tuning.
      properties:
        input:
          $ref: "#/components/schemas/FineTunePreferenceRequestInput_input"
        preferred_output:
          description: The preferred completion message for the output.
          items:
            $ref: "#/components/schemas/ChatCompletionRequestAssistantMessage"
          maxItems: 1
          type: array
        non_preferred_output:
          description: The non-preferred completion message for the output.
          items:
            $ref: "#/components/schemas/ChatCompletionRequestAssistantMessage"
          maxItems: 1
          type: array
      x-oaiMeta:
        name: Training format for chat models using the preference method
        example: |
          {
            "input": {
              "messages": [
                { "role": "user", "content": "What is the weather in San Francisco?" }
              ]
            },
            "preferred_output": [
              {
                "role": "assistant",
                "content": "The weather in San Francisco is 70 degrees Fahrenheit."
              }
            ],
            "non_preferred_output": [
              {
                "role": "assistant",
                "content": "The weather in San Francisco is 21 degrees Celsius."
              }
            ]
          }
    FineTuneReinforcementHyperparameters:
      description: The hyperparameters used for the reinforcement fine-tuning job.
      example:
        reasoning_effort: default
        batch_size: null
        n_epochs: null
        eval_interval: auto
        compute_multiplier: auto
        eval_samples: auto
        learning_rate_multiplier: null
      properties:
        batch_size:
          $ref: "#/components/schemas/FineTuneDPOHyperparameters_batch_size"
        learning_rate_multiplier:
          $ref: "#/components/schemas/FineTuneDPOHyperparameters_learning_rate_multiplier"
        n_epochs:
          $ref: "#/components/schemas/FineTuneDPOHyperparameters_n_epochs"
        reasoning_effort:
          default: default
          description: |
            Level of reasoning effort.
          enum:
          - default
          - low
          - medium
          - high
          type: string
        compute_multiplier:
          $ref: "#/components/schemas/FineTuneReinforcementHyperparameters_compute_multiplier"
        eval_interval:
          $ref: "#/components/schemas/FineTuneReinforcementHyperparameters_eval_interval"
        eval_samples:
          $ref: "#/components/schemas/FineTuneReinforcementHyperparameters_eval_samples"
    FineTuneReinforcementMethod:
      description: Configuration for the reinforcement fine-tuning method.
      example:
        hyperparameters:
          reasoning_effort: default
          batch_size: null
          n_epochs: null
          eval_interval: auto
          compute_multiplier: auto
          eval_samples: auto
          learning_rate_multiplier: null
        grader:
          reference: reference
          input: input
          name: name
          type: string_check
          operation: eq
      properties:
        grader:
          $ref: "#/components/schemas/FineTuneReinforcementMethod_grader"
        hyperparameters:
          $ref: "#/components/schemas/FineTuneReinforcementHyperparameters"
      required:
      - grader
    FineTuneReinforcementRequestInput:
      description: |
        Per-line training example for reinforcement fine-tuning. Note that `messages` and `tools` are the only reserved keywords.
        Any other arbitrary key-value data can be included on training datapoints and will be available to reference during grading under the `{{ item.XXX }}` template variable.
        Input messages may contain text or image content only. Audio and file input messages
        are not currently supported for fine-tuning.
      properties:
        messages:
          items:
            $ref: "#/components/schemas/FineTuneReinforcementRequestInput_messages_inner"
          minItems: 1
          type: array
        tools:
          description: A list of tools the model may generate JSON inputs for.
          items:
            $ref: "#/components/schemas/ChatCompletionTool"
          type: array
      required:
      - messages
      x-oaiMeta:
        name: Training format for reasoning models using the reinforcement method
        example: |
          {
            "messages": [
              {
                "role": "user",
                "content": "Your task is to take a chemical in SMILES format and predict the number of hydrobond bond donors and acceptors according to Lipinkski's rule. CCN(CC)CCC(=O)c1sc(N)nc1C"
              },
            ],
            # Any other JSON data can be inserted into an example and referenced during RFT grading
            "reference_answer": {
              "donor_bond_counts": 5,
              "acceptor_bond_counts": 7
            }
          }
    FineTuneSupervisedHyperparameters:
      description: The hyperparameters used for the fine-tuning job.
      example:
        batch_size: auto
        n_epochs: auto
        learning_rate_multiplier: auto
      properties:
        batch_size:
          $ref: "#/components/schemas/FineTuneDPOHyperparameters_batch_size"
        learning_rate_multiplier:
          $ref: "#/components/schemas/FineTuneDPOHyperparameters_learning_rate_multiplier"
        n_epochs:
          $ref: "#/components/schemas/FineTuneDPOHyperparameters_n_epochs"
    FineTuneSupervisedMethod:
      description: Configuration for the supervised fine-tuning method.
      example:
        hyperparameters:
          batch_size: auto
          n_epochs: auto
          learning_rate_multiplier: auto
      properties:
        hyperparameters:
          $ref: "#/components/schemas/FineTuneSupervisedHyperparameters"
    FineTuningCheckpointPermission:
      description: |
        The `checkpoint.permission` object represents a permission for a fine-tuned model checkpoint.
      example:
        project_id: project_id
        created_at: 0
        id: id
        object: checkpoint.permission
      properties:
        id:
          description: "The permission identifier, which can be referenced in the\
            \ API endpoints."
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the permission was
            created.
          type: integer
        project_id:
          description: The project identifier that the permission is for.
          type: string
        object:
          description: "The object type, which is always \"checkpoint.permission\"\
            ."
          enum:
          - checkpoint.permission
          type: string
          x-stainless-const: true
      required:
      - created_at
      - id
      - object
      - project_id
      title: FineTuningCheckpointPermission
      x-oaiMeta:
        name: The fine-tuned model checkpoint permission object
        example: |
          {
            "object": "checkpoint.permission",
            "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
            "created_at": 1712211699,
            "project_id": "proj_abGMw1llN8IrBb6SvvY5A1iH"
          }
    FineTuningIntegration:
      example:
        wandb:
          name: name
          project: my-wandb-project
          entity: entity
          tags:
          - custom-tag
          - custom-tag
        type: wandb
      properties:
        type:
          description: The type of the integration being enabled for the fine-tuning
            job
          enum:
          - wandb
          type: string
          x-stainless-const: true
        wandb:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_integrations_inner_wandb"
      required:
      - type
      - wandb
      title: Fine-Tuning Job Integration
    FineTuningJob:
      description: |
        The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.
      example:
        training_file: training_file
        result_files:
        - file-abc123
        - file-abc123
        metadata:
          key: metadata
        finished_at: 6
        seed: 5
        method:
          supervised:
            hyperparameters:
              batch_size: auto
              n_epochs: auto
              learning_rate_multiplier: auto
          dpo:
            hyperparameters:
              batch_size: null
              n_epochs: null
              beta: auto
              learning_rate_multiplier: null
          reinforcement:
            hyperparameters:
              reasoning_effort: default
              batch_size: null
              n_epochs: null
              eval_interval: auto
              compute_multiplier: auto
              eval_samples: auto
              learning_rate_multiplier: null
            grader:
              reference: reference
              input: input
              name: name
              type: string_check
              operation: eq
          type: supervised
        fine_tuned_model: fine_tuned_model
        validation_file: validation_file
        created_at: 0
        error:
          code: code
          param: param
          message: message
        estimated_finish: 5
        organization_id: organization_id
        hyperparameters:
          batch_size: auto
          n_epochs: auto
          learning_rate_multiplier: auto
        model: model
        id: id
        trained_tokens: 1
        integrations:
        - wandb:
            name: name
            project: my-wandb-project
            entity: entity
            tags:
            - custom-tag
            - custom-tag
          type: wandb
        - wandb:
            name: name
            project: my-wandb-project
            entity: entity
            tags:
            - custom-tag
            - custom-tag
          type: wandb
        - wandb:
            name: name
            project: my-wandb-project
            entity: entity
            tags:
            - custom-tag
            - custom-tag
          type: wandb
        - wandb:
            name: name
            project: my-wandb-project
            entity: entity
            tags:
            - custom-tag
            - custom-tag
          type: wandb
        - wandb:
            name: name
            project: my-wandb-project
            entity: entity
            tags:
            - custom-tag
            - custom-tag
          type: wandb
        object: fine_tuning.job
        status: validating_files
      properties:
        id:
          description: "The object identifier, which can be referenced in the API\
            \ endpoints."
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            was created.
          type: integer
        error:
          $ref: "#/components/schemas/FineTuningJob_error"
        fine_tuned_model:
          description: The name of the fine-tuned model that is being created. The
            value will be null if the fine-tuning job is still running.
          type: string
          nullable: true
        finished_at:
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            was finished. The value will be null if the fine-tuning job is still running.
          type: integer
          nullable: true
        hyperparameters:
          $ref: "#/components/schemas/FineTuningJob_hyperparameters"
        model:
          description: The base model that is being fine-tuned.
          type: string
        object:
          description: "The object type, which is always \"fine_tuning.job\"."
          enum:
          - fine_tuning.job
          type: string
          x-stainless-const: true
        organization_id:
          description: The organization that owns the fine-tuning job.
          type: string
        result_files:
          description: "The compiled results file ID(s) for the fine-tuning job. You\
            \ can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents)."
          items:
            example: file-abc123
            type: string
          type: array
        status:
          description: "The current status of the fine-tuning job, which can be either\
            \ `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`."
          enum:
          - validating_files
          - queued
          - running
          - succeeded
          - failed
          - cancelled
          type: string
        trained_tokens:
          description: The total number of billable tokens processed by this fine-tuning
            job. The value will be null if the fine-tuning job is still running.
          type: integer
          nullable: true
        training_file:
          description: "The file ID used for training. You can retrieve the training\
            \ data with the [Files API](/docs/api-reference/files/retrieve-contents)."
          type: string
        validation_file:
          description: "The file ID used for validation. You can retrieve the validation\
            \ results with the [Files API](/docs/api-reference/files/retrieve-contents)."
          type: string
          nullable: true
        integrations:
          description: A list of integrations to enable for this fine-tuning job.
          items:
            $ref: "#/components/schemas/FineTuningIntegration"
          maxItems: 5
          type: array
          nullable: true
        seed:
          description: The seed used for the fine-tuning job.
          type: integer
        estimated_finish:
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            is estimated to finish. The value will be null if the fine-tuning job
            is not running.
          type: integer
          nullable: true
        method:
          $ref: "#/components/schemas/FineTuneMethod"
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
      required:
      - created_at
      - error
      - fine_tuned_model
      - finished_at
      - hyperparameters
      - id
      - model
      - object
      - organization_id
      - result_files
      - seed
      - status
      - trained_tokens
      - training_file
      - validation_file
      title: FineTuningJob
      x-oaiMeta:
        name: The fine-tuning job object
        example: |
          {
            "object": "fine_tuning.job",
            "id": "ftjob-abc123",
            "model": "davinci-002",
            "created_at": 1692661014,
            "finished_at": 1692661190,
            "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
            "organization_id": "org-123",
            "result_files": [
                "file-abc123"
            ],
            "status": "succeeded",
            "validation_file": null,
            "training_file": "file-abc123",
            "hyperparameters": {
                "n_epochs": 4,
                "batch_size": 1,
                "learning_rate_multiplier": 1.0
            },
            "trained_tokens": 5768,
            "integrations": [],
            "seed": 0,
            "estimated_finish": 0,
            "method": {
              "type": "supervised",
              "supervised": {
                "hyperparameters": {
                  "n_epochs": 4,
                  "batch_size": 1,
                  "learning_rate_multiplier": 1.0
                }
              }
            },
            "metadata": {
              "key": "value"
            }
          }
    FineTuningJobCheckpoint:
      description: |
        The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.
      example:
        step_number: 6
        created_at: 0
        fine_tuning_job_id: fine_tuning_job_id
        id: id
        metrics:
          full_valid_mean_token_accuracy: 3.616076749251911
          valid_loss: 2.3021358869347655
          full_valid_loss: 9.301444243932576
          train_mean_token_accuracy: 5.637376656633329
          valid_mean_token_accuracy: 7.061401241503109
          train_loss: 5.962133916683182
          step: 1.4658129805029452
        fine_tuned_model_checkpoint: fine_tuned_model_checkpoint
        object: fine_tuning.job.checkpoint
      properties:
        id:
          description: "The checkpoint identifier, which can be referenced in the\
            \ API endpoints."
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the checkpoint was
            created.
          type: integer
        fine_tuned_model_checkpoint:
          description: The name of the fine-tuned checkpoint model that is created.
          type: string
        step_number:
          description: The step number that the checkpoint was created at.
          type: integer
        metrics:
          $ref: "#/components/schemas/FineTuningJobCheckpoint_metrics"
        fine_tuning_job_id:
          description: The name of the fine-tuning job that this checkpoint was created
            from.
          type: string
        object:
          description: "The object type, which is always \"fine_tuning.job.checkpoint\"\
            ."
          enum:
          - fine_tuning.job.checkpoint
          type: string
          x-stainless-const: true
      required:
      - created_at
      - fine_tuned_model_checkpoint
      - fine_tuning_job_id
      - id
      - metrics
      - object
      - step_number
      title: FineTuningJobCheckpoint
      x-oaiMeta:
        name: The fine-tuning job checkpoint object
        example: |
          {
            "object": "fine_tuning.job.checkpoint",
            "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
            "created_at": 1712211699,
            "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
            "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
            "metrics": {
              "step": 88,
              "train_loss": 0.478,
              "train_mean_token_accuracy": 0.924,
              "valid_loss": 10.112,
              "valid_mean_token_accuracy": 0.145,
              "full_valid_loss": 0.567,
              "full_valid_mean_token_accuracy": 0.944
            },
            "step_number": 88
          }
    FineTuningJobEvent:
      description: Fine-tuning job event object
      example:
        data: "{}"
        level: info
        created_at: 0
        id: id
        message: message
        type: message
        object: fine_tuning.job.event
      properties:
        object:
          description: "The object type, which is always \"fine_tuning.job.event\"\
            ."
          enum:
          - fine_tuning.job.event
          type: string
          x-stainless-const: true
        id:
          description: The object identifier.
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            was created.
          type: integer
        level:
          description: The log level of the event.
          enum:
          - info
          - warn
          - error
          type: string
        message:
          description: The message of the event.
          type: string
        type:
          description: The type of event.
          enum:
          - message
          - metrics
          type: string
        data:
          description: The data associated with the event.
          type: object
      required:
      - created_at
      - id
      - level
      - message
      - object
      x-oaiMeta:
        name: The fine-tuning job event object
        example: |
          {
            "object": "fine_tuning.job.event",
            "id": "ftevent-abc123"
            "created_at": 1677610602,
            "level": "info",
            "message": "Created fine-tuning job",
            "data": {},
            "type": "message"
          }
    FunctionObject:
      example:
        name: name
        description: description
        strict: false
        parameters:
          key: ""
      properties:
        description:
          description: "A description of what the function does, used by the model\
            \ to choose when and how to call the function."
          type: string
        name:
          description: "The name of the function to be called. Must be a-z, A-Z, 0-9,\
            \ or contain underscores and dashes, with a maximum length of 64."
          type: string
        parameters:
          additionalProperties: true
          description: "The parameters the functions accepts, described as a JSON\
            \ Schema object. See the [guide](/docs/guides/function-calling) for examples,\
            \ and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/)\
            \ for documentation about the format. \n\nOmitting `parameters` defines\
            \ a function with an empty parameter list."
          type: object
        strict:
          default: false
          description: "Whether to enable strict schema adherence when generating\
            \ the function call. If set to true, the model will follow the exact schema\
            \ defined in the `parameters` field. Only a subset of JSON Schema is supported\
            \ when `strict` is `true`. Learn more about Structured Outputs in the\
            \ [function calling guide](docs/guides/function-calling)."
          type: boolean
          nullable: true
      required:
      - name
    FunctionParameters:
      additionalProperties: true
      description: "The parameters the functions accepts, described as a JSON Schema\
        \ object. See the [guide](/docs/guides/function-calling) for examples, and\
        \ the [JSON Schema reference](https://json-schema.org/understanding-json-schema/)\
        \ for documentation about the format. \n\nOmitting `parameters` defines a\
        \ function with an empty parameter list."
      type: object
    FunctionToolCall:
      description: "A tool call to run a function. See the \n[function calling guide](/docs/guides/function-calling)\
        \ for more information.\n"
      properties:
        id:
          description: |
            The unique ID of the function tool call.
          type: string
        type:
          description: |
            The type of the function tool call. Always `function_call`.
          enum:
          - function_call
          type: string
          x-stainless-const: true
        call_id:
          description: |
            The unique ID of the function tool call generated by the model.
          type: string
        name:
          description: |
            The name of the function to run.
          type: string
        arguments:
          description: |
            A JSON string of the arguments to pass to the function.
          type: string
        status:
          description: |
            The status of the item. One of `in_progress`, `completed`, or
            `incomplete`. Populated when items are returned via API.
          enum:
          - in_progress
          - completed
          - incomplete
          type: string
      required:
      - arguments
      - call_id
      - name
      - type
      title: Function tool call
    FunctionToolCallOutput:
      description: |
        The output of a function tool call.
      properties:
        id:
          description: |
            The unique ID of the function tool call output. Populated when this item
            is returned via API.
          type: string
        type:
          description: |
            The type of the function tool call output. Always `function_call_output`.
          enum:
          - function_call_output
          type: string
          x-stainless-const: true
        call_id:
          description: |
            The unique ID of the function tool call generated by the model.
          type: string
        output:
          description: |
            A JSON string of the output of the function tool call.
          type: string
        status:
          description: |
            The status of the item. One of `in_progress`, `completed`, or
            `incomplete`. Populated when items are returned via API.
          enum:
          - in_progress
          - completed
          - incomplete
          type: string
      required:
      - call_id
      - output
      - type
      title: Function tool call output
    FunctionToolCallOutputResource:
      allOf:
      - $ref: "#/components/schemas/FunctionToolCallOutput"
      - properties:
          id:
            description: |
              The unique ID of the function call tool output.
            type: string
        required:
        - id
    FunctionToolCallResource:
      allOf:
      - $ref: "#/components/schemas/FunctionToolCall"
      - properties:
          id:
            description: |
              The unique ID of the function tool call.
            type: string
        required:
        - id
    GraderLabelModel:
      description: |
        A LabelModelGrader object which uses a model to assign labels to each item
        in the evaluation.
      properties:
        type:
          description: "The object type, which is always `label_model`."
          enum:
          - label_model
          type: string
          x-stainless-const: true
        name:
          description: The name of the grader.
          type: string
        model:
          description: The model to use for the evaluation. Must support structured
            outputs.
          type: string
        input:
          items:
            $ref: "#/components/schemas/EvalItem"
          type: array
        labels:
          description: The labels to assign to each item in the evaluation.
          items:
            type: string
          type: array
        passing_labels:
          description: The labels that indicate a passing result. Must be a subset
            of labels.
          items:
            type: string
          type: array
      required:
      - input
      - labels
      - model
      - name
      - passing_labels
      - type
      title: LabelModelGrader
      x-oaiMeta:
        name: Label Model Grader
        group: graders
        example: |
          {
            "name": "First label grader",
            "type": "label_model",
            "model": "gpt-4o-2024-08-06",
            "input": [
              {
                "type": "message",
                "role": "system",
                "content": {
                  "type": "input_text",
                  "text": "Classify the sentiment of the following statement as one of positive, neutral, or negative"
                }
              },
              {
                "type": "message",
                "role": "user",
                "content": {
                  "type": "input_text",
                  "text": "Statement: {{item.response}}"
                }
              }
            ],
            "passing_labels": [
              "positive"
            ],
            "labels": [
              "positive",
              "neutral",
              "negative"
            ]
          }
    GraderMulti:
      description: A MultiGrader object combines the output of multiple graders to
        produce a single score.
      properties:
        type:
          default: multi
          description: "The object type, which is always `multi`."
          enum:
          - multi
          type: string
          x-stainless-const: true
        name:
          description: The name of the grader.
          type: string
        graders:
          $ref: "#/components/schemas/GraderMulti_graders"
        calculate_output:
          description: A formula to calculate the output based on grader results.
          type: string
      required:
      - calculate_output
      - graders
      - name
      - type
      title: MultiGrader
      x-oaiMeta:
        name: Multi Grader
        group: graders
        example: |
          {
            "type": "multi",
            "name": "example multi grader",
            "graders": [
              {
                "type": "text_similarity",
                "name": "example text similarity grader",
                "input": "The graded text",
                "reference": "The reference text",
                "evaluation_metric": "fuzzy_match"
              },
              {
                "type": "string_check",
                "name": "Example string check grader",
                "input": "{{sample.output_text}}",
                "reference": "{{item.label}}",
                "operation": "eq"
              }
            ],
            "calculate_output": "0.5 * text_similarity_score +  0.5 * string_check_score)"
          }
    GraderPython:
      description: |
        A PythonGrader object that runs a python script on the input.
      properties:
        type:
          description: "The object type, which is always `python`."
          enum:
          - python
          type: string
          x-stainless-const: true
        name:
          description: The name of the grader.
          type: string
        source:
          description: The source code of the python script.
          type: string
        image_tag:
          description: The image tag to use for the python script.
          type: string
      required:
      - name
      - source
      - type
      title: PythonGrader
      x-oaiMeta:
        name: Python Grader
        group: graders
        example: |
          {
            "type": "python",
            "name": "Example python grader",
            "image_tag": "2025-05-08",
            "source": """
          def grade(sample: dict, item: dict) -> float:
              \"""
              Returns 1.0 if `output_text` equals `label`, otherwise 0.0.
              \"""
              output = sample.get("output_text")
              label = item.get("label")
              return 1.0 if output == label else 0.0
          """,
          }
    GraderScoreModel:
      description: |
        A ScoreModelGrader object that uses a model to assign a score to the input.
      properties:
        type:
          description: "The object type, which is always `score_model`."
          enum:
          - score_model
          type: string
          x-stainless-const: true
        name:
          description: The name of the grader.
          type: string
        model:
          description: The model to use for the evaluation.
          type: string
        sampling_params:
          description: The sampling parameters for the model.
          type: object
        input:
          description: The input text. This may include template strings.
          items:
            $ref: "#/components/schemas/EvalItem"
          type: array
        range:
          description: "The range of the score. Defaults to `[0, 1]`."
          items:
            type: number
            min_items: 2
            max_items: 2
          type: array
      required:
      - input
      - model
      - name
      - type
      title: ScoreModelGrader
      x-oaiMeta:
        name: Score Model Grader
        group: graders
        example: |
          {
              "type": "score_model",
              "name": "Example score model grader",
              "input": [
                  {
                      "role": "user",
                      "content": (
                          "Score how close the reference answer is to the model answer. Score 1.0 if they are the same and 0.0 if they are different."
                          " Return just a floating point score\n\n"
                          " Reference answer: {{item.label}}\n\n"
                          " Model answer: {{sample.output_text}}"
                      ),
                  }
              ],
              "model": "gpt-4o-2024-08-06",
              "sampling_params": {
                  "temperature": 1,
                  "top_p": 1,
                  "seed": 42,
              },
          }
    GraderStringCheck:
      description: |
        A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.
      example:
        reference: reference
        input: input
        name: name
        type: string_check
        operation: eq
      properties:
        type:
          description: "The object type, which is always `string_check`."
          enum:
          - string_check
          type: string
          x-stainless-const: true
        name:
          description: The name of the grader.
          type: string
        input:
          description: The input text. This may include template strings.
          type: string
        reference:
          description: The reference text. This may include template strings.
          type: string
        operation:
          description: "The string check operation to perform. One of `eq`, `ne`,\
            \ `like`, or `ilike`."
          enum:
          - eq
          - ne
          - like
          - ilike
          type: string
      required:
      - input
      - name
      - operation
      - reference
      - type
      title: StringCheckGrader
      x-oaiMeta:
        name: String Check Grader
        group: graders
        example: |
          {
            "type": "string_check",
            "name": "Example string check grader",
            "input": "{{sample.output_text}}",
            "reference": "{{item.label}}",
            "operation": "eq"
          }
    GraderTextSimilarity:
      description: |
        A TextSimilarityGrader object which grades text based on similarity metrics.
      properties:
        type:
          default: text_similarity
          description: The type of grader.
          enum:
          - text_similarity
          type: string
          x-stainless-const: true
        name:
          description: The name of the grader.
          type: string
        input:
          description: The text being graded.
          type: string
        reference:
          description: The text being graded against.
          type: string
        evaluation_metric:
          description: "The evaluation metric to use. One of `fuzzy_match`, `bleu`,\
            \ `gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\
            \ or `rouge_l`."
          enum:
          - fuzzy_match
          - bleu
          - gleu
          - meteor
          - rouge_1
          - rouge_2
          - rouge_3
          - rouge_4
          - rouge_5
          - rouge_l
          type: string
      required:
      - evaluation_metric
      - input
      - name
      - reference
      - type
      title: TextSimilarityGrader
      x-oaiMeta:
        name: Text Similarity Grader
        group: graders
        example: |
          {
            "type": "text_similarity",
            "name": "Example text similarity grader",
            "input": "{{sample.output_text}}",
            "reference": "{{item.label}}",
            "evaluation_metric": "fuzzy_match"
          }
    Image:
      description: Represents the content or the URL of an image generated by the
        OpenAI API.
      example:
        revised_prompt: revised_prompt
        b64_json: b64_json
        url: url
      properties:
        b64_json:
          description: "The base64-encoded JSON of the generated image. Default value\
            \ for `gpt-image-1`, and only present if `response_format` is set to `b64_json`\
            \ for `dall-e-2` and `dall-e-3`."
          type: string
        url:
          description: "When using `dall-e-2` or `dall-e-3`, the URL of the generated\
            \ image if `response_format` is set to `url` (default value). Unsupported\
            \ for `gpt-image-1`."
          type: string
        revised_prompt:
          description: "For `dall-e-3` only, the revised prompt that was used to generate\
            \ the image."
          type: string
    ImageGenTool:
      description: |
        A tool that generates images using a model like `gpt-image-1`.
      properties:
        type:
          description: |
            The type of the image generation tool. Always `image_generation`.
          enum:
          - image_generation
          type: string
          x-stainless-const: true
        model:
          default: gpt-image-1
          description: |
            The image generation model to use. Default: `gpt-image-1`.
          enum:
          - gpt-image-1
          type: string
        quality:
          default: auto
          description: "The quality of the generated image. One of `low`, `medium`,\
            \ `high`, \nor `auto`. Default: `auto`.\n"
          enum:
          - low
          - medium
          - high
          - auto
          type: string
        size:
          default: auto
          description: "The size of the generated image. One of `1024x1024`, `1024x1536`,\
            \ \n`1536x1024`, or `auto`. Default: `auto`.\n"
          enum:
          - 1024x1024
          - 1024x1536
          - 1536x1024
          - auto
          type: string
        output_format:
          default: png
          description: "The output format of the generated image. One of `png`, `webp`,\
            \ or \n`jpeg`. Default: `png`.\n"
          enum:
          - png
          - webp
          - jpeg
          type: string
        output_compression:
          default: 100
          description: |
            Compression level for the output image. Default: 100.
          maximum: 100
          minimum: 0
          type: integer
        moderation:
          default: auto
          description: |
            Moderation level for the generated image. Default: `auto`.
          enum:
          - auto
          - low
          type: string
        background:
          default: auto
          description: "Background type for the generated image. One of `transparent`,\
            \ \n`opaque`, or `auto`. Default: `auto`.\n"
          enum:
          - transparent
          - opaque
          - auto
          type: string
        input_image_mask:
          $ref: "#/components/schemas/ImageGenTool_input_image_mask"
        partial_images:
          default: 0
          description: |
            Number of partial images to generate in streaming mode, from 0 (default value) to 3.
          maximum: 3
          minimum: 0
          type: integer
      required:
      - type
      title: Image generation tool
    ImageGenToolCall:
      description: |
        An image generation request made by the model.
      properties:
        type:
          description: |
            The type of the image generation call. Always `image_generation_call`.
          enum:
          - image_generation_call
          type: string
          x-stainless-const: true
        id:
          description: |
            The unique ID of the image generation call.
          type: string
        status:
          description: |
            The status of the image generation call.
          enum:
          - in_progress
          - completed
          - generating
          - failed
          type: string
        result:
          description: |
            The generated image encoded in base64.
          type: string
          nullable: true
      required:
      - id
      - result
      - status
      - type
      title: Image generation call
    ImagesResponse:
      description: The response from the image generation endpoint.
      example:
        data:
        - revised_prompt: revised_prompt
          b64_json: b64_json
          url: url
        - revised_prompt: revised_prompt
          b64_json: b64_json
          url: url
        output_format: png
        size: 1024x1024
        created: 0
        background: transparent
        usage:
          input_tokens_details:
            text_tokens: 5
            image_tokens: 2
          total_tokens: 6
          output_tokens: 5
          input_tokens: 1
        quality: low
      properties:
        created:
          description: The Unix timestamp (in seconds) of when the image was created.
          type: integer
        data:
          description: The list of generated images.
          items:
            $ref: "#/components/schemas/Image"
          type: array
        background:
          description: The background parameter used for the image generation. Either
            `transparent` or `opaque`.
          enum:
          - transparent
          - opaque
          type: string
        output_format:
          description: "The output format of the image generation. Either `png`, `webp`,\
            \ or `jpeg`."
          enum:
          - png
          - webp
          - jpeg
          type: string
        size:
          description: "The size of the image generated. Either `1024x1024`, `1024x1536`,\
            \ or `1536x1024`."
          enum:
          - 1024x1024
          - 1024x1536
          - 1536x1024
          type: string
        quality:
          description: "The quality of the image generated. Either `low`, `medium`,\
            \ or `high`."
          enum:
          - low
          - medium
          - high
          type: string
        usage:
          $ref: "#/components/schemas/ImagesResponse_usage"
      required:
      - created
      title: Image generation response
      x-oaiMeta:
        name: The image generation response
        group: images
        example: |
          {
            "created": 1713833628,
            "data": [
              {
                "b64_json": "..."
              }
            ],
            "background": "transparent",
            "output_format": "png",
            "size": "1024x1024",
            "quality": "high",
            "usage": {
              "total_tokens": 100,
              "input_tokens": 50,
              "output_tokens": 50,
              "input_tokens_details": {
                "text_tokens": 10,
                "image_tokens": 40
              }
            }
          }
    Includable:
      description: |
        Specify additional output data to include in the model response. Currently
        supported values are:
        - `code_interpreter_call.outputs`: Includes the outputs of python code execution
          in code interpreter tool call items.
        - `computer_call_output.output.image_url`: Include image urls from the computer call output.
        - `file_search_call.results`: Include the search results of
          the file search tool call.
        - `message.input_image.image_url`: Include image urls from the input message.
        - `message.output_text.logprobs`: Include logprobs with assistant messages.
        - `reasoning.encrypted_content`: Includes an encrypted version of reasoning
          tokens in reasoning item outputs. This enables reasoning items to be used in
          multi-turn conversations when using the Responses API statelessly (like
          when the `store` parameter is set to `false`, or when an organization is
          enrolled in the zero data retention program).
      enum:
      - code_interpreter_call.outputs
      - computer_call_output.output.image_url
      - file_search_call.results
      - message.input_image.image_url
      - message.output_text.logprobs
      - reasoning.encrypted_content
      type: string
    InputAudio:
      description: |
        An audio input to the model.
      properties:
        type:
          description: |
            The type of the input item. Always `input_audio`.
          enum:
          - input_audio
          type: string
          x-stainless-const: true
        data:
          description: |
            Base64-encoded audio data.
          type: string
        format:
          description: |
            The format of the audio data. Currently supported formats are `mp3` and
            `wav`.
          enum:
          - mp3
          - wav
          type: string
      required:
      - data
      - format
      - type
      title: Audio input
    InputContent:
      oneOf:
      - $ref: "#/components/schemas/InputTextContent"
      - $ref: "#/components/schemas/InputImageContent"
      - $ref: "#/components/schemas/InputFileContent"
    InputItem:
      discriminator:
        propertyName: type
      oneOf:
      - $ref: "#/components/schemas/EasyInputMessage"
      - $ref: "#/components/schemas/Item"
      - $ref: "#/components/schemas/ItemReferenceParam"
    InputMessage:
      description: |
        A message input to the model with a role indicating instruction following
        hierarchy. Instructions given with the `developer` or `system` role take
        precedence over instructions given with the `user` role.
      properties:
        type:
          description: |
            The type of the message input. Always set to `message`.
          enum:
          - message
          type: string
          x-stainless-const: true
        role:
          description: |
            The role of the message input. One of `user`, `system`, or `developer`.
          enum:
          - user
          - system
          - developer
          type: string
        status:
          description: |
            The status of item. One of `in_progress`, `completed`, or
            `incomplete`. Populated when items are returned via API.
          enum:
          - in_progress
          - completed
          - incomplete
          type: string
        content:
          description: "A list of one or many input items to the model, containing\
            \ different content \ntypes.\n"
          items:
            $ref: "#/components/schemas/InputContent"
          type: array
      required:
      - content
      - role
      title: Input message
    InputMessageContentList:
      description: "A list of one or many input items to the model, containing different\
        \ content \ntypes.\n"
      items:
        $ref: "#/components/schemas/InputContent"
      type: array
    InputMessageResource:
      allOf:
      - $ref: "#/components/schemas/InputMessage"
      - properties:
          id:
            description: |
              The unique ID of the message input.
            type: string
        required:
        - id
      example:
        role: user
        id: id
        type: message
        content:
        - text: text
          type: input_text
        - text: text
          type: input_text
        status: in_progress
    Invite:
      description: Represents an individual `invite` to the organization.
      example:
        role: owner
        expires_at: 6
        projects:
        - role: member
          id: id
        - role: member
          id: id
        invited_at: 0
        id: id
        accepted_at: 1
        email: email
        object: organization.invite
        status: accepted
      properties:
        object:
          description: "The object type, which is always `organization.invite`"
          enum:
          - organization.invite
          type: string
          x-stainless-const: true
        id:
          description: "The identifier, which can be referenced in API endpoints"
          type: string
        email:
          description: The email address of the individual to whom the invite was
            sent
          type: string
        role:
          description: '`owner` or `reader`'
          enum:
          - owner
          - reader
          type: string
        status:
          description: "`accepted`,`expired`, or `pending`"
          enum:
          - accepted
          - expired
          - pending
          type: string
        invited_at:
          description: The Unix timestamp (in seconds) of when the invite was sent.
          type: integer
        expires_at:
          description: The Unix timestamp (in seconds) of when the invite expires.
          type: integer
        accepted_at:
          description: The Unix timestamp (in seconds) of when the invite was accepted.
          type: integer
        projects:
          description: The projects that were granted membership upon acceptance of
            the invite.
          items:
            $ref: "#/components/schemas/Invite_projects_inner"
          type: array
      required:
      - email
      - expires_at
      - id
      - invited_at
      - object
      - role
      - status
      x-oaiMeta:
        name: The invite object
        example: |
          {
            "object": "organization.invite",
            "id": "invite-abc",
            "email": "user@example.com",
            "role": "owner",
            "status": "accepted",
            "invited_at": 1711471533,
            "expires_at": 1711471533,
            "accepted_at": 1711471533,
            "projects": [
              {
                "id": "project-xyz",
                "role": "member"
              }
            ]
          }
    InviteDeleteResponse:
      example:
        deleted: true
        id: id
        object: organization.invite.deleted
      properties:
        object:
          description: "The object type, which is always `organization.invite.deleted`"
          enum:
          - organization.invite.deleted
          type: string
          x-stainless-const: true
        id:
          type: string
        deleted:
          type: boolean
      required:
      - deleted
      - id
      - object
    InviteListResponse:
      example:
        first_id: first_id
        data:
        - role: owner
          expires_at: 6
          projects:
          - role: member
            id: id
          - role: member
            id: id
          invited_at: 0
          id: id
          accepted_at: 1
          email: email
          object: organization.invite
          status: accepted
        - role: owner
          expires_at: 6
          projects:
          - role: member
            id: id
          - role: member
            id: id
          invited_at: 0
          id: id
          accepted_at: 1
          email: email
          object: organization.invite
          status: accepted
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          description: "The object type, which is always `list`"
          enum:
          - list
          type: string
          x-stainless-const: true
        data:
          items:
            $ref: "#/components/schemas/Invite"
          type: array
        first_id:
          description: The first `invite_id` in the retrieved `list`
          type: string
        last_id:
          description: The last `invite_id` in the retrieved `list`
          type: string
        has_more:
          description: The `has_more` property is used for pagination to indicate
            there are additional results.
          type: boolean
      required:
      - data
      - object
    InviteRequest:
      example:
        role: reader
        projects:
        - role: member
          id: id
        - role: member
          id: id
        email: email
      properties:
        email:
          description: Send an email to this address
          type: string
        role:
          description: '`owner` or `reader`'
          enum:
          - reader
          - owner
          type: string
        projects:
          description: "An array of projects to which membership is granted at the\
            \ same time the org invite is accepted. If omitted, the user will be invited\
            \ to the default project for compatibility with legacy behavior."
          items:
            $ref: "#/components/schemas/InviteRequest_projects_inner"
          type: array
      required:
      - email
      - role
    Item:
      description: |
        Content item used to generate a response.
      discriminator:
        propertyName: type
      oneOf:
      - $ref: "#/components/schemas/InputMessage"
      - $ref: "#/components/schemas/OutputMessage"
      - $ref: "#/components/schemas/FileSearchToolCall"
      - $ref: "#/components/schemas/ComputerToolCall"
      - $ref: "#/components/schemas/ComputerCallOutputItemParam"
      - $ref: "#/components/schemas/WebSearchToolCall"
      - $ref: "#/components/schemas/FunctionToolCall"
      - $ref: "#/components/schemas/FunctionCallOutputItemParam"
      - $ref: "#/components/schemas/ReasoningItem"
      - $ref: "#/components/schemas/ImageGenToolCall"
      - $ref: "#/components/schemas/CodeInterpreterToolCall"
      - $ref: "#/components/schemas/LocalShellToolCall"
      - $ref: "#/components/schemas/LocalShellToolCallOutput"
      - $ref: "#/components/schemas/MCPListTools"
      - $ref: "#/components/schemas/MCPApprovalRequest"
      - $ref: "#/components/schemas/MCPApprovalResponse"
      - $ref: "#/components/schemas/MCPToolCall"
    ItemResource:
      description: |
        Content item used to generate a response.
      discriminator:
        propertyName: type
      oneOf:
      - $ref: "#/components/schemas/InputMessageResource"
      - $ref: "#/components/schemas/OutputMessage"
      - $ref: "#/components/schemas/FileSearchToolCall"
      - $ref: "#/components/schemas/ComputerToolCall"
      - $ref: "#/components/schemas/ComputerToolCallOutputResource"
      - $ref: "#/components/schemas/WebSearchToolCall"
      - $ref: "#/components/schemas/FunctionToolCallResource"
      - $ref: "#/components/schemas/FunctionToolCallOutputResource"
      - $ref: "#/components/schemas/ImageGenToolCall"
      - $ref: "#/components/schemas/CodeInterpreterToolCall"
      - $ref: "#/components/schemas/LocalShellToolCall"
      - $ref: "#/components/schemas/LocalShellToolCallOutput"
      - $ref: "#/components/schemas/MCPListTools"
      - $ref: "#/components/schemas/MCPApprovalRequest"
      - $ref: "#/components/schemas/MCPApprovalResponseResource"
      - $ref: "#/components/schemas/MCPToolCall"
    KeyPress:
      description: |
        A collection of keypresses the model would like to perform.
      properties:
        type:
          default: keypress
          description: "Specifies the event type. For a keypress action, this property\
            \ is \nalways set to `keypress`.\n"
          enum:
          - keypress
          type: string
          x-stainless-const: true
        keys:
          description: |
            The combination of keys the model is requesting to be pressed. This is an
            array of strings, each representing a key.
          items:
            description: |
              One of the keys the model is requesting to be pressed.
            type: string
          type: array
      required:
      - keys
      - type
      title: KeyPress
    ListAssistantsResponse:
      example:
        first_id: asst_abc123
        data:
        - instructions: instructions
          tool_resources:
            code_interpreter:
              file_ids:
              - file_ids
              - file_ids
              - file_ids
              - file_ids
              - file_ids
            file_search:
              vector_store_ids:
              - vector_store_ids
          metadata:
            key: metadata
          created_at: 0
          description: description
          tools:
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          top_p: 1
          response_format: auto
          name: name
          temperature: 1
          model: model
          id: id
          object: assistant
        - instructions: instructions
          tool_resources:
            code_interpreter:
              file_ids:
              - file_ids
              - file_ids
              - file_ids
              - file_ids
              - file_ids
            file_search:
              vector_store_ids:
              - vector_store_ids
          metadata:
            key: metadata
          created_at: 0
          description: description
          tools:
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          top_p: 1
          response_format: auto
          name: name
          temperature: 1
          model: model
          id: id
          object: assistant
        last_id: asst_abc456
        has_more: false
        object: list
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: "#/components/schemas/AssistantObject"
          type: array
        first_id:
          example: asst_abc123
          type: string
        last_id:
          example: asst_abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      x-oaiMeta:
        name: List assistants response object
        group: chat
        example: |
          {
            "object": "list",
            "data": [
              {
                "id": "asst_abc123",
                "object": "assistant",
                "created_at": 1698982736,
                "name": "Coding Tutor",
                "description": null,
                "model": "gpt-4o",
                "instructions": "You are a helpful assistant designed to make me better at coding!",
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              },
              {
                "id": "asst_abc456",
                "object": "assistant",
                "created_at": 1698982718,
                "name": "My Assistant",
                "description": null,
                "model": "gpt-4o",
                "instructions": "You are a helpful assistant designed to make me better at coding!",
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              },
              {
                "id": "asst_abc789",
                "object": "assistant",
                "created_at": 1698982643,
                "name": null,
                "description": null,
                "model": "gpt-4o",
                "instructions": null,
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              }
            ],
            "first_id": "asst_abc123",
            "last_id": "asst_abc789",
            "has_more": false
          }
    ListAuditLogsResponse:
      example:
        first_id: audit_log-defb456h8dks
        data:
        - rate_limit.updated:
            changes_requested:
              batch_1_day_max_input_tokens: 7
              max_tokens_per_1_minute: 1
              max_images_per_1_minute: 5
              max_audio_megabytes_per_1_minute: 5
              max_requests_per_1_minute: 6
              max_requests_per_1_day: 2
            id: id
          user.updated:
            changes_requested:
              role: role
            id: id
          project:
            name: name
            id: id
          certificate.deleted:
            name: name
            certificate: certificate
            id: id
          service_account.deleted:
            id: id
          type: api_key.created
          logout.failed:
            error_message: error_message
            error_code: error_code
          certificate.updated:
            name: name
            id: id
          login.failed:
            error_message: error_message
            error_code: error_code
          service_account.updated:
            changes_requested:
              role: role
            id: id
          rate_limit.deleted:
            id: id
          id: id
          project.created:
            data:
              name: name
              title: title
            id: id
          certificate.created:
            name: name
            id: id
          checkpoint_permission.created:
            data:
              project_id: project_id
              fine_tuned_model_checkpoint: fine_tuned_model_checkpoint
            id: id
          organization.updated:
            changes_requested:
              threads_ui_visibility: threads_ui_visibility
              usage_dashboard_visibility: usage_dashboard_visibility
              api_call_logging: api_call_logging
              name: name
              description: description
              title: title
              api_call_logging_project_ids: api_call_logging_project_ids
            id: id
          project.updated:
            changes_requested:
              title: title
            id: id
          project.archived:
            id: id
          user.added:
            data:
              role: role
            id: id
          invite.accepted:
            id: id
          invite.deleted:
            id: id
          actor:
            api_key:
              service_account:
                id: id
              id: id
              type: user
              user:
                id: id
                email: email
            session:
              ip_address: ip_address
              user:
                id: id
                email: email
            type: session
          effective_at: 0
          checkpoint_permission.deleted:
            id: id
          invite.sent:
            data:
              role: role
              email: email
            id: id
          certificates.deactivated:
            certificates:
            - name: name
              id: id
            - name: name
              id: id
          service_account.created:
            data:
              role: role
            id: id
          api_key.created:
            data:
              scopes:
              - scopes
              - scopes
            id: id
          user.deleted:
            id: id
          api_key.deleted:
            id: id
          certificates.activated:
            certificates:
            - name: name
              id: id
            - name: name
              id: id
          api_key.updated:
            changes_requested:
              scopes:
              - scopes
              - scopes
            id: id
        - rate_limit.updated:
            changes_requested:
              batch_1_day_max_input_tokens: 7
              max_tokens_per_1_minute: 1
              max_images_per_1_minute: 5
              max_audio_megabytes_per_1_minute: 5
              max_requests_per_1_minute: 6
              max_requests_per_1_day: 2
            id: id
          user.updated:
            changes_requested:
              role: role
            id: id
          project:
            name: name
            id: id
          certificate.deleted:
            name: name
            certificate: certificate
            id: id
          service_account.deleted:
            id: id
          type: api_key.created
          logout.failed:
            error_message: error_message
            error_code: error_code
          certificate.updated:
            name: name
            id: id
          login.failed:
            error_message: error_message
            error_code: error_code
          service_account.updated:
            changes_requested:
              role: role
            id: id
          rate_limit.deleted:
            id: id
          id: id
          project.created:
            data:
              name: name
              title: title
            id: id
          certificate.created:
            name: name
            id: id
          checkpoint_permission.created:
            data:
              project_id: project_id
              fine_tuned_model_checkpoint: fine_tuned_model_checkpoint
            id: id
          organization.updated:
            changes_requested:
              threads_ui_visibility: threads_ui_visibility
              usage_dashboard_visibility: usage_dashboard_visibility
              api_call_logging: api_call_logging
              name: name
              description: description
              title: title
              api_call_logging_project_ids: api_call_logging_project_ids
            id: id
          project.updated:
            changes_requested:
              title: title
            id: id
          project.archived:
            id: id
          user.added:
            data:
              role: role
            id: id
          invite.accepted:
            id: id
          invite.deleted:
            id: id
          actor:
            api_key:
              service_account:
                id: id
              id: id
              type: user
              user:
                id: id
                email: email
            session:
              ip_address: ip_address
              user:
                id: id
                email: email
            type: session
          effective_at: 0
          checkpoint_permission.deleted:
            id: id
          invite.sent:
            data:
              role: role
              email: email
            id: id
          certificates.deactivated:
            certificates:
            - name: name
              id: id
            - name: name
              id: id
          service_account.created:
            data:
              role: role
            id: id
          api_key.created:
            data:
              scopes:
              - scopes
              - scopes
            id: id
          user.deleted:
            id: id
          api_key.deleted:
            id: id
          certificates.activated:
            certificates:
            - name: name
              id: id
            - name: name
              id: id
          api_key.updated:
            changes_requested:
              scopes:
              - scopes
              - scopes
            id: id
        last_id: audit_log-hnbkd8s93s
        has_more: true
        object: list
      properties:
        object:
          enum:
          - list
          type: string
          x-stainless-const: true
        data:
          items:
            $ref: "#/components/schemas/AuditLog"
          type: array
        first_id:
          example: audit_log-defb456h8dks
          type: string
        last_id:
          example: audit_log-hnbkd8s93s
          type: string
        has_more:
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ListBatchesResponse:
      example:
        first_id: batch_abc123
        data:
        - cancelled_at: 2
          metadata:
            key: metadata
          request_counts:
            total: 4
            completed: 7
            failed: 1
          input_file_id: input_file_id
          output_file_id: output_file_id
          error_file_id: error_file_id
          created_at: 6
          in_progress_at: 1
          expired_at: 9
          finalizing_at: 5
          completed_at: 2
          endpoint: endpoint
          expires_at: 5
          cancelling_at: 3
          completion_window: completion_window
          id: id
          failed_at: 7
          errors:
            data:
            - code: code
              param: param
              line: 0
              message: message
            - code: code
              param: param
              line: 0
              message: message
            object: object
          object: batch
          status: validating
        - cancelled_at: 2
          metadata:
            key: metadata
          request_counts:
            total: 4
            completed: 7
            failed: 1
          input_file_id: input_file_id
          output_file_id: output_file_id
          error_file_id: error_file_id
          created_at: 6
          in_progress_at: 1
          expired_at: 9
          finalizing_at: 5
          completed_at: 2
          endpoint: endpoint
          expires_at: 5
          cancelling_at: 3
          completion_window: completion_window
          id: id
          failed_at: 7
          errors:
            data:
            - code: code
              param: param
              line: 0
              message: message
            - code: code
              param: param
              line: 0
              message: message
            object: object
          object: batch
          status: validating
        last_id: batch_abc456
        has_more: true
        object: list
      properties:
        data:
          items:
            $ref: "#/components/schemas/Batch"
          type: array
        first_id:
          example: batch_abc123
          type: string
        last_id:
          example: batch_abc456
          type: string
        has_more:
          type: boolean
        object:
          enum:
          - list
          type: string
          x-stainless-const: true
      required:
      - data
      - has_more
      - object
    ListCertificatesResponse:
      example:
        first_id: cert_abc
        data:
        - name: name
          created_at: 0
          active: true
          id: id
          certificate_details:
            expires_at: 1
            content: content
            valid_at: 6
          object: certificate
        - name: name
          created_at: 0
          active: true
          id: id
          certificate_details:
            expires_at: 1
            content: content
            valid_at: 6
          object: certificate
        last_id: cert_abc
        has_more: true
        object: list
      properties:
        data:
          items:
            $ref: "#/components/schemas/Certificate"
          type: array
        first_id:
          example: cert_abc
          type: string
        last_id:
          example: cert_abc
          type: string
        has_more:
          type: boolean
        object:
          enum:
          - list
          type: string
          x-stainless-const: true
      required:
      - data
      - has_more
      - object
    ListFilesResponse:
      example:
        first_id: file-abc123
        data:
        - expires_at: 1
          filename: filename
          purpose: assistants
          bytes: 0
          created_at: 6
          id: id
          status_details: status_details
          object: file
          status: uploaded
        - expires_at: 1
          filename: filename
          purpose: assistants
          bytes: 0
          created_at: 6
          id: id
          status_details: status_details
          object: file
          status: uploaded
        last_id: file-abc456
        has_more: false
        object: list
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: "#/components/schemas/OpenAIFile"
          type: array
        first_id:
          example: file-abc123
          type: string
        last_id:
          example: file-abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ListFineTuningCheckpointPermissionResponse:
      example:
        first_id: first_id
        data:
        - project_id: project_id
          created_at: 0
          id: id
          object: checkpoint.permission
        - project_id: project_id
          created_at: 0
          id: id
          object: checkpoint.permission
        last_id: last_id
        has_more: true
        object: list
      properties:
        data:
          items:
            $ref: "#/components/schemas/FineTuningCheckpointPermission"
          type: array
        object:
          enum:
          - list
          type: string
          x-stainless-const: true
        first_id:
          type: string
          nullable: true
        last_id:
          type: string
          nullable: true
        has_more:
          type: boolean
      required:
      - data
      - has_more
      - object
    ListFineTuningJobCheckpointsResponse:
      example:
        first_id: first_id
        data:
        - step_number: 6
          created_at: 0
          fine_tuning_job_id: fine_tuning_job_id
          id: id
          metrics:
            full_valid_mean_token_accuracy: 3.616076749251911
            valid_loss: 2.3021358869347655
            full_valid_loss: 9.301444243932576
            train_mean_token_accuracy: 5.637376656633329
            valid_mean_token_accuracy: 7.061401241503109
            train_loss: 5.962133916683182
            step: 1.4658129805029452
          fine_tuned_model_checkpoint: fine_tuned_model_checkpoint
          object: fine_tuning.job.checkpoint
        - step_number: 6
          created_at: 0
          fine_tuning_job_id: fine_tuning_job_id
          id: id
          metrics:
            full_valid_mean_token_accuracy: 3.616076749251911
            valid_loss: 2.3021358869347655
            full_valid_loss: 9.301444243932576
            train_mean_token_accuracy: 5.637376656633329
            valid_mean_token_accuracy: 7.061401241503109
            train_loss: 5.962133916683182
            step: 1.4658129805029452
          fine_tuned_model_checkpoint: fine_tuned_model_checkpoint
          object: fine_tuning.job.checkpoint
        last_id: last_id
        has_more: true
        object: list
      properties:
        data:
          items:
            $ref: "#/components/schemas/FineTuningJobCheckpoint"
          type: array
        object:
          enum:
          - list
          type: string
          x-stainless-const: true
        first_id:
          type: string
          nullable: true
        last_id:
          type: string
          nullable: true
        has_more:
          type: boolean
      required:
      - data
      - has_more
      - object
    ListFineTuningJobEventsResponse:
      example:
        data:
        - data: "{}"
          level: info
          created_at: 0
          id: id
          message: message
          type: message
          object: fine_tuning.job.event
        - data: "{}"
          level: info
          created_at: 0
          id: id
          message: message
          type: message
          object: fine_tuning.job.event
        has_more: true
        object: list
      properties:
        data:
          items:
            $ref: "#/components/schemas/FineTuningJobEvent"
          type: array
        object:
          enum:
          - list
          type: string
          x-stainless-const: true
        has_more:
          type: boolean
      required:
      - data
      - has_more
      - object
    ListMessagesResponse:
      example:
        first_id: msg_abc123
        data:
        - metadata:
            key: metadata
          role: user
          assistant_id: assistant_id
          run_id: run_id
          attachments:
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          created_at: 0
          content:
          - image_file:
              file_id: file_id
              detail: auto
            type: image_file
          - image_file:
              file_id: file_id
              detail: auto
            type: image_file
          completed_at: 6
          thread_id: thread_id
          id: id
          incomplete_at: 1
          incomplete_details:
            reason: content_filter
          object: thread.message
          status: in_progress
        - metadata:
            key: metadata
          role: user
          assistant_id: assistant_id
          run_id: run_id
          attachments:
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          created_at: 0
          content:
          - image_file:
              file_id: file_id
              detail: auto
            type: image_file
          - image_file:
              file_id: file_id
              detail: auto
            type: image_file
          completed_at: 6
          thread_id: thread_id
          id: id
          incomplete_at: 1
          incomplete_details:
            reason: content_filter
          object: thread.message
          status: in_progress
        last_id: msg_abc123
        has_more: false
        object: list
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: "#/components/schemas/MessageObject"
          type: array
        first_id:
          example: msg_abc123
          type: string
        last_id:
          example: msg_abc123
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ListModelsResponse:
      example:
        data:
        - created: 0
          owned_by: owned_by
          id: id
          object: model
        - created: 0
          owned_by: owned_by
          id: id
          object: model
        object: list
      properties:
        object:
          enum:
          - list
          type: string
          x-stainless-const: true
        data:
          items:
            $ref: "#/components/schemas/Model"
          type: array
      required:
      - data
      - object
    ListPaginatedFineTuningJobsResponse:
      example:
        data:
        - training_file: training_file
          result_files:
          - file-abc123
          - file-abc123
          metadata:
            key: metadata
          finished_at: 6
          seed: 5
          method:
            supervised:
              hyperparameters:
                batch_size: auto
                n_epochs: auto
                learning_rate_multiplier: auto
            dpo:
              hyperparameters:
                batch_size: null
                n_epochs: null
                beta: auto
                learning_rate_multiplier: null
            reinforcement:
              hyperparameters:
                reasoning_effort: default
                batch_size: null
                n_epochs: null
                eval_interval: auto
                compute_multiplier: auto
                eval_samples: auto
                learning_rate_multiplier: null
              grader:
                reference: reference
                input: input
                name: name
                type: string_check
                operation: eq
            type: supervised
          fine_tuned_model: fine_tuned_model
          validation_file: validation_file
          created_at: 0
          error:
            code: code
            param: param
            message: message
          estimated_finish: 5
          organization_id: organization_id
          hyperparameters:
            batch_size: auto
            n_epochs: auto
            learning_rate_multiplier: auto
          model: model
          id: id
          trained_tokens: 1
          integrations:
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          object: fine_tuning.job
          status: validating_files
        - training_file: training_file
          result_files:
          - file-abc123
          - file-abc123
          metadata:
            key: metadata
          finished_at: 6
          seed: 5
          method:
            supervised:
              hyperparameters:
                batch_size: auto
                n_epochs: auto
                learning_rate_multiplier: auto
            dpo:
              hyperparameters:
                batch_size: null
                n_epochs: null
                beta: auto
                learning_rate_multiplier: null
            reinforcement:
              hyperparameters:
                reasoning_effort: default
                batch_size: null
                n_epochs: null
                eval_interval: auto
                compute_multiplier: auto
                eval_samples: auto
                learning_rate_multiplier: null
              grader:
                reference: reference
                input: input
                name: name
                type: string_check
                operation: eq
            type: supervised
          fine_tuned_model: fine_tuned_model
          validation_file: validation_file
          created_at: 0
          error:
            code: code
            param: param
            message: message
          estimated_finish: 5
          organization_id: organization_id
          hyperparameters:
            batch_size: auto
            n_epochs: auto
            learning_rate_multiplier: auto
          model: model
          id: id
          trained_tokens: 1
          integrations:
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          object: fine_tuning.job
          status: validating_files
        has_more: true
        object: list
      properties:
        data:
          items:
            $ref: "#/components/schemas/FineTuningJob"
          type: array
        has_more:
          type: boolean
        object:
          enum:
          - list
          type: string
          x-stainless-const: true
      required:
      - data
      - has_more
      - object
    ListRunStepsResponse:
      example:
        first_id: step_abc123
        data:
        - cancelled_at: 1
          metadata:
            key: metadata
          assistant_id: assistant_id
          run_id: run_id
          usage:
            completion_tokens: 2
            prompt_tokens: 7
            total_tokens: 9
          created_at: 0
          expired_at: 6
          type: message_creation
          step_details:
            message_creation:
              message_id: message_id
            type: message_creation
          completed_at: 5
          thread_id: thread_id
          id: id
          last_error:
            code: server_error
            message: message
          failed_at: 5
          object: thread.run.step
          status: in_progress
        - cancelled_at: 1
          metadata:
            key: metadata
          assistant_id: assistant_id
          run_id: run_id
          usage:
            completion_tokens: 2
            prompt_tokens: 7
            total_tokens: 9
          created_at: 0
          expired_at: 6
          type: message_creation
          step_details:
            message_creation:
              message_id: message_id
            type: message_creation
          completed_at: 5
          thread_id: thread_id
          id: id
          last_error:
            code: server_error
            message: message
          failed_at: 5
          object: thread.run.step
          status: in_progress
        last_id: step_abc456
        has_more: false
        object: list
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: "#/components/schemas/RunStepObject"
          type: array
        first_id:
          example: step_abc123
          type: string
        last_id:
          example: step_abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ListRunsResponse:
      example:
        first_id: run_abc123
        data:
        - cancelled_at: 5
          instructions: instructions
          metadata:
            key: metadata
          assistant_id: assistant_id
          required_action:
            submit_tool_outputs:
              tool_calls:
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
            type: submit_tool_outputs
          usage:
            completion_tokens: 7
            prompt_tokens: 9
            total_tokens: 3
          created_at: 0
          tools:
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          top_p: 4.145608029883936
          max_completion_tokens: 256
          thread_id: thread_id
          expires_at: 6
          response_format: auto
          temperature: 2.027123023002322
          tool_choice: ""
          model: model
          id: id
          last_error:
            code: server_error
            message: message
          incomplete_details:
            reason: max_completion_tokens
          truncation_strategy: ""
          completed_at: 2
          parallel_tool_calls: true
          started_at: 1
          failed_at: 5
          max_prompt_tokens: 256
          object: thread.run
          status: queued
        - cancelled_at: 5
          instructions: instructions
          metadata:
            key: metadata
          assistant_id: assistant_id
          required_action:
            submit_tool_outputs:
              tool_calls:
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
            type: submit_tool_outputs
          usage:
            completion_tokens: 7
            prompt_tokens: 9
            total_tokens: 3
          created_at: 0
          tools:
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          top_p: 4.145608029883936
          max_completion_tokens: 256
          thread_id: thread_id
          expires_at: 6
          response_format: auto
          temperature: 2.027123023002322
          tool_choice: ""
          model: model
          id: id
          last_error:
            code: server_error
            message: message
          incomplete_details:
            reason: max_completion_tokens
          truncation_strategy: ""
          completed_at: 2
          parallel_tool_calls: true
          started_at: 1
          failed_at: 5
          max_prompt_tokens: 256
          object: thread.run
          status: queued
        last_id: run_abc456
        has_more: false
        object: list
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: "#/components/schemas/RunObject"
          type: array
        first_id:
          example: run_abc123
          type: string
        last_id:
          example: run_abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ListVectorStoreFilesResponse:
      example:
        first_id: file-abc123
        data:
        - chunking_strategy:
            static:
              max_chunk_size_tokens: 685
              chunk_overlap_tokens: 5
            type: static
          usage_bytes: 0
          created_at: 6
          attributes:
            key: VectorStoreFileAttributes_value
          id: id
          last_error:
            code: server_error
            message: message
          object: vector_store.file
          vector_store_id: vector_store_id
          status: in_progress
        - chunking_strategy:
            static:
              max_chunk_size_tokens: 685
              chunk_overlap_tokens: 5
            type: static
          usage_bytes: 0
          created_at: 6
          attributes:
            key: VectorStoreFileAttributes_value
          id: id
          last_error:
            code: server_error
            message: message
          object: vector_store.file
          vector_store_id: vector_store_id
          status: in_progress
        last_id: file-abc456
        has_more: false
        object: list
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: "#/components/schemas/VectorStoreFileObject"
          type: array
        first_id:
          example: file-abc123
          type: string
        last_id:
          example: file-abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ListVectorStoresResponse:
      example:
        first_id: vs_abc123
        data:
        - file_counts:
            in_progress: 1
            total: 7
            cancelled: 2
            completed: 5
            failed: 5
          metadata:
            key: metadata
          expires_at: 3
          expires_after:
            anchor: last_active_at
            days: 339
          last_active_at: 2
          usage_bytes: 6
          name: name
          created_at: 0
          id: id
          object: vector_store
          status: expired
        - file_counts:
            in_progress: 1
            total: 7
            cancelled: 2
            completed: 5
            failed: 5
          metadata:
            key: metadata
          expires_at: 3
          expires_after:
            anchor: last_active_at
            days: 339
          last_active_at: 2
          usage_bytes: 6
          name: name
          created_at: 0
          id: id
          object: vector_store
          status: expired
        last_id: vs_abc456
        has_more: false
        object: list
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: "#/components/schemas/VectorStoreObject"
          type: array
        first_id:
          example: vs_abc123
          type: string
        last_id:
          example: vs_abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    LocalShellExecAction:
      description: |
        Execute a shell command on the server.
      properties:
        type:
          description: |
            The type of the local shell action. Always `exec`.
          enum:
          - exec
          type: string
          x-stainless-const: true
        command:
          description: |
            The command to run.
          items:
            type: string
          type: array
        timeout_ms:
          description: |
            Optional timeout in milliseconds for the command.
          type: integer
          nullable: true
        working_directory:
          description: |
            Optional working directory to run the command in.
          type: string
          nullable: true
        env:
          additionalProperties:
            type: string
          description: |
            Environment variables to set for the command.
        user:
          description: |
            Optional user to run the command as.
          type: string
          nullable: true
      required:
      - command
      - env
      - type
      title: Local shell exec action
    LocalShellTool:
      description: |
        A tool that allows the model to execute shell commands in a local environment.
      properties:
        type:
          description: The type of the local shell tool. Always `local_shell`.
          enum:
          - local_shell
          type: string
          x-stainless-const: true
      required:
      - type
      title: Local shell tool
    LocalShellToolCall:
      description: |
        A tool call to run a command on the local shell.
      properties:
        type:
          description: |
            The type of the local shell call. Always `local_shell_call`.
          enum:
          - local_shell_call
          type: string
          x-stainless-const: true
        id:
          description: |
            The unique ID of the local shell call.
          type: string
        call_id:
          description: |
            The unique ID of the local shell tool call generated by the model.
          type: string
        action:
          $ref: "#/components/schemas/LocalShellExecAction"
        status:
          description: |
            The status of the local shell call.
          enum:
          - in_progress
          - completed
          - incomplete
          type: string
      required:
      - action
      - call_id
      - id
      - status
      - type
      title: Local shell call
    LocalShellToolCallOutput:
      description: |
        The output of a local shell tool call.
      properties:
        type:
          description: |
            The type of the local shell tool call output. Always `local_shell_call_output`.
          enum:
          - local_shell_call_output
          type: string
          x-stainless-const: true
        id:
          description: |
            The unique ID of the local shell tool call generated by the model.
          type: string
        output:
          description: |
            A JSON string of the output of the local shell tool call.
          type: string
        status:
          description: |
            The status of the item. One of `in_progress`, `completed`, or `incomplete`.
          enum:
          - in_progress
          - completed
          - incomplete
          type: string
          nullable: true
      required:
      - id
      - output
      - type
      title: Local shell call output
    LogProbProperties:
      description: |
        A log probability object.
      properties:
        token:
          description: |
            The token that was used to generate the log probability.
          type: string
        logprob:
          description: |
            The log probability of the token.
          type: number
        bytes:
          description: |
            The bytes that were used to generate the log probability.
          items:
            type: integer
          type: array
      required:
      - bytes
      - logprob
      - token
    MCPApprovalRequest:
      description: |
        A request for human approval of a tool invocation.
      properties:
        type:
          description: |
            The type of the item. Always `mcp_approval_request`.
          enum:
          - mcp_approval_request
          type: string
          x-stainless-const: true
        id:
          description: |
            The unique ID of the approval request.
          type: string
        server_label:
          description: |
            The label of the MCP server making the request.
          type: string
        name:
          description: |
            The name of the tool to run.
          type: string
        arguments:
          description: |
            A JSON string of arguments for the tool.
          type: string
      required:
      - arguments
      - id
      - name
      - server_label
      - type
      title: MCP approval request
    MCPApprovalResponse:
      description: |
        A response to an MCP approval request.
      properties:
        type:
          description: |
            The type of the item. Always `mcp_approval_response`.
          enum:
          - mcp_approval_response
          type: string
          x-stainless-const: true
        id:
          description: |
            The unique ID of the approval response
          type: string
          nullable: true
        approval_request_id:
          description: |
            The ID of the approval request being answered.
          type: string
        approve:
          description: |
            Whether the request was approved.
          type: boolean
        reason:
          description: |
            Optional reason for the decision.
          type: string
          nullable: true
      required:
      - approval_request_id
      - approve
      - type
      title: MCP approval response
    MCPApprovalResponseResource:
      description: |
        A response to an MCP approval request.
      properties:
        type:
          description: |
            The type of the item. Always `mcp_approval_response`.
          enum:
          - mcp_approval_response
          type: string
          x-stainless-const: true
        id:
          description: |
            The unique ID of the approval response
          type: string
        approval_request_id:
          description: |
            The ID of the approval request being answered.
          type: string
        approve:
          description: |
            Whether the request was approved.
          type: boolean
        reason:
          description: |
            Optional reason for the decision.
          type: string
          nullable: true
      required:
      - approval_request_id
      - approve
      - id
      - type
      title: MCP approval response
    MCPListTools:
      description: |
        A list of tools available on an MCP server.
      properties:
        type:
          description: |
            The type of the item. Always `mcp_list_tools`.
          enum:
          - mcp_list_tools
          type: string
          x-stainless-const: true
        id:
          description: |
            The unique ID of the list.
          type: string
        server_label:
          description: |
            The label of the MCP server.
          type: string
        tools:
          description: |
            The tools available on the server.
          items:
            $ref: "#/components/schemas/MCPListToolsTool"
          type: array
        error:
          description: |
            Error message if the server could not list tools.
          type: string
          nullable: true
      required:
      - id
      - server_label
      - tools
      - type
      title: MCP list tools
    MCPListToolsTool:
      description: |
        A tool available on an MCP server.
      properties:
        name:
          description: |
            The name of the tool.
          type: string
        description:
          description: |
            The description of the tool.
          type: string
          nullable: true
        input_schema:
          description: |
            The JSON schema describing the tool's input.
          type: object
        annotations:
          description: |
            Additional annotations about the tool.
          type: object
          nullable: true
      required:
      - input_schema
      - name
      title: MCP list tools tool
    MCPTool:
      description: "Give the model access to additional tools via remote Model Context\
        \ Protocol \n(MCP) servers. [Learn more about MCP](/docs/guides/tools-remote-mcp).\n"
      properties:
        type:
          description: The type of the MCP tool. Always `mcp`.
          enum:
          - mcp
          type: string
          x-stainless-const: true
        server_label:
          description: |
            A label for this MCP server, used to identify it in tool calls.
          type: string
        server_url:
          description: |
            The URL for the MCP server.
          type: string
        headers:
          additionalProperties:
            type: string
          description: |
            Optional HTTP headers to send to the MCP server. Use for authentication
            or other purposes.
          nullable: true
        allowed_tools:
          $ref: "#/components/schemas/MCPTool_allowed_tools"
        require_approval:
          $ref: "#/components/schemas/MCPTool_require_approval"
      required:
      - server_label
      - server_url
      - type
      title: MCP tool
    MCPToolCall:
      description: |
        An invocation of a tool on an MCP server.
      properties:
        type:
          description: |
            The type of the item. Always `mcp_call`.
          enum:
          - mcp_call
          type: string
          x-stainless-const: true
        id:
          description: |
            The unique ID of the tool call.
          type: string
        server_label:
          description: |
            The label of the MCP server running the tool.
          type: string
        name:
          description: |
            The name of the tool that was run.
          type: string
        arguments:
          description: |
            A JSON string of the arguments passed to the tool.
          type: string
        output:
          description: |
            The output from the tool call.
          type: string
          nullable: true
        error:
          description: |
            The error from the tool call, if any.
          type: string
          nullable: true
      required:
      - arguments
      - id
      - name
      - server_label
      - type
      title: MCP tool call
    MessageContentImageFileObject:
      description: "References an image [File](/docs/api-reference/files) in the content\
        \ of a message."
      example:
        image_file:
          file_id: file_id
          detail: auto
        type: image_file
      properties:
        type:
          description: Always `image_file`.
          enum:
          - image_file
          type: string
          x-stainless-const: true
        image_file:
          $ref: "#/components/schemas/MessageContentImageFileObject_image_file"
      required:
      - image_file
      - type
      title: Image file
    MessageContentImageUrlObject:
      description: References an image URL in the content of a message.
      properties:
        type:
          description: The type of the content part.
          enum:
          - image_url
          type: string
          x-stainless-const: true
        image_url:
          $ref: "#/components/schemas/MessageContentImageUrlObject_image_url"
      required:
      - image_url
      - type
      title: Image URL
    MessageContentRefusalObject:
      description: The refusal content generated by the assistant.
      properties:
        type:
          description: Always `refusal`.
          enum:
          - refusal
          type: string
          x-stainless-const: true
        refusal:
          type: string
          nullable: false
      required:
      - refusal
      - type
      title: Refusal
    MessageContentTextAnnotationsFileCitationObject:
      description: A citation within the message that points to a specific quote from
        a specific File associated with the assistant or the message. Generated when
        the assistant uses the "file_search" tool to search files.
      properties:
        type:
          description: Always `file_citation`.
          enum:
          - file_citation
          type: string
          x-stainless-const: true
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_citation:
          $ref: "#/components/schemas/MessageContentTextAnnotationsFileCitationObject_file_citation"
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      required:
      - end_index
      - file_citation
      - start_index
      - text
      - type
      title: File citation
    MessageContentTextAnnotationsFilePathObject:
      description: A URL for the file that's generated when the assistant used the
        `code_interpreter` tool to generate a file.
      properties:
        type:
          description: Always `file_path`.
          enum:
          - file_path
          type: string
          x-stainless-const: true
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_path:
          $ref: "#/components/schemas/MessageContentTextAnnotationsFilePathObject_file_path"
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      required:
      - end_index
      - file_path
      - start_index
      - text
      - type
      title: File path
    MessageContentTextObject:
      description: The text content that is part of a message.
      properties:
        type:
          description: Always `text`.
          enum:
          - text
          type: string
          x-stainless-const: true
        text:
          $ref: "#/components/schemas/MessageContentTextObject_text"
      required:
      - text
      - type
      title: Text
    MessageDeltaContentImageFileObject:
      description: "References an image [File](/docs/api-reference/files) in the content\
        \ of a message."
      properties:
        index:
          description: The index of the content part in the message.
          type: integer
        type:
          description: Always `image_file`.
          enum:
          - image_file
          type: string
          x-stainless-const: true
        image_file:
          $ref: "#/components/schemas/MessageDeltaContentImageFileObject_image_file"
      required:
      - index
      - type
      title: Image file
    MessageDeltaContentImageUrlObject:
      description: References an image URL in the content of a message.
      properties:
        index:
          description: The index of the content part in the message.
          type: integer
        type:
          description: Always `image_url`.
          enum:
          - image_url
          type: string
          x-stainless-const: true
        image_url:
          $ref: "#/components/schemas/MessageDeltaContentImageUrlObject_image_url"
      required:
      - index
      - type
      title: Image URL
    MessageDeltaContentRefusalObject:
      description: The refusal content that is part of a message.
      properties:
        index:
          description: The index of the refusal part in the message.
          type: integer
        type:
          description: Always `refusal`.
          enum:
          - refusal
          type: string
          x-stainless-const: true
        refusal:
          type: string
      required:
      - index
      - type
      title: Refusal
    MessageDeltaContentTextAnnotationsFileCitationObject:
      description: A citation within the message that points to a specific quote from
        a specific File associated with the assistant or the message. Generated when
        the assistant uses the "file_search" tool to search files.
      properties:
        index:
          description: The index of the annotation in the text content part.
          type: integer
        type:
          description: Always `file_citation`.
          enum:
          - file_citation
          type: string
          x-stainless-const: true
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_citation:
          $ref: "#/components/schemas/MessageDeltaContentTextAnnotationsFileCitationObject_file_citation"
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      required:
      - index
      - type
      title: File citation
    MessageDeltaContentTextAnnotationsFilePathObject:
      description: A URL for the file that's generated when the assistant used the
        `code_interpreter` tool to generate a file.
      properties:
        index:
          description: The index of the annotation in the text content part.
          type: integer
        type:
          description: Always `file_path`.
          enum:
          - file_path
          type: string
          x-stainless-const: true
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_path:
          $ref: "#/components/schemas/MessageDeltaContentTextAnnotationsFilePathObject_file_path"
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      required:
      - index
      - type
      title: File path
    MessageDeltaContentTextObject:
      description: The text content that is part of a message.
      properties:
        index:
          description: The index of the content part in the message.
          type: integer
        type:
          description: Always `text`.
          enum:
          - text
          type: string
          x-stainless-const: true
        text:
          $ref: "#/components/schemas/MessageDeltaContentTextObject_text"
      required:
      - index
      - type
      title: Text
    MessageDeltaObject:
      description: |
        Represents a message delta i.e. any changed fields on a message during streaming.
      properties:
        id:
          description: "The identifier of the message, which can be referenced in\
            \ API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread.message.delta`."
          enum:
          - thread.message.delta
          type: string
          x-stainless-const: true
        delta:
          $ref: "#/components/schemas/MessageDeltaObject_delta"
      required:
      - delta
      - id
      - object
      title: Message delta object
      x-oaiMeta:
        name: The message delta object
        beta: true
        example: |
          {
            "id": "msg_123",
            "object": "thread.message.delta",
            "delta": {
              "content": [
                {
                  "index": 0,
                  "type": "text",
                  "text": { "value": "Hello", "annotations": [] }
                }
              ]
            }
          }
    MessageObject:
      description: "Represents a message within a [thread](/docs/api-reference/threads)."
      example:
        metadata:
          key: metadata
        role: user
        assistant_id: assistant_id
        run_id: run_id
        attachments:
        - file_id: file_id
          tools:
          - type: code_interpreter
          - type: code_interpreter
        - file_id: file_id
          tools:
          - type: code_interpreter
          - type: code_interpreter
        created_at: 0
        content:
        - image_file:
            file_id: file_id
            detail: auto
          type: image_file
        - image_file:
            file_id: file_id
            detail: auto
          type: image_file
        completed_at: 6
        thread_id: thread_id
        id: id
        incomplete_at: 1
        incomplete_details:
          reason: content_filter
        object: thread.message
        status: in_progress
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread.message`."
          enum:
          - thread.message
          type: string
          x-stainless-const: true
        created_at:
          description: The Unix timestamp (in seconds) for when the message was created.
          type: integer
        thread_id:
          description: "The [thread](/docs/api-reference/threads) ID that this message\
            \ belongs to."
          type: string
        status:
          description: "The status of the message, which can be either `in_progress`,\
            \ `incomplete`, or `completed`."
          enum:
          - in_progress
          - incomplete
          - completed
          type: string
        incomplete_details:
          $ref: "#/components/schemas/MessageObject_incomplete_details"
        completed_at:
          description: The Unix timestamp (in seconds) for when the message was completed.
          type: integer
          nullable: true
        incomplete_at:
          description: The Unix timestamp (in seconds) for when the message was marked
            as incomplete.
          type: integer
          nullable: true
        role:
          description: The entity that produced the message. One of `user` or `assistant`.
          enum:
          - user
          - assistant
          type: string
        content:
          description: The content of the message in array of text and/or images.
          items:
            $ref: "#/components/schemas/MessageObject_content_inner"
          type: array
        assistant_id:
          description: "If applicable, the ID of the [assistant](/docs/api-reference/assistants)\
            \ that authored this message."
          type: string
          nullable: true
        run_id:
          description: "The ID of the [run](/docs/api-reference/runs) associated with\
            \ the creation of this message. Value is `null` when messages are created\
            \ manually using the create message or create thread endpoints."
          type: string
          nullable: true
        attachments:
          description: "A list of files attached to the message, and the tools they\
            \ were added to."
          items:
            $ref: "#/components/schemas/CreateMessageRequest_attachments_inner"
          type: array
          nullable: true
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
      required:
      - assistant_id
      - attachments
      - completed_at
      - content
      - created_at
      - id
      - incomplete_at
      - incomplete_details
      - metadata
      - object
      - role
      - run_id
      - status
      - thread_id
      title: The message object
      x-oaiMeta:
        name: The message object
        beta: true
        example: |
          {
            "id": "msg_abc123",
            "object": "thread.message",
            "created_at": 1698983503,
            "thread_id": "thread_abc123",
            "role": "assistant",
            "content": [
              {
                "type": "text",
                "text": {
                  "value": "Hi! How can I help you today?",
                  "annotations": []
                }
              }
            ],
            "assistant_id": "asst_abc123",
            "run_id": "run_abc123",
            "attachments": [],
            "metadata": {}
          }
    MessageRequestContentTextObject:
      description: The text content that is part of a message.
      properties:
        type:
          description: Always `text`.
          enum:
          - text
          type: string
          x-stainless-const: true
        text:
          description: Text content to be sent to the model
          type: string
      required:
      - text
      - type
      title: Text
    MessageStreamEvent:
      oneOf:
      - $ref: "#/components/schemas/MessageStreamEvent_oneOf"
      - $ref: "#/components/schemas/MessageStreamEvent_oneOf_1"
      - $ref: "#/components/schemas/MessageStreamEvent_oneOf_2"
      - $ref: "#/components/schemas/MessageStreamEvent_oneOf_3"
      - $ref: "#/components/schemas/MessageStreamEvent_oneOf_4"
    Metadata:
      additionalProperties:
        type: string
      description: "Set of 16 key-value pairs that can be attached to an object. This\
        \ can be\nuseful for storing additional information about the object in a\
        \ structured\nformat, and querying for objects via API or the dashboard. \n\
        \nKeys are strings with a maximum length of 64 characters. Values are strings\n\
        with a maximum length of 512 characters.\n"
      x-oaiTypeLabel: map
      nullable: true
    Model:
      description: Describes an OpenAI model offering that can be used with the API.
      example:
        created: 0
        owned_by: owned_by
        id: id
        object: model
      properties:
        id:
          description: "The model identifier, which can be referenced in the API endpoints."
          type: string
        created:
          description: The Unix timestamp (in seconds) when the model was created.
          type: integer
        object:
          description: "The object type, which is always \"model\"."
          enum:
          - model
          type: string
          x-stainless-const: true
        owned_by:
          description: The organization that owns the model.
          type: string
      required:
      - created
      - id
      - object
      - owned_by
      title: Model
      x-oaiMeta:
        name: The model object
        example: |
          {
            "id": "VAR_chat_model_id",
            "object": "model",
            "created": 1686935002,
            "owned_by": "openai"
          }
    ModelIds:
      anyOf:
      - $ref: "#/components/schemas/ModelIdsShared"
      - $ref: "#/components/schemas/ModelIdsResponses"
    ModelIdsResponses:
      anyOf:
      - $ref: "#/components/schemas/ModelIdsShared"
      - enum:
        - o1-pro
        - o1-pro-2025-03-19
        - o3-pro
        - o3-pro-2025-06-10
        - o3-deep-research
        - o3-deep-research-2025-06-26
        - o4-mini-deep-research
        - o4-mini-deep-research-2025-06-26
        - computer-use-preview
        - computer-use-preview-2025-03-11
        title: ResponsesOnlyModel
        type: string
      example: gpt-4o
    ModelIdsShared:
      anyOf:
      - type: string
      - enum:
        - gpt-4.1
        - gpt-4.1-mini
        - gpt-4.1-nano
        - gpt-4.1-2025-04-14
        - gpt-4.1-mini-2025-04-14
        - gpt-4.1-nano-2025-04-14
        - o4-mini
        - o4-mini-2025-04-16
        - o3
        - o3-2025-04-16
        - o3-mini
        - o3-mini-2025-01-31
        - o1
        - o1-2024-12-17
        - o1-preview
        - o1-preview-2024-09-12
        - o1-mini
        - o1-mini-2024-09-12
        - gpt-4o
        - gpt-4o-2024-11-20
        - gpt-4o-2024-08-06
        - gpt-4o-2024-05-13
        - gpt-4o-audio-preview
        - gpt-4o-audio-preview-2024-10-01
        - gpt-4o-audio-preview-2024-12-17
        - gpt-4o-audio-preview-2025-06-03
        - gpt-4o-mini-audio-preview
        - gpt-4o-mini-audio-preview-2024-12-17
        - gpt-4o-search-preview
        - gpt-4o-mini-search-preview
        - gpt-4o-search-preview-2025-03-11
        - gpt-4o-mini-search-preview-2025-03-11
        - chatgpt-4o-latest
        - codex-mini-latest
        - gpt-4o-mini
        - gpt-4o-mini-2024-07-18
        - gpt-4-turbo
        - gpt-4-turbo-2024-04-09
        - gpt-4-0125-preview
        - gpt-4-turbo-preview
        - gpt-4-1106-preview
        - gpt-4-vision-preview
        - gpt-4
        - gpt-4-0314
        - gpt-4-0613
        - gpt-4-32k
        - gpt-4-32k-0314
        - gpt-4-32k-0613
        - gpt-3.5-turbo
        - gpt-3.5-turbo-16k
        - gpt-3.5-turbo-0301
        - gpt-3.5-turbo-0613
        - gpt-3.5-turbo-1106
        - gpt-3.5-turbo-0125
        - gpt-3.5-turbo-16k-0613
        type: string
      example: gpt-4o
    ModelResponseProperties:
      properties:
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        top_logprobs:
          description: |
            An integer between 0 and 20 specifying the number of most likely tokens to
            return at each token position, each with an associated log probability.
          maximum: 20
          minimum: 0
          type: integer
          nullable: true
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
            We generally recommend altering this or `top_p` but not both.
          example: 1
          maximum: 2
          minimum: 0
          type: number
          nullable: true
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling,
            where the model considers the results of the tokens with top_p probability
            mass. So 0.1 means only the tokens comprising the top 10% probability mass
            are considered.

            We generally recommend altering this or `temperature` but not both.
          example: 1
          maximum: 1
          minimum: 0
          type: number
          nullable: true
        user:
          description: "A stable identifier for your end-users. \nUsed to boost cache\
            \ hit rates by better bucketing similar requests and  to help OpenAI detect\
            \ and prevent abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).\n"
          example: user-1234
          type: string
        service_tier:
          $ref: "#/components/schemas/ServiceTier"
    ModifyAssistantRequest:
      additionalProperties: true
      example:
        reasoning_effort: medium
        top_p: 1
        instructions: instructions
        tool_resources:
          code_interpreter:
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
          file_search:
            vector_store_ids:
            - vector_store_ids
        metadata:
          key: metadata
        response_format: auto
        name: name
        temperature: 1
        description: description
        model: ModifyAssistantRequest_model
        tools:
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
      properties:
        model:
          $ref: "#/components/schemas/ModifyAssistantRequest_model"
        reasoning_effort:
          $ref: "#/components/schemas/ReasoningEffort"
        name:
          description: |
            The name of the assistant. The maximum length is 256 characters.
          maxLength: 256
          type: string
          nullable: true
        description:
          description: |
            The description of the assistant. The maximum length is 512 characters.
          maxLength: 512
          type: string
          nullable: true
        instructions:
          description: |
            The system instructions that the assistant uses. The maximum length is 256,000 characters.
          maxLength: 256000
          type: string
          nullable: true
        tools:
          default: []
          description: |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: "#/components/schemas/AssistantObject_tools_inner"
          maxItems: 128
          type: array
        tool_resources:
          $ref: "#/components/schemas/ModifyAssistantRequest_tool_resources"
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          example: 1
          maximum: 2
          minimum: 0
          type: number
          nullable: true
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
          example: 1
          maximum: 1
          minimum: 0
          type: number
          nullable: true
        response_format:
          $ref: "#/components/schemas/AssistantsApiResponseFormatOption"
    ModifyCertificateRequest:
      example:
        name: name
      properties:
        name:
          description: The updated name for the certificate
          type: string
      required:
      - name
    ModifyMessageRequest:
      additionalProperties: true
      example:
        metadata:
          key: metadata
      properties:
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
    ModifyRunRequest:
      additionalProperties: true
      example:
        metadata:
          key: metadata
      properties:
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
    ModifyThreadRequest:
      additionalProperties: true
      example:
        tool_resources:
          code_interpreter:
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
          file_search:
            vector_store_ids:
            - vector_store_ids
        metadata:
          key: metadata
      properties:
        tool_resources:
          $ref: "#/components/schemas/ModifyThreadRequest_tool_resources"
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
    Move:
      description: |
        A mouse move action.
      properties:
        type:
          default: move
          description: "Specifies the event type. For a move action, this property\
            \ is \nalways set to `move`.\n"
          enum:
          - move
          type: string
          x-stainless-const: true
        x:
          description: |
            The x-coordinate to move to.
          type: integer
        "y":
          description: |
            The y-coordinate to move to.
          type: integer
      required:
      - type
      - x
      - "y"
      title: Move
    OpenAIFile:
      description: The `File` object represents a document that has been uploaded
        to OpenAI.
      example:
        expires_at: 1
        filename: filename
        purpose: assistants
        bytes: 0
        created_at: 6
        id: id
        status_details: status_details
        object: file
        status: uploaded
      properties:
        id:
          description: "The file identifier, which can be referenced in the API endpoints."
          type: string
        bytes:
          description: "The size of the file, in bytes."
          type: integer
        created_at:
          description: The Unix timestamp (in seconds) for when the file was created.
          type: integer
        expires_at:
          description: The Unix timestamp (in seconds) for when the file will expire.
          type: integer
        filename:
          description: The name of the file.
          type: string
        object:
          description: "The object type, which is always `file`."
          enum:
          - file
          type: string
          x-stainless-const: true
        purpose:
          description: "The intended purpose of the file. Supported values are `assistants`,\
            \ `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results`\
            \ and `vision`."
          enum:
          - assistants
          - assistants_output
          - batch
          - batch_output
          - fine-tune
          - fine-tune-results
          - vision
          type: string
        status:
          deprecated: true
          description: "Deprecated. The current status of the file, which can be either\
            \ `uploaded`, `processed`, or `error`."
          enum:
          - uploaded
          - processed
          - error
          type: string
        status_details:
          deprecated: true
          description: "Deprecated. For details on why a fine-tuning training file\
            \ failed validation, see the `error` field on `fine_tuning.job`."
          type: string
      required:
      - bytes
      - created_at
      - filename
      - id
      - object
      - purpose
      - status
      title: OpenAIFile
      x-oaiMeta:
        name: The file object
        example: |
          {
            "id": "file-abc123",
            "object": "file",
            "bytes": 120000,
            "created_at": 1677610602,
            "expires_at": 1680202602,
            "filename": "salesOverview.pdf",
            "purpose": "assistants",
          }
    OtherChunkingStrategyResponseParam:
      additionalProperties: true
      description: "This is returned when the chunking strategy is unknown. Typically,\
        \ this is because the file was indexed before the `chunking_strategy` concept\
        \ was introduced in the API."
      properties:
        type:
          description: Always `other`.
          enum:
          - other
          type: string
          x-stainless-const: true
      required:
      - type
      title: Other Chunking Strategy
    OutputAudio:
      description: |
        An audio output from the model.
      properties:
        type:
          description: |
            The type of the output audio. Always `output_audio`.
          enum:
          - output_audio
          type: string
          x-stainless-const: true
        data:
          description: |
            Base64-encoded audio data from the model.
          type: string
        transcript:
          description: |
            The transcript of the audio data from the model.
          type: string
      required:
      - data
      - transcript
      - type
      title: Output audio
    OutputContent:
      oneOf:
      - $ref: "#/components/schemas/OutputTextContent"
      - $ref: "#/components/schemas/RefusalContent"
    OutputItem:
      anyOf:
      - $ref: "#/components/schemas/OutputMessage"
      - $ref: "#/components/schemas/FileSearchToolCall"
      - $ref: "#/components/schemas/FunctionToolCall"
      - $ref: "#/components/schemas/WebSearchToolCall"
      - $ref: "#/components/schemas/ComputerToolCall"
      - $ref: "#/components/schemas/ReasoningItem"
      - $ref: "#/components/schemas/ImageGenToolCall"
      - $ref: "#/components/schemas/CodeInterpreterToolCall"
      - $ref: "#/components/schemas/LocalShellToolCall"
      - $ref: "#/components/schemas/MCPToolCall"
      - $ref: "#/components/schemas/MCPListTools"
      - $ref: "#/components/schemas/MCPApprovalRequest"
      discriminator:
        propertyName: type
    OutputMessage:
      description: |
        An output message from the model.
      properties:
        id:
          description: |
            The unique ID of the output message.
          type: string
        type:
          description: |
            The type of the output message. Always `message`.
          enum:
          - message
          type: string
          x-stainless-const: true
        role:
          description: |
            The role of the output message. Always `assistant`.
          enum:
          - assistant
          type: string
          x-stainless-const: true
        content:
          description: |
            The content of the output message.
          items:
            $ref: "#/components/schemas/OutputContent"
          type: array
        status:
          description: |
            The status of the message input. One of `in_progress`, `completed`, or
            `incomplete`. Populated when input items are returned via API.
          enum:
          - in_progress
          - completed
          - incomplete
          type: string
      required:
      - content
      - id
      - role
      - status
      - type
      title: Output message
    ParallelToolCalls:
      default: true
      description: "Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling)\
        \ during tool use."
      type: boolean
    PredictionContent:
      description: |
        Static predicted output content, such as the content of a text file that is
        being regenerated.
      example:
        type: content
        content: PredictionContent_content
      properties:
        type:
          description: |
            The type of the predicted content you want to provide. This type is
            currently always `content`.
          enum:
          - content
          type: string
          x-stainless-const: true
        content:
          $ref: "#/components/schemas/PredictionContent_content"
      required:
      - content
      - type
      title: Static Content
    Project:
      description: Represents an individual project.
      example:
        archived_at: 6
        name: name
        created_at: 0
        id: id
        object: organization.project
        status: active
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints"
          type: string
        object:
          description: "The object type, which is always `organization.project`"
          enum:
          - organization.project
          type: string
          x-stainless-const: true
        name:
          description: The name of the project. This appears in reporting.
          type: string
        created_at:
          description: The Unix timestamp (in seconds) of when the project was created.
          type: integer
        archived_at:
          description: The Unix timestamp (in seconds) of when the project was archived
            or `null`.
          type: integer
          nullable: true
        status:
          description: '`active` or `archived`'
          enum:
          - active
          - archived
          type: string
      required:
      - created_at
      - id
      - name
      - object
      - status
      x-oaiMeta:
        name: The project object
        example: |
          {
              "id": "proj_abc",
              "object": "organization.project",
              "name": "Project example",
              "created_at": 1711471533,
              "archived_at": null,
              "status": "active"
          }
    ProjectApiKey:
      description: Represents an individual API key in a project.
      example:
        owner:
          service_account:
            role: owner
            name: name
            created_at: 5
            id: id
            object: organization.project.service_account
          type: user
          user:
            added_at: 1
            role: owner
            name: name
            id: id
            email: email
            object: organization.project.user
        last_used_at: 6
        name: name
        created_at: 0
        redacted_value: redacted_value
        id: id
        object: organization.project.api_key
      properties:
        object:
          description: "The object type, which is always `organization.project.api_key`"
          enum:
          - organization.project.api_key
          type: string
          x-stainless-const: true
        redacted_value:
          description: The redacted value of the API key
          type: string
        name:
          description: The name of the API key
          type: string
        created_at:
          description: The Unix timestamp (in seconds) of when the API key was created
          type: integer
        last_used_at:
          description: The Unix timestamp (in seconds) of when the API key was last
            used.
          type: integer
        id:
          description: "The identifier, which can be referenced in API endpoints"
          type: string
        owner:
          $ref: "#/components/schemas/ProjectApiKey_owner"
      required:
      - created_at
      - id
      - last_used_at
      - name
      - object
      - owner
      - redacted_value
      x-oaiMeta:
        name: The project API key object
        example: |
          {
              "object": "organization.project.api_key",
              "redacted_value": "sk-abc...def",
              "name": "My API Key",
              "created_at": 1711471533,
              "last_used_at": 1711471534,
              "id": "key_abc",
              "owner": {
                  "type": "user",
                  "user": {
                      "object": "organization.project.user",
                      "id": "user_abc",
                      "name": "First Last",
                      "email": "user@example.com",
                      "role": "owner",
                      "created_at": 1711471533
                  }
              }
          }
    ProjectApiKeyDeleteResponse:
      example:
        deleted: true
        id: id
        object: organization.project.api_key.deleted
      properties:
        object:
          enum:
          - organization.project.api_key.deleted
          type: string
          x-stainless-const: true
        id:
          type: string
        deleted:
          type: boolean
      required:
      - deleted
      - id
      - object
    ProjectApiKeyListResponse:
      example:
        first_id: first_id
        data:
        - owner:
            service_account:
              role: owner
              name: name
              created_at: 5
              id: id
              object: organization.project.service_account
            type: user
            user:
              added_at: 1
              role: owner
              name: name
              id: id
              email: email
              object: organization.project.user
          last_used_at: 6
          name: name
          created_at: 0
          redacted_value: redacted_value
          id: id
          object: organization.project.api_key
        - owner:
            service_account:
              role: owner
              name: name
              created_at: 5
              id: id
              object: organization.project.service_account
            type: user
            user:
              added_at: 1
              role: owner
              name: name
              id: id
              email: email
              object: organization.project.user
          last_used_at: 6
          name: name
          created_at: 0
          redacted_value: redacted_value
          id: id
          object: organization.project.api_key
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          enum:
          - list
          type: string
          x-stainless-const: true
        data:
          items:
            $ref: "#/components/schemas/ProjectApiKey"
          type: array
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ProjectCreateRequest:
      example:
        name: name
      properties:
        name:
          description: "The friendly name of the project, this name appears in reports."
          type: string
      required:
      - name
    ProjectListResponse:
      example:
        first_id: first_id
        data:
        - archived_at: 6
          name: name
          created_at: 0
          id: id
          object: organization.project
          status: active
        - archived_at: 6
          name: name
          created_at: 0
          id: id
          object: organization.project
          status: active
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          enum:
          - list
          type: string
          x-stainless-const: true
        data:
          items:
            $ref: "#/components/schemas/Project"
          type: array
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ProjectRateLimit:
      description: Represents a project rate limit config.
      example:
        batch_1_day_max_input_tokens: 2
        max_tokens_per_1_minute: 6
        model: model
        id: id
        max_images_per_1_minute: 1
        max_audio_megabytes_per_1_minute: 5
        max_requests_per_1_minute: 0
        object: project.rate_limit
        max_requests_per_1_day: 5
      properties:
        object:
          description: "The object type, which is always `project.rate_limit`"
          enum:
          - project.rate_limit
          type: string
          x-stainless-const: true
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        model:
          description: The model this rate limit applies to.
          type: string
        max_requests_per_1_minute:
          description: The maximum requests per minute.
          type: integer
        max_tokens_per_1_minute:
          description: The maximum tokens per minute.
          type: integer
        max_images_per_1_minute:
          description: The maximum images per minute. Only present for relevant models.
          type: integer
        max_audio_megabytes_per_1_minute:
          description: The maximum audio megabytes per minute. Only present for relevant
            models.
          type: integer
        max_requests_per_1_day:
          description: The maximum requests per day. Only present for relevant models.
          type: integer
        batch_1_day_max_input_tokens:
          description: The maximum batch input tokens per day. Only present for relevant
            models.
          type: integer
      required:
      - id
      - max_requests_per_1_minute
      - max_tokens_per_1_minute
      - model
      - object
      x-oaiMeta:
        name: The project rate limit object
        example: |
          {
              "object": "project.rate_limit",
              "id": "rl_ada",
              "model": "ada",
              "max_requests_per_1_minute": 600,
              "max_tokens_per_1_minute": 150000,
              "max_images_per_1_minute": 10
          }
    ProjectRateLimitListResponse:
      example:
        first_id: first_id
        data:
        - batch_1_day_max_input_tokens: 2
          max_tokens_per_1_minute: 6
          model: model
          id: id
          max_images_per_1_minute: 1
          max_audio_megabytes_per_1_minute: 5
          max_requests_per_1_minute: 0
          object: project.rate_limit
          max_requests_per_1_day: 5
        - batch_1_day_max_input_tokens: 2
          max_tokens_per_1_minute: 6
          model: model
          id: id
          max_images_per_1_minute: 1
          max_audio_megabytes_per_1_minute: 5
          max_requests_per_1_minute: 0
          object: project.rate_limit
          max_requests_per_1_day: 5
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          enum:
          - list
          type: string
          x-stainless-const: true
        data:
          items:
            $ref: "#/components/schemas/ProjectRateLimit"
          type: array
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ProjectRateLimitUpdateRequest:
      example:
        batch_1_day_max_input_tokens: 2
        max_tokens_per_1_minute: 6
        max_images_per_1_minute: 1
        max_audio_megabytes_per_1_minute: 5
        max_requests_per_1_minute: 0
        max_requests_per_1_day: 5
      properties:
        max_requests_per_1_minute:
          description: The maximum requests per minute.
          type: integer
        max_tokens_per_1_minute:
          description: The maximum tokens per minute.
          type: integer
        max_images_per_1_minute:
          description: The maximum images per minute. Only relevant for certain models.
          type: integer
        max_audio_megabytes_per_1_minute:
          description: The maximum audio megabytes per minute. Only relevant for certain
            models.
          type: integer
        max_requests_per_1_day:
          description: The maximum requests per day. Only relevant for certain models.
          type: integer
        batch_1_day_max_input_tokens:
          description: The maximum batch input tokens per day. Only relevant for certain
            models.
          type: integer
    ProjectServiceAccount:
      description: Represents an individual service account in a project.
      example:
        role: owner
        name: name
        created_at: 5
        id: id
        object: organization.project.service_account
      properties:
        object:
          description: "The object type, which is always `organization.project.service_account`"
          enum:
          - organization.project.service_account
          type: string
          x-stainless-const: true
        id:
          description: "The identifier, which can be referenced in API endpoints"
          type: string
        name:
          description: The name of the service account
          type: string
        role:
          description: '`owner` or `member`'
          enum:
          - owner
          - member
          type: string
        created_at:
          description: The Unix timestamp (in seconds) of when the service account
            was created
          type: integer
      required:
      - created_at
      - id
      - name
      - object
      - role
      x-oaiMeta:
        name: The project service account object
        example: |
          {
              "object": "organization.project.service_account",
              "id": "svc_acct_abc",
              "name": "Service Account",
              "role": "owner",
              "created_at": 1711471533
          }
    ProjectServiceAccountApiKey:
      example:
        name: name
        created_at: 6
        id: id
        value: value
        object: organization.project.service_account.api_key
      properties:
        object:
          description: "The object type, which is always `organization.project.service_account.api_key`"
          enum:
          - organization.project.service_account.api_key
          type: string
          x-stainless-const: true
        value:
          type: string
        name:
          type: string
        created_at:
          type: integer
        id:
          type: string
      required:
      - created_at
      - id
      - name
      - object
      - value
    ProjectServiceAccountCreateRequest:
      example:
        name: name
      properties:
        name:
          description: The name of the service account being created.
          type: string
      required:
      - name
    ProjectServiceAccountCreateResponse:
      example:
        role: member
        api_key:
          name: name
          created_at: 6
          id: id
          value: value
          object: organization.project.service_account.api_key
        name: name
        created_at: 0
        id: id
        object: organization.project.service_account
      properties:
        object:
          enum:
          - organization.project.service_account
          type: string
          x-stainless-const: true
        id:
          type: string
        name:
          type: string
        role:
          description: Service accounts can only have one role of type `member`
          enum:
          - member
          type: string
          x-stainless-const: true
        created_at:
          type: integer
        api_key:
          $ref: "#/components/schemas/ProjectServiceAccountApiKey"
      required:
      - api_key
      - created_at
      - id
      - name
      - object
      - role
    ProjectServiceAccountDeleteResponse:
      example:
        deleted: true
        id: id
        object: organization.project.service_account.deleted
      properties:
        object:
          enum:
          - organization.project.service_account.deleted
          type: string
          x-stainless-const: true
        id:
          type: string
        deleted:
          type: boolean
      required:
      - deleted
      - id
      - object
    ProjectServiceAccountListResponse:
      example:
        first_id: first_id
        data:
        - role: owner
          name: name
          created_at: 5
          id: id
          object: organization.project.service_account
        - role: owner
          name: name
          created_at: 5
          id: id
          object: organization.project.service_account
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          enum:
          - list
          type: string
          x-stainless-const: true
        data:
          items:
            $ref: "#/components/schemas/ProjectServiceAccount"
          type: array
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ProjectUpdateRequest:
      example:
        name: name
      properties:
        name:
          description: "The updated name of the project, this name appears in reports."
          type: string
      required:
      - name
    ProjectUser:
      description: Represents an individual user in a project.
      example:
        added_at: 1
        role: owner
        name: name
        id: id
        email: email
        object: organization.project.user
      properties:
        object:
          description: "The object type, which is always `organization.project.user`"
          enum:
          - organization.project.user
          type: string
          x-stainless-const: true
        id:
          description: "The identifier, which can be referenced in API endpoints"
          type: string
        name:
          description: The name of the user
          type: string
        email:
          description: The email address of the user
          type: string
        role:
          description: '`owner` or `member`'
          enum:
          - owner
          - member
          type: string
        added_at:
          description: The Unix timestamp (in seconds) of when the project was added.
          type: integer
      required:
      - added_at
      - email
      - id
      - name
      - object
      - role
      x-oaiMeta:
        name: The project user object
        example: |
          {
              "object": "organization.project.user",
              "id": "user_abc",
              "name": "First Last",
              "email": "user@example.com",
              "role": "owner",
              "added_at": 1711471533
          }
    ProjectUserCreateRequest:
      example:
        role: owner
        user_id: user_id
      properties:
        user_id:
          description: The ID of the user.
          type: string
        role:
          description: '`owner` or `member`'
          enum:
          - owner
          - member
          type: string
      required:
      - role
      - user_id
    ProjectUserDeleteResponse:
      example:
        deleted: true
        id: id
        object: organization.project.user.deleted
      properties:
        object:
          enum:
          - organization.project.user.deleted
          type: string
          x-stainless-const: true
        id:
          type: string
        deleted:
          type: boolean
      required:
      - deleted
      - id
      - object
    ProjectUserListResponse:
      example:
        first_id: first_id
        data:
        - added_at: 1
          role: owner
          name: name
          id: id
          email: email
          object: organization.project.user
        - added_at: 1
          role: owner
          name: name
          id: id
          email: email
          object: organization.project.user
        last_id: last_id
        has_more: true
        object: object
      properties:
        object:
          type: string
        data:
          items:
            $ref: "#/components/schemas/ProjectUser"
          type: array
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ProjectUserUpdateRequest:
      example:
        role: owner
      properties:
        role:
          description: '`owner` or `member`'
          enum:
          - owner
          - member
          type: string
      required:
      - role
    Prompt:
      description: "Reference to a prompt template and its variables. \n[Learn more](/docs/guides/text?api-mode=responses#reusable-prompts).\n"
      example:
        variables:
          key: ResponsePromptVariables_value
        id: id
        version: version
      properties:
        id:
          description: The unique identifier of the prompt template to use.
          type: string
        version:
          description: Optional version of the prompt template.
          type: string
          nullable: true
        variables:
          additionalProperties:
            $ref: "#/components/schemas/ResponsePromptVariables_value"
          description: |
            Optional map of values to substitute in for variables in your
            prompt. The substitution values can either be strings, or other
            Response input types like images or files.
          title: Prompt Variables
          x-oaiExpandable: true
          x-oaiTypeLabel: map
          nullable: true
      required:
      - id
      nullable: true
    RealtimeClientEvent:
      anyOf:
      - $ref: "#/components/schemas/RealtimeClientEventConversationItemCreate"
      - $ref: "#/components/schemas/RealtimeClientEventConversationItemDelete"
      - $ref: "#/components/schemas/RealtimeClientEventConversationItemRetrieve"
      - $ref: "#/components/schemas/RealtimeClientEventConversationItemTruncate"
      - $ref: "#/components/schemas/RealtimeClientEventInputAudioBufferAppend"
      - $ref: "#/components/schemas/RealtimeClientEventInputAudioBufferClear"
      - $ref: "#/components/schemas/RealtimeClientEventOutputAudioBufferClear"
      - $ref: "#/components/schemas/RealtimeClientEventInputAudioBufferCommit"
      - $ref: "#/components/schemas/RealtimeClientEventResponseCancel"
      - $ref: "#/components/schemas/RealtimeClientEventResponseCreate"
      - $ref: "#/components/schemas/RealtimeClientEventSessionUpdate"
      - $ref: "#/components/schemas/RealtimeClientEventTranscriptionSessionUpdate"
      description: |
        A realtime client event.
      discriminator:
        propertyName: type
    RealtimeClientEventConversationItemCreate:
      description: "Add a new Item to the Conversation's context, including messages,\
        \ function \ncalls, and function call responses. This event can be used both\
        \ to populate a \n\"history\" of the conversation and to add new items mid-stream,\
        \ but has the \ncurrent limitation that it cannot populate assistant audio\
        \ messages.\n\nIf successful, the server will respond with a `conversation.item.created`\
        \ \nevent, otherwise an `error` event will be sent.\n"
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be `conversation.item.create`."
          enum:
          - conversation.item.create
          type: string
          x-stainless-const: true
        previous_item_id:
          description: "The ID of the preceding item after which the new item will\
            \ be inserted. \nIf not set, the new item will be appended to the end\
            \ of the conversation.\nIf set to `root`, the new item will be added to\
            \ the beginning of the conversation.\nIf set to an existing ID, it allows\
            \ an item to be inserted mid-conversation. If the\nID cannot be found,\
            \ an error will be returned and the item will not be added.\n"
          type: string
        item:
          $ref: "#/components/schemas/RealtimeConversationItem"
      required:
      - item
      - type
      x-oaiMeta:
        name: conversation.item.create
        group: realtime
        example: |
          {
              "event_id": "event_345",
              "type": "conversation.item.create",
              "previous_item_id": null,
              "item": {
                  "id": "msg_001",
                  "type": "message",
                  "role": "user",
                  "content": [
                      {
                          "type": "input_text",
                          "text": "Hello, how are you?"
                      }
                  ]
              }
          }
    RealtimeClientEventConversationItemDelete:
      description: "Send this event when you want to remove any item from the conversation\
        \ \nhistory. The server will respond with a `conversation.item.deleted` event,\
        \ \nunless the item does not exist in the conversation history, in which case\
        \ the \nserver will respond with an error.\n"
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be `conversation.item.delete`."
          enum:
          - conversation.item.delete
          type: string
          x-stainless-const: true
        item_id:
          description: The ID of the item to delete.
          type: string
      required:
      - item_id
      - type
      x-oaiMeta:
        name: conversation.item.delete
        group: realtime
        example: |
          {
              "event_id": "event_901",
              "type": "conversation.item.delete",
              "item_id": "msg_003"
          }
    RealtimeClientEventConversationItemRetrieve:
      description: "Send this event when you want to retrieve the server's representation\
        \ of a specific item in the conversation history. This is useful, for example,\
        \ to inspect user audio after noise cancellation and VAD.\nThe server will\
        \ respond with a `conversation.item.retrieved` event, \nunless the item does\
        \ not exist in the conversation history, in which case the \nserver will respond\
        \ with an error.\n"
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be `conversation.item.retrieve`."
          enum:
          - conversation.item.retrieve
          type: string
          x-stainless-const: true
        item_id:
          description: The ID of the item to retrieve.
          type: string
      required:
      - item_id
      - type
      x-oaiMeta:
        name: conversation.item.retrieve
        group: realtime
        example: |
          {
              "event_id": "event_901",
              "type": "conversation.item.retrieve",
              "item_id": "msg_003"
          }
    RealtimeClientEventConversationItemTruncate:
      description: "Send this event to truncate a previous assistant messages audio.\
        \ The server \nwill produce audio faster than realtime, so this event is useful\
        \ when the user \ninterrupts to truncate audio that has already been sent\
        \ to the client but not \nyet played. This will synchronize the server's understanding\
        \ of the audio with \nthe client's playback.\n\nTruncating audio will delete\
        \ the server-side text transcript to ensure there \nis not text in the context\
        \ that hasn't been heard by the user.\n\nIf successful, the server will respond\
        \ with a `conversation.item.truncated` \nevent. \n"
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be `conversation.item.truncate`."
          enum:
          - conversation.item.truncate
          type: string
          x-stainless-const: true
        item_id:
          description: "The ID of the assistant message item to truncate. Only assistant\
            \ message \nitems can be truncated.\n"
          type: string
        content_index:
          description: The index of the content part to truncate. Set this to 0.
          type: integer
        audio_end_ms:
          description: "Inclusive duration up to which audio is truncated, in milliseconds.\
            \ If \nthe audio_end_ms is greater than the actual audio duration, the\
            \ server \nwill respond with an error.\n"
          type: integer
      required:
      - audio_end_ms
      - content_index
      - item_id
      - type
      x-oaiMeta:
        name: conversation.item.truncate
        group: realtime
        example: |
          {
              "event_id": "event_678",
              "type": "conversation.item.truncate",
              "item_id": "msg_002",
              "content_index": 0,
              "audio_end_ms": 1500
          }
    RealtimeClientEventInputAudioBufferAppend:
      description: "Send this event to append audio bytes to the input audio buffer.\
        \ The audio \nbuffer is temporary storage you can write to and later commit.\
        \ In Server VAD \nmode, the audio buffer is used to detect speech and the\
        \ server will decide \nwhen to commit. When Server VAD is disabled, you must\
        \ commit the audio buffer\nmanually.\n\nThe client may choose how much audio\
        \ to place in each event up to a maximum \nof 15 MiB, for example streaming\
        \ smaller chunks from the client may allow the \nVAD to be more responsive.\
        \ Unlike made other client events, the server will \nnot send a confirmation\
        \ response to this event.\n"
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be `input_audio_buffer.append`."
          enum:
          - input_audio_buffer.append
          type: string
          x-stainless-const: true
        audio:
          description: "Base64-encoded audio bytes. This must be in the format specified\
            \ by the \n`input_audio_format` field in the session configuration.\n"
          type: string
      required:
      - audio
      - type
      x-oaiMeta:
        name: input_audio_buffer.append
        group: realtime
        example: |
          {
              "event_id": "event_456",
              "type": "input_audio_buffer.append",
              "audio": "Base64EncodedAudioData"
          }
    RealtimeClientEventInputAudioBufferClear:
      description: "Send this event to clear the audio bytes in the buffer. The server\
        \ will \nrespond with an `input_audio_buffer.cleared` event.\n"
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be `input_audio_buffer.clear`."
          enum:
          - input_audio_buffer.clear
          type: string
          x-stainless-const: true
      required:
      - type
      x-oaiMeta:
        name: input_audio_buffer.clear
        group: realtime
        example: |
          {
              "event_id": "event_012",
              "type": "input_audio_buffer.clear"
          }
    RealtimeClientEventInputAudioBufferCommit:
      description: "Send this event to commit the user input audio buffer, which will\
        \ create a \nnew user message item in the conversation. This event will produce\
        \ an error \nif the input audio buffer is empty. When in Server VAD mode,\
        \ the client does \nnot need to send this event, the server will commit the\
        \ audio buffer \nautomatically.\n\nCommitting the input audio buffer will\
        \ trigger input audio transcription \n(if enabled in session configuration),\
        \ but it will not create a response \nfrom the model. The server will respond\
        \ with an `input_audio_buffer.committed` \nevent.\n"
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be `input_audio_buffer.commit`."
          enum:
          - input_audio_buffer.commit
          type: string
          x-stainless-const: true
      required:
      - type
      x-oaiMeta:
        name: input_audio_buffer.commit
        group: realtime
        example: |
          {
              "event_id": "event_789",
              "type": "input_audio_buffer.commit"
          }
    RealtimeClientEventOutputAudioBufferClear:
      description: "**WebRTC Only:** Emit to cut off the current audio response. This\
        \ will trigger the server to\nstop generating audio and emit a `output_audio_buffer.cleared`\
        \ event. This \nevent should be preceded by a `response.cancel` client event\
        \ to stop the \ngeneration of the current response.\n[Learn more](/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n"
      properties:
        event_id:
          description: The unique ID of the client event used for error handling.
          type: string
        type:
          description: "The event type, must be `output_audio_buffer.clear`."
          enum:
          - output_audio_buffer.clear
          type: string
          x-stainless-const: true
      required:
      - type
      x-oaiMeta:
        name: output_audio_buffer.clear
        group: realtime
        example: |
          {
              "event_id": "optional_client_event_id",
              "type": "output_audio_buffer.clear"
          }
    RealtimeClientEventResponseCancel:
      description: "Send this event to cancel an in-progress response. The server\
        \ will respond \nwith a `response.cancelled` event or an error if there is\
        \ no response to \ncancel.\n"
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be `response.cancel`."
          enum:
          - response.cancel
          type: string
          x-stainless-const: true
        response_id:
          description: "A specific response ID to cancel - if not provided, will cancel\
            \ an \nin-progress response in the default conversation.\n"
          type: string
      required:
      - type
      x-oaiMeta:
        name: response.cancel
        group: realtime
        example: |
          {
              "event_id": "event_567",
              "type": "response.cancel"
          }
    RealtimeClientEventResponseCreate:
      description: "This event instructs the server to create a Response, which means\
        \ triggering \nmodel inference. When in Server VAD mode, the server will create\
        \ Responses \nautomatically.\n\nA Response will include at least one Item,\
        \ and may have two, in which case \nthe second will be a function call. These\
        \ Items will be appended to the \nconversation history.\n\nThe server will\
        \ respond with a `response.created` event, events for Items \nand content\
        \ created, and finally a `response.done` event to indicate the \nResponse\
        \ is complete.\n\nThe `response.create` event includes inference configuration\
        \ like \n`instructions`, and `temperature`. These fields will override the\
        \ Session's \nconfiguration for this Response only.\n"
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be `response.create`."
          enum:
          - response.create
          type: string
          x-stainless-const: true
        response:
          $ref: "#/components/schemas/RealtimeResponseCreateParams"
      required:
      - type
      x-oaiMeta:
        name: response.create
        group: realtime
        example: |
          {
              "event_id": "event_234",
              "type": "response.create",
              "response": {
                  "modalities": ["text", "audio"],
                  "instructions": "Please assist the user.",
                  "voice": "sage",
                  "output_audio_format": "pcm16",
                  "tools": [
                      {
                          "type": "function",
                          "name": "calculate_sum",
                          "description": "Calculates the sum of two numbers.",
                          "parameters": {
                              "type": "object",
                              "properties": {
                                  "a": { "type": "number" },
                                  "b": { "type": "number" }
                              },
                              "required": ["a", "b"]
                          }
                      }
                  ],
                  "tool_choice": "auto",
                  "temperature": 0.8,
                  "max_output_tokens": 1024
              }
          }
    RealtimeClientEventSessionUpdate:
      description: |
        Send this event to update the sessions default configuration.
        The client may send this event at any time to update any field,
        except for `voice`. However, note that once a session has been
        initialized with a particular `model`, it cant be changed to
        another model using `session.update`.

        When the server receives a `session.update`, it will respond
        with a `session.updated` event showing the full, effective configuration.
        Only the fields that are present are updated. To clear a field like
        `instructions`, pass an empty string.
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be `session.update`."
          enum:
          - session.update
          type: string
          x-stainless-const: true
        session:
          $ref: "#/components/schemas/RealtimeSessionCreateRequest"
      required:
      - session
      - type
      x-oaiMeta:
        name: session.update
        group: realtime
        example: |
          {
              "event_id": "event_123",
              "type": "session.update",
              "session": {
                  "modalities": ["text", "audio"],
                  "instructions": "You are a helpful assistant.",
                  "voice": "sage",
                  "input_audio_format": "pcm16",
                  "output_audio_format": "pcm16",
                  "input_audio_transcription": {
                      "model": "whisper-1"
                  },
                  "turn_detection": {
                      "type": "server_vad",
                      "threshold": 0.5,
                      "prefix_padding_ms": 300,
                      "silence_duration_ms": 500,
                      "create_response": true
                  },
                  "tools": [
                      {
                          "type": "function",
                          "name": "get_weather",
                          "description": "Get the current weather...",
                          "parameters": {
                              "type": "object",
                              "properties": {
                                  "location": { "type": "string" }
                              },
                              "required": ["location"]
                          }
                      }
                  ],
                  "tool_choice": "auto",
                  "temperature": 0.8,
                  "max_response_output_tokens": "inf",
                  "speed": 1.1,
                  "tracing": "auto"
              }
          }
    RealtimeClientEventTranscriptionSessionUpdate:
      description: |
        Send this event to update a transcription session.
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be `transcription_session.update`."
          enum:
          - transcription_session.update
          type: string
          x-stainless-const: true
        session:
          $ref: "#/components/schemas/RealtimeTranscriptionSessionCreateRequest"
      required:
      - session
      - type
      x-oaiMeta:
        name: transcription_session.update
        group: realtime
        example: |
          {
            "type": "transcription_session.update",
            "session": {
              "input_audio_format": "pcm16",
              "input_audio_transcription": {
                "model": "gpt-4o-transcribe",
                "prompt": "",
                "language": ""
              },
              "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 500,
                "create_response": true,
              },
              "input_audio_noise_reduction": {
                "type": "near_field"
              },
              "include": [
                "item.input_audio_transcription.logprobs",
              ]
            }
          }
    RealtimeConversationItem:
      description: The item to add to the conversation.
      properties:
        id:
          description: "The unique ID of the item, this can be generated by the client\
            \ to help \nmanage server-side context, but is not required because the\
            \ server will \ngenerate one if not provided.\n"
          type: string
        type:
          description: |
            The type of the item (`message`, `function_call`, `function_call_output`).
          enum:
          - message
          - function_call
          - function_call_output
          type: string
        object:
          description: |
            Identifier for the API object being returned - always `realtime.item`.
          enum:
          - realtime.item
          type: string
          x-stainless-const: true
        status:
          description: "The status of the item (`completed`, `incomplete`). These\
            \ have no effect \non the conversation, but are accepted for consistency\
            \ with the \n`conversation.item.created` event.\n"
          enum:
          - completed
          - incomplete
          type: string
        role:
          description: "The role of the message sender (`user`, `assistant`, `system`),\
            \ only \napplicable for `message` items.\n"
          enum:
          - user
          - assistant
          - system
          type: string
        content:
          description: "The content of the message, applicable for `message` items.\
            \ \n- Message items of role `system` support only `input_text` content\n\
            - Message items of role `user` support `input_text` and `input_audio`\
            \ \n  content\n- Message items of role `assistant` support `text` content.\n"
          items:
            $ref: "#/components/schemas/RealtimeConversationItem_content_inner"
          type: array
        call_id:
          description: "The ID of the function call (for `function_call` and \n`function_call_output`\
            \ items). If passed on a `function_call_output` \nitem, the server will\
            \ check that a `function_call` item with the same \nID exists in the conversation\
            \ history.\n"
          type: string
        name:
          description: |
            The name of the function being called (for `function_call` items).
          type: string
        arguments:
          description: |
            The arguments of the function call (for `function_call` items).
          type: string
        output:
          description: |
            The output of the function call (for `function_call_output` items).
          type: string
    RealtimeConversationItemWithReference:
      description: The item to add to the conversation.
      properties:
        id:
          description: |
            For an item of type (`message` | `function_call` | `function_call_output`)
            this field allows the client to assign the unique ID of the item. It is
            not required because the server will generate one if not provided.

            For an item of type `item_reference`, this field is required and is a
            reference to any item that has previously existed in the conversation.
          type: string
        type:
          description: |
            The type of the item (`message`, `function_call`, `function_call_output`, `item_reference`).
          enum:
          - message
          - function_call
          - function_call_output
          type: string
        object:
          description: |
            Identifier for the API object being returned - always `realtime.item`.
          enum:
          - realtime.item
          type: string
          x-stainless-const: true
        status:
          description: "The status of the item (`completed`, `incomplete`). These\
            \ have no effect \non the conversation, but are accepted for consistency\
            \ with the \n`conversation.item.created` event.\n"
          enum:
          - completed
          - incomplete
          type: string
        role:
          description: "The role of the message sender (`user`, `assistant`, `system`),\
            \ only \napplicable for `message` items.\n"
          enum:
          - user
          - assistant
          - system
          type: string
        content:
          description: "The content of the message, applicable for `message` items.\
            \ \n- Message items of role `system` support only `input_text` content\n\
            - Message items of role `user` support `input_text` and `input_audio`\
            \ \n  content\n- Message items of role `assistant` support `text` content.\n"
          items:
            $ref: "#/components/schemas/RealtimeConversationItem_content_inner"
          type: array
        call_id:
          description: "The ID of the function call (for `function_call` and \n`function_call_output`\
            \ items). If passed on a `function_call_output` \nitem, the server will\
            \ check that a `function_call` item with the same \nID exists in the conversation\
            \ history.\n"
          type: string
        name:
          description: |
            The name of the function being called (for `function_call` items).
          type: string
        arguments:
          description: |
            The arguments of the function call (for `function_call` items).
          type: string
        output:
          description: |
            The output of the function call (for `function_call_output` items).
          type: string
    RealtimeResponse:
      description: The response resource.
      properties:
        id:
          description: The unique ID of the response.
          type: string
        object:
          description: "The object type, must be `realtime.response`."
          enum:
          - realtime.response
          type: string
          x-stainless-const: true
        status:
          description: "The final status of the response (`completed`, `cancelled`,\
            \ `failed`, or \n`incomplete`).\n"
          enum:
          - completed
          - cancelled
          - failed
          - incomplete
          type: string
        status_details:
          $ref: "#/components/schemas/RealtimeResponse_status_details"
        output:
          description: The list of output items generated by the response.
          items:
            $ref: "#/components/schemas/RealtimeConversationItem"
          type: array
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        usage:
          $ref: "#/components/schemas/RealtimeResponse_usage"
        conversation_id:
          description: |
            Which conversation the response is added to, determined by the `conversation`
            field in the `response.create` event. If `auto`, the response will be added to
            the default conversation and the value of `conversation_id` will be an id like
            `conv_1234`. If `none`, the response will not be added to any conversation and
            the value of `conversation_id` will be `null`. If responses are being triggered
            by server VAD, the response will be added to the default conversation, thus
            the `conversation_id` will be an id like `conv_1234`.
          type: string
        voice:
          $ref: "#/components/schemas/VoiceIdsShared"
        modalities:
          description: |
            The set of modalities the model used to respond. If there are multiple modalities,
            the model will pick one, for example if `modalities` is `["text", "audio"]`, the model
            could be responding in either text or audio.
          items:
            enum:
            - text
            - audio
            type: string
          type: array
        output_audio_format:
          description: |
            The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
          enum:
          - pcm16
          - g711_ulaw
          - g711_alaw
          type: string
        temperature:
          description: |
            Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.
          type: number
        max_output_tokens:
          $ref: "#/components/schemas/RealtimeResponse_max_output_tokens"
    RealtimeResponseCreateParams:
      description: Create a new Realtime response with these parameters
      properties:
        modalities:
          description: |
            The set of modalities the model can respond with. To disable audio,
            set this to ["text"].
          items:
            enum:
            - text
            - audio
            type: string
          type: array
        instructions:
          description: "The default system instructions (i.e. system message) prepended\
            \ to model \ncalls. This field allows the client to guide the model on\
            \ desired \nresponses. The model can be instructed on response content\
            \ and format, \n(e.g. \"be extremely succinct\", \"act friendly\", \"\
            here are examples of good \nresponses\") and on audio behavior (e.g. \"\
            talk quickly\", \"inject emotion \ninto your voice\", \"laugh frequently\"\
            ). The instructions are not guaranteed \nto be followed by the model,\
            \ but they provide guidance to the model on the \ndesired behavior.\n\n\
            Note that the server sets default instructions which will be used if this\
            \ \nfield is not set and are visible in the `session.created` event at\
            \ the \nstart of the session.\n"
          type: string
        voice:
          $ref: "#/components/schemas/VoiceIdsShared"
        output_audio_format:
          description: |
            The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
          enum:
          - pcm16
          - g711_ulaw
          - g711_alaw
          type: string
        tools:
          description: Tools (functions) available to the model.
          items:
            $ref: "#/components/schemas/RealtimeResponseCreateParams_tools_inner"
          type: array
        tool_choice:
          description: "How the model chooses tools. Options are `auto`, `none`, `required`,\
            \ or \nspecify a function, like `{\"type\": \"function\", \"function\"\
            : {\"name\": \"my_function\"}}`.\n"
          type: string
        temperature:
          description: |
            Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.
          type: number
        max_response_output_tokens:
          $ref: "#/components/schemas/RealtimeResponseCreateParams_max_response_output_tokens"
        conversation:
          $ref: "#/components/schemas/RealtimeResponseCreateParams_conversation"
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        input:
          description: |
            Input items to include in the prompt for the model. Using this field
            creates a new context for this Response instead of using the default
            conversation. An empty array `[]` will clear the context for this Response.
            Note that this can include references to items from the default conversation.
          items:
            $ref: "#/components/schemas/RealtimeConversationItemWithReference"
          type: array
    RealtimeServerEvent:
      anyOf:
      - $ref: "#/components/schemas/RealtimeServerEventConversationCreated"
      - $ref: "#/components/schemas/RealtimeServerEventConversationItemCreated"
      - $ref: "#/components/schemas/RealtimeServerEventConversationItemDeleted"
      - $ref: "#/components/schemas/RealtimeServerEventConversationItemInputAudioTranscriptionCompleted"
      - $ref: "#/components/schemas/RealtimeServerEventConversationItemInputAudioTranscriptionDelta"
      - $ref: "#/components/schemas/RealtimeServerEventConversationItemInputAudioTranscriptionFailed"
      - $ref: "#/components/schemas/RealtimeServerEventConversationItemRetrieved"
      - $ref: "#/components/schemas/RealtimeServerEventConversationItemTruncated"
      - $ref: "#/components/schemas/RealtimeServerEventError"
      - $ref: "#/components/schemas/RealtimeServerEventInputAudioBufferCleared"
      - $ref: "#/components/schemas/RealtimeServerEventInputAudioBufferCommitted"
      - $ref: "#/components/schemas/RealtimeServerEventInputAudioBufferSpeechStarted"
      - $ref: "#/components/schemas/RealtimeServerEventInputAudioBufferSpeechStopped"
      - $ref: "#/components/schemas/RealtimeServerEventRateLimitsUpdated"
      - $ref: "#/components/schemas/RealtimeServerEventResponseAudioDelta"
      - $ref: "#/components/schemas/RealtimeServerEventResponseAudioDone"
      - $ref: "#/components/schemas/RealtimeServerEventResponseAudioTranscriptDelta"
      - $ref: "#/components/schemas/RealtimeServerEventResponseAudioTranscriptDone"
      - $ref: "#/components/schemas/RealtimeServerEventResponseContentPartAdded"
      - $ref: "#/components/schemas/RealtimeServerEventResponseContentPartDone"
      - $ref: "#/components/schemas/RealtimeServerEventResponseCreated"
      - $ref: "#/components/schemas/RealtimeServerEventResponseDone"
      - $ref: "#/components/schemas/RealtimeServerEventResponseFunctionCallArgumentsDelta"
      - $ref: "#/components/schemas/RealtimeServerEventResponseFunctionCallArgumentsDone"
      - $ref: "#/components/schemas/RealtimeServerEventResponseOutputItemAdded"
      - $ref: "#/components/schemas/RealtimeServerEventResponseOutputItemDone"
      - $ref: "#/components/schemas/RealtimeServerEventResponseTextDelta"
      - $ref: "#/components/schemas/RealtimeServerEventResponseTextDone"
      - $ref: "#/components/schemas/RealtimeServerEventSessionCreated"
      - $ref: "#/components/schemas/RealtimeServerEventSessionUpdated"
      - $ref: "#/components/schemas/RealtimeServerEventTranscriptionSessionUpdated"
      - $ref: "#/components/schemas/RealtimeServerEventOutputAudioBufferStarted"
      - $ref: "#/components/schemas/RealtimeServerEventOutputAudioBufferStopped"
      - $ref: "#/components/schemas/RealtimeServerEventOutputAudioBufferCleared"
      description: |
        A realtime server event.
      discriminator:
        propertyName: type
    RealtimeServerEventConversationCreated:
      description: |
        Returned when a conversation is created. Emitted right after session creation.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `conversation.created`."
          enum:
          - conversation.created
          type: string
          x-stainless-const: true
        conversation:
          $ref: "#/components/schemas/RealtimeServerEventConversationCreated_conversation"
      required:
      - conversation
      - event_id
      - type
      x-oaiMeta:
        name: conversation.created
        group: realtime
        example: |
          {
              "event_id": "event_9101",
              "type": "conversation.created",
              "conversation": {
                  "id": "conv_001",
                  "object": "realtime.conversation"
              }
          }
    RealtimeServerEventConversationItemCreated:
      description: "Returned when a conversation item is created. There are several\
        \ scenarios that produce this event:\n  - The server is generating a Response,\
        \ which if successful will produce \n    either one or two Items, which will\
        \ be of type `message` \n    (role `assistant`) or type `function_call`.\n\
        \  - The input audio buffer has been committed, either by the client or the\
        \ \n    server (in `server_vad` mode). The server will take the content of\
        \ the \n    input audio buffer and add it to a new user message Item.\n  -\
        \ The client has sent a `conversation.item.create` event to add a new Item\
        \ \n    to the Conversation.\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `conversation.item.created`."
          enum:
          - conversation.item.created
          type: string
          x-stainless-const: true
        previous_item_id:
          description: "The ID of the preceding item in the Conversation context,\
            \ allows the \nclient to understand the order of the conversation.\n"
          type: string
        item:
          $ref: "#/components/schemas/RealtimeConversationItem"
      required:
      - event_id
      - item
      - previous_item_id
      - type
      x-oaiMeta:
        name: conversation.item.created
        group: realtime
        example: |
          {
              "event_id": "event_1920",
              "type": "conversation.item.created",
              "previous_item_id": "msg_002",
              "item": {
                  "id": "msg_003",
                  "object": "realtime.item",
                  "type": "message",
                  "status": "completed",
                  "role": "user",
                  "content": []
              }
          }
    RealtimeServerEventConversationItemDeleted:
      description: "Returned when an item in the conversation is deleted by the client\
        \ with a \n`conversation.item.delete` event. This event is used to synchronize\
        \ the \nserver's understanding of the conversation history with the client's\
        \ view.\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `conversation.item.deleted`."
          enum:
          - conversation.item.deleted
          type: string
          x-stainless-const: true
        item_id:
          description: The ID of the item that was deleted.
          type: string
      required:
      - event_id
      - item_id
      - type
      x-oaiMeta:
        name: conversation.item.deleted
        group: realtime
        example: |
          {
              "event_id": "event_2728",
              "type": "conversation.item.deleted",
              "item_id": "msg_005"
          }
    RealtimeServerEventConversationItemInputAudioTranscriptionCompleted:
      description: "This event is the output of audio transcription for user audio\
        \ written to the \nuser audio buffer. Transcription begins when the input\
        \ audio buffer is \ncommitted by the client or server (in `server_vad` mode).\
        \ Transcription runs \nasynchronously with Response creation, so this event\
        \ may come before or after \nthe Response events.\n\nRealtime API models accept\
        \ audio natively, and thus input transcription is a\nseparate process run\
        \ on a separate ASR (Automatic Speech Recognition) model.\nThe transcript\
        \ may diverge somewhat from the model's interpretation, and\nshould be treated\
        \ as a rough guide.\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: |
            The event type, must be
            `conversation.item.input_audio_transcription.completed`.
          enum:
          - conversation.item.input_audio_transcription.completed
          type: string
          x-stainless-const: true
        item_id:
          description: The ID of the user message item containing the audio.
          type: string
        content_index:
          description: The index of the content part containing the audio.
          type: integer
        transcript:
          description: The transcribed text.
          type: string
        logprobs:
          description: The log probabilities of the transcription.
          items:
            $ref: "#/components/schemas/LogProbProperties"
          type: array
          nullable: true
      required:
      - content_index
      - event_id
      - item_id
      - transcript
      - type
      x-oaiMeta:
        name: conversation.item.input_audio_transcription.completed
        group: realtime
        example: |
          {
              "event_id": "event_2122",
              "type": "conversation.item.input_audio_transcription.completed",
              "item_id": "msg_003",
              "content_index": 0,
              "transcript": "Hello, how are you?"
          }
    RealtimeServerEventConversationItemInputAudioTranscriptionDelta:
      description: |
        Returned when the text value of an input audio transcription content part is updated.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `conversation.item.input_audio_transcription.delta`."
          enum:
          - conversation.item.input_audio_transcription.delta
          type: string
          x-stainless-const: true
        item_id:
          description: The ID of the item.
          type: string
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
        delta:
          description: The text delta.
          type: string
        logprobs:
          description: The log probabilities of the transcription.
          items:
            $ref: "#/components/schemas/LogProbProperties"
          type: array
          nullable: true
      required:
      - event_id
      - item_id
      - type
      x-oaiMeta:
        name: conversation.item.input_audio_transcription.delta
        group: realtime
        example: |
          {
            "type": "conversation.item.input_audio_transcription.delta",
            "event_id": "event_001",
            "item_id": "item_001",
            "content_index": 0,
            "delta": "Hello"
          }
    RealtimeServerEventConversationItemInputAudioTranscriptionFailed:
      description: "Returned when input audio transcription is configured, and a transcription\
        \ \nrequest for a user message failed. These events are separate from other\
        \ \n`error` events so that the client can identify the related Item.\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: |
            The event type, must be
            `conversation.item.input_audio_transcription.failed`.
          enum:
          - conversation.item.input_audio_transcription.failed
          type: string
          x-stainless-const: true
        item_id:
          description: The ID of the user message item.
          type: string
        content_index:
          description: The index of the content part containing the audio.
          type: integer
        error:
          $ref: "#/components/schemas/RealtimeServerEventConversationItemInputAudioTranscriptionFailed_error"
      required:
      - content_index
      - error
      - event_id
      - item_id
      - type
      x-oaiMeta:
        name: conversation.item.input_audio_transcription.failed
        group: realtime
        example: |
          {
              "event_id": "event_2324",
              "type": "conversation.item.input_audio_transcription.failed",
              "item_id": "msg_003",
              "content_index": 0,
              "error": {
                  "type": "transcription_error",
                  "code": "audio_unintelligible",
                  "message": "The audio could not be transcribed.",
                  "param": null
              }
          }
    RealtimeServerEventConversationItemRetrieved:
      description: |
        Returned when a conversation item is retrieved with `conversation.item.retrieve`.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `conversation.item.retrieved`."
          enum:
          - conversation.item.retrieved
          type: string
          x-stainless-const: true
        item:
          $ref: "#/components/schemas/RealtimeConversationItem"
      required:
      - event_id
      - item
      - type
      x-oaiMeta:
        name: conversation.item.retrieved
        group: realtime
        example: |
          {
              "event_id": "event_1920",
              "type": "conversation.item.created",
              "previous_item_id": "msg_002",
              "item": {
                  "id": "msg_003",
                  "object": "realtime.item",
                  "type": "message",
                  "status": "completed",
                  "role": "user",
                  "content": [
                      {
                          "type": "input_audio",
                          "transcript": "hello how are you",
                          "audio": "base64encodedaudio=="
                      }
                  ]
              }
          }
    RealtimeServerEventConversationItemTruncated:
      description: "Returned when an earlier assistant audio message item is truncated\
        \ by the \nclient with a `conversation.item.truncate` event. This event is\
        \ used to \nsynchronize the server's understanding of the audio with the client's\
        \ playback.\n\nThis action will truncate the audio and remove the server-side\
        \ text transcript \nto ensure there is no text in the context that hasn't\
        \ been heard by the user.\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `conversation.item.truncated`."
          enum:
          - conversation.item.truncated
          type: string
          x-stainless-const: true
        item_id:
          description: The ID of the assistant message item that was truncated.
          type: string
        content_index:
          description: The index of the content part that was truncated.
          type: integer
        audio_end_ms:
          description: |
            The duration up to which the audio was truncated, in milliseconds.
          type: integer
      required:
      - audio_end_ms
      - content_index
      - event_id
      - item_id
      - type
      x-oaiMeta:
        name: conversation.item.truncated
        group: realtime
        example: |
          {
              "event_id": "event_2526",
              "type": "conversation.item.truncated",
              "item_id": "msg_004",
              "content_index": 0,
              "audio_end_ms": 1500
          }
    RealtimeServerEventError:
      description: "Returned when an error occurs, which could be a client problem\
        \ or a server \nproblem. Most errors are recoverable and the session will\
        \ stay open, we \nrecommend to implementors to monitor and log error messages\
        \ by default.\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `error`."
          enum:
          - error
          type: string
          x-stainless-const: true
        error:
          $ref: "#/components/schemas/RealtimeServerEventError_error"
      required:
      - error
      - event_id
      - type
      x-oaiMeta:
        name: error
        group: realtime
        example: |
          {
              "event_id": "event_890",
              "type": "error",
              "error": {
                  "type": "invalid_request_error",
                  "code": "invalid_event",
                  "message": "The 'type' field is missing.",
                  "param": null,
                  "event_id": "event_567"
              }
          }
    RealtimeServerEventInputAudioBufferCleared:
      description: "Returned when the input audio buffer is cleared by the client\
        \ with a \n`input_audio_buffer.clear` event.\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `input_audio_buffer.cleared`."
          enum:
          - input_audio_buffer.cleared
          type: string
          x-stainless-const: true
      required:
      - event_id
      - type
      x-oaiMeta:
        name: input_audio_buffer.cleared
        group: realtime
        example: |
          {
              "event_id": "event_1314",
              "type": "input_audio_buffer.cleared"
          }
    RealtimeServerEventInputAudioBufferCommitted:
      description: "Returned when an input audio buffer is committed, either by the\
        \ client or \nautomatically in server VAD mode. The `item_id` property is\
        \ the ID of the user\nmessage item that will be created, thus a `conversation.item.created`\
        \ event \nwill also be sent to the client.\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `input_audio_buffer.committed`."
          enum:
          - input_audio_buffer.committed
          type: string
          x-stainless-const: true
        previous_item_id:
          description: |
            The ID of the preceding item after which the new item will be inserted.
          type: string
        item_id:
          description: The ID of the user message item that will be created.
          type: string
      required:
      - event_id
      - item_id
      - previous_item_id
      - type
      x-oaiMeta:
        name: input_audio_buffer.committed
        group: realtime
        example: |
          {
              "event_id": "event_1121",
              "type": "input_audio_buffer.committed",
              "previous_item_id": "msg_001",
              "item_id": "msg_002"
          }
    RealtimeServerEventInputAudioBufferSpeechStarted:
      description: "Sent by the server when in `server_vad` mode to indicate that\
        \ speech has been \ndetected in the audio buffer. This can happen any time\
        \ audio is added to the \nbuffer (unless speech is already detected). The\
        \ client may want to use this \nevent to interrupt audio playback or provide\
        \ visual feedback to the user. \n\nThe client should expect to receive a `input_audio_buffer.speech_stopped`\
        \ event \nwhen speech stops. The `item_id` property is the ID of the user\
        \ message item \nthat will be created when speech stops and will also be included\
        \ in the \n`input_audio_buffer.speech_stopped` event (unless the client manually\
        \ commits \nthe audio buffer during VAD activation).\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `input_audio_buffer.speech_started`."
          enum:
          - input_audio_buffer.speech_started
          type: string
          x-stainless-const: true
        audio_start_ms:
          description: "Milliseconds from the start of all audio written to the buffer\
            \ during the \nsession when speech was first detected. This will correspond\
            \ to the \nbeginning of audio sent to the model, and thus includes the\
            \ \n`prefix_padding_ms` configured in the Session.\n"
          type: integer
        item_id:
          description: |
            The ID of the user message item that will be created when speech stops.
          type: string
      required:
      - audio_start_ms
      - event_id
      - item_id
      - type
      x-oaiMeta:
        name: input_audio_buffer.speech_started
        group: realtime
        example: |
          {
              "event_id": "event_1516",
              "type": "input_audio_buffer.speech_started",
              "audio_start_ms": 1000,
              "item_id": "msg_003"
          }
    RealtimeServerEventInputAudioBufferSpeechStopped:
      description: "Returned in `server_vad` mode when the server detects the end\
        \ of speech in \nthe audio buffer. The server will also send an `conversation.item.created`\
        \ \nevent with the user message item that is created from the audio buffer.\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `input_audio_buffer.speech_stopped`."
          enum:
          - input_audio_buffer.speech_stopped
          type: string
          x-stainless-const: true
        audio_end_ms:
          description: "Milliseconds since the session started when speech stopped.\
            \ This will \ncorrespond to the end of audio sent to the model, and thus\
            \ includes the \n`min_silence_duration_ms` configured in the Session.\n"
          type: integer
        item_id:
          description: The ID of the user message item that will be created.
          type: string
      required:
      - audio_end_ms
      - event_id
      - item_id
      - type
      x-oaiMeta:
        name: input_audio_buffer.speech_stopped
        group: realtime
        example: |
          {
              "event_id": "event_1718",
              "type": "input_audio_buffer.speech_stopped",
              "audio_end_ms": 2000,
              "item_id": "msg_003"
          }
    RealtimeServerEventOutputAudioBufferCleared:
      description: |
        **WebRTC Only:** Emitted when the output audio buffer is cleared. This happens either in VAD
        mode when the user has interrupted (`input_audio_buffer.speech_started`),
        or when the client has emitted the `output_audio_buffer.clear` event to manually
        cut off the current audio response.
        [Learn more](/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `output_audio_buffer.cleared`."
          enum:
          - output_audio_buffer.cleared
          type: string
          x-stainless-const: true
        response_id:
          description: The unique ID of the response that produced the audio.
          type: string
      required:
      - event_id
      - response_id
      - type
      x-oaiMeta:
        name: output_audio_buffer.cleared
        group: realtime
        example: |
          {
              "event_id": "event_abc123",
              "type": "output_audio_buffer.cleared",
              "response_id": "resp_abc123"
          }
    RealtimeServerEventOutputAudioBufferStarted:
      description: |
        **WebRTC Only:** Emitted when the server begins streaming audio to the client. This event is
        emitted after an audio content part has been added (`response.content_part.added`)
        to the response.
        [Learn more](/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `output_audio_buffer.started`."
          enum:
          - output_audio_buffer.started
          type: string
          x-stainless-const: true
        response_id:
          description: The unique ID of the response that produced the audio.
          type: string
      required:
      - event_id
      - response_id
      - type
      x-oaiMeta:
        name: output_audio_buffer.started
        group: realtime
        example: |
          {
              "event_id": "event_abc123",
              "type": "output_audio_buffer.started",
              "response_id": "resp_abc123"
          }
    RealtimeServerEventOutputAudioBufferStopped:
      description: |
        **WebRTC Only:** Emitted when the output audio buffer has been completely drained on the server,
        and no more audio is forthcoming. This event is emitted after the full response
        data has been sent to the client (`response.done`).
        [Learn more](/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `output_audio_buffer.stopped`."
          enum:
          - output_audio_buffer.stopped
          type: string
          x-stainless-const: true
        response_id:
          description: The unique ID of the response that produced the audio.
          type: string
      required:
      - event_id
      - response_id
      - type
      x-oaiMeta:
        name: output_audio_buffer.stopped
        group: realtime
        example: |
          {
              "event_id": "event_abc123",
              "type": "output_audio_buffer.stopped",
              "response_id": "resp_abc123"
          }
    RealtimeServerEventRateLimitsUpdated:
      description: "Emitted at the beginning of a Response to indicate the updated\
        \ rate limits. \nWhen a Response is created some tokens will be \"reserved\"\
        \ for the output \ntokens, the rate limits shown here reflect that reservation,\
        \ which is then \nadjusted accordingly once the Response is completed.\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `rate_limits.updated`."
          enum:
          - rate_limits.updated
          type: string
          x-stainless-const: true
        rate_limits:
          description: List of rate limit information.
          items:
            $ref: "#/components/schemas/RealtimeServerEventRateLimitsUpdated_rate_limits_inner"
          type: array
      required:
      - event_id
      - rate_limits
      - type
      x-oaiMeta:
        name: rate_limits.updated
        group: realtime
        example: |
          {
              "event_id": "event_5758",
              "type": "rate_limits.updated",
              "rate_limits": [
                  {
                      "name": "requests",
                      "limit": 1000,
                      "remaining": 999,
                      "reset_seconds": 60
                  },
                  {
                      "name": "tokens",
                      "limit": 50000,
                      "remaining": 49950,
                      "reset_seconds": 60
                  }
              ]
          }
    RealtimeServerEventResponseAudioDelta:
      description: Returned when the model-generated audio is updated.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `response.audio.delta`."
          enum:
          - response.audio.delta
          type: string
          x-stainless-const: true
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
        delta:
          description: Base64-encoded audio data delta.
          type: string
      required:
      - content_index
      - delta
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      x-oaiMeta:
        name: response.audio.delta
        group: realtime
        example: |
          {
              "event_id": "event_4950",
              "type": "response.audio.delta",
              "response_id": "resp_001",
              "item_id": "msg_008",
              "output_index": 0,
              "content_index": 0,
              "delta": "Base64EncodedAudioDelta"
          }
    RealtimeServerEventResponseAudioDone:
      description: |
        Returned when the model-generated audio is done. Also emitted when a Response
        is interrupted, incomplete, or cancelled.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `response.audio.done`."
          enum:
          - response.audio.done
          type: string
          x-stainless-const: true
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
      required:
      - content_index
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      x-oaiMeta:
        name: response.audio.done
        group: realtime
        example: |
          {
              "event_id": "event_5152",
              "type": "response.audio.done",
              "response_id": "resp_001",
              "item_id": "msg_008",
              "output_index": 0,
              "content_index": 0
          }
    RealtimeServerEventResponseAudioTranscriptDelta:
      description: |
        Returned when the model-generated transcription of audio output is updated.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `response.audio_transcript.delta`."
          enum:
          - response.audio_transcript.delta
          type: string
          x-stainless-const: true
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
        delta:
          description: The transcript delta.
          type: string
      required:
      - content_index
      - delta
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      x-oaiMeta:
        name: response.audio_transcript.delta
        group: realtime
        example: |
          {
              "event_id": "event_4546",
              "type": "response.audio_transcript.delta",
              "response_id": "resp_001",
              "item_id": "msg_008",
              "output_index": 0,
              "content_index": 0,
              "delta": "Hello, how can I a"
          }
    RealtimeServerEventResponseAudioTranscriptDone:
      description: |
        Returned when the model-generated transcription of audio output is done
        streaming. Also emitted when a Response is interrupted, incomplete, or
        cancelled.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `response.audio_transcript.done`."
          enum:
          - response.audio_transcript.done
          type: string
          x-stainless-const: true
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
        transcript:
          description: The final transcript of the audio.
          type: string
      required:
      - content_index
      - event_id
      - item_id
      - output_index
      - response_id
      - transcript
      - type
      x-oaiMeta:
        name: response.audio_transcript.done
        group: realtime
        example: |
          {
              "event_id": "event_4748",
              "type": "response.audio_transcript.done",
              "response_id": "resp_001",
              "item_id": "msg_008",
              "output_index": 0,
              "content_index": 0,
              "transcript": "Hello, how can I assist you today?"
          }
    RealtimeServerEventResponseContentPartAdded:
      description: |
        Returned when a new content part is added to an assistant message item during
        response generation.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `response.content_part.added`."
          enum:
          - response.content_part.added
          type: string
          x-stainless-const: true
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item to which the content part was added.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
        part:
          $ref: "#/components/schemas/RealtimeServerEventResponseContentPartAdded_part"
      required:
      - content_index
      - event_id
      - item_id
      - output_index
      - part
      - response_id
      - type
      x-oaiMeta:
        name: response.content_part.added
        group: realtime
        example: |
          {
              "event_id": "event_3738",
              "type": "response.content_part.added",
              "response_id": "resp_001",
              "item_id": "msg_007",
              "output_index": 0,
              "content_index": 0,
              "part": {
                  "type": "text",
                  "text": ""
              }
          }
    RealtimeServerEventResponseContentPartDone:
      description: |
        Returned when a content part is done streaming in an assistant message item.
        Also emitted when a Response is interrupted, incomplete, or cancelled.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `response.content_part.done`."
          enum:
          - response.content_part.done
          type: string
          x-stainless-const: true
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
        part:
          $ref: "#/components/schemas/RealtimeServerEventResponseContentPartDone_part"
      required:
      - content_index
      - event_id
      - item_id
      - output_index
      - part
      - response_id
      - type
      x-oaiMeta:
        name: response.content_part.done
        group: realtime
        example: |
          {
              "event_id": "event_3940",
              "type": "response.content_part.done",
              "response_id": "resp_001",
              "item_id": "msg_007",
              "output_index": 0,
              "content_index": 0,
              "part": {
                  "type": "text",
                  "text": "Sure, I can help with that."
              }
          }
    RealtimeServerEventResponseCreated:
      description: |
        Returned when a new Response is created. The first event of response creation,
        where the response is in an initial state of `in_progress`.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `response.created`."
          enum:
          - response.created
          type: string
          x-stainless-const: true
        response:
          $ref: "#/components/schemas/RealtimeResponse"
      required:
      - event_id
      - response
      - type
      x-oaiMeta:
        name: response.created
        group: realtime
        example: |
          {
              "event_id": "event_2930",
              "type": "response.created",
              "response": {
                  "id": "resp_001",
                  "object": "realtime.response",
                  "status": "in_progress",
                  "status_details": null,
                  "output": [],
                  "usage": null
              }
          }
    RealtimeServerEventResponseDone:
      description: "Returned when a Response is done streaming. Always emitted, no\
        \ matter the \nfinal state. The Response object included in the `response.done`\
        \ event will \ninclude all output Items in the Response but will omit the\
        \ raw audio data.\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `response.done`."
          enum:
          - response.done
          type: string
          x-stainless-const: true
        response:
          $ref: "#/components/schemas/RealtimeResponse"
      required:
      - event_id
      - response
      - type
      x-oaiMeta:
        name: response.done
        group: realtime
        example: |
          {
              "event_id": "event_3132",
              "type": "response.done",
              "response": {
                  "id": "resp_001",
                  "object": "realtime.response",
                  "status": "completed",
                  "status_details": null,
                  "output": [
                      {
                          "id": "msg_006",
                          "object": "realtime.item",
                          "type": "message",
                          "status": "completed",
                          "role": "assistant",
                          "content": [
                              {
                                  "type": "text",
                                  "text": "Sure, how can I assist you today?"
                              }
                          ]
                      }
                  ],
                  "usage": {
                      "total_tokens":275,
                      "input_tokens":127,
                      "output_tokens":148,
                      "input_token_details": {
                          "cached_tokens":384,
                          "text_tokens":119,
                          "audio_tokens":8,
                          "cached_tokens_details": {
                              "text_tokens": 128,
                              "audio_tokens": 256
                          }
                      },
                      "output_token_details": {
                        "text_tokens":36,
                        "audio_tokens":112
                      }
                  }
              }
          }
    RealtimeServerEventResponseFunctionCallArgumentsDelta:
      description: |
        Returned when the model-generated function call arguments are updated.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: |
            The event type, must be `response.function_call_arguments.delta`.
          enum:
          - response.function_call_arguments.delta
          type: string
          x-stainless-const: true
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the function call item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        call_id:
          description: The ID of the function call.
          type: string
        delta:
          description: The arguments delta as a JSON string.
          type: string
      required:
      - call_id
      - delta
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      x-oaiMeta:
        name: response.function_call_arguments.delta
        group: realtime
        example: |
          {
              "event_id": "event_5354",
              "type": "response.function_call_arguments.delta",
              "response_id": "resp_002",
              "item_id": "fc_001",
              "output_index": 0,
              "call_id": "call_001",
              "delta": "{\"location\": \"San\""
          }
    RealtimeServerEventResponseFunctionCallArgumentsDone:
      description: |
        Returned when the model-generated function call arguments are done streaming.
        Also emitted when a Response is interrupted, incomplete, or cancelled.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: |
            The event type, must be `response.function_call_arguments.done`.
          enum:
          - response.function_call_arguments.done
          type: string
          x-stainless-const: true
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the function call item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        call_id:
          description: The ID of the function call.
          type: string
        arguments:
          description: The final arguments as a JSON string.
          type: string
      required:
      - arguments
      - call_id
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      x-oaiMeta:
        name: response.function_call_arguments.done
        group: realtime
        example: |
          {
              "event_id": "event_5556",
              "type": "response.function_call_arguments.done",
              "response_id": "resp_002",
              "item_id": "fc_001",
              "output_index": 0,
              "call_id": "call_001",
              "arguments": "{\"location\": \"San Francisco\"}"
          }
    RealtimeServerEventResponseOutputItemAdded:
      description: Returned when a new Item is created during Response generation.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `response.output_item.added`."
          enum:
          - response.output_item.added
          type: string
          x-stainless-const: true
        response_id:
          description: The ID of the Response to which the item belongs.
          type: string
        output_index:
          description: The index of the output item in the Response.
          type: integer
        item:
          $ref: "#/components/schemas/RealtimeConversationItem"
      required:
      - event_id
      - item
      - output_index
      - response_id
      - type
      x-oaiMeta:
        name: response.output_item.added
        group: realtime
        example: |
          {
              "event_id": "event_3334",
              "type": "response.output_item.added",
              "response_id": "resp_001",
              "output_index": 0,
              "item": {
                  "id": "msg_007",
                  "object": "realtime.item",
                  "type": "message",
                  "status": "in_progress",
                  "role": "assistant",
                  "content": []
              }
          }
    RealtimeServerEventResponseOutputItemDone:
      description: "Returned when an Item is done streaming. Also emitted when a Response\
        \ is \ninterrupted, incomplete, or cancelled.\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `response.output_item.done`."
          enum:
          - response.output_item.done
          type: string
          x-stainless-const: true
        response_id:
          description: The ID of the Response to which the item belongs.
          type: string
        output_index:
          description: The index of the output item in the Response.
          type: integer
        item:
          $ref: "#/components/schemas/RealtimeConversationItem"
      required:
      - event_id
      - item
      - output_index
      - response_id
      - type
      x-oaiMeta:
        name: response.output_item.done
        group: realtime
        example: |
          {
              "event_id": "event_3536",
              "type": "response.output_item.done",
              "response_id": "resp_001",
              "output_index": 0,
              "item": {
                  "id": "msg_007",
                  "object": "realtime.item",
                  "type": "message",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                      {
                          "type": "text",
                          "text": "Sure, I can help with that."
                      }
                  ]
              }
          }
    RealtimeServerEventResponseTextDelta:
      description: Returned when the text value of a "text" content part is updated.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `response.text.delta`."
          enum:
          - response.text.delta
          type: string
          x-stainless-const: true
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
        delta:
          description: The text delta.
          type: string
      required:
      - content_index
      - delta
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      x-oaiMeta:
        name: response.text.delta
        group: realtime
        example: |
          {
              "event_id": "event_4142",
              "type": "response.text.delta",
              "response_id": "resp_001",
              "item_id": "msg_007",
              "output_index": 0,
              "content_index": 0,
              "delta": "Sure, I can h"
          }
    RealtimeServerEventResponseTextDone:
      description: |
        Returned when the text value of a "text" content part is done streaming. Also
        emitted when a Response is interrupted, incomplete, or cancelled.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `response.text.done`."
          enum:
          - response.text.done
          type: string
          x-stainless-const: true
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
        text:
          description: The final text content.
          type: string
      required:
      - content_index
      - event_id
      - item_id
      - output_index
      - response_id
      - text
      - type
      x-oaiMeta:
        name: response.text.done
        group: realtime
        example: |
          {
              "event_id": "event_4344",
              "type": "response.text.done",
              "response_id": "resp_001",
              "item_id": "msg_007",
              "output_index": 0,
              "content_index": 0,
              "text": "Sure, I can help with that."
          }
    RealtimeServerEventSessionCreated:
      description: "Returned when a Session is created. Emitted automatically when\
        \ a new \nconnection is established as the first server event. This event\
        \ will contain \nthe default Session configuration.\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `session.created`."
          enum:
          - session.created
          type: string
          x-stainless-const: true
        session:
          $ref: "#/components/schemas/RealtimeSession"
      required:
      - event_id
      - session
      - type
      x-oaiMeta:
        name: session.created
        group: realtime
        example: |
          {
              "event_id": "event_1234",
              "type": "session.created",
              "session": {
                  "id": "sess_001",
                  "object": "realtime.session",
                  "model": "gpt-4o-realtime-preview",
                  "modalities": ["text", "audio"],
                  "instructions": "...model instructions here...",
                  "voice": "sage",
                  "input_audio_format": "pcm16",
                  "output_audio_format": "pcm16",
                  "input_audio_transcription": null,
                  "turn_detection": {
                      "type": "server_vad",
                      "threshold": 0.5,
                      "prefix_padding_ms": 300,
                      "silence_duration_ms": 200
                  },
                  "tools": [],
                  "tool_choice": "auto",
                  "temperature": 0.8,
                  "max_response_output_tokens": "inf",
                  "speed": 1.1,
                  "tracing": "auto"
              }
          }
    RealtimeServerEventSessionUpdated:
      description: "Returned when a session is updated with a `session.update` event,\
        \ unless \nthere is an error.\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `session.updated`."
          enum:
          - session.updated
          type: string
          x-stainless-const: true
        session:
          $ref: "#/components/schemas/RealtimeSession"
      required:
      - event_id
      - session
      - type
      x-oaiMeta:
        name: session.updated
        group: realtime
        example: |
          {
              "event_id": "event_5678",
              "type": "session.updated",
              "session": {
                  "id": "sess_001",
                  "object": "realtime.session",
                  "model": "gpt-4o-realtime-preview",
                  "modalities": ["text"],
                  "instructions": "New instructions",
                  "voice": "sage",
                  "input_audio_format": "pcm16",
                  "output_audio_format": "pcm16",
                  "input_audio_transcription": {
                      "model": "whisper-1"
                  },
                  "turn_detection": null,
                  "tools": [],
                  "tool_choice": "none",
                  "temperature": 0.7,
                  "max_response_output_tokens": 200,
                  "speed": 1.1,
                  "tracing": "auto"
              }
          }
    RealtimeServerEventTranscriptionSessionUpdated:
      description: "Returned when a transcription session is updated with a `transcription_session.update`\
        \ event, unless \nthere is an error.\n"
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be `transcription_session.updated`."
          enum:
          - transcription_session.updated
          type: string
          x-stainless-const: true
        session:
          $ref: "#/components/schemas/RealtimeTranscriptionSessionCreateResponse"
      required:
      - event_id
      - session
      - type
      x-oaiMeta:
        name: transcription_session.updated
        group: realtime
        example: |
          {
            "event_id": "event_5678",
            "type": "transcription_session.updated",
            "session": {
              "id": "sess_001",
              "object": "realtime.transcription_session",
              "input_audio_format": "pcm16",
              "input_audio_transcription": {
                "model": "gpt-4o-transcribe",
                "prompt": "",
                "language": ""
              },
              "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 500,
                "create_response": true,
                // "interrupt_response": false  -- this will NOT be returned
              },
              "input_audio_noise_reduction": {
                "type": "near_field"
              },
              "include": [
                "item.input_audio_transcription.avg_logprob",
              ],
            }
          }
    RealtimeSession:
      description: Realtime session object configuration.
      properties:
        id:
          description: |
            Unique identifier for the session that looks like `sess_1234567890abcdef`.
          type: string
        modalities: {}
        model:
          description: |
            The Realtime model used for this session.
          enum:
          - gpt-4o-realtime-preview
          - gpt-4o-realtime-preview-2024-10-01
          - gpt-4o-realtime-preview-2024-12-17
          - gpt-4o-realtime-preview-2025-06-03
          - gpt-4o-mini-realtime-preview
          - gpt-4o-mini-realtime-preview-2024-12-17
          type: string
        instructions:
          description: "The default system instructions (i.e. system message) prepended\
            \ to model \ncalls. This field allows the client to guide the model on\
            \ desired \nresponses. The model can be instructed on response content\
            \ and format, \n(e.g. \"be extremely succinct\", \"act friendly\", \"\
            here are examples of good \nresponses\") and on audio behavior (e.g. \"\
            talk quickly\", \"inject emotion \ninto your voice\", \"laugh frequently\"\
            ). The instructions are not\nguaranteed to be followed by the model, but\
            \ they provide guidance to the \nmodel on the desired behavior.\n\n\n\
            Note that the server sets default instructions which will be used if this\n\
            field is not set and are visible in the `session.created` event at the\n\
            start of the session.\n"
          type: string
        voice:
          $ref: "#/components/schemas/VoiceIdsShared"
        input_audio_format:
          default: pcm16
          description: "The format of input audio. Options are `pcm16`, `g711_ulaw`,\
            \ or `g711_alaw`.\nFor `pcm16`, input audio must be 16-bit PCM at a 24kHz\
            \ sample rate, \nsingle channel (mono), and little-endian byte order.\n"
          enum:
          - pcm16
          - g711_ulaw
          - g711_alaw
          type: string
        output_audio_format:
          default: pcm16
          description: |
            The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
            For `pcm16`, output audio is sampled at a rate of 24kHz.
          enum:
          - pcm16
          - g711_ulaw
          - g711_alaw
          type: string
        input_audio_transcription:
          $ref: "#/components/schemas/RealtimeSession_input_audio_transcription"
        turn_detection:
          $ref: "#/components/schemas/RealtimeSession_turn_detection"
        input_audio_noise_reduction:
          $ref: "#/components/schemas/RealtimeSession_input_audio_noise_reduction"
        speed:
          default: 1
          description: |
            The speed of the model's spoken response. 1.0 is the default speed. 0.25 is
            the minimum speed. 1.5 is the maximum speed. This value can only be changed
            in between model turns, not while a response is in progress.
          maximum: 1.5
          minimum: 0.25
          type: number
        tracing:
          $ref: "#/components/schemas/Tracing_Configuration"
        tools:
          description: Tools (functions) available to the model.
          items:
            $ref: "#/components/schemas/RealtimeResponseCreateParams_tools_inner"
          type: array
        tool_choice:
          default: auto
          description: "How the model chooses tools. Options are `auto`, `none`, `required`,\
            \ or \nspecify a function.\n"
          type: string
        temperature:
          default: 0.8
          description: |
            Sampling temperature for the model, limited to [0.6, 1.2]. For audio models a temperature of 0.8 is highly recommended for best performance.
          type: number
        max_response_output_tokens:
          $ref: "#/components/schemas/RealtimeResponseCreateParams_max_response_output_tokens"
    RealtimeSessionCreateRequest:
      description: Realtime session object configuration.
      example:
        voice: ash
        instructions: instructions
        input_audio_format: pcm16
        tracing: auto
        input_audio_noise_reduction:
          type: near_field
        input_audio_transcription:
          model: model
          language: language
          prompt: prompt
        turn_detection:
          silence_duration_ms: 1
          create_response: true
          interrupt_response: true
          prefix_padding_ms: 6
          eagerness: auto
          threshold: 0.8008281904610115
          type: server_vad
        tools:
        - name: name
          description: description
          type: function
          parameters: "{}"
        - name: name
          description: description
          type: function
          parameters: "{}"
        speed: 0.9952667395853978
        modalities: ""
        max_response_output_tokens: 2
        output_audio_format: pcm16
        temperature: 5.637376656633329
        tool_choice: auto
        model: gpt-4o-realtime-preview
        client_secret:
          expires_after:
            seconds: 7
            anchor: created_at
      properties:
        modalities: {}
        model:
          description: |
            The Realtime model used for this session.
          enum:
          - gpt-4o-realtime-preview
          - gpt-4o-realtime-preview-2024-10-01
          - gpt-4o-realtime-preview-2024-12-17
          - gpt-4o-realtime-preview-2025-06-03
          - gpt-4o-mini-realtime-preview
          - gpt-4o-mini-realtime-preview-2024-12-17
          type: string
        instructions:
          description: |
            The default system instructions (i.e. system message) prepended to model calls. This field allows the client to guide the model on desired responses. The model can be instructed on response content and format, (e.g. "be extremely succinct", "act friendly", "here are examples of good responses") and on audio behavior (e.g. "talk quickly", "inject emotion into your voice", "laugh frequently"). The instructions are not guaranteed to be followed by the model, but they provide guidance to the model on the desired behavior.

            Note that the server sets default instructions which will be used if this field is not set and are visible in the `session.created` event at the start of the session.
          type: string
        voice:
          $ref: "#/components/schemas/VoiceIdsShared"
        input_audio_format:
          default: pcm16
          description: |
            The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
            For `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate,
            single channel (mono), and little-endian byte order.
          enum:
          - pcm16
          - g711_ulaw
          - g711_alaw
          type: string
        output_audio_format:
          default: pcm16
          description: |
            The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
            For `pcm16`, output audio is sampled at a rate of 24kHz.
          enum:
          - pcm16
          - g711_ulaw
          - g711_alaw
          type: string
        input_audio_transcription:
          $ref: "#/components/schemas/RealtimeSessionCreateRequest_input_audio_transcription"
        turn_detection:
          $ref: "#/components/schemas/RealtimeSessionCreateRequest_turn_detection"
        input_audio_noise_reduction:
          $ref: "#/components/schemas/RealtimeSession_input_audio_noise_reduction"
        speed:
          default: 1
          description: |
            The speed of the model's spoken response. 1.0 is the default speed. 0.25 is
            the minimum speed. 1.5 is the maximum speed. This value can only be changed
            in between model turns, not while a response is in progress.
          maximum: 1.5
          minimum: 0.25
          type: number
        tracing:
          $ref: "#/components/schemas/Tracing_Configuration"
        tools:
          description: Tools (functions) available to the model.
          items:
            $ref: "#/components/schemas/RealtimeSessionCreateRequest_tools_inner"
          type: array
        tool_choice:
          default: auto
          description: |
            How the model chooses tools. Options are `auto`, `none`, `required`, or
            specify a function.
          type: string
        temperature:
          default: 0.8
          description: |
            Sampling temperature for the model, limited to [0.6, 1.2]. For audio models a temperature of 0.8 is highly recommended for best performance.
          type: number
        max_response_output_tokens:
          $ref: "#/components/schemas/RealtimeResponseCreateParams_max_response_output_tokens"
        client_secret:
          $ref: "#/components/schemas/RealtimeSessionCreateRequest_client_secret"
    RealtimeSessionCreateResponse:
      description: |
        A new Realtime session configuration, with an ephermeral key. Default TTL
        for keys is one minute.
      example:
        voice: ash
        instructions: instructions
        input_audio_format: input_audio_format
        tracing: auto
        input_audio_transcription:
          model: model
        turn_detection:
          silence_duration_ms: 5
          prefix_padding_ms: 5
          threshold: 1.4658129805029452
          type: type
        tools:
        - name: name
          description: description
          type: function
          parameters: "{}"
        - name: name
          description: description
          type: function
          parameters: "{}"
        speed: 1.0034320228838003
        modalities: ""
        max_response_output_tokens: 7
        output_audio_format: output_audio_format
        temperature: 2.3021358869347655
        tool_choice: tool_choice
        client_secret:
          expires_at: 0
          value: value
      properties:
        client_secret:
          $ref: "#/components/schemas/RealtimeSessionCreateResponse_client_secret"
        modalities: {}
        instructions:
          description: "The default system instructions (i.e. system message) prepended\
            \ to model \ncalls. This field allows the client to guide the model on\
            \ desired \nresponses. The model can be instructed on response content\
            \ and format, \n(e.g. \"be extremely succinct\", \"act friendly\", \"\
            here are examples of good \nresponses\") and on audio behavior (e.g. \"\
            talk quickly\", \"inject emotion \ninto your voice\", \"laugh frequently\"\
            ). The instructions are not guaranteed \nto be followed by the model,\
            \ but they provide guidance to the model on the \ndesired behavior.\n\n\
            Note that the server sets default instructions which will be used if this\
            \ \nfield is not set and are visible in the `session.created` event at\
            \ the \nstart of the session.\n"
          type: string
        voice:
          $ref: "#/components/schemas/VoiceIdsShared"
        input_audio_format:
          description: |
            The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
          type: string
        output_audio_format:
          description: |
            The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
          type: string
        input_audio_transcription:
          $ref: "#/components/schemas/RealtimeSessionCreateResponse_input_audio_transcription"
        speed:
          default: 1
          description: |
            The speed of the model's spoken response. 1.0 is the default speed. 0.25 is
            the minimum speed. 1.5 is the maximum speed. This value can only be changed
            in between model turns, not while a response is in progress.
          maximum: 1.5
          minimum: 0.25
          type: number
        tracing:
          $ref: "#/components/schemas/Tracing_Configuration"
        turn_detection:
          $ref: "#/components/schemas/RealtimeSessionCreateResponse_turn_detection"
        tools:
          description: Tools (functions) available to the model.
          items:
            $ref: "#/components/schemas/RealtimeResponseCreateParams_tools_inner"
          type: array
        tool_choice:
          description: "How the model chooses tools. Options are `auto`, `none`, `required`,\
            \ or \nspecify a function.\n"
          type: string
        temperature:
          description: |
            Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.
          type: number
        max_response_output_tokens:
          $ref: "#/components/schemas/RealtimeResponseCreateParams_max_response_output_tokens"
      required:
      - client_secret
      x-oaiMeta:
        name: The session object
        group: realtime
        example: "{\n  \"id\": \"sess_001\",\n  \"object\": \"realtime.session\",\n\
          \  \"model\": \"gpt-4o-realtime-preview\",\n  \"modalities\": [\"audio\"\
          , \"text\"],\n  \"instructions\": \"You are a friendly assistant.\",\n \
          \ \"voice\": \"alloy\",\n  \"input_audio_format\": \"pcm16\",\n  \"output_audio_format\"\
          : \"pcm16\",\n  \"input_audio_transcription\": {\n      \"model\": \"whisper-1\"\
          \n  },\n  \"turn_detection\": null,\n  \"tools\": [],\n  \"tool_choice\"\
          : \"none\",\n  \"temperature\": 0.7,\n  \"speed\": 1.1,\n  \"tracing\":\
          \ \"auto\",\n  \"max_response_output_tokens\": 200,\n  \"client_secret\"\
          : {\n    \"value\": \"ek_abc123\", \n    \"expires_at\": 1234567890\n  }\n\
          }\n"
    RealtimeTranscriptionSessionCreateRequest:
      description: Realtime transcription session object configuration.
      example:
        input_audio_format: pcm16
        include:
        - include
        - include
        modalities: ""
        input_audio_noise_reduction:
          type: near_field
        input_audio_transcription:
          model: gpt-4o-transcribe
          language: language
          prompt: prompt
        turn_detection:
          silence_duration_ms: 1
          create_response: true
          interrupt_response: true
          prefix_padding_ms: 6
          eagerness: auto
          threshold: 0.8008281904610115
          type: server_vad
        client_secret:
          expires_at:
            seconds: 5
            anchor: created_at
      properties:
        modalities: {}
        input_audio_format:
          default: pcm16
          description: |
            The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
            For `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate,
            single channel (mono), and little-endian byte order.
          enum:
          - pcm16
          - g711_ulaw
          - g711_alaw
          type: string
        input_audio_transcription:
          $ref: "#/components/schemas/RealtimeTranscriptionSessionCreateRequest_input_audio_transcription"
        turn_detection:
          $ref: "#/components/schemas/RealtimeTranscriptionSessionCreateRequest_turn_detection"
        input_audio_noise_reduction:
          $ref: "#/components/schemas/RealtimeSession_input_audio_noise_reduction"
        include:
          description: |
            The set of items to include in the transcription. Current available items are:
            - `item.input_audio_transcription.logprobs`
          items:
            type: string
          type: array
        client_secret:
          $ref: "#/components/schemas/RealtimeTranscriptionSessionCreateRequest_client_secret"
    RealtimeTranscriptionSessionCreateResponse:
      description: "A new Realtime transcription session configuration.\n\nWhen a\
        \ session is created on the server via REST API, the session object\nalso\
        \ contains an ephemeral key. Default TTL for keys is 10 minutes. This \nproperty\
        \ is not present when a session is updated via the WebSocket API.\n"
      example:
        input_audio_format: input_audio_format
        modalities: ""
        input_audio_transcription:
          model: gpt-4o-transcribe
          language: language
          prompt: prompt
        turn_detection:
          silence_duration_ms: 5
          prefix_padding_ms: 5
          threshold: 1.4658129805029452
          type: type
        client_secret:
          expires_at: 0
          value: value
      properties:
        client_secret:
          $ref: "#/components/schemas/RealtimeTranscriptionSessionCreateResponse_client_secret"
        modalities: {}
        input_audio_format:
          description: |
            The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
          type: string
        input_audio_transcription:
          $ref: "#/components/schemas/RealtimeTranscriptionSessionCreateResponse_input_audio_transcription"
        turn_detection:
          $ref: "#/components/schemas/RealtimeSessionCreateResponse_turn_detection"
      required:
      - client_secret
      x-oaiMeta:
        name: The transcription session object
        group: realtime
        example: |
          {
            "id": "sess_BBwZc7cFV3XizEyKGDCGL",
            "object": "realtime.transcription_session",
            "expires_at": 1742188264,
            "modalities": ["audio", "text"],
            "turn_detection": {
              "type": "server_vad",
              "threshold": 0.5,
              "prefix_padding_ms": 300,
              "silence_duration_ms": 200
            },
            "input_audio_format": "pcm16",
            "input_audio_transcription": {
              "model": "gpt-4o-transcribe",
              "language": null,
              "prompt": ""
            },
            "client_secret": null
          }
    Reasoning:
      description: "**o-series models only**\n\nConfiguration options for \n[reasoning\
        \ models](https://platform.openai.com/docs/guides/reasoning).\n"
      example:
        summary: auto
        effort: medium
        generate_summary: auto
      properties:
        effort:
          $ref: "#/components/schemas/ReasoningEffort"
        summary:
          description: |
            A summary of the reasoning performed by the model. This can be
            useful for debugging and understanding the model's reasoning process.
            One of `auto`, `concise`, or `detailed`.
          enum:
          - auto
          - concise
          - detailed
          type: string
          nullable: true
        generate_summary:
          deprecated: true
          description: |
            **Deprecated:** use `summary` instead.

            A summary of the reasoning performed by the model. This can be
            useful for debugging and understanding the model's reasoning process.
            One of `auto`, `concise`, or `detailed`.
          enum:
          - auto
          - concise
          - detailed
          type: string
          nullable: true
      title: Reasoning
    ReasoningEffort:
      default: medium
      description: "**o-series models only** \n\nConstrains effort on reasoning for\
        \ \n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\n\
        Currently supported values are `low`, `medium`, and `high`. Reducing\nreasoning\
        \ effort can result in faster responses and fewer tokens used\non reasoning\
        \ in a response.\n"
      enum:
      - low
      - medium
      - high
      type: string
      nullable: true
    ReasoningItem:
      description: "A description of the chain of thought used by a reasoning model\
        \ while generating\na response. Be sure to include these items in your `input`\
        \ to the Responses API\nfor subsequent turns of a conversation if you are\
        \ manually \n[managing context](/docs/guides/conversation-state).\n"
      properties:
        type:
          description: |
            The type of the object. Always `reasoning`.
          enum:
          - reasoning
          type: string
          x-stainless-const: true
        id:
          description: |
            The unique identifier of the reasoning content.
          type: string
        encrypted_content:
          description: |
            The encrypted content of the reasoning item - populated when a response is
            generated with `reasoning.encrypted_content` in the `include` parameter.
          type: string
          nullable: true
        summary:
          description: |
            Reasoning text contents.
          items:
            $ref: "#/components/schemas/ReasoningItem_summary_inner"
          type: array
        status:
          description: |
            The status of the item. One of `in_progress`, `completed`, or
            `incomplete`. Populated when items are returned via API.
          enum:
          - in_progress
          - completed
          - incomplete
          type: string
      required:
      - id
      - summary
      - type
      title: Reasoning
    Response:
      allOf:
      - $ref: "#/components/schemas/ModelResponseProperties"
      - $ref: "#/components/schemas/ResponseProperties"
      - properties:
          id:
            description: |
              Unique identifier for this Response.
            type: string
          object:
            description: |
              The object type of this resource - always set to `response`.
            enum:
            - response
            type: string
            x-stainless-const: true
          status:
            description: "The status of the response generation. One of `completed`,\
              \ `failed`, \n`in_progress`, `cancelled`, `queued`, or `incomplete`.\n"
            enum:
            - completed
            - failed
            - in_progress
            - cancelled
            - queued
            - incomplete
            type: string
          created_at:
            description: |
              Unix timestamp (in seconds) of when this Response was created.
            type: number
          error:
            $ref: "#/components/schemas/ResponseError"
          incomplete_details:
            $ref: "#/components/schemas/Response_allOf_incomplete_details"
          output:
            description: "An array of content items generated by the model.\n\n- The\
              \ length and order of items in the `output` array is dependent\n  on\
              \ the model's response.\n- Rather than accessing the first item in the\
              \ `output` array and \n  assuming it's an `assistant` message with the\
              \ content generated by\n  the model, you might consider using the `output_text`\
              \ property where\n  supported in SDKs.\n"
            items:
              $ref: "#/components/schemas/OutputItem"
            type: array
          instructions:
            $ref: "#/components/schemas/Response_allOf_instructions"
          output_text:
            description: "SDK-only convenience property that contains the aggregated\
              \ text output \nfrom all `output_text` items in the `output` array,\
              \ if any are present. \nSupported in the Python and JavaScript SDKs.\n"
            type: string
            x-oaiSupportedSDKs:
            - python
            - javascript
            nullable: true
          usage:
            $ref: "#/components/schemas/ResponseUsage"
          parallel_tool_calls:
            default: true
            description: |
              Whether to allow the model to run tool calls in parallel.
            type: boolean
        required:
        - created_at
        - error
        - id
        - incomplete_details
        - instructions
        - object
        - output
        - parallel_tool_calls
      example:
        id: resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41
        object: response
        created_at: 1741476777
        status: completed
        error: null
        incomplete_details: null
        instructions: null
        max_output_tokens: null
        model: gpt-4o-2024-08-06
        output:
        - type: message
          id: msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41
          status: completed
          role: assistant
          content:
          - type: output_text
            text: "The image depicts a scenic landscape with a wooden boardwalk or\
              \ pathway leading through lush, green grass under a blue sky with some\
              \ clouds. The setting suggests a peaceful natural area, possibly a park\
              \ or nature reserve. There are trees and shrubs in the background."
            annotations: []
        parallel_tool_calls: true
        previous_response_id: null
        reasoning:
          effort: null
          summary: null
        store: true
        temperature: 1
        text:
          format:
            type: text
        tool_choice: auto
        tools: []
        top_p: 1
        truncation: disabled
        usage:
          input_tokens: 328
          input_tokens_details:
            cached_tokens: 0
          output_tokens: 52
          output_tokens_details:
            reasoning_tokens: 0
          total_tokens: 380
        user: null
        metadata: {}
      title: The response object
    ResponseAudioDeltaEvent:
      description: Emitted when there is a partial audio response.
      properties:
        type:
          description: |
            The type of the event. Always `response.audio.delta`.
          enum:
          - response.audio.delta
          type: string
          x-stainless-const: true
        sequence_number:
          description: |
            A sequence number for this chunk of the stream response.
          type: integer
        delta:
          description: |
            A chunk of Base64 encoded response audio bytes.
          type: string
      required:
      - delta
      - sequence_number
      - type
      x-oaiMeta:
        name: response.audio.delta
        group: responses
        example: |
          {
            "type": "response.audio.delta",
            "response_id": "resp_123",
            "delta": "base64encoded...",
            "sequence_number": 1
          }
    ResponseAudioDoneEvent:
      description: Emitted when the audio response is complete.
      properties:
        type:
          description: |
            The type of the event. Always `response.audio.done`.
          enum:
          - response.audio.done
          type: string
          x-stainless-const: true
        sequence_number:
          description: |
            The sequence number of the delta.
          type: integer
      required:
      - sequence_number
      - type
      x-oaiMeta:
        name: response.audio.done
        group: responses
        example: |
          {
            "type": "response.audio.done",
            "response_id": "resp-123",
            "sequence_number": 1
          }
    ResponseAudioTranscriptDeltaEvent:
      description: Emitted when there is a partial transcript of audio.
      properties:
        type:
          description: |
            The type of the event. Always `response.audio.transcript.delta`.
          enum:
          - response.audio.transcript.delta
          type: string
          x-stainless-const: true
        delta:
          description: |
            The partial transcript of the audio response.
          type: string
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - delta
      - sequence_number
      - type
      x-oaiMeta:
        name: response.audio.transcript.delta
        group: responses
        example: |
          {
            "type": "response.audio.transcript.delta",
            "response_id": "resp_123",
            "delta": " ... partial transcript ... ",
            "sequence_number": 1
          }
    ResponseAudioTranscriptDoneEvent:
      description: Emitted when the full audio transcript is completed.
      properties:
        type:
          description: |
            The type of the event. Always `response.audio.transcript.done`.
          enum:
          - response.audio.transcript.done
          type: string
          x-stainless-const: true
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - sequence_number
      - type
      x-oaiMeta:
        name: response.audio.transcript.done
        group: responses
        example: |
          {
            "type": "response.audio.transcript.done",
            "response_id": "resp_123",
            "sequence_number": 1
          }
    ResponseCodeInterpreterCallCodeDeltaEvent:
      description: Emitted when a partial code snippet is streamed by the code interpreter.
      properties:
        type:
          description: The type of the event. Always `response.code_interpreter_call_code.delta`.
          enum:
          - response.code_interpreter_call_code.delta
          type: string
          x-stainless-const: true
        output_index:
          description: The index of the output item in the response for which the
            code is being streamed.
          type: integer
        item_id:
          description: The unique identifier of the code interpreter tool call item.
          type: string
        delta:
          description: The partial code snippet being streamed by the code interpreter.
          type: string
        sequence_number:
          description: "The sequence number of this event, used to order streaming\
            \ events."
          type: integer
      required:
      - delta
      - item_id
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.code_interpreter_call_code.delta
        group: responses
        example: |
          {
            "type": "response.code_interpreter_call_code.delta",
            "output_index": 0,
            "item_id": "ci_12345",
            "delta": "print('Hello, world')",
            "sequence_number": 1
          }
    ResponseCodeInterpreterCallCodeDoneEvent:
      description: Emitted when the code snippet is finalized by the code interpreter.
      properties:
        type:
          description: The type of the event. Always `response.code_interpreter_call_code.done`.
          enum:
          - response.code_interpreter_call_code.done
          type: string
          x-stainless-const: true
        output_index:
          description: The index of the output item in the response for which the
            code is finalized.
          type: integer
        item_id:
          description: The unique identifier of the code interpreter tool call item.
          type: string
        code:
          description: The final code snippet output by the code interpreter.
          type: string
        sequence_number:
          description: "The sequence number of this event, used to order streaming\
            \ events."
          type: integer
      required:
      - code
      - item_id
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.code_interpreter_call_code.done
        group: responses
        example: |
          {
            "type": "response.code_interpreter_call_code.done",
            "output_index": 3,
            "item_id": "ci_12345",
            "code": "print('done')",
            "sequence_number": 1
          }
    ResponseCodeInterpreterCallCompletedEvent:
      description: Emitted when the code interpreter call is completed.
      properties:
        type:
          description: The type of the event. Always `response.code_interpreter_call.completed`.
          enum:
          - response.code_interpreter_call.completed
          type: string
          x-stainless-const: true
        output_index:
          description: The index of the output item in the response for which the
            code interpreter call is completed.
          type: integer
        item_id:
          description: The unique identifier of the code interpreter tool call item.
          type: string
        sequence_number:
          description: "The sequence number of this event, used to order streaming\
            \ events."
          type: integer
      required:
      - item_id
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.code_interpreter_call.completed
        group: responses
        example: |
          {
            "type": "response.code_interpreter_call.completed",
            "output_index": 5,
            "item_id": "ci_12345",
            "sequence_number": 1
          }
    ResponseCodeInterpreterCallInProgressEvent:
      description: Emitted when a code interpreter call is in progress.
      properties:
        type:
          description: The type of the event. Always `response.code_interpreter_call.in_progress`.
          enum:
          - response.code_interpreter_call.in_progress
          type: string
          x-stainless-const: true
        output_index:
          description: The index of the output item in the response for which the
            code interpreter call is in progress.
          type: integer
        item_id:
          description: The unique identifier of the code interpreter tool call item.
          type: string
        sequence_number:
          description: "The sequence number of this event, used to order streaming\
            \ events."
          type: integer
      required:
      - item_id
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.code_interpreter_call.in_progress
        group: responses
        example: |
          {
            "type": "response.code_interpreter_call.in_progress",
            "output_index": 0,
            "item_id": "ci_12345",
            "sequence_number": 1
          }
    ResponseCodeInterpreterCallInterpretingEvent:
      description: Emitted when the code interpreter is actively interpreting the
        code snippet.
      properties:
        type:
          description: The type of the event. Always `response.code_interpreter_call.interpreting`.
          enum:
          - response.code_interpreter_call.interpreting
          type: string
          x-stainless-const: true
        output_index:
          description: The index of the output item in the response for which the
            code interpreter is interpreting code.
          type: integer
        item_id:
          description: The unique identifier of the code interpreter tool call item.
          type: string
        sequence_number:
          description: "The sequence number of this event, used to order streaming\
            \ events."
          type: integer
      required:
      - item_id
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.code_interpreter_call.interpreting
        group: responses
        example: |
          {
            "type": "response.code_interpreter_call.interpreting",
            "output_index": 4,
            "item_id": "ci_12345",
            "sequence_number": 1
          }
    ResponseCompletedEvent:
      description: Emitted when the model response is complete.
      properties:
        type:
          description: |
            The type of the event. Always `response.completed`.
          enum:
          - response.completed
          type: string
          x-stainless-const: true
        response:
          $ref: "#/components/schemas/Response"
        sequence_number:
          description: The sequence number for this event.
          type: integer
      required:
      - response
      - sequence_number
      - type
      x-oaiMeta:
        name: response.completed
        group: responses
        example: |
          {
            "type": "response.completed",
            "response": {
              "id": "resp_123",
              "object": "response",
              "created_at": 1740855869,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "input": [],
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-mini-2024-07-18",
              "output": [
                {
                  "id": "msg_123",
                  "type": "message",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
                      "annotations": []
                    }
                  ]
                }
              ],
              "previous_response_id": null,
              "reasoning_effort": null,
              "store": false,
              "temperature": 1,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 0,
                "output_tokens": 0,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 0
              },
              "user": null,
              "metadata": {}
            },
            "sequence_number": 1
          }
    ResponseContentPartAddedEvent:
      description: Emitted when a new content part is added.
      properties:
        type:
          description: |
            The type of the event. Always `response.content_part.added`.
          enum:
          - response.content_part.added
          type: string
          x-stainless-const: true
        item_id:
          description: |
            The ID of the output item that the content part was added to.
          type: string
        output_index:
          description: |
            The index of the output item that the content part was added to.
          type: integer
        content_index:
          description: |
            The index of the content part that was added.
          type: integer
        part:
          $ref: "#/components/schemas/OutputContent"
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - content_index
      - item_id
      - output_index
      - part
      - sequence_number
      - type
      x-oaiMeta:
        name: response.content_part.added
        group: responses
        example: |
          {
            "type": "response.content_part.added",
            "item_id": "msg_123",
            "output_index": 0,
            "content_index": 0,
            "part": {
              "type": "output_text",
              "text": "",
              "annotations": []
            },
            "sequence_number": 1
          }
    ResponseContentPartDoneEvent:
      description: Emitted when a content part is done.
      properties:
        type:
          description: |
            The type of the event. Always `response.content_part.done`.
          enum:
          - response.content_part.done
          type: string
          x-stainless-const: true
        item_id:
          description: |
            The ID of the output item that the content part was added to.
          type: string
        output_index:
          description: |
            The index of the output item that the content part was added to.
          type: integer
        content_index:
          description: |
            The index of the content part that is done.
          type: integer
        sequence_number:
          description: The sequence number of this event.
          type: integer
        part:
          $ref: "#/components/schemas/OutputContent"
      required:
      - content_index
      - item_id
      - output_index
      - part
      - sequence_number
      - type
      x-oaiMeta:
        name: response.content_part.done
        group: responses
        example: |
          {
            "type": "response.content_part.done",
            "item_id": "msg_123",
            "output_index": 0,
            "content_index": 0,
            "sequence_number": 1,
            "part": {
              "type": "output_text",
              "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
              "annotations": []
            }
          }
    ResponseCreatedEvent:
      description: |
        An event that is emitted when a response is created.
      properties:
        type:
          description: |
            The type of the event. Always `response.created`.
          enum:
          - response.created
          type: string
          x-stainless-const: true
        response:
          $ref: "#/components/schemas/Response"
        sequence_number:
          description: The sequence number for this event.
          type: integer
      required:
      - response
      - sequence_number
      - type
      x-oaiMeta:
        name: response.created
        group: responses
        example: |
          {
            "type": "response.created",
            "response": {
              "id": "resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c",
              "object": "response",
              "created_at": 1741487325,
              "status": "in_progress",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1,
              "truncation": "disabled",
              "usage": null,
              "user": null,
              "metadata": {}
            },
            "sequence_number": 1
          }
    ResponseError:
      description: |
        An error object returned when the model fails to generate a Response.
      properties:
        code:
          $ref: "#/components/schemas/ResponseErrorCode"
        message:
          description: |
            A human-readable description of the error.
          type: string
      required:
      - code
      - message
      nullable: true
    ResponseErrorCode:
      description: |
        The error code for the response.
      enum:
      - server_error
      - rate_limit_exceeded
      - invalid_prompt
      - vector_store_timeout
      - invalid_image
      - invalid_image_format
      - invalid_base64_image
      - invalid_image_url
      - image_too_large
      - image_too_small
      - image_parse_error
      - image_content_policy_violation
      - invalid_image_mode
      - image_file_too_large
      - unsupported_image_media_type
      - empty_image_file
      - failed_to_download_image
      - image_file_not_found
      type: string
    ResponseErrorEvent:
      description: Emitted when an error occurs.
      properties:
        type:
          description: |
            The type of the event. Always `error`.
          enum:
          - error
          type: string
          x-stainless-const: true
        code:
          description: |
            The error code.
          type: string
          nullable: true
        message:
          description: |
            The error message.
          type: string
        param:
          description: |
            The error parameter.
          type: string
          nullable: true
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - code
      - message
      - param
      - sequence_number
      - type
      x-oaiMeta:
        name: error
        group: responses
        example: |
          {
            "type": "error",
            "code": "ERR_SOMETHING",
            "message": "Something went wrong",
            "param": null,
            "sequence_number": 1
          }
    ResponseFailedEvent:
      description: |
        An event that is emitted when a response fails.
      properties:
        type:
          description: |
            The type of the event. Always `response.failed`.
          enum:
          - response.failed
          type: string
          x-stainless-const: true
        sequence_number:
          description: The sequence number of this event.
          type: integer
        response:
          $ref: "#/components/schemas/Response"
      required:
      - response
      - sequence_number
      - type
      x-oaiMeta:
        name: response.failed
        group: responses
        example: |
          {
            "type": "response.failed",
            "response": {
              "id": "resp_123",
              "object": "response",
              "created_at": 1740855869,
              "status": "failed",
              "error": {
                "code": "server_error",
                "message": "The model failed to generate a response."
              },
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-mini-2024-07-18",
              "output": [],
              "previous_response_id": null,
              "reasoning_effort": null,
              "store": false,
              "temperature": 1,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1,
              "truncation": "disabled",
              "usage": null,
              "user": null,
              "metadata": {}
            }
          }
    ResponseFileSearchCallCompletedEvent:
      description: Emitted when a file search call is completed (results found).
      properties:
        type:
          description: |
            The type of the event. Always `response.file_search_call.completed`.
          enum:
          - response.file_search_call.completed
          type: string
          x-stainless-const: true
        output_index:
          description: |
            The index of the output item that the file search call is initiated.
          type: integer
        item_id:
          description: |
            The ID of the output item that the file search call is initiated.
          type: string
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - item_id
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.file_search_call.completed
        group: responses
        example: |
          {
            "type": "response.file_search_call.completed",
            "output_index": 0,
            "item_id": "fs_123",
            "sequence_number": 1
          }
    ResponseFileSearchCallInProgressEvent:
      description: Emitted when a file search call is initiated.
      properties:
        type:
          description: |
            The type of the event. Always `response.file_search_call.in_progress`.
          enum:
          - response.file_search_call.in_progress
          type: string
          x-stainless-const: true
        output_index:
          description: |
            The index of the output item that the file search call is initiated.
          type: integer
        item_id:
          description: |
            The ID of the output item that the file search call is initiated.
          type: string
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - item_id
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.file_search_call.in_progress
        group: responses
        example: |
          {
            "type": "response.file_search_call.in_progress",
            "output_index": 0,
            "item_id": "fs_123",
            "sequence_number": 1
          }
    ResponseFileSearchCallSearchingEvent:
      description: Emitted when a file search is currently searching.
      properties:
        type:
          description: |
            The type of the event. Always `response.file_search_call.searching`.
          enum:
          - response.file_search_call.searching
          type: string
          x-stainless-const: true
        output_index:
          description: |
            The index of the output item that the file search call is searching.
          type: integer
        item_id:
          description: |
            The ID of the output item that the file search call is initiated.
          type: string
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - item_id
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.file_search_call.searching
        group: responses
        example: |
          {
            "type": "response.file_search_call.searching",
            "output_index": 0,
            "item_id": "fs_123",
            "sequence_number": 1
          }
    ResponseFormatJsonObject:
      description: |
        JSON object response format. An older method of generating JSON responses.
        Using `json_schema` is recommended for models that support it. Note that the
        model will not generate JSON without a system or user message instructing it
        to do so.
      properties:
        type:
          description: The type of response format being defined. Always `json_object`.
          enum:
          - json_object
          type: string
          x-stainless-const: true
      required:
      - type
      title: JSON object
    ResponseFormatJsonSchema:
      description: |
        JSON Schema response format. Used to generate structured JSON responses.
        Learn more about [Structured Outputs](/docs/guides/structured-outputs).
      properties:
        type:
          description: The type of response format being defined. Always `json_schema`.
          enum:
          - json_schema
          type: string
          x-stainless-const: true
        json_schema:
          $ref: "#/components/schemas/JSON_schema"
      required:
      - json_schema
      - type
      title: JSON schema
    ResponseFormatJsonSchemaSchema:
      additionalProperties: true
      description: |
        The schema for the response format, described as a JSON Schema object.
        Learn how to build JSON schemas [here](https://json-schema.org/).
      title: JSON schema
      type: object
    ResponseFormatText:
      description: |
        Default response format. Used to generate text responses.
      example:
        type: text
      properties:
        type:
          description: The type of response format being defined. Always `text`.
          enum:
          - text
          type: string
          x-stainless-const: true
      required:
      - type
      title: Text
    ResponseFunctionCallArgumentsDeltaEvent:
      description: Emitted when there is a partial function-call arguments delta.
      properties:
        type:
          description: |
            The type of the event. Always `response.function_call_arguments.delta`.
          enum:
          - response.function_call_arguments.delta
          type: string
          x-stainless-const: true
        item_id:
          description: |
            The ID of the output item that the function-call arguments delta is added to.
          type: string
        output_index:
          description: |
            The index of the output item that the function-call arguments delta is added to.
          type: integer
        sequence_number:
          description: The sequence number of this event.
          type: integer
        delta:
          description: |
            The function-call arguments delta that is added.
          type: string
      required:
      - delta
      - item_id
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.function_call_arguments.delta
        group: responses
        example: |
          {
            "type": "response.function_call_arguments.delta",
            "item_id": "item-abc",
            "output_index": 0,
            "delta": "{ \"arg\":"
            "sequence_number": 1
          }
    ResponseFunctionCallArgumentsDoneEvent:
      description: Emitted when function-call arguments are finalized.
      properties:
        type:
          enum:
          - response.function_call_arguments.done
          type: string
          x-stainless-const: true
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item.
          type: integer
        sequence_number:
          description: The sequence number of this event.
          type: integer
        arguments:
          description: The function-call arguments.
          type: string
      required:
      - arguments
      - item_id
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.function_call_arguments.done
        group: responses
        example: |
          {
            "type": "response.function_call_arguments.done",
            "item_id": "item-abc",
            "output_index": 1,
            "arguments": "{ \"arg\": 123 }",
            "sequence_number": 1
          }
    ResponseImageGenCallCompletedEvent:
      description: |
        Emitted when an image generation tool call has completed and the final image is available.
      properties:
        type:
          description: The type of the event. Always 'response.image_generation_call.completed'.
          enum:
          - response.image_generation_call.completed
          type: string
          x-stainless-const: true
        output_index:
          description: The index of the output item in the response's output array.
          type: integer
        sequence_number:
          description: The sequence number of this event.
          type: integer
        item_id:
          description: The unique identifier of the image generation item being processed.
          type: string
      required:
      - item_id
      - output_index
      - sequence_number
      - type
      title: ResponseImageGenCallCompletedEvent
      x-oaiMeta:
        name: response.image_generation_call.completed
        group: responses
        example: |
          {
            "type": "response.image_generation_call.completed",
            "output_index": 0,
            "item_id": "item-123",
            "sequence_number": 1
          }
    ResponseImageGenCallGeneratingEvent:
      description: |
        Emitted when an image generation tool call is actively generating an image (intermediate state).
      properties:
        type:
          description: The type of the event. Always 'response.image_generation_call.generating'.
          enum:
          - response.image_generation_call.generating
          type: string
          x-stainless-const: true
        output_index:
          description: The index of the output item in the response's output array.
          type: integer
        item_id:
          description: The unique identifier of the image generation item being processed.
          type: string
        sequence_number:
          description: The sequence number of the image generation item being processed.
          type: integer
      required:
      - item_id
      - output_index
      - sequence_number
      - type
      title: ResponseImageGenCallGeneratingEvent
      x-oaiMeta:
        name: response.image_generation_call.generating
        group: responses
        example: |
          {
            "type": "response.image_generation_call.generating",
            "output_index": 0,
            "item_id": "item-123",
            "sequence_number": 0
          }
    ResponseImageGenCallInProgressEvent:
      description: |
        Emitted when an image generation tool call is in progress.
      properties:
        type:
          description: The type of the event. Always 'response.image_generation_call.in_progress'.
          enum:
          - response.image_generation_call.in_progress
          type: string
          x-stainless-const: true
        output_index:
          description: The index of the output item in the response's output array.
          type: integer
        item_id:
          description: The unique identifier of the image generation item being processed.
          type: string
        sequence_number:
          description: The sequence number of the image generation item being processed.
          type: integer
      required:
      - item_id
      - output_index
      - sequence_number
      - type
      title: ResponseImageGenCallInProgressEvent
      x-oaiMeta:
        name: response.image_generation_call.in_progress
        group: responses
        example: |
          {
            "type": "response.image_generation_call.in_progress",
            "output_index": 0,
            "item_id": "item-123",
            "sequence_number": 0
          }
    ResponseImageGenCallPartialImageEvent:
      description: |
        Emitted when a partial image is available during image generation streaming.
      properties:
        type:
          description: The type of the event. Always 'response.image_generation_call.partial_image'.
          enum:
          - response.image_generation_call.partial_image
          type: string
          x-stainless-const: true
        output_index:
          description: The index of the output item in the response's output array.
          type: integer
        item_id:
          description: The unique identifier of the image generation item being processed.
          type: string
        sequence_number:
          description: The sequence number of the image generation item being processed.
          type: integer
        partial_image_index:
          description: "0-based index for the partial image (backend is 1-based, but\
            \ this is 0-based for the user)."
          type: integer
        partial_image_b64:
          description: "Base64-encoded partial image data, suitable for rendering\
            \ as an image."
          type: string
      required:
      - item_id
      - output_index
      - partial_image_b64
      - partial_image_index
      - sequence_number
      - type
      title: ResponseImageGenCallPartialImageEvent
      x-oaiMeta:
        name: response.image_generation_call.partial_image
        group: responses
        example: |
          {
            "type": "response.image_generation_call.partial_image",
            "output_index": 0,
            "item_id": "item-123",
            "sequence_number": 0,
            "partial_image_index": 0,
            "partial_image_b64": "..."
          }
    ResponseInProgressEvent:
      description: Emitted when the response is in progress.
      properties:
        type:
          description: |
            The type of the event. Always `response.in_progress`.
          enum:
          - response.in_progress
          type: string
          x-stainless-const: true
        response:
          $ref: "#/components/schemas/Response"
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - response
      - sequence_number
      - type
      x-oaiMeta:
        name: response.in_progress
        group: responses
        example: |
          {
            "type": "response.in_progress",
            "response": {
              "id": "resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c",
              "object": "response",
              "created_at": 1741487325,
              "status": "in_progress",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1,
              "truncation": "disabled",
              "usage": null,
              "user": null,
              "metadata": {}
            },
            "sequence_number": 1
          }
    ResponseIncompleteEvent:
      description: |
        An event that is emitted when a response finishes as incomplete.
      properties:
        type:
          description: |
            The type of the event. Always `response.incomplete`.
          enum:
          - response.incomplete
          type: string
          x-stainless-const: true
        response:
          $ref: "#/components/schemas/Response"
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - response
      - sequence_number
      - type
      x-oaiMeta:
        name: response.incomplete
        group: responses
        example: "{\n  \"type\": \"response.incomplete\",\n  \"response\": {\n   \
          \ \"id\": \"resp_123\",\n    \"object\": \"response\",\n    \"created_at\"\
          : 1740855869,\n    \"status\": \"incomplete\",\n    \"error\": null, \n\
          \    \"incomplete_details\": {\n      \"reason\": \"max_tokens\"\n    },\n\
          \    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\"\
          : \"gpt-4o-mini-2024-07-18\",\n    \"output\": [],\n    \"previous_response_id\"\
          : null,\n    \"reasoning_effort\": null,\n    \"store\": false,\n    \"\
          temperature\": 1,\n    \"text\": {\n      \"format\": {\n        \"type\"\
          : \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n    \"tools\"\
          : [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\",\n    \"usage\"\
          : null,\n    \"user\": null,\n    \"metadata\": {}\n  },\n  \"sequence_number\"\
          : 1\n}\n"
    ResponseItemList:
      description: A list of Response items.
      example:
        first_id: first_id
        data:
        - role: user
          id: id
          type: message
          content:
          - text: text
            type: input_text
          - text: text
            type: input_text
          status: in_progress
        - role: user
          id: id
          type: message
          content:
          - text: text
            type: input_text
          - text: text
            type: input_text
          status: in_progress
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          description: "The type of object returned, must be `list`."
          enum:
          - list
          type: string
          x-stainless-const: true
        data:
          description: A list of items used to generate this response.
          items:
            $ref: "#/components/schemas/ItemResource"
          type: array
        has_more:
          description: Whether there are more items available.
          type: boolean
        first_id:
          description: The ID of the first item in the list.
          type: string
        last_id:
          description: The ID of the last item in the list.
          type: string
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      x-oaiMeta:
        name: The input item list
        group: responses
        example: |
          {
            "object": "list",
            "data": [
              {
                "id": "msg_abc123",
                "type": "message",
                "role": "user",
                "content": [
                  {
                    "type": "input_text",
                    "text": "Tell me a three sentence bedtime story about a unicorn."
                  }
                ]
              }
            ],
            "first_id": "msg_abc123",
            "last_id": "msg_abc123",
            "has_more": false
          }
    ResponseMCPCallArgumentsDeltaEvent:
      description: |
        Emitted when there is a delta (partial update) to the arguments of an MCP tool call.
      properties:
        type:
          description: The type of the event. Always 'response.mcp_call.arguments_delta'.
          enum:
          - response.mcp_call.arguments_delta
          type: string
          x-stainless-const: true
        output_index:
          description: The index of the output item in the response's output array.
          type: integer
        item_id:
          description: The unique identifier of the MCP tool call item being processed.
          type: string
        delta:
          description: The partial update to the arguments for the MCP tool call.
          type: object
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - delta
      - item_id
      - output_index
      - sequence_number
      - type
      title: ResponseMCPCallArgumentsDeltaEvent
      x-oaiMeta:
        name: response.mcp_call.arguments.delta
        group: responses
        example: |
          {
            "type": "response.mcp_call.arguments.delta",
            "output_index": 0,
            "item_id": "item-abc",
            "delta": {
              "arg1": "new_value1",
              "arg2": "new_value2"
            },
            "sequence_number": 1
          }
    ResponseMCPCallArgumentsDoneEvent:
      description: |
        Emitted when the arguments for an MCP tool call are finalized.
      properties:
        type:
          description: The type of the event. Always 'response.mcp_call.arguments_done'.
          enum:
          - response.mcp_call.arguments_done
          type: string
          x-stainless-const: true
        output_index:
          description: The index of the output item in the response's output array.
          type: integer
        item_id:
          description: The unique identifier of the MCP tool call item being processed.
          type: string
        arguments:
          description: The finalized arguments for the MCP tool call.
          type: object
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - arguments
      - item_id
      - output_index
      - sequence_number
      - type
      title: ResponseMCPCallArgumentsDoneEvent
      x-oaiMeta:
        name: response.mcp_call.arguments.done
        group: responses
        example: |
          {
            "type": "response.mcp_call.arguments.done",
            "output_index": 0,
            "item_id": "item-abc",
            "arguments": {
              "arg1": "value1",
              "arg2": "value2"
            },
            "sequence_number": 1
          }
    ResponseMCPCallCompletedEvent:
      description: |
        Emitted when an MCP  tool call has completed successfully.
      properties:
        type:
          description: The type of the event. Always 'response.mcp_call.completed'.
          enum:
          - response.mcp_call.completed
          type: string
          x-stainless-const: true
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - sequence_number
      - type
      title: ResponseMCPCallCompletedEvent
      x-oaiMeta:
        name: response.mcp_call.completed
        group: responses
        example: |
          {
            "type": "response.mcp_call.completed",
            "sequence_number": 1
          }
    ResponseMCPCallFailedEvent:
      description: |
        Emitted when an MCP  tool call has failed.
      properties:
        type:
          description: The type of the event. Always 'response.mcp_call.failed'.
          enum:
          - response.mcp_call.failed
          type: string
          x-stainless-const: true
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - sequence_number
      - type
      title: ResponseMCPCallFailedEvent
      x-oaiMeta:
        name: response.mcp_call.failed
        group: responses
        example: |
          {
            "type": "response.mcp_call.failed",
            "sequence_number": 1
          }
    ResponseMCPCallInProgressEvent:
      description: |
        Emitted when an MCP  tool call is in progress.
      properties:
        type:
          description: The type of the event. Always 'response.mcp_call.in_progress'.
          enum:
          - response.mcp_call.in_progress
          type: string
          x-stainless-const: true
        sequence_number:
          description: The sequence number of this event.
          type: integer
        output_index:
          description: The index of the output item in the response's output array.
          type: integer
        item_id:
          description: The unique identifier of the MCP tool call item being processed.
          type: string
      required:
      - item_id
      - output_index
      - sequence_number
      - type
      title: ResponseMCPCallInProgressEvent
      x-oaiMeta:
        name: response.mcp_call.in_progress
        group: responses
        example: |
          {
            "type": "response.mcp_call.in_progress",
            "output_index": 0,
            "item_id": "item-abc",
            "sequence_number": 1
          }
    ResponseMCPListToolsCompletedEvent:
      description: |
        Emitted when the list of available MCP tools has been successfully retrieved.
      properties:
        type:
          description: The type of the event. Always 'response.mcp_list_tools.completed'.
          enum:
          - response.mcp_list_tools.completed
          type: string
          x-stainless-const: true
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - sequence_number
      - type
      title: ResponseMCPListToolsCompletedEvent
      x-oaiMeta:
        name: response.mcp_list_tools.completed
        group: responses
        example: |
          {
            "type": "response.mcp_list_tools.completed",
            "sequence_number": 1
          }
    ResponseMCPListToolsFailedEvent:
      description: |
        Emitted when the attempt to list available MCP tools has failed.
      properties:
        type:
          description: The type of the event. Always 'response.mcp_list_tools.failed'.
          enum:
          - response.mcp_list_tools.failed
          type: string
          x-stainless-const: true
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - sequence_number
      - type
      title: ResponseMCPListToolsFailedEvent
      x-oaiMeta:
        name: response.mcp_list_tools.failed
        group: responses
        example: |
          {
            "type": "response.mcp_list_tools.failed",
            "sequence_number": 1
          }
    ResponseMCPListToolsInProgressEvent:
      description: |
        Emitted when the system is in the process of retrieving the list of available MCP tools.
      properties:
        type:
          description: The type of the event. Always 'response.mcp_list_tools.in_progress'.
          enum:
          - response.mcp_list_tools.in_progress
          type: string
          x-stainless-const: true
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - sequence_number
      - type
      title: ResponseMCPListToolsInProgressEvent
      x-oaiMeta:
        name: response.mcp_list_tools.in_progress
        group: responses
        example: |
          {
            "type": "response.mcp_list_tools.in_progress",
            "sequence_number": 1
          }
    ResponseModalities:
      description: "Output types that you would like the model to generate.\nMost\
        \ models are capable of generating text, which is the default:\n\n`[\"text\"\
        ]`\n\nThe `gpt-4o-audio-preview` model can also be used to \n[generate audio](/docs/guides/audio).\
        \ To request that this model generate \nboth text and audio responses, you\
        \ can use:\n\n`[\"text\", \"audio\"]`\n"
      items:
        enum:
        - text
        - audio
        type: string
      type: array
      nullable: true
    ResponseOutputItemAddedEvent:
      description: Emitted when a new output item is added.
      properties:
        type:
          description: |
            The type of the event. Always `response.output_item.added`.
          enum:
          - response.output_item.added
          type: string
          x-stainless-const: true
        output_index:
          description: |
            The index of the output item that was added.
          type: integer
        sequence_number:
          description: |
            The sequence number of this event.
          type: integer
        item:
          $ref: "#/components/schemas/OutputItem"
      required:
      - item
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.output_item.added
        group: responses
        example: |
          {
            "type": "response.output_item.added",
            "output_index": 0,
            "item": {
              "id": "msg_123",
              "status": "in_progress",
              "type": "message",
              "role": "assistant",
              "content": []
            },
            "sequence_number": 1
          }
    ResponseOutputItemDoneEvent:
      description: Emitted when an output item is marked done.
      properties:
        type:
          description: |
            The type of the event. Always `response.output_item.done`.
          enum:
          - response.output_item.done
          type: string
          x-stainless-const: true
        output_index:
          description: |
            The index of the output item that was marked done.
          type: integer
        sequence_number:
          description: |
            The sequence number of this event.
          type: integer
        item:
          $ref: "#/components/schemas/OutputItem"
      required:
      - item
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.output_item.done
        group: responses
        example: |
          {
            "type": "response.output_item.done",
            "output_index": 0,
            "item": {
              "id": "msg_123",
              "status": "completed",
              "type": "message",
              "role": "assistant",
              "content": [
                {
                  "type": "output_text",
                  "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
                  "annotations": []
                }
              ]
            },
            "sequence_number": 1
          }
    ResponseOutputTextAnnotationAddedEvent:
      description: |
        Emitted when an annotation is added to output text content.
      properties:
        type:
          description: The type of the event. Always 'response.output_text_annotation.added'.
          enum:
          - response.output_text_annotation.added
          type: string
          x-stainless-const: true
        item_id:
          description: The unique identifier of the item to which the annotation is
            being added.
          type: string
        output_index:
          description: The index of the output item in the response's output array.
          type: integer
        content_index:
          description: The index of the content part within the output item.
          type: integer
        annotation_index:
          description: The index of the annotation within the content part.
          type: integer
        sequence_number:
          description: The sequence number of this event.
          type: integer
        annotation:
          description: The annotation object being added. (See annotation schema for
            details.)
          type: object
      required:
      - annotation
      - annotation_index
      - content_index
      - item_id
      - output_index
      - sequence_number
      - type
      title: ResponseOutputTextAnnotationAddedEvent
      x-oaiMeta:
        name: response.output_text_annotation.added
        group: responses
        example: |
          {
            "type": "response.output_text_annotation.added",
            "item_id": "item-abc",
            "output_index": 0,
            "content_index": 0,
            "annotation_index": 0,
            "annotation": {
              "type": "text_annotation",
              "text": "This is a test annotation",
              "start": 0,
              "end": 10
            },
            "sequence_number": 1
          }
    ResponsePromptVariables:
      additionalProperties:
        $ref: "#/components/schemas/ResponsePromptVariables_value"
      description: |
        Optional map of values to substitute in for variables in your
        prompt. The substitution values can either be strings, or other
        Response input types like images or files.
      title: Prompt Variables
      x-oaiExpandable: true
      x-oaiTypeLabel: map
      nullable: true
    ResponseProperties:
      properties:
        previous_response_id:
          description: "The unique ID of the previous response to the model. Use this\
            \ to\ncreate multi-turn conversations. Learn more about \n[conversation\
            \ state](/docs/guides/conversation-state).\n"
          type: string
          nullable: true
        model:
          $ref: "#/components/schemas/ModelIdsResponses"
        reasoning:
          $ref: "#/components/schemas/Reasoning"
        background:
          default: false
          description: "Whether to run the model response in the background. \n[Learn\
            \ more](/docs/guides/background).\n"
          type: boolean
          nullable: true
        max_output_tokens:
          description: |
            An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).
          type: integer
          nullable: true
        max_tool_calls:
          description: |
            The maximum number of total calls to built-in tools that can be processed in a response. This maximum number applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored.
          type: integer
          nullable: true
        text:
          $ref: "#/components/schemas/CreateEvalResponsesRunDataSource_sampling_params_text"
        tools:
          description: "An array of tools the model may call while generating a response.\
            \ You \ncan specify which tool to use by setting the `tool_choice` parameter.\n\
            \nThe two categories of tools you can provide the model are:\n\n- **Built-in\
            \ tools**: Tools that are provided by OpenAI that extend the\n  model's\
            \ capabilities, like [web search](/docs/guides/tools-web-search)\n  or\
            \ [file search](/docs/guides/tools-file-search). Learn more about\n  [built-in\
            \ tools](/docs/guides/tools).\n- **Function calls (custom tools)**: Functions\
            \ that are defined by you,\n  enabling the model to call your own code.\
            \ Learn more about\n  [function calling](/docs/guides/function-calling).\n"
          items:
            $ref: "#/components/schemas/Tool"
          type: array
        tool_choice:
          $ref: "#/components/schemas/ResponseProperties_tool_choice"
        prompt:
          $ref: "#/components/schemas/Prompt"
        truncation:
          default: disabled
          description: "The truncation strategy to use for the model response.\n-\
            \ `auto`: If the context of this response and previous ones exceeds\n\
            \  the model's context window size, the model will truncate the \n  response\
            \ to fit the context window by dropping input items in the\n  middle of\
            \ the conversation. \n- `disabled` (default): If a model response will\
            \ exceed the context window \n  size for a model, the request will fail\
            \ with a 400 error.\n"
          enum:
          - auto
          - disabled
          type: string
          nullable: true
    ResponseQueuedEvent:
      description: |
        Emitted when a response is queued and waiting to be processed.
      properties:
        type:
          description: The type of the event. Always 'response.queued'.
          enum:
          - response.queued
          type: string
          x-stainless-const: true
        response:
          $ref: "#/components/schemas/Response"
        sequence_number:
          description: The sequence number for this event.
          type: integer
      required:
      - response
      - sequence_number
      - type
      title: ResponseQueuedEvent
      x-oaiMeta:
        name: response.queued
        group: responses
        example: |
          {
            "type": "response.queued",
            "response": {
              "id": "res_123",
              "status": "queued",
              "created_at": "2021-01-01T00:00:00Z",
              "updated_at": "2021-01-01T00:00:00Z"
            },
            "sequence_number": 1
          }
    ResponseReasoningDeltaEvent:
      description: |
        Emitted when there is a delta (partial update) to the reasoning content.
      properties:
        type:
          description: The type of the event. Always 'response.reasoning.delta'.
          enum:
          - response.reasoning.delta
          type: string
          x-stainless-const: true
        item_id:
          description: The unique identifier of the item for which reasoning is being
            updated.
          type: string
        output_index:
          description: The index of the output item in the response's output array.
          type: integer
        content_index:
          description: The index of the reasoning content part within the output item.
          type: integer
        delta:
          description: The partial update to the reasoning content.
          type: object
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - content_index
      - delta
      - item_id
      - output_index
      - sequence_number
      - type
      title: ResponseReasoningDeltaEvent
      x-oaiMeta:
        name: response.reasoning.delta
        group: responses
        example: |
          {
            "type": "response.reasoning.delta",
            "item_id": "item-abc",
            "output_index": 0,
            "content_index": 0,
            "delta": {
              "text": "This is a test delta"
            },
            "sequence_number": 1
          }
    ResponseReasoningDoneEvent:
      description: |
        Emitted when the reasoning content is finalized for an item.
      properties:
        type:
          description: The type of the event. Always 'response.reasoning.done'.
          enum:
          - response.reasoning.done
          type: string
          x-stainless-const: true
        item_id:
          description: The unique identifier of the item for which reasoning is finalized.
          type: string
        output_index:
          description: The index of the output item in the response's output array.
          type: integer
        content_index:
          description: The index of the reasoning content part within the output item.
          type: integer
        text:
          description: The finalized reasoning text.
          type: string
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - content_index
      - item_id
      - output_index
      - sequence_number
      - text
      - type
      title: ResponseReasoningDoneEvent
      x-oaiMeta:
        name: response.reasoning.done
        group: responses
        example: |
          {
            "type": "response.reasoning.done",
            "item_id": "item-abc",
            "output_index": 0,
            "content_index": 0,
            "text": "This is a test reasoning",
            "sequence_number": 1
          }
    ResponseReasoningSummaryDeltaEvent:
      description: |
        Emitted when there is a delta (partial update) to the reasoning summary content.
      properties:
        type:
          description: The type of the event. Always 'response.reasoning_summary.delta'.
          enum:
          - response.reasoning_summary.delta
          type: string
          x-stainless-const: true
        item_id:
          description: The unique identifier of the item for which the reasoning summary
            is being updated.
          type: string
        output_index:
          description: The index of the output item in the response's output array.
          type: integer
        summary_index:
          description: The index of the summary part within the output item.
          type: integer
        sequence_number:
          description: The sequence number of this event.
          type: integer
        delta:
          description: The partial update to the reasoning summary content.
          type: object
      required:
      - delta
      - item_id
      - output_index
      - sequence_number
      - summary_index
      - type
      title: ResponseReasoningSummaryDeltaEvent
      x-oaiMeta:
        name: response.reasoning_summary.delta
        group: responses
        example: |
          {
            "type": "response.reasoning_summary.delta",
            "item_id": "item-abc",
            "output_index": 0,
            "summary_index": 0,
            "delta": {
              "text": "delta text"
            },
            "sequence_number": 1
          }
    ResponseReasoningSummaryDoneEvent:
      description: |
        Emitted when the reasoning summary content is finalized for an item.
      properties:
        type:
          description: The type of the event. Always 'response.reasoning_summary.done'.
          enum:
          - response.reasoning_summary.done
          type: string
          x-stainless-const: true
        item_id:
          description: The unique identifier of the item for which the reasoning summary
            is finalized.
          type: string
        output_index:
          description: The index of the output item in the response's output array.
          type: integer
        summary_index:
          description: The index of the summary part within the output item.
          type: integer
        text:
          description: The finalized reasoning summary text.
          type: string
        sequence_number:
          description: The sequence number of this event.
          type: integer
      required:
      - item_id
      - output_index
      - sequence_number
      - summary_index
      - text
      - type
      title: ResponseReasoningSummaryDoneEvent
      x-oaiMeta:
        name: response.reasoning_summary.done
        group: responses
        example: |
          {
            "type": "response.reasoning_summary.done",
            "item_id": "item-abc",
            "output_index": 0,
            "summary_index": 0,
            "text": "This is a test reasoning summary",
            "sequence_number": 1
          }
    ResponseReasoningSummaryPartAddedEvent:
      description: Emitted when a new reasoning summary part is added.
      properties:
        type:
          description: |
            The type of the event. Always `response.reasoning_summary_part.added`.
          enum:
          - response.reasoning_summary_part.added
          type: string
          x-stainless-const: true
        item_id:
          description: |
            The ID of the item this summary part is associated with.
          type: string
        output_index:
          description: |
            The index of the output item this summary part is associated with.
          type: integer
        summary_index:
          description: |
            The index of the summary part within the reasoning summary.
          type: integer
        sequence_number:
          description: |
            The sequence number of this event.
          type: integer
        part:
          $ref: "#/components/schemas/ResponseReasoningSummaryPartAddedEvent_part"
      required:
      - item_id
      - output_index
      - part
      - sequence_number
      - summary_index
      - type
      x-oaiMeta:
        name: response.reasoning_summary_part.added
        group: responses
        example: |
          {
            "type": "response.reasoning_summary_part.added",
            "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
            "output_index": 0,
            "summary_index": 0,
            "part": {
              "type": "summary_text",
              "text": ""
            },
            "sequence_number": 1
          }
    ResponseReasoningSummaryPartDoneEvent:
      description: Emitted when a reasoning summary part is completed.
      properties:
        type:
          description: |
            The type of the event. Always `response.reasoning_summary_part.done`.
          enum:
          - response.reasoning_summary_part.done
          type: string
          x-stainless-const: true
        item_id:
          description: |
            The ID of the item this summary part is associated with.
          type: string
        output_index:
          description: |
            The index of the output item this summary part is associated with.
          type: integer
        summary_index:
          description: |
            The index of the summary part within the reasoning summary.
          type: integer
        sequence_number:
          description: |
            The sequence number of this event.
          type: integer
        part:
          $ref: "#/components/schemas/ResponseReasoningSummaryPartDoneEvent_part"
      required:
      - item_id
      - output_index
      - part
      - sequence_number
      - summary_index
      - type
      x-oaiMeta:
        name: response.reasoning_summary_part.done
        group: responses
        example: |
          {
            "type": "response.reasoning_summary_part.done",
            "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
            "output_index": 0,
            "summary_index": 0,
            "part": {
              "type": "summary_text",
              "text": "**Responding to a greeting**\n\nThe user just said, \"Hello!\" So, it seems I need to engage. I'll greet them back and offer help since they're looking to chat. I could say something like, \"Hello! How can I assist you today?\" That feels friendly and open. They didn't ask a specific question, so this approach will work well for starting a conversation. Let's see where it goes from there!"
            },
            "sequence_number": 1
          }
    ResponseReasoningSummaryTextDeltaEvent:
      description: Emitted when a delta is added to a reasoning summary text.
      properties:
        type:
          description: |
            The type of the event. Always `response.reasoning_summary_text.delta`.
          enum:
          - response.reasoning_summary_text.delta
          type: string
          x-stainless-const: true
        item_id:
          description: |
            The ID of the item this summary text delta is associated with.
          type: string
        output_index:
          description: |
            The index of the output item this summary text delta is associated with.
          type: integer
        summary_index:
          description: |
            The index of the summary part within the reasoning summary.
          type: integer
        delta:
          description: |
            The text delta that was added to the summary.
          type: string
        sequence_number:
          description: |
            The sequence number of this event.
          type: integer
      required:
      - delta
      - item_id
      - output_index
      - sequence_number
      - summary_index
      - type
      x-oaiMeta:
        name: response.reasoning_summary_text.delta
        group: responses
        example: |
          {
            "type": "response.reasoning_summary_text.delta",
            "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
            "output_index": 0,
            "summary_index": 0,
            "delta": "**Responding to a greeting**\n\nThe user just said, \"Hello!\" So, it seems I need to engage. I'll greet them back and offer help since they're looking to chat. I could say something like, \"Hello! How can I assist you today?\" That feels friendly and open. They didn't ask a specific question, so this approach will work well for starting a conversation. Let's see where it goes from there!",
            "sequence_number": 1
          }
    ResponseReasoningSummaryTextDoneEvent:
      description: Emitted when a reasoning summary text is completed.
      properties:
        type:
          description: |
            The type of the event. Always `response.reasoning_summary_text.done`.
          enum:
          - response.reasoning_summary_text.done
          type: string
          x-stainless-const: true
        item_id:
          description: |
            The ID of the item this summary text is associated with.
          type: string
        output_index:
          description: |
            The index of the output item this summary text is associated with.
          type: integer
        summary_index:
          description: |
            The index of the summary part within the reasoning summary.
          type: integer
        text:
          description: |
            The full text of the completed reasoning summary.
          type: string
        sequence_number:
          description: |
            The sequence number of this event.
          type: integer
      required:
      - item_id
      - output_index
      - sequence_number
      - summary_index
      - text
      - type
      x-oaiMeta:
        name: response.reasoning_summary_text.done
        group: responses
        example: |
          {
            "type": "response.reasoning_summary_text.done",
            "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
            "output_index": 0,
            "summary_index": 0,
            "text": "**Responding to a greeting**\n\nThe user just said, \"Hello!\" So, it seems I need to engage. I'll greet them back and offer help since they're looking to chat. I could say something like, \"Hello! How can I assist you today?\" That feels friendly and open. They didn't ask a specific question, so this approach will work well for starting a conversation. Let's see where it goes from there!",
            "sequence_number": 1
          }
    ResponseRefusalDeltaEvent:
      description: Emitted when there is a partial refusal text.
      properties:
        type:
          description: |
            The type of the event. Always `response.refusal.delta`.
          enum:
          - response.refusal.delta
          type: string
          x-stainless-const: true
        item_id:
          description: |
            The ID of the output item that the refusal text is added to.
          type: string
        output_index:
          description: |
            The index of the output item that the refusal text is added to.
          type: integer
        content_index:
          description: |
            The index of the content part that the refusal text is added to.
          type: integer
        delta:
          description: |
            The refusal text that is added.
          type: string
        sequence_number:
          description: |
            The sequence number of this event.
          type: integer
      required:
      - content_index
      - delta
      - item_id
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.refusal.delta
        group: responses
        example: |
          {
            "type": "response.refusal.delta",
            "item_id": "msg_123",
            "output_index": 0,
            "content_index": 0,
            "delta": "refusal text so far",
            "sequence_number": 1
          }
    ResponseRefusalDoneEvent:
      description: Emitted when refusal text is finalized.
      properties:
        type:
          description: |
            The type of the event. Always `response.refusal.done`.
          enum:
          - response.refusal.done
          type: string
          x-stainless-const: true
        item_id:
          description: |
            The ID of the output item that the refusal text is finalized.
          type: string
        output_index:
          description: |
            The index of the output item that the refusal text is finalized.
          type: integer
        content_index:
          description: |
            The index of the content part that the refusal text is finalized.
          type: integer
        refusal:
          description: |
            The refusal text that is finalized.
          type: string
        sequence_number:
          description: |
            The sequence number of this event.
          type: integer
      required:
      - content_index
      - item_id
      - output_index
      - refusal
      - sequence_number
      - type
      x-oaiMeta:
        name: response.refusal.done
        group: responses
        example: |
          {
            "type": "response.refusal.done",
            "item_id": "item-abc",
            "output_index": 1,
            "content_index": 2,
            "refusal": "final refusal text",
            "sequence_number": 1
          }
    ResponseStreamEvent:
      anyOf:
      - $ref: "#/components/schemas/ResponseAudioDeltaEvent"
      - $ref: "#/components/schemas/ResponseAudioDoneEvent"
      - $ref: "#/components/schemas/ResponseAudioTranscriptDeltaEvent"
      - $ref: "#/components/schemas/ResponseAudioTranscriptDoneEvent"
      - $ref: "#/components/schemas/ResponseCodeInterpreterCallCodeDeltaEvent"
      - $ref: "#/components/schemas/ResponseCodeInterpreterCallCodeDoneEvent"
      - $ref: "#/components/schemas/ResponseCodeInterpreterCallCompletedEvent"
      - $ref: "#/components/schemas/ResponseCodeInterpreterCallInProgressEvent"
      - $ref: "#/components/schemas/ResponseCodeInterpreterCallInterpretingEvent"
      - $ref: "#/components/schemas/ResponseCompletedEvent"
      - $ref: "#/components/schemas/ResponseContentPartAddedEvent"
      - $ref: "#/components/schemas/ResponseContentPartDoneEvent"
      - $ref: "#/components/schemas/ResponseCreatedEvent"
      - $ref: "#/components/schemas/ResponseErrorEvent"
      - $ref: "#/components/schemas/ResponseFileSearchCallCompletedEvent"
      - $ref: "#/components/schemas/ResponseFileSearchCallInProgressEvent"
      - $ref: "#/components/schemas/ResponseFileSearchCallSearchingEvent"
      - $ref: "#/components/schemas/ResponseFunctionCallArgumentsDeltaEvent"
      - $ref: "#/components/schemas/ResponseFunctionCallArgumentsDoneEvent"
      - $ref: "#/components/schemas/ResponseInProgressEvent"
      - $ref: "#/components/schemas/ResponseFailedEvent"
      - $ref: "#/components/schemas/ResponseIncompleteEvent"
      - $ref: "#/components/schemas/ResponseOutputItemAddedEvent"
      - $ref: "#/components/schemas/ResponseOutputItemDoneEvent"
      - $ref: "#/components/schemas/ResponseReasoningSummaryPartAddedEvent"
      - $ref: "#/components/schemas/ResponseReasoningSummaryPartDoneEvent"
      - $ref: "#/components/schemas/ResponseReasoningSummaryTextDeltaEvent"
      - $ref: "#/components/schemas/ResponseReasoningSummaryTextDoneEvent"
      - $ref: "#/components/schemas/ResponseRefusalDeltaEvent"
      - $ref: "#/components/schemas/ResponseRefusalDoneEvent"
      - $ref: "#/components/schemas/ResponseTextDeltaEvent"
      - $ref: "#/components/schemas/ResponseTextDoneEvent"
      - $ref: "#/components/schemas/ResponseWebSearchCallCompletedEvent"
      - $ref: "#/components/schemas/ResponseWebSearchCallInProgressEvent"
      - $ref: "#/components/schemas/ResponseWebSearchCallSearchingEvent"
      - $ref: "#/components/schemas/ResponseImageGenCallCompletedEvent"
      - $ref: "#/components/schemas/ResponseImageGenCallGeneratingEvent"
      - $ref: "#/components/schemas/ResponseImageGenCallInProgressEvent"
      - $ref: "#/components/schemas/ResponseImageGenCallPartialImageEvent"
      - $ref: "#/components/schemas/ResponseMCPCallArgumentsDeltaEvent"
      - $ref: "#/components/schemas/ResponseMCPCallArgumentsDoneEvent"
      - $ref: "#/components/schemas/ResponseMCPCallCompletedEvent"
      - $ref: "#/components/schemas/ResponseMCPCallFailedEvent"
      - $ref: "#/components/schemas/ResponseMCPCallInProgressEvent"
      - $ref: "#/components/schemas/ResponseMCPListToolsCompletedEvent"
      - $ref: "#/components/schemas/ResponseMCPListToolsFailedEvent"
      - $ref: "#/components/schemas/ResponseMCPListToolsInProgressEvent"
      - $ref: "#/components/schemas/ResponseOutputTextAnnotationAddedEvent"
      - $ref: "#/components/schemas/ResponseQueuedEvent"
      - $ref: "#/components/schemas/ResponseReasoningDeltaEvent"
      - $ref: "#/components/schemas/ResponseReasoningDoneEvent"
      - $ref: "#/components/schemas/ResponseReasoningSummaryDeltaEvent"
      - $ref: "#/components/schemas/ResponseReasoningSummaryDoneEvent"
      discriminator:
        propertyName: type
    ResponseTextDeltaEvent:
      description: Emitted when there is an additional text delta.
      properties:
        type:
          description: |
            The type of the event. Always `response.output_text.delta`.
          enum:
          - response.output_text.delta
          type: string
          x-stainless-const: true
        item_id:
          description: |
            The ID of the output item that the text delta was added to.
          type: string
        output_index:
          description: |
            The index of the output item that the text delta was added to.
          type: integer
        content_index:
          description: |
            The index of the content part that the text delta was added to.
          type: integer
        delta:
          description: |
            The text delta that was added.
          type: string
        sequence_number:
          description: The sequence number for this event.
          type: integer
      required:
      - content_index
      - delta
      - item_id
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.output_text.delta
        group: responses
        example: |
          {
            "type": "response.output_text.delta",
            "item_id": "msg_123",
            "output_index": 0,
            "content_index": 0,
            "delta": "In",
            "sequence_number": 1
          }
    ResponseTextDoneEvent:
      description: Emitted when text content is finalized.
      properties:
        type:
          description: |
            The type of the event. Always `response.output_text.done`.
          enum:
          - response.output_text.done
          type: string
          x-stainless-const: true
        item_id:
          description: |
            The ID of the output item that the text content is finalized.
          type: string
        output_index:
          description: |
            The index of the output item that the text content is finalized.
          type: integer
        content_index:
          description: |
            The index of the content part that the text content is finalized.
          type: integer
        text:
          description: |
            The text content that is finalized.
          type: string
        sequence_number:
          description: The sequence number for this event.
          type: integer
      required:
      - content_index
      - item_id
      - output_index
      - sequence_number
      - text
      - type
      x-oaiMeta:
        name: response.output_text.done
        group: responses
        example: |
          {
            "type": "response.output_text.done",
            "item_id": "msg_123",
            "output_index": 0,
            "content_index": 0,
            "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
            "sequence_number": 1
          }
    ResponseUsage:
      description: |
        Represents token usage details including input tokens, output tokens,
        a breakdown of output tokens, and the total tokens used.
      properties:
        input_tokens:
          description: The number of input tokens.
          type: integer
        input_tokens_details:
          $ref: "#/components/schemas/ResponseUsage_input_tokens_details"
        output_tokens:
          description: The number of output tokens.
          type: integer
        output_tokens_details:
          $ref: "#/components/schemas/ResponseUsage_output_tokens_details"
        total_tokens:
          description: The total number of tokens used.
          type: integer
      required:
      - input_tokens
      - input_tokens_details
      - output_tokens
      - output_tokens_details
      - total_tokens
    ResponseWebSearchCallCompletedEvent:
      description: Emitted when a web search call is completed.
      properties:
        type:
          description: |
            The type of the event. Always `response.web_search_call.completed`.
          enum:
          - response.web_search_call.completed
          type: string
          x-stainless-const: true
        output_index:
          description: |
            The index of the output item that the web search call is associated with.
          type: integer
        item_id:
          description: |
            Unique ID for the output item associated with the web search call.
          type: string
        sequence_number:
          description: The sequence number of the web search call being processed.
          type: integer
      required:
      - item_id
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.web_search_call.completed
        group: responses
        example: |
          {
            "type": "response.web_search_call.completed",
            "output_index": 0,
            "item_id": "ws_123",
            "sequence_number": 0
          }
    ResponseWebSearchCallInProgressEvent:
      description: Emitted when a web search call is initiated.
      properties:
        type:
          description: |
            The type of the event. Always `response.web_search_call.in_progress`.
          enum:
          - response.web_search_call.in_progress
          type: string
          x-stainless-const: true
        output_index:
          description: |
            The index of the output item that the web search call is associated with.
          type: integer
        item_id:
          description: |
            Unique ID for the output item associated with the web search call.
          type: string
        sequence_number:
          description: The sequence number of the web search call being processed.
          type: integer
      required:
      - item_id
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.web_search_call.in_progress
        group: responses
        example: |
          {
            "type": "response.web_search_call.in_progress",
            "output_index": 0,
            "item_id": "ws_123",
            "sequence_number": 0
          }
    ResponseWebSearchCallSearchingEvent:
      description: Emitted when a web search call is executing.
      properties:
        type:
          description: |
            The type of the event. Always `response.web_search_call.searching`.
          enum:
          - response.web_search_call.searching
          type: string
          x-stainless-const: true
        output_index:
          description: |
            The index of the output item that the web search call is associated with.
          type: integer
        item_id:
          description: |
            Unique ID for the output item associated with the web search call.
          type: string
        sequence_number:
          description: The sequence number of the web search call being processed.
          type: integer
      required:
      - item_id
      - output_index
      - sequence_number
      - type
      x-oaiMeta:
        name: response.web_search_call.searching
        group: responses
        example: |
          {
            "type": "response.web_search_call.searching",
            "output_index": 0,
            "item_id": "ws_123",
            "sequence_number": 0
          }
    RunCompletionUsage:
      description: "Usage statistics related to the run. This value will be `null`\
        \ if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.)."
      example:
        completion_tokens: 7
        prompt_tokens: 9
        total_tokens: 3
      properties:
        completion_tokens:
          description: Number of completion tokens used over the course of the run.
          type: integer
        prompt_tokens:
          description: Number of prompt tokens used over the course of the run.
          type: integer
        total_tokens:
          description: Total number of tokens used (prompt + completion).
          type: integer
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      nullable: true
    RunGraderRequest:
      example:
        item: "{}"
        model_sample: model_sample
        grader:
          reference: reference
          input: input
          name: name
          type: string_check
          operation: eq
      properties:
        grader:
          $ref: "#/components/schemas/FineTuneReinforcementMethod_grader"
        item:
          description: "The dataset item provided to the grader. This will be used\
            \ to populate \nthe `item` namespace. See [the guide](/docs/guides/graders)\
            \ for more details. \n"
          type: object
        model_sample:
          description: "The model sample to be evaluated. This value will be used\
            \ to populate \nthe `sample` namespace. See [the guide](/docs/guides/graders)\
            \ for more details.\nThe `output_json` variable will be populated if the\
            \ model sample is a \nvalid JSON string.\n \n"
          type: string
      required:
      - grader
      - model_sample
      title: RunGraderRequest
    RunGraderResponse:
      example:
        reward: 0.8008281904610115
        metadata:
          token_usage: 1
          scores:
            key: ""
          name: name
          type: type
          sampled_model_name: sampled_model_name
          errors:
            sample_parse_error: true
            python_grader_runtime_error_details: python_grader_runtime_error_details
            unresponsive_reward_error: true
            model_grader_refusal_error: true
            truncated_observation_error: true
            other_error: true
            formula_parse_error: true
            python_grader_server_error_type: python_grader_server_error_type
            python_grader_server_error: true
            model_grader_server_error: true
            invalid_variable_error: true
            python_grader_runtime_error: true
            model_grader_server_error_details: model_grader_server_error_details
            model_grader_parse_error: true
          execution_time: 6.027456183070403
        model_grader_token_usage_per_model:
          key: ""
        sub_rewards:
          key: ""
      properties:
        reward:
          type: number
        metadata:
          $ref: "#/components/schemas/RunGraderResponse_metadata"
        sub_rewards:
          additionalProperties: true
          type: object
        model_grader_token_usage_per_model:
          additionalProperties: true
          type: object
      required:
      - metadata
      - model_grader_token_usage_per_model
      - reward
      - sub_rewards
    RunObject:
      description: "Represents an execution run on a [thread](/docs/api-reference/threads)."
      example:
        cancelled_at: 5
        instructions: instructions
        metadata:
          key: metadata
        assistant_id: assistant_id
        required_action:
          submit_tool_outputs:
            tool_calls:
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
          type: submit_tool_outputs
        usage:
          completion_tokens: 7
          prompt_tokens: 9
          total_tokens: 3
        created_at: 0
        tools:
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        top_p: 4.145608029883936
        max_completion_tokens: 256
        thread_id: thread_id
        expires_at: 6
        response_format: auto
        temperature: 2.027123023002322
        tool_choice: ""
        model: model
        id: id
        last_error:
          code: server_error
          message: message
        incomplete_details:
          reason: max_completion_tokens
        truncation_strategy: ""
        completed_at: 2
        parallel_tool_calls: true
        started_at: 1
        failed_at: 5
        max_prompt_tokens: 256
        object: thread.run
        status: queued
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread.run`."
          enum:
          - thread.run
          type: string
          x-stainless-const: true
        created_at:
          description: The Unix timestamp (in seconds) for when the run was created.
          type: integer
        thread_id:
          description: "The ID of the [thread](/docs/api-reference/threads) that was\
            \ executed on as a part of this run."
          type: string
        assistant_id:
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ used for execution of this run."
          type: string
        status:
          description: "The status of the run, which can be either `queued`, `in_progress`,\
            \ `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\
            \ `incomplete`, or `expired`."
          enum:
          - queued
          - in_progress
          - requires_action
          - cancelling
          - cancelled
          - failed
          - completed
          - incomplete
          - expired
          type: string
        required_action:
          $ref: "#/components/schemas/RunObject_required_action"
        last_error:
          $ref: "#/components/schemas/RunObject_last_error"
        expires_at:
          description: The Unix timestamp (in seconds) for when the run will expire.
          type: integer
          nullable: true
        started_at:
          description: The Unix timestamp (in seconds) for when the run was started.
          type: integer
          nullable: true
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the run was cancelled.
          type: integer
          nullable: true
        failed_at:
          description: The Unix timestamp (in seconds) for when the run failed.
          type: integer
          nullable: true
        completed_at:
          description: The Unix timestamp (in seconds) for when the run was completed.
          type: integer
          nullable: true
        incomplete_details:
          $ref: "#/components/schemas/RunObject_incomplete_details"
        model:
          description: "The model that the [assistant](/docs/api-reference/assistants)\
            \ used for this run."
          type: string
        instructions:
          description: "The instructions that the [assistant](/docs/api-reference/assistants)\
            \ used for this run."
          type: string
        tools:
          default: []
          description: "The list of tools that the [assistant](/docs/api-reference/assistants)\
            \ used for this run."
          items:
            $ref: "#/components/schemas/AssistantObject_tools_inner"
          maxItems: 20
          type: array
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        usage:
          $ref: "#/components/schemas/RunCompletionUsage"
        temperature:
          description: "The sampling temperature used for this run. If not set, defaults\
            \ to 1."
          type: number
          nullable: true
        top_p:
          description: "The nucleus sampling value used for this run. If not set,\
            \ defaults to 1."
          type: number
          nullable: true
        max_prompt_tokens:
          description: |
            The maximum number of prompt tokens specified to have been used over the course of the run.
          minimum: 256
          type: integer
          nullable: true
        max_completion_tokens:
          description: |
            The maximum number of completion tokens specified to have been used over the course of the run.
          minimum: 256
          type: integer
          nullable: true
        truncation_strategy:
          allOf:
          - $ref: "#/components/schemas/TruncationObject"
          nullable: true
        tool_choice:
          allOf:
          - $ref: "#/components/schemas/AssistantsApiToolChoiceOption"
          nullable: true
        parallel_tool_calls:
          default: true
          description: "Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling)\
            \ during tool use."
          type: boolean
        response_format:
          $ref: "#/components/schemas/AssistantsApiResponseFormatOption"
      required:
      - assistant_id
      - cancelled_at
      - completed_at
      - created_at
      - expires_at
      - failed_at
      - id
      - incomplete_details
      - instructions
      - last_error
      - max_completion_tokens
      - max_prompt_tokens
      - metadata
      - model
      - object
      - parallel_tool_calls
      - required_action
      - response_format
      - started_at
      - status
      - thread_id
      - tool_choice
      - tools
      - truncation_strategy
      - usage
      title: A run on a thread
      x-oaiMeta:
        name: The run object
        beta: true
        example: |
          {
            "id": "run_abc123",
            "object": "thread.run",
            "created_at": 1698107661,
            "assistant_id": "asst_abc123",
            "thread_id": "thread_abc123",
            "status": "completed",
            "started_at": 1699073476,
            "expires_at": null,
            "cancelled_at": null,
            "failed_at": null,
            "completed_at": 1699073498,
            "last_error": null,
            "model": "gpt-4o",
            "instructions": null,
            "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
            "metadata": {},
            "incomplete_details": null,
            "usage": {
              "prompt_tokens": 123,
              "completion_tokens": 456,
              "total_tokens": 579
            },
            "temperature": 1.0,
            "top_p": 1.0,
            "max_prompt_tokens": 1000,
            "max_completion_tokens": 1000,
            "truncation_strategy": {
              "type": "auto",
              "last_messages": null
            },
            "response_format": "auto",
            "tool_choice": "auto",
            "parallel_tool_calls": true
          }
    RunStepCompletionUsage:
      description: Usage statistics related to the run step. This value will be `null`
        while the run step's status is `in_progress`.
      example:
        completion_tokens: 2
        prompt_tokens: 7
        total_tokens: 9
      properties:
        completion_tokens:
          description: Number of completion tokens used over the course of the run
            step.
          type: integer
        prompt_tokens:
          description: Number of prompt tokens used over the course of the run step.
          type: integer
        total_tokens:
          description: Total number of tokens used (prompt + completion).
          type: integer
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      nullable: true
    RunStepDeltaObject:
      description: |
        Represents a run step delta i.e. any changed fields on a run step during streaming.
      properties:
        id:
          description: "The identifier of the run step, which can be referenced in\
            \ API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread.run.step.delta`."
          enum:
          - thread.run.step.delta
          type: string
          x-stainless-const: true
        delta:
          $ref: "#/components/schemas/RunStepDeltaObject_delta"
      required:
      - delta
      - id
      - object
      title: Run step delta object
      x-oaiMeta:
        name: The run step delta object
        beta: true
        example: |
          {
            "id": "step_123",
            "object": "thread.run.step.delta",
            "delta": {
              "step_details": {
                "type": "tool_calls",
                "tool_calls": [
                  {
                    "index": 0,
                    "id": "call_123",
                    "type": "code_interpreter",
                    "code_interpreter": { "input": "", "outputs": [] }
                  }
                ]
              }
            }
          }
    RunStepDeltaStepDetailsMessageCreationObject:
      description: Details of the message creation by the run step.
      properties:
        type:
          description: Always `message_creation`.
          enum:
          - message_creation
          type: string
          x-stainless-const: true
        message_creation:
          $ref: "#/components/schemas/RunStepDeltaStepDetailsMessageCreationObject_message_creation"
      required:
      - type
      title: Message creation
    RunStepDeltaStepDetailsToolCallsCodeObject:
      description: Details of the Code Interpreter tool call the run step was involved
        in.
      properties:
        index:
          description: The index of the tool call in the tool calls array.
          type: integer
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: The type of tool call. This is always going to be `code_interpreter`
            for this type of tool call.
          enum:
          - code_interpreter
          type: string
          x-stainless-const: true
        code_interpreter:
          $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObject_code_interpreter"
      required:
      - index
      - type
      title: Code interpreter tool call
    RunStepDeltaStepDetailsToolCallsCodeOutputImageObject:
      properties:
        index:
          description: The index of the output in the outputs array.
          type: integer
        type:
          description: Always `image`.
          enum:
          - image
          type: string
          x-stainless-const: true
        image:
          $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputImageObject_image"
      required:
      - index
      - type
      title: Code interpreter image output
    RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject:
      description: Text output from the Code Interpreter tool call as part of a run
        step.
      properties:
        index:
          description: The index of the output in the outputs array.
          type: integer
        type:
          description: Always `logs`.
          enum:
          - logs
          type: string
          x-stainless-const: true
        logs:
          description: The text output from the Code Interpreter tool call.
          type: string
      required:
      - index
      - type
      title: Code interpreter log output
    RunStepDeltaStepDetailsToolCallsFileSearchObject:
      properties:
        index:
          description: The index of the tool call in the tool calls array.
          type: integer
        id:
          description: The ID of the tool call object.
          type: string
        type:
          description: The type of tool call. This is always going to be `file_search`
            for this type of tool call.
          enum:
          - file_search
          type: string
          x-stainless-const: true
        file_search:
          description: "For now, this is always going to be an empty object."
          type: object
          x-oaiTypeLabel: map
      required:
      - file_search
      - index
      - type
      title: File search tool call
    RunStepDeltaStepDetailsToolCallsFunctionObject:
      properties:
        index:
          description: The index of the tool call in the tool calls array.
          type: integer
        id:
          description: The ID of the tool call object.
          type: string
        type:
          description: The type of tool call. This is always going to be `function`
            for this type of tool call.
          enum:
          - function
          type: string
          x-stainless-const: true
        function:
          $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsFunctionObject_function"
      required:
      - index
      - type
      title: Function tool call
    RunStepDeltaStepDetailsToolCallsObject:
      description: Details of the tool call.
      properties:
        type:
          description: Always `tool_calls`.
          enum:
          - tool_calls
          type: string
          x-stainless-const: true
        tool_calls:
          description: |
            An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsObject_tool_calls_inner"
          type: array
      required:
      - type
      title: Tool calls
    RunStepDetailsMessageCreationObject:
      description: Details of the message creation by the run step.
      example:
        message_creation:
          message_id: message_id
        type: message_creation
      properties:
        type:
          description: Always `message_creation`.
          enum:
          - message_creation
          type: string
          x-stainless-const: true
        message_creation:
          $ref: "#/components/schemas/RunStepDetailsMessageCreationObject_message_creation"
      required:
      - message_creation
      - type
      title: Message creation
    RunStepDetailsToolCallsCodeObject:
      description: Details of the Code Interpreter tool call the run step was involved
        in.
      properties:
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: The type of tool call. This is always going to be `code_interpreter`
            for this type of tool call.
          enum:
          - code_interpreter
          type: string
          x-stainless-const: true
        code_interpreter:
          $ref: "#/components/schemas/RunStepDetailsToolCallsCodeObject_code_interpreter"
      required:
      - code_interpreter
      - id
      - type
      title: Code Interpreter tool call
    RunStepDetailsToolCallsCodeOutputImageObject:
      properties:
        type:
          description: Always `image`.
          enum:
          - image
          type: string
          x-stainless-const: true
        image:
          $ref: "#/components/schemas/RunStepDetailsToolCallsCodeOutputImageObject_image"
      required:
      - image
      - type
      title: Code Interpreter image output
    RunStepDetailsToolCallsCodeOutputLogsObject:
      description: Text output from the Code Interpreter tool call as part of a run
        step.
      properties:
        type:
          description: Always `logs`.
          enum:
          - logs
          type: string
          x-stainless-const: true
        logs:
          description: The text output from the Code Interpreter tool call.
          type: string
      required:
      - logs
      - type
      title: Code Interpreter log output
    RunStepDetailsToolCallsFileSearchObject:
      properties:
        id:
          description: The ID of the tool call object.
          type: string
        type:
          description: The type of tool call. This is always going to be `file_search`
            for this type of tool call.
          enum:
          - file_search
          type: string
          x-stainless-const: true
        file_search:
          $ref: "#/components/schemas/RunStepDetailsToolCallsFileSearchObject_file_search"
      required:
      - file_search
      - id
      - type
      title: File search tool call
    RunStepDetailsToolCallsFileSearchRankingOptionsObject:
      description: The ranking options for the file search.
      properties:
        ranker:
          $ref: "#/components/schemas/FileSearchRanker"
        score_threshold:
          description: The score threshold for the file search. All values must be
            a floating point number between 0 and 1.
          maximum: 1
          minimum: 0
          type: number
      required:
      - ranker
      - score_threshold
      title: File search tool call ranking options
    RunStepDetailsToolCallsFileSearchResultObject:
      description: A result instance of the file search.
      properties:
        file_id:
          description: The ID of the file that result was found in.
          type: string
        file_name:
          description: The name of the file that result was found in.
          type: string
        score:
          description: The score of the result. All values must be a floating point
            number between 0 and 1.
          maximum: 1
          minimum: 0
          type: number
        content:
          description: The content of the result that was found. The content is only
            included if requested via the include query parameter.
          items:
            $ref: "#/components/schemas/RunStepDetailsToolCallsFileSearchResultObject_content_inner"
          type: array
      required:
      - file_id
      - file_name
      - score
      title: File search tool call result
      x-oaiTypeLabel: map
    RunStepDetailsToolCallsFunctionObject:
      properties:
        id:
          description: The ID of the tool call object.
          type: string
        type:
          description: The type of tool call. This is always going to be `function`
            for this type of tool call.
          enum:
          - function
          type: string
          x-stainless-const: true
        function:
          $ref: "#/components/schemas/RunStepDetailsToolCallsFunctionObject_function"
      required:
      - function
      - id
      - type
      title: Function tool call
    RunStepDetailsToolCallsObject:
      description: Details of the tool call.
      properties:
        type:
          description: Always `tool_calls`.
          enum:
          - tool_calls
          type: string
          x-stainless-const: true
        tool_calls:
          description: |
            An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: "#/components/schemas/RunStepDetailsToolCallsObject_tool_calls_inner"
          type: array
      required:
      - tool_calls
      - type
      title: Tool calls
    RunStepObject:
      description: |
        Represents a step in execution of a run.
      example:
        cancelled_at: 1
        metadata:
          key: metadata
        assistant_id: assistant_id
        run_id: run_id
        usage:
          completion_tokens: 2
          prompt_tokens: 7
          total_tokens: 9
        created_at: 0
        expired_at: 6
        type: message_creation
        step_details:
          message_creation:
            message_id: message_id
          type: message_creation
        completed_at: 5
        thread_id: thread_id
        id: id
        last_error:
          code: server_error
          message: message
        failed_at: 5
        object: thread.run.step
        status: in_progress
      properties:
        id:
          description: "The identifier of the run step, which can be referenced in\
            \ API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread.run.step`."
          enum:
          - thread.run.step
          type: string
          x-stainless-const: true
        created_at:
          description: The Unix timestamp (in seconds) for when the run step was created.
          type: integer
        assistant_id:
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ associated with the run step."
          type: string
        thread_id:
          description: "The ID of the [thread](/docs/api-reference/threads) that was\
            \ run."
          type: string
        run_id:
          description: "The ID of the [run](/docs/api-reference/runs) that this run\
            \ step is a part of."
          type: string
        type:
          description: "The type of run step, which can be either `message_creation`\
            \ or `tool_calls`."
          enum:
          - message_creation
          - tool_calls
          type: string
        status:
          description: "The status of the run step, which can be either `in_progress`,\
            \ `cancelled`, `failed`, `completed`, or `expired`."
          enum:
          - in_progress
          - cancelled
          - failed
          - completed
          - expired
          type: string
        step_details:
          $ref: "#/components/schemas/RunStepObject_step_details"
        last_error:
          $ref: "#/components/schemas/RunStepObject_last_error"
        expired_at:
          description: The Unix timestamp (in seconds) for when the run step expired.
            A step is considered expired if the parent run is expired.
          type: integer
          nullable: true
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the run step was cancelled.
          type: integer
          nullable: true
        failed_at:
          description: The Unix timestamp (in seconds) for when the run step failed.
          type: integer
          nullable: true
        completed_at:
          description: The Unix timestamp (in seconds) for when the run step completed.
          type: integer
          nullable: true
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
        usage:
          $ref: "#/components/schemas/RunStepCompletionUsage"
      required:
      - assistant_id
      - cancelled_at
      - completed_at
      - created_at
      - expired_at
      - failed_at
      - id
      - last_error
      - metadata
      - object
      - run_id
      - status
      - step_details
      - thread_id
      - type
      - usage
      title: Run steps
      x-oaiMeta:
        name: The run step object
        beta: true
        example: |
          {
            "id": "step_abc123",
            "object": "thread.run.step",
            "created_at": 1699063291,
            "run_id": "run_abc123",
            "assistant_id": "asst_abc123",
            "thread_id": "thread_abc123",
            "type": "message_creation",
            "status": "completed",
            "cancelled_at": null,
            "completed_at": 1699063291,
            "expired_at": null,
            "failed_at": null,
            "last_error": null,
            "step_details": {
              "type": "message_creation",
              "message_creation": {
                "message_id": "msg_abc123"
              }
            },
            "usage": {
              "prompt_tokens": 123,
              "completion_tokens": 456,
              "total_tokens": 579
            }
          }
    RunStepStreamEvent:
      oneOf:
      - $ref: "#/components/schemas/RunStepStreamEvent_oneOf"
      - $ref: "#/components/schemas/RunStepStreamEvent_oneOf_1"
      - $ref: "#/components/schemas/RunStepStreamEvent_oneOf_2"
      - $ref: "#/components/schemas/RunStepStreamEvent_oneOf_3"
      - $ref: "#/components/schemas/RunStepStreamEvent_oneOf_4"
      - $ref: "#/components/schemas/RunStepStreamEvent_oneOf_5"
      - $ref: "#/components/schemas/RunStepStreamEvent_oneOf_6"
    RunStreamEvent:
      oneOf:
      - $ref: "#/components/schemas/RunStreamEvent_oneOf"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_1"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_2"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_3"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_4"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_5"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_6"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_7"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_8"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_9"
    RunToolCallObject:
      description: Tool call objects
      example:
        function:
          name: name
          arguments: arguments
        id: id
        type: function
      properties:
        id:
          description: "The ID of the tool call. This ID must be referenced when you\
            \ submit the tool outputs in using the [Submit tool outputs to run](/docs/api-reference/runs/submitToolOutputs)\
            \ endpoint."
          type: string
        type:
          description: "The type of tool call the output is required for. For now,\
            \ this is always `function`."
          enum:
          - function
          type: string
          x-stainless-const: true
        function:
          $ref: "#/components/schemas/RunToolCallObject_function"
      required:
      - function
      - id
      - type
    Screenshot:
      description: |
        A screenshot action.
      properties:
        type:
          default: screenshot
          description: "Specifies the event type. For a screenshot action, this property\
            \ is \nalways set to `screenshot`.\n"
          enum:
          - screenshot
          type: string
          x-stainless-const: true
      required:
      - type
      title: Screenshot
    Scroll:
      description: |
        A scroll action.
      properties:
        type:
          default: scroll
          description: "Specifies the event type. For a scroll action, this property\
            \ is \nalways set to `scroll`.\n"
          enum:
          - scroll
          type: string
          x-stainless-const: true
        x:
          description: |
            The x-coordinate where the scroll occurred.
          type: integer
        "y":
          description: |
            The y-coordinate where the scroll occurred.
          type: integer
        scroll_x:
          description: |
            The horizontal scroll distance.
          type: integer
        scroll_y:
          description: |
            The vertical scroll distance.
          type: integer
      required:
      - scroll_x
      - scroll_y
      - type
      - x
      - "y"
      title: Scroll
    ServiceTier:
      default: auto
      description: |
        Specifies the processing type used for serving the request.
          - If set to 'auto', then the request will be processed with the service tier configured in the Project settings. Unless otherwise configured, the Project will use 'default'.
          - If set to 'default', then the requset will be processed with the standard pricing and performance for the selected model.
          - If set to '[flex](/docs/guides/flex-processing)' or 'priority', then the request will be processed with the corresponding service tier. [Contact sales](https://openai.com/contact-sales) to learn more about Priority processing.
          - When not set, the default behavior is 'auto'.

          When the `service_tier` parameter is set, the response body will include the `service_tier` value based on the processing mode actually used to serve the request. This response value may be different from the value set in the parameter.
      enum:
      - auto
      - default
      - flex
      - scale
      - priority
      type: string
      nullable: true
    SpeechAudioDeltaEvent:
      description: Emitted for each chunk of audio data generated during speech synthesis.
      properties:
        type:
          description: |
            The type of the event. Always `speech.audio.delta`.
          enum:
          - speech.audio.delta
          type: string
          x-stainless-const: true
        audio:
          description: |
            A chunk of Base64-encoded audio data.
          type: string
      required:
      - audio
      - type
      x-oaiMeta:
        name: Stream Event (speech.audio.delta)
        group: speech
        example: |
          {
            "type": "speech.audio.delta",
            "audio": "base64-encoded-audio-data"
          }
    SpeechAudioDoneEvent:
      description: Emitted when the speech synthesis is complete and all audio has
        been streamed.
      properties:
        type:
          description: |
            The type of the event. Always `speech.audio.done`.
          enum:
          - speech.audio.done
          type: string
          x-stainless-const: true
        usage:
          $ref: "#/components/schemas/SpeechAudioDoneEvent_usage"
      required:
      - type
      - usage
      x-oaiMeta:
        name: Stream Event (speech.audio.done)
        group: speech
        example: |
          {
            "type": "speech.audio.done",
            "usage": {
              "input_tokens": 14,
              "output_tokens": 101,
              "total_tokens": 115
            }
          }
    StaticChunkingStrategy:
      additionalProperties: true
      example:
        max_chunk_size_tokens: 685
        chunk_overlap_tokens: 5
      properties:
        max_chunk_size_tokens:
          description: The maximum number of tokens in each chunk. The default value
            is `800`. The minimum value is `100` and the maximum value is `4096`.
          maximum: 4096
          minimum: 100
          type: integer
        chunk_overlap_tokens:
          description: |
            The number of tokens that overlap between chunks. The default value is `400`.

            Note that the overlap must not exceed half of `max_chunk_size_tokens`.
          type: integer
      required:
      - chunk_overlap_tokens
      - max_chunk_size_tokens
    StaticChunkingStrategyRequestParam:
      additionalProperties: true
      description: Customize your own chunking strategy by setting chunk size and
        chunk overlap.
      properties:
        type:
          description: Always `static`.
          enum:
          - static
          type: string
          x-stainless-const: true
        static:
          $ref: "#/components/schemas/StaticChunkingStrategy"
      required:
      - static
      - type
      title: Static Chunking Strategy
    StaticChunkingStrategyResponseParam:
      additionalProperties: true
      example:
        static:
          max_chunk_size_tokens: 685
          chunk_overlap_tokens: 5
        type: static
      properties:
        type:
          description: Always `static`.
          enum:
          - static
          type: string
          x-stainless-const: true
        static:
          $ref: "#/components/schemas/StaticChunkingStrategy"
      required:
      - static
      - type
      title: Static Chunking Strategy
    StopConfiguration:
      description: |
        Not supported with latest reasoning models `o3` and `o4-mini`.

        Up to 4 sequences where the API will stop generating further tokens. The
        returned text will not contain the stop sequence.
      oneOf:
      - default: <|endoftext|>
        example: |2+

        type: string
        nullable: true
      - items:
          example: "[\"\\n\"]"
          type: string
        maxItems: 4
        minItems: 1
        type: array
      nullable: true
    SubmitToolOutputsRunRequest:
      additionalProperties: true
      example:
        stream: true
        tool_outputs:
        - output: output
          tool_call_id: tool_call_id
        - output: output
          tool_call_id: tool_call_id
      properties:
        tool_outputs:
          description: A list of tools for which the outputs are being submitted.
          items:
            $ref: "#/components/schemas/SubmitToolOutputsRunRequest_tool_outputs_inner"
          type: array
        stream:
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.
          type: boolean
          nullable: true
      required:
      - tool_outputs
    TextResponseFormatConfiguration:
      description: "An object specifying the format that the model must output.\n\n\
        Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, \n\
        which ensures the model will match your supplied JSON schema. Learn more in\
        \ the \n[Structured Outputs guide](/docs/guides/structured-outputs).\n\nThe\
        \ default format is `{ \"type\": \"text\" }` with no additional options.\n\
        \n**Not recommended for gpt-4o and newer models:**\n\nSetting to `{ \"type\"\
        : \"json_object\" }` enables the older JSON mode, which\nensures the message\
        \ the model generates is valid JSON. Using `json_schema`\nis preferred for\
        \ models that support it.\n"
      oneOf:
      - $ref: "#/components/schemas/ResponseFormatText"
      - $ref: "#/components/schemas/TextResponseFormatJsonSchema"
      - $ref: "#/components/schemas/ResponseFormatJsonObject"
    TextResponseFormatJsonSchema:
      description: |
        JSON Schema response format. Used to generate structured JSON responses.
        Learn more about [Structured Outputs](/docs/guides/structured-outputs).
      properties:
        type:
          description: The type of response format being defined. Always `json_schema`.
          enum:
          - json_schema
          type: string
          x-stainless-const: true
        description:
          description: |
            A description of what the response format is for, used by the model to
            determine how to respond in the format.
          type: string
        name:
          description: |
            The name of the response format. Must be a-z, A-Z, 0-9, or contain
            underscores and dashes, with a maximum length of 64.
          type: string
        schema:
          additionalProperties: true
          description: |
            The schema for the response format, described as a JSON Schema object.
            Learn how to build JSON schemas [here](https://json-schema.org/).
          title: JSON schema
          type: object
        strict:
          default: false
          description: |
            Whether to enable strict schema adherence when generating the output.
            If set to true, the model will always follow the exact schema defined
            in the `schema` field. Only a subset of JSON Schema is supported when
            `strict` is `true`. To learn more, read the [Structured Outputs
            guide](/docs/guides/structured-outputs).
          type: boolean
          nullable: true
      required:
      - name
      - schema
      - type
      title: JSON schema
    ThreadObject:
      description: "Represents a thread that contains [messages](/docs/api-reference/messages)."
      example:
        tool_resources:
          code_interpreter:
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
          file_search:
            vector_store_ids:
            - vector_store_ids
        metadata:
          key: metadata
        created_at: 0
        id: id
        object: thread
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread`."
          enum:
          - thread
          type: string
          x-stainless-const: true
        created_at:
          description: The Unix timestamp (in seconds) for when the thread was created.
          type: integer
        tool_resources:
          $ref: "#/components/schemas/ModifyThreadRequest_tool_resources"
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
      required:
      - created_at
      - id
      - metadata
      - object
      - tool_resources
      title: Thread
      x-oaiMeta:
        name: The thread object
        beta: true
        example: |
          {
            "id": "thread_abc123",
            "object": "thread",
            "created_at": 1698107661,
            "metadata": {}
          }
    ThreadStreamEvent:
      description: "Occurs when a new [thread](/docs/api-reference/threads/object)\
        \ is created."
      properties:
        enabled:
          description: Whether to enable input audio transcription.
          type: boolean
        event:
          enum:
          - thread.created
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/ThreadObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [thread](/docs/api-reference/threads/object)"
    ToggleCertificatesRequest:
      example:
        certificate_ids:
        - cert_abc
        - cert_abc
        - cert_abc
        - cert_abc
        - cert_abc
      properties:
        certificate_ids:
          items:
            example: cert_abc
            type: string
          maxItems: 10
          minItems: 1
          type: array
      required:
      - certificate_ids
    Tool:
      description: |
        A tool that can be used to generate a response.
      discriminator:
        propertyName: type
      oneOf:
      - $ref: "#/components/schemas/FunctionTool"
      - $ref: "#/components/schemas/FileSearchTool"
      - $ref: "#/components/schemas/WebSearchPreviewTool"
      - $ref: "#/components/schemas/ComputerUsePreviewTool"
      - $ref: "#/components/schemas/MCPTool"
      - $ref: "#/components/schemas/CodeInterpreterTool"
      - $ref: "#/components/schemas/ImageGenTool"
      - $ref: "#/components/schemas/LocalShellTool"
    ToolChoiceFunction:
      description: |
        Use this option to force the model to call a specific function.
      properties:
        type:
          description: "For function calling, the type is always `function`."
          enum:
          - function
          type: string
          x-stainless-const: true
        name:
          description: The name of the function to call.
          type: string
      required:
      - name
      - type
      title: Function tool
    ToolChoiceMCP:
      description: |
        Use this option to force the model to call a specific tool on a remote MCP server.
      properties:
        type:
          description: "For MCP tools, the type is always `mcp`."
          enum:
          - mcp
          type: string
          x-stainless-const: true
        server_label:
          description: |
            The label of the MCP server to use.
          type: string
        name:
          description: |
            The name of the tool to call on the server.
          type: string
          nullable: true
      required:
      - server_label
      - type
      title: MCP tool
    ToolChoiceOptions:
      description: |
        Controls which (if any) tool is called by the model.

        `none` means the model will not call any tool and instead generates a message.

        `auto` means the model can pick between generating a message or calling one or
        more tools.

        `required` means the model must call one or more tools.
      enum:
      - none
      - auto
      - required
      title: Tool choice mode
      type: string
    ToolChoiceTypes:
      description: |
        Indicates that the model should use a built-in tool to generate a response.
        [Learn more about built-in tools](/docs/guides/tools).
      properties:
        type:
          description: |
            The type of hosted tool the model should to use. Learn more about
            [built-in tools](/docs/guides/tools).

            Allowed values are:
            - `file_search`
            - `web_search_preview`
            - `computer_use_preview`
            - `code_interpreter`
            - `image_generation`
          enum:
          - file_search
          - web_search_preview
          - computer_use_preview
          - web_search_preview_2025_03_11
          - image_generation
          - code_interpreter
          type: string
      required:
      - type
      title: Hosted tool
    TranscriptTextDeltaEvent:
      description: "Emitted when there is an additional text delta. This is also the\
        \ first event emitted when the transcription starts. Only emitted when you\
        \ [create a transcription](/docs/api-reference/audio/create-transcription)\
        \ with the `Stream` parameter set to `true`."
      properties:
        type:
          description: |
            The type of the event. Always `transcript.text.delta`.
          enum:
          - transcript.text.delta
          type: string
          x-stainless-const: true
        delta:
          description: |
            The text delta that was additionally transcribed.
          type: string
        logprobs:
          description: |
            The log probabilities of the delta. Only included if you [create a transcription](/docs/api-reference/audio/create-transcription) with the `include[]` parameter set to `logprobs`.
          items:
            $ref: "#/components/schemas/TranscriptTextDeltaEvent_logprobs_inner"
          type: array
      required:
      - delta
      - type
      x-oaiMeta:
        name: Stream Event (transcript.text.delta)
        group: transcript
        example: |
          {
            "type": "transcript.text.delta",
            "delta": " wonderful"
          }
    TranscriptTextDoneEvent:
      description: "Emitted when the transcription is complete. Contains the complete\
        \ transcription text. Only emitted when you [create a transcription](/docs/api-reference/audio/create-transcription)\
        \ with the `Stream` parameter set to `true`."
      properties:
        type:
          description: |
            The type of the event. Always `transcript.text.done`.
          enum:
          - transcript.text.done
          type: string
          x-stainless-const: true
        text:
          description: |
            The text that was transcribed.
          type: string
        logprobs:
          description: |
            The log probabilities of the individual tokens in the transcription. Only included if you [create a transcription](/docs/api-reference/audio/create-transcription) with the `include[]` parameter set to `logprobs`.
          items:
            $ref: "#/components/schemas/TranscriptTextDeltaEvent_logprobs_inner"
          type: array
        usage:
          $ref: "#/components/schemas/TranscriptTextUsageTokens"
      required:
      - text
      - type
      x-oaiMeta:
        name: Stream Event (transcript.text.done)
        group: transcript
        example: |
          {
            "type": "transcript.text.done",
            "text": "I see skies of blue and clouds of white, the bright blessed days, the dark sacred nights, and I think to myself, what a wonderful world.",
            "usage": {
              "type": "tokens",
              "input_tokens": 14,
              "input_token_details": {
                "text_tokens": 10,
                "audio_tokens": 4
              },
              "output_tokens": 31,
              "total_tokens": 45
            }
          }
    TranscriptTextUsageDuration:
      description: Usage statistics for models billed by audio input duration.
      properties:
        type:
          description: The type of the usage object. Always `duration` for this variant.
          enum:
          - duration
          type: string
          x-stainless-const: true
        duration:
          description: Duration of the input audio in seconds.
          type: number
      required:
      - duration
      - type
      title: Duration Usage
    TranscriptTextUsageTokens:
      description: Usage statistics for models billed by token usage.
      example:
        total_tokens: 7
        input_token_details:
          audio_tokens: 5
          text_tokens: 5
        output_tokens: 2
        type: tokens
        input_tokens: 1
      properties:
        type:
          description: The type of the usage object. Always `tokens` for this variant.
          enum:
          - tokens
          type: string
          x-stainless-const: true
        input_tokens:
          description: Number of input tokens billed for this request.
          type: integer
        input_token_details:
          $ref: "#/components/schemas/TranscriptTextUsageTokens_input_token_details"
        output_tokens:
          description: Number of output tokens generated.
          type: integer
        total_tokens:
          description: Total number of tokens used (input + output).
          type: integer
      required:
      - input_tokens
      - output_tokens
      - total_tokens
      - type
      title: Token Usage
    TranscriptionChunkingStrategy:
      description: "Controls how the audio is cut into chunks. When set to `\"auto\"\
        `, the\nserver first normalizes loudness and then uses voice activity detection\
        \ (VAD) to\nchoose boundaries. `server_vad` object can be provided to tweak\
        \ VAD detection\nparameters manually. If unset, the audio is transcribed as\
        \ a single block. "
      oneOf:
      - default:
        - auto
        description: |
          Automatically set chunking parameters based on the audio. Must be set to `"auto"`.
        enum:
        - auto
        type: string
        x-stainless-const: true
      - $ref: "#/components/schemas/VadConfig"
    TranscriptionInclude:
      default: []
      enum:
      - logprobs
      type: string
    TranscriptionSegment:
      properties:
        id:
          description: Unique identifier of the segment.
          type: integer
        seek:
          description: Seek offset of the segment.
          type: integer
        start:
          description: Start time of the segment in seconds.
          format: float
          type: number
        end:
          description: End time of the segment in seconds.
          format: float
          type: number
        text:
          description: Text content of the segment.
          type: string
        tokens:
          description: Array of token IDs for the text content.
          items:
            type: integer
          type: array
        temperature:
          description: Temperature parameter used for generating the segment.
          format: float
          type: number
        avg_logprob:
          description: "Average logprob of the segment. If the value is lower than\
            \ -1, consider the logprobs failed."
          format: float
          type: number
        compression_ratio:
          description: "Compression ratio of the segment. If the value is greater\
            \ than 2.4, consider the compression failed."
          format: float
          type: number
        no_speech_prob:
          description: "Probability of no speech in the segment. If the value is higher\
            \ than 1.0 and the `avg_logprob` is below -1, consider this segment silent."
          format: float
          type: number
      required:
      - avg_logprob
      - compression_ratio
      - end
      - id
      - no_speech_prob
      - seek
      - start
      - temperature
      - text
      - tokens
    TranscriptionWord:
      properties:
        word:
          description: The text content of the word.
          type: string
        start:
          description: Start time of the word in seconds.
          format: float
          type: number
        end:
          description: End time of the word in seconds.
          format: float
          type: number
      required:
      - end
      - start
      - word
    TruncationObject:
      description: Controls for how a thread will be truncated prior to the run. Use
        this to control the intial context window of the run.
      properties:
        type:
          description: "The truncation strategy to use for the thread. The default\
            \ is `auto`. If set to `last_messages`, the thread will be truncated to\
            \ the n most recent messages in the thread. When set to `auto`, messages\
            \ in the middle of the thread will be dropped to fit the context length\
            \ of the model, `max_prompt_tokens`."
          enum:
          - auto
          - last_messages
          type: string
        last_messages:
          description: The number of most recent messages from the thread when constructing
            the context for the run.
          minimum: 1
          type: integer
          nullable: true
      required:
      - type
      title: Thread Truncation Controls
    Type:
      description: |
        An action to type in text.
      properties:
        type:
          default: type
          description: "Specifies the event type. For a type action, this property\
            \ is \nalways set to `type`.\n"
          enum:
          - type
          type: string
          x-stainless-const: true
        text:
          description: |
            The text to type.
          type: string
      required:
      - text
      - type
      title: Type
    UpdateVectorStoreFileAttributesRequest:
      additionalProperties: true
      example:
        attributes:
          key: VectorStoreFileAttributes_value
      properties:
        attributes:
          additionalProperties:
            $ref: "#/components/schemas/VectorStoreFileAttributes_value"
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be \nuseful for storing additional information about the object\
            \ in a structured \nformat, and querying for objects via API or the dashboard.\
            \ Keys are strings \nwith a maximum length of 64 characters. Values are\
            \ strings with a maximum \nlength of 512 characters, booleans, or numbers.\n"
          maxProperties: 16
          x-oaiTypeLabel: map
          nullable: true
      required:
      - attributes
      x-oaiMeta:
        name: Update vector store file attributes request
    UpdateVectorStoreRequest:
      additionalProperties: true
      example:
        metadata:
          key: metadata
        expires_after: ""
        name: name
      properties:
        name:
          description: The name of the vector store.
          type: string
          nullable: true
        expires_after:
          allOf:
          - $ref: "#/components/schemas/VectorStoreExpirationAfter"
          nullable: true
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
    Upload:
      description: |
        The Upload object can accept byte chunks in the form of Parts.
      example:
        filename: filename
        expires_at: 1
        file: ""
        purpose: purpose
        bytes: 6
        created_at: 0
        id: id
        status: pending
        object: upload
      properties:
        id:
          description: "The Upload unique identifier, which can be referenced in API\
            \ endpoints."
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the Upload was created.
          type: integer
        filename:
          description: The name of the file to be uploaded.
          type: string
        bytes:
          description: The intended number of bytes to be uploaded.
          type: integer
        purpose:
          description: "The intended purpose of the file. [Please refer here](/docs/api-reference/files/object#files/object-purpose)\
            \ for acceptable values."
          type: string
        status:
          description: The status of the Upload.
          enum:
          - pending
          - completed
          - cancelled
          - expired
          type: string
        expires_at:
          description: The Unix timestamp (in seconds) for when the Upload will expire.
          type: integer
        object:
          description: "The object type, which is always \"upload\"."
          enum:
          - upload
          type: string
          x-stainless-const: true
        file:
          allOf:
          - $ref: "#/components/schemas/OpenAIFile"
          description: The ready File object after the Upload is completed.
          nullable: true
      required:
      - bytes
      - created_at
      - expires_at
      - filename
      - id
      - purpose
      - status
      title: Upload
      x-oaiMeta:
        name: The upload object
        example: |
          {
            "id": "upload_abc123",
            "object": "upload",
            "bytes": 2147483648,
            "created_at": 1719184911,
            "filename": "training_examples.jsonl",
            "purpose": "fine-tune",
            "status": "completed",
            "expires_at": 1719127296,
            "file": {
              "id": "file-xyz321",
              "object": "file",
              "bytes": 2147483648,
              "created_at": 1719186911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
            }
          }
    UploadCertificateRequest:
      example:
        name: name
        content: content
      properties:
        name:
          description: An optional name for the certificate
          type: string
        content:
          description: The certificate content in PEM format
          type: string
      required:
      - content
    UploadPart:
      description: |
        The upload Part represents a chunk of bytes we can add to an Upload object.
      example:
        upload_id: upload_id
        created_at: 0
        id: id
        object: upload.part
      properties:
        id:
          description: "The upload Part unique identifier, which can be referenced\
            \ in API endpoints."
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the Part was created.
          type: integer
        upload_id:
          description: The ID of the Upload object that this Part was added to.
          type: string
        object:
          description: "The object type, which is always `upload.part`."
          enum:
          - upload.part
          type: string
          x-stainless-const: true
      required:
      - created_at
      - id
      - object
      - upload_id
      title: UploadPart
      x-oaiMeta:
        name: The upload part object
        example: |
          {
              "id": "part_def456",
              "object": "upload.part",
              "created_at": 1719186911,
              "upload_id": "upload_abc123"
          }
    UsageAudioSpeechesResult:
      description: The aggregated audio speeches usage details of the specific time
        bucket.
      properties:
        object:
          enum:
          - organization.usage.audio_speeches.result
          type: string
          x-stainless-const: true
        characters:
          description: The number of characters processed.
          type: integer
        num_model_requests:
          description: The count of requests made to the model.
          type: integer
        project_id:
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result."
          type: string
          nullable: true
        user_id:
          description: "When `group_by=user_id`, this field provides the user ID of\
            \ the grouped usage result."
          type: string
          nullable: true
        api_key_id:
          description: "When `group_by=api_key_id`, this field provides the API key\
            \ ID of the grouped usage result."
          type: string
          nullable: true
        model:
          description: "When `group_by=model`, this field provides the model name\
            \ of the grouped usage result."
          type: string
          nullable: true
      required:
      - characters
      - num_model_requests
      - object
      x-oaiMeta:
        name: Audio speeches usage object
        example: |
          {
              "object": "organization.usage.audio_speeches.result",
              "characters": 45,
              "num_model_requests": 1,
              "project_id": "proj_abc",
              "user_id": "user-abc",
              "api_key_id": "key_abc",
              "model": "tts-1"
          }
    UsageAudioTranscriptionsResult:
      description: The aggregated audio transcriptions usage details of the specific
        time bucket.
      properties:
        object:
          enum:
          - organization.usage.audio_transcriptions.result
          type: string
          x-stainless-const: true
        seconds:
          description: The number of seconds processed.
          type: integer
        num_model_requests:
          description: The count of requests made to the model.
          type: integer
        project_id:
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result."
          type: string
          nullable: true
        user_id:
          description: "When `group_by=user_id`, this field provides the user ID of\
            \ the grouped usage result."
          type: string
          nullable: true
        api_key_id:
          description: "When `group_by=api_key_id`, this field provides the API key\
            \ ID of the grouped usage result."
          type: string
          nullable: true
        model:
          description: "When `group_by=model`, this field provides the model name\
            \ of the grouped usage result."
          type: string
          nullable: true
      required:
      - num_model_requests
      - object
      - seconds
      x-oaiMeta:
        name: Audio transcriptions usage object
        example: |
          {
              "object": "organization.usage.audio_transcriptions.result",
              "seconds": 10,
              "num_model_requests": 1,
              "project_id": "proj_abc",
              "user_id": "user-abc",
              "api_key_id": "key_abc",
              "model": "tts-1"
          }
    UsageCodeInterpreterSessionsResult:
      description: The aggregated code interpreter sessions usage details of the specific
        time bucket.
      properties:
        object:
          enum:
          - organization.usage.code_interpreter_sessions.result
          type: string
          x-stainless-const: true
        num_sessions:
          description: The number of code interpreter sessions.
          type: integer
        project_id:
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result."
          type: string
          nullable: true
      required:
      - object
      x-oaiMeta:
        name: Code interpreter sessions usage object
        example: |
          {
              "object": "organization.usage.code_interpreter_sessions.result",
              "num_sessions": 1,
              "project_id": "proj_abc"
          }
    UsageCompletionsResult:
      description: The aggregated completions usage details of the specific time bucket.
      example:
        num_model_requests: 9
        project_id: project_id
        user_id: user_id
        output_audio_tokens: 7
        batch: true
        output_tokens: 5
        model: model
        input_cached_tokens: 5
        input_audio_tokens: 2
        input_tokens: 1
        api_key_id: api_key_id
        object: organization.usage.completions.result
      properties:
        object:
          enum:
          - organization.usage.completions.result
          type: string
          x-stainless-const: true
        input_tokens:
          description: "The aggregated number of text input tokens used, including\
            \ cached tokens. For customers subscribe to scale tier, this includes\
            \ scale tier tokens."
          type: integer
        input_cached_tokens:
          description: "The aggregated number of text input tokens that has been cached\
            \ from previous requests. For customers subscribe to scale tier, this\
            \ includes scale tier tokens."
          type: integer
        output_tokens:
          description: "The aggregated number of text output tokens used. For customers\
            \ subscribe to scale tier, this includes scale tier tokens."
          type: integer
        input_audio_tokens:
          description: "The aggregated number of audio input tokens used, including\
            \ cached tokens."
          type: integer
        output_audio_tokens:
          description: The aggregated number of audio output tokens used.
          type: integer
        num_model_requests:
          description: The count of requests made to the model.
          type: integer
        project_id:
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result."
          type: string
          nullable: true
        user_id:
          description: "When `group_by=user_id`, this field provides the user ID of\
            \ the grouped usage result."
          type: string
          nullable: true
        api_key_id:
          description: "When `group_by=api_key_id`, this field provides the API key\
            \ ID of the grouped usage result."
          type: string
          nullable: true
        model:
          description: "When `group_by=model`, this field provides the model name\
            \ of the grouped usage result."
          type: string
          nullable: true
        batch:
          description: "When `group_by=batch`, this field tells whether the grouped\
            \ usage result is batch or not."
          type: boolean
          nullable: true
      required:
      - input_tokens
      - num_model_requests
      - object
      - output_tokens
      x-oaiMeta:
        name: Completions usage object
        example: |
          {
              "object": "organization.usage.completions.result",
              "input_tokens": 5000,
              "output_tokens": 1000,
              "input_cached_tokens": 4000,
              "input_audio_tokens": 300,
              "output_audio_tokens": 200,
              "num_model_requests": 5,
              "project_id": "proj_abc",
              "user_id": "user-abc",
              "api_key_id": "key_abc",
              "model": "gpt-4o-mini-2024-07-18",
              "batch": false
          }
    UsageEmbeddingsResult:
      description: The aggregated embeddings usage details of the specific time bucket.
      properties:
        object:
          enum:
          - organization.usage.embeddings.result
          type: string
          x-stainless-const: true
        input_tokens:
          description: The aggregated number of input tokens used.
          type: integer
        num_model_requests:
          description: The count of requests made to the model.
          type: integer
        project_id:
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result."
          type: string
          nullable: true
        user_id:
          description: "When `group_by=user_id`, this field provides the user ID of\
            \ the grouped usage result."
          type: string
          nullable: true
        api_key_id:
          description: "When `group_by=api_key_id`, this field provides the API key\
            \ ID of the grouped usage result."
          type: string
          nullable: true
        model:
          description: "When `group_by=model`, this field provides the model name\
            \ of the grouped usage result."
          type: string
          nullable: true
      required:
      - input_tokens
      - num_model_requests
      - object
      x-oaiMeta:
        name: Embeddings usage object
        example: |
          {
              "object": "organization.usage.embeddings.result",
              "input_tokens": 20,
              "num_model_requests": 2,
              "project_id": "proj_abc",
              "user_id": "user-abc",
              "api_key_id": "key_abc",
              "model": "text-embedding-ada-002-v2"
          }
    UsageImagesResult:
      description: The aggregated images usage details of the specific time bucket.
      properties:
        object:
          enum:
          - organization.usage.images.result
          type: string
          x-stainless-const: true
        images:
          description: The number of images processed.
          type: integer
        num_model_requests:
          description: The count of requests made to the model.
          type: integer
        source:
          description: "When `group_by=source`, this field provides the source of\
            \ the grouped usage result, possible values are `image.generation`, `image.edit`,\
            \ `image.variation`."
          type: string
          nullable: true
        size:
          description: "When `group_by=size`, this field provides the image size of\
            \ the grouped usage result."
          type: string
          nullable: true
        project_id:
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result."
          type: string
          nullable: true
        user_id:
          description: "When `group_by=user_id`, this field provides the user ID of\
            \ the grouped usage result."
          type: string
          nullable: true
        api_key_id:
          description: "When `group_by=api_key_id`, this field provides the API key\
            \ ID of the grouped usage result."
          type: string
          nullable: true
        model:
          description: "When `group_by=model`, this field provides the model name\
            \ of the grouped usage result."
          type: string
          nullable: true
      required:
      - images
      - num_model_requests
      - object
      x-oaiMeta:
        name: Images usage object
        example: |
          {
              "object": "organization.usage.images.result",
              "images": 2,
              "num_model_requests": 2,
              "size": "1024x1024",
              "source": "image.generation",
              "project_id": "proj_abc",
              "user_id": "user-abc",
              "api_key_id": "key_abc",
              "model": "dall-e-3"
          }
    UsageModerationsResult:
      description: The aggregated moderations usage details of the specific time bucket.
      properties:
        object:
          enum:
          - organization.usage.moderations.result
          type: string
          x-stainless-const: true
        input_tokens:
          description: The aggregated number of input tokens used.
          type: integer
        num_model_requests:
          description: The count of requests made to the model.
          type: integer
        project_id:
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result."
          type: string
          nullable: true
        user_id:
          description: "When `group_by=user_id`, this field provides the user ID of\
            \ the grouped usage result."
          type: string
          nullable: true
        api_key_id:
          description: "When `group_by=api_key_id`, this field provides the API key\
            \ ID of the grouped usage result."
          type: string
          nullable: true
        model:
          description: "When `group_by=model`, this field provides the model name\
            \ of the grouped usage result."
          type: string
          nullable: true
      required:
      - input_tokens
      - num_model_requests
      - object
      x-oaiMeta:
        name: Moderations usage object
        example: |
          {
              "object": "organization.usage.moderations.result",
              "input_tokens": 20,
              "num_model_requests": 2,
              "project_id": "proj_abc",
              "user_id": "user-abc",
              "api_key_id": "key_abc",
              "model": "text-moderation"
          }
    UsageResponse:
      example:
        next_page: next_page
        data:
        - result:
          - num_model_requests: 9
            project_id: project_id
            user_id: user_id
            output_audio_tokens: 7
            batch: true
            output_tokens: 5
            model: model
            input_cached_tokens: 5
            input_audio_tokens: 2
            input_tokens: 1
            api_key_id: api_key_id
            object: organization.usage.completions.result
          - num_model_requests: 9
            project_id: project_id
            user_id: user_id
            output_audio_tokens: 7
            batch: true
            output_tokens: 5
            model: model
            input_cached_tokens: 5
            input_audio_tokens: 2
            input_tokens: 1
            api_key_id: api_key_id
            object: organization.usage.completions.result
          start_time: 0
          end_time: 6
          object: bucket
        - result:
          - num_model_requests: 9
            project_id: project_id
            user_id: user_id
            output_audio_tokens: 7
            batch: true
            output_tokens: 5
            model: model
            input_cached_tokens: 5
            input_audio_tokens: 2
            input_tokens: 1
            api_key_id: api_key_id
            object: organization.usage.completions.result
          - num_model_requests: 9
            project_id: project_id
            user_id: user_id
            output_audio_tokens: 7
            batch: true
            output_tokens: 5
            model: model
            input_cached_tokens: 5
            input_audio_tokens: 2
            input_tokens: 1
            api_key_id: api_key_id
            object: organization.usage.completions.result
          start_time: 0
          end_time: 6
          object: bucket
        has_more: true
        object: page
      properties:
        object:
          enum:
          - page
          type: string
          x-stainless-const: true
        data:
          items:
            $ref: "#/components/schemas/UsageTimeBucket"
          type: array
        has_more:
          type: boolean
        next_page:
          type: string
      required:
      - data
      - has_more
      - next_page
      - object
    UsageTimeBucket:
      example:
        result:
        - num_model_requests: 9
          project_id: project_id
          user_id: user_id
          output_audio_tokens: 7
          batch: true
          output_tokens: 5
          model: model
          input_cached_tokens: 5
          input_audio_tokens: 2
          input_tokens: 1
          api_key_id: api_key_id
          object: organization.usage.completions.result
        - num_model_requests: 9
          project_id: project_id
          user_id: user_id
          output_audio_tokens: 7
          batch: true
          output_tokens: 5
          model: model
          input_cached_tokens: 5
          input_audio_tokens: 2
          input_tokens: 1
          api_key_id: api_key_id
          object: organization.usage.completions.result
        start_time: 0
        end_time: 6
        object: bucket
      properties:
        object:
          enum:
          - bucket
          type: string
          x-stainless-const: true
        start_time:
          type: integer
        end_time:
          type: integer
        result:
          items:
            $ref: "#/components/schemas/UsageTimeBucket_result_inner"
          type: array
      required:
      - end_time
      - object
      - result
      - start_time
    UsageVectorStoresResult:
      description: The aggregated vector stores usage details of the specific time
        bucket.
      properties:
        object:
          enum:
          - organization.usage.vector_stores.result
          type: string
          x-stainless-const: true
        usage_bytes:
          description: The vector stores usage in bytes.
          type: integer
        project_id:
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result."
          type: string
          nullable: true
      required:
      - object
      - usage_bytes
      x-oaiMeta:
        name: Vector stores usage object
        example: |
          {
              "object": "organization.usage.vector_stores.result",
              "usage_bytes": 1024,
              "project_id": "proj_abc"
          }
    User:
      description: Represents an individual `user` within an organization.
      example:
        added_at: 0
        role: owner
        name: name
        id: id
        email: email
        object: organization.user
      properties:
        object:
          description: "The object type, which is always `organization.user`"
          enum:
          - organization.user
          type: string
          x-stainless-const: true
        id:
          description: "The identifier, which can be referenced in API endpoints"
          type: string
        name:
          description: The name of the user
          type: string
        email:
          description: The email address of the user
          type: string
        role:
          description: '`owner` or `reader`'
          enum:
          - owner
          - reader
          type: string
        added_at:
          description: The Unix timestamp (in seconds) of when the user was added.
          type: integer
      required:
      - added_at
      - email
      - id
      - name
      - object
      - role
      x-oaiMeta:
        name: The user object
        example: |
          {
              "object": "organization.user",
              "id": "user_abc",
              "name": "First Last",
              "email": "user@example.com",
              "role": "owner",
              "added_at": 1711471533
          }
    UserDeleteResponse:
      example:
        deleted: true
        id: id
        object: organization.user.deleted
      properties:
        object:
          enum:
          - organization.user.deleted
          type: string
          x-stainless-const: true
        id:
          type: string
        deleted:
          type: boolean
      required:
      - deleted
      - id
      - object
    UserListResponse:
      example:
        first_id: first_id
        data:
        - added_at: 0
          role: owner
          name: name
          id: id
          email: email
          object: organization.user
        - added_at: 0
          role: owner
          name: name
          id: id
          email: email
          object: organization.user
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          enum:
          - list
          type: string
          x-stainless-const: true
        data:
          items:
            $ref: "#/components/schemas/User"
          type: array
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    UserRoleUpdateRequest:
      example:
        role: owner
      properties:
        role:
          description: '`owner` or `reader`'
          enum:
          - owner
          - reader
          type: string
      required:
      - role
    VadConfig:
      additionalProperties: {}
      properties:
        type:
          description: Must be set to `server_vad` to enable manual chunking using
            server side VAD.
          enum:
          - server_vad
        prefix_padding_ms:
          default: 300
          description: "Amount of audio to include before the VAD detected speech\
            \ (in \nmilliseconds).\n"
        silence_duration_ms:
          default: 200
          description: "Duration of silence to detect speech stop (in milliseconds).\n\
            With shorter values the model will respond more quickly, \nbut may jump\
            \ in on short pauses from the user.\n"
        threshold:
          default: 0.5
          description: "Sensitivity threshold (0.0 to 1.0) for voice activity detection.\
            \ A \nhigher threshold will require louder audio to activate the model,\
            \ and \nthus might perform better in noisy environments.\n"
      required:
      - type
    ValidateGraderRequest:
      example:
        grader:
          reference: reference
          input: input
          name: name
          type: string_check
          operation: eq
      properties:
        grader:
          $ref: "#/components/schemas/FineTuneReinforcementMethod_grader"
      required:
      - grader
      title: ValidateGraderRequest
    ValidateGraderResponse:
      example:
        grader:
          reference: reference
          input: input
          name: name
          type: string_check
          operation: eq
      properties:
        grader:
          $ref: "#/components/schemas/FineTuneReinforcementMethod_grader"
      title: ValidateGraderResponse
    VectorStoreExpirationAfter:
      description: The expiration policy for a vector store.
      example:
        anchor: last_active_at
        days: 339
      properties:
        anchor:
          description: "Anchor timestamp after which the expiration policy applies.\
            \ Supported anchors: `last_active_at`."
          enum:
          - last_active_at
          type: string
          x-stainless-const: true
        days:
          description: The number of days after the anchor time that the vector store
            will expire.
          maximum: 365
          minimum: 1
          type: integer
      required:
      - anchor
      - days
      title: Vector store expiration policy
    VectorStoreFileAttributes:
      additionalProperties:
        $ref: "#/components/schemas/VectorStoreFileAttributes_value"
      description: "Set of 16 key-value pairs that can be attached to an object. This\
        \ can be \nuseful for storing additional information about the object in a\
        \ structured \nformat, and querying for objects via API or the dashboard.\
        \ Keys are strings \nwith a maximum length of 64 characters. Values are strings\
        \ with a maximum \nlength of 512 characters, booleans, or numbers.\n"
      maxProperties: 16
      x-oaiTypeLabel: map
      nullable: true
    VectorStoreFileBatchObject:
      description: A batch of files attached to a vector store.
      example:
        file_counts:
          in_progress: 6
          total: 2
          cancelled: 5
          completed: 1
          failed: 5
        created_at: 0
        id: id
        object: vector_store.files_batch
        vector_store_id: vector_store_id
        status: in_progress
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `vector_store.file_batch`."
          enum:
          - vector_store.files_batch
          type: string
          x-stainless-const: true
        created_at:
          description: The Unix timestamp (in seconds) for when the vector store files
            batch was created.
          type: integer
        vector_store_id:
          description: "The ID of the [vector store](/docs/api-reference/vector-stores/object)\
            \ that the [File](/docs/api-reference/files) is attached to."
          type: string
        status:
          description: "The status of the vector store files batch, which can be either\
            \ `in_progress`, `completed`, `cancelled` or `failed`."
          enum:
          - in_progress
          - completed
          - cancelled
          - failed
          type: string
        file_counts:
          $ref: "#/components/schemas/VectorStoreFileBatchObject_file_counts"
      required:
      - created_at
      - file_counts
      - id
      - object
      - status
      - vector_store_id
      title: Vector store file batch
      x-oaiMeta:
        name: The vector store files batch object
        beta: true
        example: |
          {
            "id": "vsfb_123",
            "object": "vector_store.files_batch",
            "created_at": 1698107661,
            "vector_store_id": "vs_abc123",
            "status": "completed",
            "file_counts": {
              "in_progress": 0,
              "completed": 100,
              "failed": 0,
              "cancelled": 0,
              "total": 100
            }
          }
    VectorStoreFileContentResponse:
      description: Represents the parsed content of a vector store file.
      example:
        next_page: next_page
        data:
        - text: text
          type: type
        - text: text
          type: type
        has_more: true
        object: vector_store.file_content.page
      properties:
        object:
          description: "The object type, which is always `vector_store.file_content.page`"
          enum:
          - vector_store.file_content.page
          type: string
          x-stainless-const: true
        data:
          description: Parsed content of the file.
          items:
            $ref: "#/components/schemas/VectorStoreFileContentResponse_data_inner"
          type: array
        has_more:
          description: Indicates if there are more content pages to fetch.
          type: boolean
        next_page:
          description: "The token for the next page, if any."
          type: string
          nullable: true
      required:
      - data
      - has_more
      - next_page
      - object
    VectorStoreFileObject:
      description: A list of files attached to a vector store.
      example:
        chunking_strategy:
          static:
            max_chunk_size_tokens: 685
            chunk_overlap_tokens: 5
          type: static
        usage_bytes: 0
        created_at: 6
        attributes:
          key: VectorStoreFileAttributes_value
        id: id
        last_error:
          code: server_error
          message: message
        object: vector_store.file
        vector_store_id: vector_store_id
        status: in_progress
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `vector_store.file`."
          enum:
          - vector_store.file
          type: string
          x-stainless-const: true
        usage_bytes:
          description: The total vector store usage in bytes. Note that this may be
            different from the original file size.
          type: integer
        created_at:
          description: The Unix timestamp (in seconds) for when the vector store file
            was created.
          type: integer
        vector_store_id:
          description: "The ID of the [vector store](/docs/api-reference/vector-stores/object)\
            \ that the [File](/docs/api-reference/files) is attached to."
          type: string
        status:
          description: "The status of the vector store file, which can be either `in_progress`,\
            \ `completed`, `cancelled`, or `failed`. The status `completed` indicates\
            \ that the vector store file is ready for use."
          enum:
          - in_progress
          - completed
          - cancelled
          - failed
          type: string
        last_error:
          $ref: "#/components/schemas/VectorStoreFileObject_last_error"
        chunking_strategy:
          $ref: "#/components/schemas/VectorStoreFileObject_chunking_strategy"
        attributes:
          additionalProperties:
            $ref: "#/components/schemas/VectorStoreFileAttributes_value"
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be \nuseful for storing additional information about the object\
            \ in a structured \nformat, and querying for objects via API or the dashboard.\
            \ Keys are strings \nwith a maximum length of 64 characters. Values are\
            \ strings with a maximum \nlength of 512 characters, booleans, or numbers.\n"
          maxProperties: 16
          x-oaiTypeLabel: map
          nullable: true
      required:
      - created_at
      - id
      - last_error
      - object
      - status
      - usage_bytes
      - vector_store_id
      title: Vector store files
      x-oaiMeta:
        name: The vector store file object
        beta: true
        example: |
          {
            "id": "file-abc123",
            "object": "vector_store.file",
            "usage_bytes": 1234,
            "created_at": 1698107661,
            "vector_store_id": "vs_abc123",
            "status": "completed",
            "last_error": null,
            "chunking_strategy": {
              "type": "static",
              "static": {
                "max_chunk_size_tokens": 800,
                "chunk_overlap_tokens": 400
              }
            }
          }
    VectorStoreObject:
      description: A vector store is a collection of processed files can be used by
        the `file_search` tool.
      example:
        file_counts:
          in_progress: 1
          total: 7
          cancelled: 2
          completed: 5
          failed: 5
        metadata:
          key: metadata
        expires_at: 3
        expires_after:
          anchor: last_active_at
          days: 339
        last_active_at: 2
        usage_bytes: 6
        name: name
        created_at: 0
        id: id
        object: vector_store
        status: expired
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `vector_store`."
          enum:
          - vector_store
          type: string
          x-stainless-const: true
        created_at:
          description: The Unix timestamp (in seconds) for when the vector store was
            created.
          type: integer
        name:
          description: The name of the vector store.
          type: string
        usage_bytes:
          description: The total number of bytes used by the files in the vector store.
          type: integer
        file_counts:
          $ref: "#/components/schemas/VectorStoreObject_file_counts"
        status:
          description: "The status of the vector store, which can be either `expired`,\
            \ `in_progress`, or `completed`. A status of `completed` indicates that\
            \ the vector store is ready for use."
          enum:
          - expired
          - in_progress
          - completed
          type: string
        expires_after:
          $ref: "#/components/schemas/VectorStoreExpirationAfter"
        expires_at:
          description: The Unix timestamp (in seconds) for when the vector store will
            expire.
          type: integer
          nullable: true
        last_active_at:
          description: The Unix timestamp (in seconds) for when the vector store was
            last active.
          type: integer
          nullable: true
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
      required:
      - created_at
      - file_counts
      - id
      - last_active_at
      - metadata
      - name
      - object
      - status
      - usage_bytes
      title: Vector store
      x-oaiMeta:
        name: The vector store object
        example: |
          {
            "id": "vs_123",
            "object": "vector_store",
            "created_at": 1698107661,
            "usage_bytes": 123456,
            "last_active_at": 1698107661,
            "name": "my_vector_store",
            "status": "completed",
            "file_counts": {
              "in_progress": 0,
              "completed": 100,
              "cancelled": 0,
              "failed": 0,
              "total": 100
            },
            "last_used_at": 1698107661
          }
    VectorStoreSearchRequest:
      additionalProperties: {}
      example:
        max_num_results: 4
        ranking_options:
          score_threshold: 0.6027456183070403
          ranker: auto
        query: VectorStoreSearchRequest_query
        rewrite_query: false
        filters:
          type: eq
          value: ComparisonFilter_value
          key: key
      properties:
        query:
          $ref: "#/components/schemas/VectorStoreSearchRequest_query"
        rewrite_query:
          default: false
          description: Whether to rewrite the natural language query for vector search.
        max_num_results:
          default: 10
          description: The maximum number of results to return. This number should
            be between 1 and 50 inclusive.
          maximum: 50
          minimum: 1
        filters:
          $ref: "#/components/schemas/VectorStoreSearchRequest_filters"
        ranking_options:
          $ref: "#/components/schemas/VectorStoreSearchRequest_ranking_options"
      required:
      - query
      x-oaiMeta:
        name: Vector store search request
    VectorStoreSearchResultContentObject:
      additionalProperties: true
      example:
        text: text
        type: text
      properties:
        type:
          description: The type of content.
          enum:
          - text
          type: string
        text:
          description: The text content returned from search.
          type: string
      required:
      - text
      - type
      x-oaiMeta:
        name: Vector store search result content object
    VectorStoreSearchResultItem:
      additionalProperties: true
      example:
        score: 0.08008281904610115
        filename: filename
        file_id: file_id
        attributes:
          key: VectorStoreFileAttributes_value
        content:
        - text: text
          type: text
        - text: text
          type: text
      properties:
        file_id:
          description: The ID of the vector store file.
          type: string
        filename:
          description: The name of the vector store file.
          type: string
        score:
          description: The similarity score for the result.
          maximum: 1
          minimum: 0
          type: number
        attributes:
          additionalProperties:
            $ref: "#/components/schemas/VectorStoreFileAttributes_value"
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be \nuseful for storing additional information about the object\
            \ in a structured \nformat, and querying for objects via API or the dashboard.\
            \ Keys are strings \nwith a maximum length of 64 characters. Values are\
            \ strings with a maximum \nlength of 512 characters, booleans, or numbers.\n"
          maxProperties: 16
          x-oaiTypeLabel: map
          nullable: true
        content:
          description: Content chunks from the file.
          items:
            $ref: "#/components/schemas/VectorStoreSearchResultContentObject"
          type: array
      required:
      - attributes
      - content
      - file_id
      - filename
      - score
      x-oaiMeta:
        name: Vector store search result item
    VectorStoreSearchResultsPage:
      additionalProperties: true
      example:
        next_page: next_page
        data:
        - score: 0.08008281904610115
          filename: filename
          file_id: file_id
          attributes:
            key: VectorStoreFileAttributes_value
          content:
          - text: text
            type: text
          - text: text
            type: text
        - score: 0.08008281904610115
          filename: filename
          file_id: file_id
          attributes:
            key: VectorStoreFileAttributes_value
          content:
          - text: text
            type: text
          - text: text
            type: text
        has_more: true
        search_query:
        - search_query
        - search_query
        object: vector_store.search_results.page
      properties:
        object:
          description: "The object type, which is always `vector_store.search_results.page`"
          enum:
          - vector_store.search_results.page
          type: string
          x-stainless-const: true
        search_query:
          items:
            description: The query used for this search.
            minItems: 1
            type: string
          type: array
        data:
          description: The list of search result items.
          items:
            $ref: "#/components/schemas/VectorStoreSearchResultItem"
          type: array
        has_more:
          description: Indicates if there are more results to fetch.
          type: boolean
        next_page:
          description: "The token for the next page, if any."
          type: string
          nullable: true
      required:
      - data
      - has_more
      - next_page
      - object
      - search_query
      x-oaiMeta:
        name: Vector store search results page
    VoiceIdsShared:
      anyOf:
      - type: string
      - enum:
        - alloy
        - ash
        - ballad
        - coral
        - echo
        - fable
        - onyx
        - nova
        - sage
        - shimmer
        - verse
        type: string
      example: ash
    Wait:
      description: |
        A wait action.
      properties:
        type:
          default: wait
          description: "Specifies the event type. For a wait action, this property\
            \ is \nalways set to `wait`.\n"
          enum:
          - wait
          type: string
          x-stainless-const: true
      required:
      - type
      title: Wait
    WebSearchActionFind:
      description: |
        Action type "find": Searches for a pattern within a loaded page.
      properties:
        type:
          description: |
            The action type.
          enum:
          - find
          type: string
          x-stainless-const: true
        url:
          description: |
            The URL of the page searched for the pattern.
          format: uri
          type: string
        pattern:
          description: |
            The pattern or text to search for within the page.
          type: string
      required:
      - pattern
      - type
      - url
      title: Find action
    WebSearchActionOpenPage:
      description: |
        Action type "open_page" - Opens a specific URL from search results.
      properties:
        type:
          description: |
            The action type.
          enum:
          - open_page
          type: string
          x-stainless-const: true
        url:
          description: |
            The URL opened by the model.
          format: uri
          type: string
      required:
      - type
      - url
      title: Open page action
    WebSearchActionSearch:
      description: |
        Action type "search" - Performs a web search query.
      properties:
        type:
          description: |
            The action type.
          enum:
          - search
          type: string
          x-stainless-const: true
        query:
          description: |
            The search query.
          type: string
      required:
      - query
      - type
      title: Search action
    WebSearchContextSize:
      default: medium
      description: "High level guidance for the amount of context window space to\
        \ use for the \nsearch. One of `low`, `medium`, or `high`. `medium` is the\
        \ default.\n"
      enum:
      - low
      - medium
      - high
      type: string
    WebSearchLocation:
      description: Approximate location parameters for the search.
      example:
        country: country
        city: city
        timezone: timezone
        region: region
      properties:
        country:
          description: "The two-letter \n[ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1)\
            \ of the user,\ne.g. `US`.\n"
          type: string
        region:
          description: |
            Free text input for the region of the user, e.g. `California`.
          type: string
        city:
          description: |
            Free text input for the city of the user, e.g. `San Francisco`.
          type: string
        timezone:
          description: "The [IANA timezone](https://timeapi.io/documentation/iana-timezones)\
            \ \nof the user, e.g. `America/Los_Angeles`.\n"
          type: string
      title: Web search location
    WebSearchToolCall:
      description: "The results of a web search tool call. See the \n[web search guide](/docs/guides/tools-web-search)\
        \ for more information.\n"
      properties:
        id:
          description: |
            The unique ID of the web search tool call.
          type: string
        type:
          description: |
            The type of the web search tool call. Always `web_search_call`.
          enum:
          - web_search_call
          type: string
          x-stainless-const: true
        status:
          description: |
            The status of the web search tool call.
          enum:
          - in_progress
          - searching
          - completed
          - failed
          type: string
        action:
          $ref: "#/components/schemas/WebSearchToolCall_action"
      required:
      - action
      - id
      - status
      - type
      title: Web search tool call
    WebhookBatchCancelled:
      description: |
        Sent when a batch API request has been cancelled.
      example:
        data:
          id: id
        created_at: 0
        id: id
        type: batch.cancelled
        object: event
      properties:
        created_at:
          description: |
            The Unix timestamp (in seconds) of when the batch API request was cancelled.
          type: integer
        id:
          description: |
            The unique ID of the event.
          type: string
        data:
          $ref: "#/components/schemas/WebhookBatchCancelled_data"
        object:
          description: |
            The object of the event. Always `event`.
          enum:
          - event
          type: string
          x-stainless-const: true
        type:
          description: |
            The type of the event. Always `batch.cancelled`.
          enum:
          - batch.cancelled
          type: string
          x-stainless-const: true
      required:
      - created_at
      - data
      - id
      - type
      title: batch.cancelled
      x-oaiMeta:
        name: batch.cancelled
        group: webhook-events
        example: |
          {
            "id": "evt_abc123",
            "type": "batch.cancelled",
            "created_at": 1719168000,
            "data": {
              "id": "batch_abc123"
            }
          }
    WebhookBatchCompleted:
      description: |
        Sent when a batch API request has been completed.
      example:
        data:
          id: id
        created_at: 0
        id: id
        type: batch.completed
        object: event
      properties:
        created_at:
          description: |
            The Unix timestamp (in seconds) of when the batch API request was completed.
          type: integer
        id:
          description: |
            The unique ID of the event.
          type: string
        data:
          $ref: "#/components/schemas/WebhookBatchCancelled_data"
        object:
          description: |
            The object of the event. Always `event`.
          enum:
          - event
          type: string
          x-stainless-const: true
        type:
          description: |
            The type of the event. Always `batch.completed`.
          enum:
          - batch.completed
          type: string
          x-stainless-const: true
      required:
      - created_at
      - data
      - id
      - type
      title: batch.completed
      x-oaiMeta:
        name: batch.completed
        group: webhook-events
        example: |
          {
            "id": "evt_abc123",
            "type": "batch.completed",
            "created_at": 1719168000,
            "data": {
              "id": "batch_abc123"
            }
          }
    WebhookBatchExpired:
      description: |
        Sent when a batch API request has expired.
      example:
        data:
          id: id
        created_at: 0
        id: id
        type: batch.expired
        object: event
      properties:
        created_at:
          description: |
            The Unix timestamp (in seconds) of when the batch API request expired.
          type: integer
        id:
          description: |
            The unique ID of the event.
          type: string
        data:
          $ref: "#/components/schemas/WebhookBatchCancelled_data"
        object:
          description: |
            The object of the event. Always `event`.
          enum:
          - event
          type: string
          x-stainless-const: true
        type:
          description: |
            The type of the event. Always `batch.expired`.
          enum:
          - batch.expired
          type: string
          x-stainless-const: true
      required:
      - created_at
      - data
      - id
      - type
      title: batch.expired
      x-oaiMeta:
        name: batch.expired
        group: webhook-events
        example: |
          {
            "id": "evt_abc123",
            "type": "batch.expired",
            "created_at": 1719168000,
            "data": {
              "id": "batch_abc123"
            }
          }
    WebhookBatchFailed:
      description: |
        Sent when a batch API request has failed.
      example:
        data:
          id: id
        created_at: 0
        id: id
        type: batch.failed
        object: event
      properties:
        created_at:
          description: |
            The Unix timestamp (in seconds) of when the batch API request failed.
          type: integer
        id:
          description: |
            The unique ID of the event.
          type: string
        data:
          $ref: "#/components/schemas/WebhookBatchCancelled_data"
        object:
          description: |
            The object of the event. Always `event`.
          enum:
          - event
          type: string
          x-stainless-const: true
        type:
          description: |
            The type of the event. Always `batch.failed`.
          enum:
          - batch.failed
          type: string
          x-stainless-const: true
      required:
      - created_at
      - data
      - id
      - type
      title: batch.failed
      x-oaiMeta:
        name: batch.failed
        group: webhook-events
        example: |
          {
            "id": "evt_abc123",
            "type": "batch.failed",
            "created_at": 1719168000,
            "data": {
              "id": "batch_abc123"
            }
          }
    WebhookEvalRunCanceled:
      description: |
        Sent when an eval run has been canceled.
      example:
        data:
          id: id
        created_at: 0
        id: id
        type: eval.run.canceled
        object: event
      properties:
        created_at:
          description: |
            The Unix timestamp (in seconds) of when the eval run was canceled.
          type: integer
        id:
          description: |
            The unique ID of the event.
          type: string
        data:
          $ref: "#/components/schemas/WebhookEvalRunCanceled_data"
        object:
          description: |
            The object of the event. Always `event`.
          enum:
          - event
          type: string
          x-stainless-const: true
        type:
          description: |
            The type of the event. Always `eval.run.canceled`.
          enum:
          - eval.run.canceled
          type: string
          x-stainless-const: true
      required:
      - created_at
      - data
      - id
      - type
      title: eval.run.canceled
      x-oaiMeta:
        name: eval.run.canceled
        group: webhook-events
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"eval.run.canceled\"\
          ,\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"evalrun_abc123\"\
          \n  }\n} \n"
    WebhookEvalRunFailed:
      description: |
        Sent when an eval run has failed.
      example:
        data:
          id: id
        created_at: 0
        id: id
        type: eval.run.failed
        object: event
      properties:
        created_at:
          description: |
            The Unix timestamp (in seconds) of when the eval run failed.
          type: integer
        id:
          description: |
            The unique ID of the event.
          type: string
        data:
          $ref: "#/components/schemas/WebhookEvalRunCanceled_data"
        object:
          description: |
            The object of the event. Always `event`.
          enum:
          - event
          type: string
          x-stainless-const: true
        type:
          description: |
            The type of the event. Always `eval.run.failed`.
          enum:
          - eval.run.failed
          type: string
          x-stainless-const: true
      required:
      - created_at
      - data
      - id
      - type
      title: eval.run.failed
      x-oaiMeta:
        name: eval.run.failed
        group: webhook-events
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"eval.run.failed\",\n\
          \  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"evalrun_abc123\"\
          \n  }\n} \n"
    WebhookEvalRunSucceeded:
      description: |
        Sent when an eval run has succeeded.
      example:
        data:
          id: id
        created_at: 0
        id: id
        type: eval.run.succeeded
        object: event
      properties:
        created_at:
          description: |
            The Unix timestamp (in seconds) of when the eval run succeeded.
          type: integer
        id:
          description: |
            The unique ID of the event.
          type: string
        data:
          $ref: "#/components/schemas/WebhookEvalRunCanceled_data"
        object:
          description: |
            The object of the event. Always `event`.
          enum:
          - event
          type: string
          x-stainless-const: true
        type:
          description: |
            The type of the event. Always `eval.run.succeeded`.
          enum:
          - eval.run.succeeded
          type: string
          x-stainless-const: true
      required:
      - created_at
      - data
      - id
      - type
      title: eval.run.succeeded
      x-oaiMeta:
        name: eval.run.succeeded
        group: webhook-events
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"eval.run.succeeded\"\
          ,\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"evalrun_abc123\"\
          \n  }\n} \n"
    WebhookFineTuningJobCancelled:
      description: |
        Sent when a fine-tuning job has been cancelled.
      example:
        data:
          id: id
        created_at: 0
        id: id
        type: fine_tuning.job.cancelled
        object: event
      properties:
        created_at:
          description: |
            The Unix timestamp (in seconds) of when the fine-tuning job was cancelled.
          type: integer
        id:
          description: |
            The unique ID of the event.
          type: string
        data:
          $ref: "#/components/schemas/WebhookFineTuningJobCancelled_data"
        object:
          description: |
            The object of the event. Always `event`.
          enum:
          - event
          type: string
          x-stainless-const: true
        type:
          description: |
            The type of the event. Always `fine_tuning.job.cancelled`.
          enum:
          - fine_tuning.job.cancelled
          type: string
          x-stainless-const: true
      required:
      - created_at
      - data
      - id
      - type
      title: fine_tuning.job.cancelled
      x-oaiMeta:
        name: fine_tuning.job.cancelled
        group: webhook-events
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"fine_tuning.job.cancelled\"\
          ,\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"ftjob_abc123\"\
          \n  }\n} \n"
    WebhookFineTuningJobFailed:
      description: |
        Sent when a fine-tuning job has failed.
      example:
        data:
          id: id
        created_at: 0
        id: id
        type: fine_tuning.job.failed
        object: event
      properties:
        created_at:
          description: |
            The Unix timestamp (in seconds) of when the fine-tuning job failed.
          type: integer
        id:
          description: |
            The unique ID of the event.
          type: string
        data:
          $ref: "#/components/schemas/WebhookFineTuningJobCancelled_data"
        object:
          description: |
            The object of the event. Always `event`.
          enum:
          - event
          type: string
          x-stainless-const: true
        type:
          description: |
            The type of the event. Always `fine_tuning.job.failed`.
          enum:
          - fine_tuning.job.failed
          type: string
          x-stainless-const: true
      required:
      - created_at
      - data
      - id
      - type
      title: fine_tuning.job.failed
      x-oaiMeta:
        name: fine_tuning.job.failed
        group: webhook-events
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"fine_tuning.job.failed\"\
          ,\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"ftjob_abc123\"\
          \n  }\n} \n"
    WebhookFineTuningJobSucceeded:
      description: |
        Sent when a fine-tuning job has succeeded.
      example:
        data:
          id: id
        created_at: 0
        id: id
        type: fine_tuning.job.succeeded
        object: event
      properties:
        created_at:
          description: |
            The Unix timestamp (in seconds) of when the fine-tuning job succeeded.
          type: integer
        id:
          description: |
            The unique ID of the event.
          type: string
        data:
          $ref: "#/components/schemas/WebhookFineTuningJobCancelled_data"
        object:
          description: |
            The object of the event. Always `event`.
          enum:
          - event
          type: string
          x-stainless-const: true
        type:
          description: |
            The type of the event. Always `fine_tuning.job.succeeded`.
          enum:
          - fine_tuning.job.succeeded
          type: string
          x-stainless-const: true
      required:
      - created_at
      - data
      - id
      - type
      title: fine_tuning.job.succeeded
      x-oaiMeta:
        name: fine_tuning.job.succeeded
        group: webhook-events
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"fine_tuning.job.succeeded\"\
          ,\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"ftjob_abc123\"\
          \n  }\n} \n"
    WebhookResponseCancelled:
      description: |
        Sent when a background response has been cancelled.
      example:
        data:
          id: id
        created_at: 0
        id: id
        type: response.cancelled
        object: event
      properties:
        created_at:
          description: |
            The Unix timestamp (in seconds) of when the model response was cancelled.
          type: integer
        id:
          description: |
            The unique ID of the event.
          type: string
        data:
          $ref: "#/components/schemas/WebhookResponseCancelled_data"
        object:
          description: |
            The object of the event. Always `event`.
          enum:
          - event
          type: string
          x-stainless-const: true
        type:
          description: |
            The type of the event. Always `response.cancelled`.
          enum:
          - response.cancelled
          type: string
          x-stainless-const: true
      required:
      - created_at
      - data
      - id
      - type
      title: response.cancelled
      x-oaiMeta:
        name: response.cancelled
        group: webhook-events
        example: |
          {
            "id": "evt_abc123",
            "type": "response.cancelled",
            "created_at": 1719168000,
            "data": {
              "id": "resp_abc123"
            }
          }
    WebhookResponseCompleted:
      description: |
        Sent when a background response has been completed.
      example:
        data:
          id: id
        created_at: 0
        id: id
        type: response.completed
        object: event
      properties:
        created_at:
          description: |
            The Unix timestamp (in seconds) of when the model response was completed.
          type: integer
        id:
          description: |
            The unique ID of the event.
          type: string
        data:
          $ref: "#/components/schemas/WebhookResponseCancelled_data"
        object:
          description: |
            The object of the event. Always `event`.
          enum:
          - event
          type: string
          x-stainless-const: true
        type:
          description: |
            The type of the event. Always `response.completed`.
          enum:
          - response.completed
          type: string
          x-stainless-const: true
      required:
      - created_at
      - data
      - id
      - type
      title: response.completed
      x-oaiMeta:
        name: response.completed
        group: webhook-events
        example: |
          {
            "id": "evt_abc123",
            "type": "response.completed",
            "created_at": 1719168000,
            "data": {
              "id": "resp_abc123"
            }
          }
    WebhookResponseFailed:
      description: |
        Sent when a background response has failed.
      example:
        data:
          id: id
        created_at: 0
        id: id
        type: response.failed
        object: event
      properties:
        created_at:
          description: |
            The Unix timestamp (in seconds) of when the model response failed.
          type: integer
        id:
          description: |
            The unique ID of the event.
          type: string
        data:
          $ref: "#/components/schemas/WebhookResponseCancelled_data"
        object:
          description: |
            The object of the event. Always `event`.
          enum:
          - event
          type: string
          x-stainless-const: true
        type:
          description: |
            The type of the event. Always `response.failed`.
          enum:
          - response.failed
          type: string
          x-stainless-const: true
      required:
      - created_at
      - data
      - id
      - type
      title: response.failed
      x-oaiMeta:
        name: response.failed
        group: webhook-events
        example: |
          {
            "id": "evt_abc123",
            "type": "response.failed",
            "created_at": 1719168000,
            "data": {
              "id": "resp_abc123"
            }
          }
    WebhookResponseIncomplete:
      description: |
        Sent when a background response has been interrupted.
      example:
        data:
          id: id
        created_at: 0
        id: id
        type: response.incomplete
        object: event
      properties:
        created_at:
          description: |
            The Unix timestamp (in seconds) of when the model response was interrupted.
          type: integer
        id:
          description: |
            The unique ID of the event.
          type: string
        data:
          $ref: "#/components/schemas/WebhookResponseCancelled_data"
        object:
          description: |
            The object of the event. Always `event`.
          enum:
          - event
          type: string
          x-stainless-const: true
        type:
          description: |
            The type of the event. Always `response.incomplete`.
          enum:
          - response.incomplete
          type: string
          x-stainless-const: true
      required:
      - created_at
      - data
      - id
      - type
      title: response.incomplete
      x-oaiMeta:
        name: response.incomplete
        group: webhook-events
        example: |
          {
            "id": "evt_abc123",
            "type": "response.incomplete",
            "created_at": 1719168000,
            "data": {
              "id": "resp_abc123"
            }
          }
    InputTextContent:
      description: A text input to the model.
      example:
        text: text
        type: input_text
      properties:
        type:
          default: input_text
          description: The type of the input item. Always `input_text`.
          enum:
          - input_text
          type: string
          x-stainless-const: true
        text:
          description: The text input to the model.
          type: string
      required:
      - text
      - type
      title: Input text
    InputImageContent:
      description: "An image input to the model. Learn about [image inputs](/docs/guides/vision)."
      properties:
        type:
          default: input_image
          description: The type of the input item. Always `input_image`.
          enum:
          - input_image
          type: string
          x-stainless-const: true
        image_url:
          description: The URL of the image to be sent to the model. A fully qualified
            URL or base64 encoded image in a data URL.
          nullable: true
          type: string
        file_id:
          description: The ID of the file to be sent to the model.
          nullable: true
          type: string
        detail:
          description: "The detail level of the image to be sent to the model. One\
            \ of `high`, `low`, or `auto`. Defaults to `auto`."
          enum:
          - low
          - high
          - auto
          type: string
      required:
      - detail
      - type
      title: Input image
    InputFileContent:
      description: A file input to the model.
      properties:
        type:
          default: input_file
          description: The type of the input item. Always `input_file`.
          enum:
          - input_file
          type: string
          x-stainless-const: true
        file_id:
          description: The ID of the file to be sent to the model.
          nullable: true
          type: string
        filename:
          description: The name of the file to be sent to the model.
          type: string
        file_data:
          description: |
            The content of the file to be sent to the model.
          type: string
      required:
      - type
      title: Input file
    FunctionTool:
      description: "Defines a function in your own code the model can choose to call.\
        \ Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling)."
      example:
        name: name
        description: description
        type: function
        strict: true
        parameters:
          key: ""
      properties:
        type:
          default: function
          description: The type of the function tool. Always `function`.
          enum:
          - function
          type: string
          x-stainless-const: true
        name:
          description: The name of the function to call.
          type: string
        description:
          description: A description of the function. Used by the model to determine
            whether or not to call the function.
          nullable: true
          type: string
        parameters:
          additionalProperties: true
          description: A JSON schema object describing the parameters of the function.
          nullable: true
          type: object
        strict:
          description: Whether to enforce strict parameter validation. Default `true`.
          nullable: true
          type: boolean
      required:
      - name
      - parameters
      - strict
      - type
      title: Function
    RankingOptions:
      properties:
        ranker:
          description: The ranker to use for the file search.
          enum:
          - auto
          - default-2024-11-15
          type: string
        score_threshold:
          description: "The score threshold for the file search, a number between\
            \ 0 and 1. Numbers closer to 1 will attempt to return only the most relevant\
            \ results, but may return fewer results."
          type: number
    Filters:
      anyOf:
      - $ref: "#/components/schemas/ComparisonFilter"
      - $ref: "#/components/schemas/CompoundFilter"
    FileSearchTool:
      description: "A tool that searches for relevant content from uploaded files.\
        \ Learn more about the [file search tool](https://platform.openai.com/docs/guides/tools-file-search)."
      properties:
        type:
          default: file_search
          description: The type of the file search tool. Always `file_search`.
          enum:
          - file_search
          type: string
          x-stainless-const: true
        vector_store_ids:
          description: The IDs of the vector stores to search.
          items:
            type: string
          type: array
        max_num_results:
          description: The maximum number of results to return. This number should
            be between 1 and 50 inclusive.
          type: integer
        ranking_options:
          $ref: "#/components/schemas/RankingOptions"
        filters:
          $ref: "#/components/schemas/Filters"
      required:
      - type
      - vector_store_ids
      title: File search
    ApproximateLocation:
      properties:
        type:
          default: approximate
          description: The type of location approximation. Always `approximate`.
          enum:
          - approximate
          type: string
          x-stainless-const: true
        country:
          description: "The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1)\
            \ of the user, e.g. `US`."
          nullable: true
          type: string
        region:
          description: "Free text input for the region of the user, e.g. `California`."
          nullable: true
          type: string
        city:
          description: "Free text input for the city of the user, e.g. `San Francisco`."
          nullable: true
          type: string
        timezone:
          description: "The [IANA timezone](https://timeapi.io/documentation/iana-timezones)\
            \ of the user, e.g. `America/Los_Angeles`."
          nullable: true
          type: string
    WebSearchPreviewTool:
      description: "This tool searches the web for relevant results to use in a response.\
        \ Learn more about the [web search tool](https://platform.openai.com/docs/guides/tools-web-search)."
      properties:
        type:
          default: web_search_preview
          description: The type of the web search tool. One of `web_search_preview`
            or `web_search_preview_2025_03_11`.
          enum:
          - web_search_preview
          - web_search_preview_2025_03_11
          type: string
          x-stainless-const: true
        user_location:
          $ref: "#/components/schemas/ApproximateLocation"
        search_context_size:
          description: "High level guidance for the amount of context window space\
            \ to use for the search. One of `low`, `medium`, or `high`. `medium` is\
            \ the default."
          enum:
          - low
          - medium
          - high
          type: string
      title: Web search preview
    ComputerUsePreviewTool:
      description: "A tool that controls a virtual computer. Learn more about the\
        \ [computer tool](https://platform.openai.com/docs/guides/tools-computer-use)."
      properties:
        type:
          default: computer_use_preview
          description: The type of the computer use tool. Always `computer_use_preview`.
          enum:
          - computer_use_preview
          type: string
          x-stainless-const: true
        environment:
          description: The type of computer environment to control.
          enum:
          - windows
          - mac
          - linux
          - ubuntu
          - browser
          type: string
        display_width:
          description: The width of the computer display.
          type: integer
        display_height:
          description: The height of the computer display.
          type: integer
      required:
      - display_height
      - display_width
      - environment
      - type
      title: Computer use preview
    FileCitationBody:
      description: A citation to a file.
      properties:
        type:
          default: file_citation
          description: The type of the file citation. Always `file_citation`.
          enum:
          - file_citation
          type: string
          x-stainless-const: true
        file_id:
          description: The ID of the file.
          type: string
        index:
          description: The index of the file in the list of files.
          type: integer
        filename:
          description: The filename of the file cited.
          type: string
      required:
      - file_id
      - filename
      - index
      - type
      title: File citation
    UrlCitationBody:
      description: A citation for a web resource used to generate a model response.
      properties:
        type:
          default: url_citation
          description: The type of the URL citation. Always `url_citation`.
          enum:
          - url_citation
          type: string
          x-stainless-const: true
        url:
          description: The URL of the web resource.
          type: string
        start_index:
          description: The index of the first character of the URL citation in the
            message.
          type: integer
        end_index:
          description: The index of the last character of the URL citation in the
            message.
          type: integer
        title:
          description: The title of the web resource.
          type: string
      required:
      - end_index
      - start_index
      - title
      - type
      - url
      title: URL citation
    ContainerFileCitationBody:
      description: A citation for a container file used to generate a model response.
      properties:
        type:
          default: container_file_citation
          description: The type of the container file citation. Always `container_file_citation`.
          enum:
          - container_file_citation
          type: string
          x-stainless-const: true
        container_id:
          description: The ID of the container file.
          type: string
        file_id:
          description: The ID of the file.
          type: string
        start_index:
          description: The index of the first character of the container file citation
            in the message.
          type: integer
        end_index:
          description: The index of the last character of the container file citation
            in the message.
          type: integer
        filename:
          description: The filename of the container file cited.
          type: string
      required:
      - container_id
      - end_index
      - file_id
      - filename
      - start_index
      - type
      title: Container file citation
    Annotation:
      discriminator:
        propertyName: type
      oneOf:
      - $ref: "#/components/schemas/FileCitationBody"
      - $ref: "#/components/schemas/UrlCitationBody"
      - $ref: "#/components/schemas/ContainerFileCitationBody"
      - $ref: "#/components/schemas/FilePath"
    TopLogProb:
      description: The top log probability of a token.
      properties:
        token:
          type: string
        logprob:
          type: number
        bytes:
          items:
            type: integer
          type: array
      required:
      - bytes
      - logprob
      - token
      title: Top log probability
    LogProb:
      description: The log probability of a token.
      properties:
        token:
          type: string
        logprob:
          type: number
        bytes:
          items:
            type: integer
          type: array
        top_logprobs:
          items:
            $ref: "#/components/schemas/TopLogProb"
          type: array
      required:
      - bytes
      - logprob
      - token
      - top_logprobs
      title: Log probability
    OutputTextContent:
      description: A text output from the model.
      properties:
        type:
          default: output_text
          description: The type of the output text. Always `output_text`.
          enum:
          - output_text
          type: string
          x-stainless-const: true
        text:
          description: The text output from the model.
          type: string
        annotations:
          description: The annotations of the text output.
          items:
            $ref: "#/components/schemas/Annotation"
          type: array
        logprobs:
          items:
            $ref: "#/components/schemas/LogProb"
          type: array
      required:
      - annotations
      - text
      - type
      title: Output text
    RefusalContent:
      description: A refusal from the model.
      properties:
        type:
          default: refusal
          description: The type of the refusal. Always `refusal`.
          enum:
          - refusal
          type: string
          x-stainless-const: true
        refusal:
          description: The refusal explanationfrom the model.
          type: string
      required:
      - refusal
      - type
      title: Refusal
    ComputerCallSafetyCheckParam:
      description: A pending safety check for the computer call.
      properties:
        id:
          description: The ID of the pending safety check.
          type: string
        code:
          description: The type of the pending safety check.
          nullable: true
          type: string
        message:
          description: Details about the pending safety check.
          nullable: true
          type: string
      required:
      - id
    ComputerCallOutputItemParam:
      description: The output of a computer tool call.
      properties:
        id:
          description: The ID of the computer tool call output.
          nullable: true
          type: string
        call_id:
          description: The ID of the computer tool call that produced the output.
          maxLength: 64
          minLength: 1
          type: string
        type:
          default: computer_call_output
          description: The type of the computer tool call output. Always `computer_call_output`.
          enum:
          - computer_call_output
          type: string
          x-stainless-const: true
        output:
          $ref: "#/components/schemas/ComputerScreenshotImage"
        acknowledged_safety_checks:
          description: The safety checks reported by the API that have been acknowledged
            by the developer.
          items:
            $ref: "#/components/schemas/ComputerCallSafetyCheckParam"
          nullable: true
          type: array
        status:
          description: "The status of the message input. One of `in_progress`, `completed`,\
            \ or `incomplete`. Populated when input items are returned via API."
          enum:
          - in_progress
          - completed
          - incomplete
          nullable: true
          type: string
      required:
      - call_id
      - output
      - type
      title: Computer tool call output
    FunctionCallOutputItemParam:
      description: The output of a function tool call.
      properties:
        id:
          description: The unique ID of the function tool call output. Populated when
            this item is returned via API.
          nullable: true
          type: string
        call_id:
          description: The unique ID of the function tool call generated by the model.
          maxLength: 64
          minLength: 1
          type: string
        type:
          default: function_call_output
          description: The type of the function tool call output. Always `function_call_output`.
          enum:
          - function_call_output
          type: string
          x-stainless-const: true
        output:
          description: A JSON string of the output of the function tool call.
          maxLength: 10485760
          type: string
        status:
          description: "The status of the item. One of `in_progress`, `completed`,\
            \ or `incomplete`. Populated when items are returned via API."
          enum:
          - in_progress
          - completed
          - incomplete
          nullable: true
          type: string
      required:
      - call_id
      - output
      - type
      title: Function tool call output
    ItemReferenceParam:
      description: An internal identifier for an item to reference.
      properties:
        type:
          default: item_reference
          description: The type of item to reference. Always `item_reference`.
          enum:
          - item_reference
          nullable: true
          type: string
          x-stainless-const: true
        id:
          description: The ID of the item to reference.
          type: string
      required:
      - id
      title: Item reference
    createTranscription_200_response:
      oneOf:
      - $ref: "#/components/schemas/CreateTranscriptionResponseJson"
      - $ref: "#/components/schemas/CreateTranscriptionResponseVerboseJson"
    createTranslation_200_response:
      oneOf:
      - $ref: "#/components/schemas/CreateTranslationResponseJson"
      - $ref: "#/components/schemas/CreateTranslationResponseVerboseJson"
    createBatch_request:
      properties:
        input_file_id:
          description: |
            The ID of an uploaded file that contains requests for the new batch.

            See [upload file](/docs/api-reference/files/create) for how to upload a file.

            Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size.
          type: string
        endpoint:
          description: "The endpoint to be used for all requests in the batch. Currently\
            \ `/v1/responses`, `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions`\
            \ are supported. Note that `/v1/embeddings` batches are also restricted\
            \ to a maximum of 50,000 embedding inputs across all requests in the batch."
          enum:
          - /v1/responses
          - /v1/chat/completions
          - /v1/embeddings
          - /v1/completions
          type: string
        completion_window:
          description: The time frame within which the batch should be processed.
            Currently only `24h` is supported.
          enum:
          - 24h
          type: string
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
      required:
      - completion_window
      - endpoint
      - input_file_id
    updateChatCompletion_request:
      properties:
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
      required:
      - metadata
    updateEval_request:
      properties:
        name:
          description: Rename the evaluation.
          type: string
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
    deleteEval_200_response:
      example:
        deleted: true
        eval_id: eval_abc123
        object: eval.deleted
      properties:
        object:
          example: eval.deleted
          type: string
        deleted:
          example: true
          type: boolean
        eval_id:
          example: eval_abc123
          type: string
      required:
      - deleted
      - eval_id
      - object
    deleteEvalRun_200_response:
      example:
        deleted: true
        run_id: evalrun_677469f564d48190807532a852da3afb
        object: eval.run.deleted
      properties:
        object:
          example: eval.run.deleted
          type: string
        deleted:
          example: true
          type: boolean
        run_id:
          example: evalrun_677469f564d48190807532a852da3afb
          type: string
    admin_api_keys_create_request:
      properties:
        name:
          example: New Admin Key
          type: string
      required:
      - name
    admin_api_keys_delete_200_response:
      example:
        deleted: true
        id: key_abc
        object: organization.admin_api_key.deleted
      properties:
        id:
          example: key_abc
          type: string
        object:
          example: organization.admin_api_key.deleted
          type: string
        deleted:
          example: true
          type: boolean
    list_audit_logs_effective_at_parameter:
      properties:
        gt:
          description: Return only events whose `effective_at` (Unix seconds) is greater
            than this value.
          type: integer
        gte:
          description: Return only events whose `effective_at` (Unix seconds) is greater
            than or equal to this value.
          type: integer
        lt:
          description: Return only events whose `effective_at` (Unix seconds) is less
            than this value.
          type: integer
        lte:
          description: Return only events whose `effective_at` (Unix seconds) is less
            than or equal to this value.
          type: integer
    AdminApiKey_owner:
      example:
        role: owner
        name: My Service Account
        created_at: 1711471533
        id: sa_456
        type: user
        object: organization.user
      properties:
        type:
          description: Always `user`
          example: user
          type: string
        object:
          description: "The object type, which is always organization.user"
          example: organization.user
          type: string
        id:
          description: "The identifier, which can be referenced in API endpoints"
          example: sa_456
          type: string
        name:
          description: The name of the user
          example: My Service Account
          type: string
        created_at:
          description: The Unix timestamp (in seconds) of when the user was created
          example: 1711471533
          format: int64
          type: integer
        role:
          description: Always `owner`
          example: owner
          type: string
    AssistantObject_tools_inner:
      oneOf:
      - $ref: "#/components/schemas/AssistantToolsCode"
      - $ref: "#/components/schemas/AssistantToolsFileSearch"
      - $ref: "#/components/schemas/AssistantToolsFunction"
    AssistantObject_tool_resources_code_interpreter:
      example:
        file_ids:
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        - file_ids
      properties:
        file_ids:
          default: []
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter`` tool. There can be a maximum of 20 files associated with the tool.
          items:
            type: string
          maxItems: 20
          type: array
    AssistantObject_tool_resources_file_search:
      example:
        vector_store_ids:
        - vector_store_ids
      properties:
        vector_store_ids:
          description: |
            The ID of the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items:
            type: string
          maxItems: 1
          type: array
    AssistantObject_tool_resources:
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      example:
        code_interpreter:
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
        file_search:
          vector_store_ids:
          - vector_store_ids
      properties:
        code_interpreter:
          $ref: "#/components/schemas/AssistantObject_tool_resources_code_interpreter"
        file_search:
          $ref: "#/components/schemas/AssistantObject_tool_resources_file_search"
      nullable: true
    AssistantToolsFileSearch_file_search:
      description: Overrides for the file search tool.
      properties:
        max_num_results:
          description: |
            The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.

            Note that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.
          maximum: 50
          minimum: 1
          type: integer
        ranking_options:
          $ref: "#/components/schemas/FileSearchRankingOptions"
    AssistantsNamedToolChoice_function:
      properties:
        name:
          description: The name of the function to call.
          type: string
      required:
      - name
    AuditLog_project:
      description: The project that the action was scoped to. Absent for actions not
        scoped to projects.
      example:
        name: name
        id: id
      properties:
        id:
          description: The project ID.
          type: string
        name:
          description: The project title.
          type: string
    AuditLog_api_key_created_data:
      description: The payload used to create the API key.
      example:
        scopes:
        - scopes
        - scopes
      properties:
        scopes:
          description: "A list of scopes allowed for the API key, e.g. `[\"api.model.request\"\
            ]`"
          items:
            type: string
          type: array
    AuditLog_api_key_created:
      description: The details for events with this `type`.
      example:
        data:
          scopes:
          - scopes
          - scopes
        id: id
      properties:
        id:
          description: The tracking ID of the API key.
          type: string
        data:
          $ref: "#/components/schemas/AuditLog_api_key_created_data"
    AuditLog_api_key_updated_changes_requested:
      description: The payload used to update the API key.
      example:
        scopes:
        - scopes
        - scopes
      properties:
        scopes:
          description: "A list of scopes allowed for the API key, e.g. `[\"api.model.request\"\
            ]`"
          items:
            type: string
          type: array
    AuditLog_api_key_updated:
      description: The details for events with this `type`.
      example:
        changes_requested:
          scopes:
          - scopes
          - scopes
        id: id
      properties:
        id:
          description: The tracking ID of the API key.
          type: string
        changes_requested:
          $ref: "#/components/schemas/AuditLog_api_key_updated_changes_requested"
    AuditLog_api_key_deleted:
      description: The details for events with this `type`.
      example:
        id: id
      properties:
        id:
          description: The tracking ID of the API key.
          type: string
    AuditLog_checkpoint_permission_created_data:
      description: The payload used to create the checkpoint permission.
      example:
        project_id: project_id
        fine_tuned_model_checkpoint: fine_tuned_model_checkpoint
      properties:
        project_id:
          description: The ID of the project that the checkpoint permission was created
            for.
          type: string
        fine_tuned_model_checkpoint:
          description: The ID of the fine-tuned model checkpoint.
          type: string
    AuditLog_checkpoint_permission_created:
      description: The project and fine-tuned model checkpoint that the checkpoint
        permission was created for.
      example:
        data:
          project_id: project_id
          fine_tuned_model_checkpoint: fine_tuned_model_checkpoint
        id: id
      properties:
        id:
          description: The ID of the checkpoint permission.
          type: string
        data:
          $ref: "#/components/schemas/AuditLog_checkpoint_permission_created_data"
    AuditLog_checkpoint_permission_deleted:
      description: The details for events with this `type`.
      example:
        id: id
      properties:
        id:
          description: The ID of the checkpoint permission.
          type: string
    AuditLog_invite_sent_data:
      description: The payload used to create the invite.
      example:
        role: role
        email: email
      properties:
        email:
          description: The email invited to the organization.
          type: string
        role:
          description: The role the email was invited to be. Is either `owner` or
            `member`.
          type: string
    AuditLog_invite_sent:
      description: The details for events with this `type`.
      example:
        data:
          role: role
          email: email
        id: id
      properties:
        id:
          description: The ID of the invite.
          type: string
        data:
          $ref: "#/components/schemas/AuditLog_invite_sent_data"
    AuditLog_invite_accepted:
      description: The details for events with this `type`.
      example:
        id: id
      properties:
        id:
          description: The ID of the invite.
          type: string
    AuditLog_login_failed:
      description: The details for events with this `type`.
      example:
        error_message: error_message
        error_code: error_code
      properties:
        error_code:
          description: The error code of the failure.
          type: string
        error_message:
          description: The error message of the failure.
          type: string
    AuditLog_organization_updated_changes_requested:
      description: The payload used to update the organization settings.
      example:
        threads_ui_visibility: threads_ui_visibility
        usage_dashboard_visibility: usage_dashboard_visibility
        api_call_logging: api_call_logging
        name: name
        description: description
        title: title
        api_call_logging_project_ids: api_call_logging_project_ids
      properties:
        title:
          description: The organization title.
          type: string
        description:
          description: The organization description.
          type: string
        name:
          description: The organization name.
          type: string
        threads_ui_visibility:
          description: "Visibility of the threads page which shows messages created\
            \ with the Assistants API and Playground. One of `ANY_ROLE`, `OWNERS`,\
            \ or `NONE`."
          type: string
        usage_dashboard_visibility:
          description: Visibility of the usage dashboard which shows activity and
            costs for your organization. One of `ANY_ROLE` or `OWNERS`.
          type: string
        api_call_logging:
          description: "How your organization logs data from supported API calls.\
            \ One of `disabled`, `enabled_per_call`, `enabled_for_all_projects`, or\
            \ `enabled_for_selected_projects`"
          type: string
        api_call_logging_project_ids:
          description: The list of project ids if api_call_logging is set to `enabled_for_selected_projects`
          type: string
    AuditLog_organization_updated:
      description: The details for events with this `type`.
      example:
        changes_requested:
          threads_ui_visibility: threads_ui_visibility
          usage_dashboard_visibility: usage_dashboard_visibility
          api_call_logging: api_call_logging
          name: name
          description: description
          title: title
          api_call_logging_project_ids: api_call_logging_project_ids
        id: id
      properties:
        id:
          description: The organization ID.
          type: string
        changes_requested:
          $ref: "#/components/schemas/AuditLog_organization_updated_changes_requested"
    AuditLog_project_created_data:
      description: The payload used to create the project.
      example:
        name: name
        title: title
      properties:
        name:
          description: The project name.
          type: string
        title:
          description: The title of the project as seen on the dashboard.
          type: string
    AuditLog_project_created:
      description: The details for events with this `type`.
      example:
        data:
          name: name
          title: title
        id: id
      properties:
        id:
          description: The project ID.
          type: string
        data:
          $ref: "#/components/schemas/AuditLog_project_created_data"
    AuditLog_project_updated_changes_requested:
      description: The payload used to update the project.
      example:
        title: title
      properties:
        title:
          description: The title of the project as seen on the dashboard.
          type: string
    AuditLog_project_updated:
      description: The details for events with this `type`.
      example:
        changes_requested:
          title: title
        id: id
      properties:
        id:
          description: The project ID.
          type: string
        changes_requested:
          $ref: "#/components/schemas/AuditLog_project_updated_changes_requested"
    AuditLog_project_archived:
      description: The details for events with this `type`.
      example:
        id: id
      properties:
        id:
          description: The project ID.
          type: string
    AuditLog_rate_limit_updated_changes_requested:
      description: The payload used to update the rate limits.
      example:
        batch_1_day_max_input_tokens: 7
        max_tokens_per_1_minute: 1
        max_images_per_1_minute: 5
        max_audio_megabytes_per_1_minute: 5
        max_requests_per_1_minute: 6
        max_requests_per_1_day: 2
      properties:
        max_requests_per_1_minute:
          description: The maximum requests per minute.
          type: integer
        max_tokens_per_1_minute:
          description: The maximum tokens per minute.
          type: integer
        max_images_per_1_minute:
          description: The maximum images per minute. Only relevant for certain models.
          type: integer
        max_audio_megabytes_per_1_minute:
          description: The maximum audio megabytes per minute. Only relevant for certain
            models.
          type: integer
        max_requests_per_1_day:
          description: The maximum requests per day. Only relevant for certain models.
          type: integer
        batch_1_day_max_input_tokens:
          description: The maximum batch input tokens per day. Only relevant for certain
            models.
          type: integer
    AuditLog_rate_limit_updated:
      description: The details for events with this `type`.
      example:
        changes_requested:
          batch_1_day_max_input_tokens: 7
          max_tokens_per_1_minute: 1
          max_images_per_1_minute: 5
          max_audio_megabytes_per_1_minute: 5
          max_requests_per_1_minute: 6
          max_requests_per_1_day: 2
        id: id
      properties:
        id:
          description: The rate limit ID
          type: string
        changes_requested:
          $ref: "#/components/schemas/AuditLog_rate_limit_updated_changes_requested"
    AuditLog_rate_limit_deleted:
      description: The details for events with this `type`.
      example:
        id: id
      properties:
        id:
          description: The rate limit ID
          type: string
    AuditLog_service_account_created_data:
      description: The payload used to create the service account.
      example:
        role: role
      properties:
        role:
          description: The role of the service account. Is either `owner` or `member`.
          type: string
    AuditLog_service_account_created:
      description: The details for events with this `type`.
      example:
        data:
          role: role
        id: id
      properties:
        id:
          description: The service account ID.
          type: string
        data:
          $ref: "#/components/schemas/AuditLog_service_account_created_data"
    AuditLog_service_account_updated_changes_requested:
      description: The payload used to updated the service account.
      example:
        role: role
      properties:
        role:
          description: The role of the service account. Is either `owner` or `member`.
          type: string
    AuditLog_service_account_updated:
      description: The details for events with this `type`.
      example:
        changes_requested:
          role: role
        id: id
      properties:
        id:
          description: The service account ID.
          type: string
        changes_requested:
          $ref: "#/components/schemas/AuditLog_service_account_updated_changes_requested"
    AuditLog_service_account_deleted:
      description: The details for events with this `type`.
      example:
        id: id
      properties:
        id:
          description: The service account ID.
          type: string
    AuditLog_user_added_data:
      description: The payload used to add the user to the project.
      example:
        role: role
      properties:
        role:
          description: The role of the user. Is either `owner` or `member`.
          type: string
    AuditLog_user_added:
      description: The details for events with this `type`.
      example:
        data:
          role: role
        id: id
      properties:
        id:
          description: The user ID.
          type: string
        data:
          $ref: "#/components/schemas/AuditLog_user_added_data"
    AuditLog_user_updated_changes_requested:
      description: The payload used to update the user.
      example:
        role: role
      properties:
        role:
          description: The role of the user. Is either `owner` or `member`.
          type: string
    AuditLog_user_updated:
      description: The details for events with this `type`.
      example:
        changes_requested:
          role: role
        id: id
      properties:
        id:
          description: The project ID.
          type: string
        changes_requested:
          $ref: "#/components/schemas/AuditLog_user_updated_changes_requested"
    AuditLog_user_deleted:
      description: The details for events with this `type`.
      example:
        id: id
      properties:
        id:
          description: The user ID.
          type: string
    AuditLog_certificate_created:
      description: The details for events with this `type`.
      example:
        name: name
        id: id
      properties:
        id:
          description: The certificate ID.
          type: string
        name:
          description: The name of the certificate.
          type: string
    AuditLog_certificate_deleted:
      description: The details for events with this `type`.
      example:
        name: name
        certificate: certificate
        id: id
      properties:
        id:
          description: The certificate ID.
          type: string
        name:
          description: The name of the certificate.
          type: string
        certificate:
          description: The certificate content in PEM format.
          type: string
    AuditLog_certificates_activated_certificates_inner:
      example:
        name: name
        id: id
      properties:
        id:
          description: The certificate ID.
          type: string
        name:
          description: The name of the certificate.
          type: string
    AuditLog_certificates_activated:
      description: The details for events with this `type`.
      example:
        certificates:
        - name: name
          id: id
        - name: name
          id: id
      properties:
        certificates:
          items:
            $ref: "#/components/schemas/AuditLog_certificates_activated_certificates_inner"
          type: array
    Batch_errors_data_inner:
      example:
        code: code
        param: param
        line: 0
        message: message
      properties:
        code:
          description: An error code identifying the error type.
          type: string
        message:
          description: A human-readable message providing more details about the error.
          type: string
        param:
          description: "The name of the parameter that caused the error, if applicable."
          type: string
          nullable: true
        line:
          description: "The line number of the input file where the error occurred,\
            \ if applicable."
          type: integer
          nullable: true
    Batch_errors:
      example:
        data:
        - code: code
          param: param
          line: 0
          message: message
        - code: code
          param: param
          line: 0
          message: message
        object: object
      properties:
        object:
          description: "The object type, which is always `list`."
          type: string
        data:
          items:
            $ref: "#/components/schemas/Batch_errors_data_inner"
          type: array
    Batch_request_counts:
      description: The request counts for different statuses within the batch.
      example:
        total: 4
        completed: 7
        failed: 1
      properties:
        total:
          description: Total number of requests in the batch.
          type: integer
        completed:
          description: Number of requests that have been completed successfully.
          type: integer
        failed:
          description: Number of requests that have failed.
          type: integer
      required:
      - completed
      - failed
      - total
    BatchRequestOutput_response:
      properties:
        status_code:
          description: The HTTP status code of the response
          type: integer
        request_id:
          description: An unique identifier for the OpenAI API request. Please include
            this request ID when contacting support.
          type: string
        body:
          description: The JSON body of the response
          type: object
          x-oaiTypeLabel: map
      nullable: true
    BatchRequestOutput_error:
      description: "For requests that failed with a non-HTTP error, this will contain\
        \ more information on the cause of the failure."
      properties:
        code:
          description: A machine-readable error code.
          type: string
        message:
          description: A human-readable error message.
          type: string
      nullable: true
    Certificate_certificate_details:
      example:
        expires_at: 1
        content: content
        valid_at: 6
      properties:
        valid_at:
          description: The Unix timestamp (in seconds) of when the certificate becomes
            valid.
          type: integer
        expires_at:
          description: The Unix timestamp (in seconds) of when the certificate expires.
          type: integer
        content:
          description: The content of the certificate in PEM format.
          type: string
    ChatCompletionMessageList_data_inner:
      allOf:
      - $ref: "#/components/schemas/ChatCompletionResponseMessage"
      - properties:
          id:
            description: The identifier of the chat message.
            type: string
        required:
        - id
      example:
        role: assistant
        function_call:
          name: name
          arguments: arguments
        refusal: refusal
        annotations:
        - type: url_citation
          url_citation:
            start_index: 1
            end_index: 6
            title: title
            url: url
        - type: url_citation
          url_citation:
            start_index: 1
            end_index: 6
            title: title
            url: url
        tool_calls:
        - function:
            name: name
            arguments: arguments
          id: id
          type: function
        - function:
            name: name
            arguments: arguments
          id: id
          type: function
        audio:
          expires_at: 5
          transcript: transcript
          data: data
          id: id
        id: id
        content: content
    ChatCompletionMessageToolCall_function:
      description: The function that the model called.
      example:
        name: name
        arguments: arguments
      properties:
        name:
          description: The name of the function to call.
          type: string
        arguments:
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function."
          type: string
      required:
      - arguments
      - name
    ChatCompletionMessageToolCallChunk_function:
      properties:
        name:
          description: The name of the function to call.
          type: string
        arguments:
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function."
          type: string
    ChatCompletionRequestAssistantMessage_content:
      description: |
        The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified.
      oneOf:
      - description: The contents of the assistant message.
        title: Text content
        type: string
      - description: "An array of content parts with a defined type. Can be one or\
          \ more of type `text`, or exactly one of type `refusal`."
        items:
          $ref: "#/components/schemas/ChatCompletionRequestAssistantMessageContentPart"
        minItems: 1
        type: array
      nullable: true
    ChatCompletionRequestAssistantMessage_audio:
      description: "Data about a previous audio response from the model. \n[Learn\
        \ more](/docs/guides/audio).\n"
      properties:
        id:
          description: |
            Unique identifier for a previous audio response from the model.
          type: string
      required:
      - id
      nullable: true
    ChatCompletionRequestAssistantMessage_function_call:
      deprecated: true
      description: "Deprecated and replaced by `tool_calls`. The name and arguments\
        \ of a function that should be called, as generated by the model."
      properties:
        arguments:
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function."
          type: string
        name:
          description: The name of the function to call.
          type: string
      required:
      - arguments
      - name
      nullable: true
    ChatCompletionRequestDeveloperMessage_content:
      description: The contents of the developer message.
      oneOf:
      - description: The contents of the developer message.
        title: Text content
        type: string
      - description: "An array of content parts with a defined type. For developer\
          \ messages, only type `text` is supported."
        items:
          $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartText"
        minItems: 1
        type: array
    ChatCompletionRequestMessageContentPartAudio_input_audio:
      properties:
        data:
          description: Base64 encoded audio data.
          type: string
        format:
          description: |
            The format of the encoded audio data. Currently supports "wav" and "mp3".
          enum:
          - wav
          - mp3
          type: string
      required:
      - data
      - format
    ChatCompletionRequestMessageContentPartFile_file:
      properties:
        filename:
          description: "The name of the file, used when passing the file to the model\
            \ as a \nstring.\n"
          type: string
        file_data:
          description: "The base64 encoded file data, used when passing the file to\
            \ the model \nas a string.\n"
          type: string
        file_id:
          description: |
            The ID of an uploaded file to use as input.
          type: string
    ChatCompletionRequestMessageContentPartImage_image_url:
      properties:
        url:
          description: Either a URL of the image or the base64 encoded image data.
          format: uri
          type: string
        detail:
          default: auto
          description: "Specifies the detail level of the image. Learn more in the\
            \ [Vision guide](/docs/guides/vision#low-or-high-fidelity-image-understanding)."
          enum:
          - auto
          - low
          - high
          type: string
      required:
      - url
    ChatCompletionRequestSystemMessage_content:
      description: The contents of the system message.
      oneOf:
      - description: The contents of the system message.
        title: Text content
        type: string
      - description: "An array of content parts with a defined type. For system messages,\
          \ only type `text` is supported."
        items:
          $ref: "#/components/schemas/ChatCompletionRequestSystemMessageContentPart"
        minItems: 1
        type: array
    ChatCompletionRequestToolMessage_content:
      description: The contents of the tool message.
      oneOf:
      - description: The contents of the tool message.
        title: Text content
        type: string
      - description: "An array of content parts with a defined type. For tool messages,\
          \ only type `text` is supported."
        items:
          $ref: "#/components/schemas/ChatCompletionRequestToolMessageContentPart"
        minItems: 1
        type: array
    ChatCompletionRequestUserMessage_content:
      description: |
        The contents of the user message.
      oneOf:
      - description: The text contents of the message.
        title: Text content
        type: string
      - description: "An array of content parts with a defined type. Supported options\
          \ differ based on the [model](/docs/models) being used to generate the response.\
          \ Can contain text, image, or audio inputs."
        items:
          $ref: "#/components/schemas/ChatCompletionRequestUserMessageContentPart"
        minItems: 1
        type: array
    ChatCompletionResponseMessage_annotations_inner_url_citation:
      description: A URL citation when using web search.
      example:
        start_index: 1
        end_index: 6
        title: title
        url: url
      properties:
        end_index:
          description: The index of the last character of the URL citation in the
            message.
          type: integer
        start_index:
          description: The index of the first character of the URL citation in the
            message.
          type: integer
        url:
          description: The URL of the web resource.
          type: string
        title:
          description: The title of the web resource.
          type: string
      required:
      - end_index
      - start_index
      - title
      - url
    ChatCompletionResponseMessage_annotations_inner:
      description: |
        A URL citation when using web search.
      example:
        type: url_citation
        url_citation:
          start_index: 1
          end_index: 6
          title: title
          url: url
      properties:
        type:
          description: The type of the URL citation. Always `url_citation`.
          enum:
          - url_citation
          type: string
          x-stainless-const: true
        url_citation:
          $ref: "#/components/schemas/ChatCompletionResponseMessage_annotations_inner_url_citation"
      required:
      - type
      - url_citation
    ChatCompletionResponseMessage_function_call:
      deprecated: true
      description: "Deprecated and replaced by `tool_calls`. The name and arguments\
        \ of a function that should be called, as generated by the model."
      example:
        name: name
        arguments: arguments
      properties:
        arguments:
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function."
          type: string
        name:
          description: The name of the function to call.
          type: string
      required:
      - arguments
      - name
    ChatCompletionResponseMessage_audio:
      description: |
        If the audio output modality is requested, this object contains data
        about the audio response from the model. [Learn more](/docs/guides/audio).
      example:
        expires_at: 5
        transcript: transcript
        data: data
        id: id
      properties:
        id:
          description: Unique identifier for this audio response.
          type: string
        expires_at:
          description: |
            The Unix timestamp (in seconds) for when this audio response will
            no longer be accessible on the server for use in multi-turn
            conversations.
          type: integer
        data:
          description: |
            Base64 encoded audio bytes generated by the model, in the format
            specified in the request.
          type: string
        transcript:
          description: Transcript of the audio generated by the model.
          type: string
      required:
      - data
      - expires_at
      - id
      - transcript
      nullable: true
    ChatCompletionStreamResponseDelta_function_call:
      deprecated: true
      description: "Deprecated and replaced by `tool_calls`. The name and arguments\
        \ of a function that should be called, as generated by the model."
      properties:
        arguments:
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function."
          type: string
        name:
          description: The name of the function to call.
          type: string
    ChatCompletionTokenLogprob_top_logprobs_inner:
      example:
        logprob: 7.061401241503109
        bytes:
        - 9
        - 9
        token: token
      properties:
        token:
          description: The token.
          type: string
        logprob:
          description: "The log probability of this token, if it is within the top\
            \ 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify\
            \ that the token is very unlikely."
          type: number
        bytes:
          description: A list of integers representing the UTF-8 bytes representation
            of the token. Useful in instances where characters are represented by
            multiple tokens and their byte representations must be combined to generate
            the correct text representation. Can be `null` if there is no bytes representation
            for the token.
          items:
            type: integer
          type: array
          nullable: true
      required:
      - bytes
      - logprob
      - token
    CodeInterpreterFileOutput_files_inner:
      properties:
        mime_type:
          description: |
            The MIME type of the file.
          type: string
        file_id:
          description: |
            The ID of the file.
          type: string
      required:
      - file_id
      - mime_type
    CodeInterpreterTool_container:
      description: |
        The code interpreter container. Can be a container ID or an object that
        specifies uploaded file IDs to make available to your code.
      oneOf:
      - description: The container ID.
        type: string
      - $ref: "#/components/schemas/CodeInterpreterToolAuto"
    CodeInterpreterToolCall_outputs_inner:
      oneOf:
      - $ref: "#/components/schemas/CodeInterpreterOutputLogs"
      - $ref: "#/components/schemas/CodeInterpreterOutputImage"
    ComparisonFilter_value:
      description: "The value to compare against the attribute key; supports string,\
        \ number, or boolean types."
      oneOf:
      - type: string
      - type: number
      - type: boolean
    CompletionUsage_completion_tokens_details:
      description: Breakdown of tokens used in a completion.
      example:
        accepted_prediction_tokens: 1
        audio_tokens: 1
        reasoning_tokens: 1
        rejected_prediction_tokens: 6
      properties:
        accepted_prediction_tokens:
          default: 0
          description: |
            When using Predicted Outputs, the number of tokens in the
            prediction that appeared in the completion.
          type: integer
        audio_tokens:
          default: 0
          description: Audio input tokens generated by the model.
          type: integer
        reasoning_tokens:
          default: 0
          description: Tokens generated by the model for reasoning.
          type: integer
        rejected_prediction_tokens:
          default: 0
          description: |
            When using Predicted Outputs, the number of tokens in the
            prediction that did not appear in the completion. However, like
            reasoning tokens, these tokens are still counted in the total
            completion tokens for purposes of billing, output, and context window
            limits.
          type: integer
    CompletionUsage_prompt_tokens_details:
      description: Breakdown of tokens used in the prompt.
      example:
        audio_tokens: 7
        cached_tokens: 1
      properties:
        audio_tokens:
          default: 0
          description: Audio input tokens present in the prompt.
          type: integer
        cached_tokens:
          default: 0
          description: Cached tokens present in the prompt.
          type: integer
    ContainerResource_expires_after:
      description: |
        The container will expire after this time period.
        The anchor is the reference point for the expiration.
        The minutes is the number of minutes after the anchor before the container expires.
      example:
        minutes: 6
        anchor: last_active_at
      properties:
        anchor:
          description: The reference point for the expiration.
          enum:
          - last_active_at
          type: string
        minutes:
          description: The number of minutes after the anchor before the container
            expires.
          type: integer
    CostsResult_amount:
      description: The monetary value in its associated currency.
      properties:
        value:
          description: The numeric value of the cost.
          type: number
        currency:
          description: Lowercase ISO-4217 currency e.g. "usd"
          type: string
    CreateAssistantRequest_model:
      anyOf:
      - {}
      - $ref: "#/components/schemas/AssistantSupportedModels"
      description: |
        ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.
      example: gpt-4o
      x-oaiTypeLabel: string
    CreateAssistantRequest_tool_resources_code_interpreter:
      example:
        file_ids:
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        - file_ids
      properties:
        file_ids:
          default: []
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.
          items:
            type: string
          maxItems: 20
    Auto_Chunking_Strategy:
      additionalProperties: true
      description: The default strategy. This strategy currently uses a `max_chunk_size_tokens`
        of `800` and `chunk_overlap_tokens` of `400`.
      example:
        type: auto
      properties:
        type:
          description: Always `auto`.
          enum:
          - auto
          x-stainless-const: true
      required:
      - type
      title: Auto Chunking Strategy
    Static_Chunking_Strategy_static:
      additionalProperties: true
      properties:
        max_chunk_size_tokens:
          description: The maximum number of tokens in each chunk. The default value
            is `800`. The minimum value is `100` and the maximum value is `4096`.
          maximum: 4096
          minimum: 100
        chunk_overlap_tokens:
          description: |
            The number of tokens that overlap between chunks. The default value is `400`.

            Note that the overlap must not exceed half of `max_chunk_size_tokens`.
      required:
      - chunk_overlap_tokens
      - max_chunk_size_tokens
    Static_Chunking_Strategy:
      additionalProperties: true
      properties:
        type:
          description: Always `static`.
          enum:
          - static
          x-stainless-const: true
        static:
          $ref: "#/components/schemas/Static_Chunking_Strategy_static"
      required:
      - static
      - type
      title: Static Chunking Strategy
    CreateAssistantRequest_tool_resources_file_search_vector_stores_inner_chunking_strategy:
      description: "The chunking strategy used to chunk the file(s). If not set, will\
        \ use the `auto` strategy."
      oneOf:
      - $ref: "#/components/schemas/Auto_Chunking_Strategy"
      - $ref: "#/components/schemas/Static_Chunking_Strategy"
    CreateAssistantRequest_tool_resources_file_search_vector_stores_inner:
      example:
        chunking_strategy:
          type: auto
        metadata:
          key: metadata
        file_ids:
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        - file_ids
      properties:
        file_ids:
          description: |
            A list of [file](/docs/api-reference/files) IDs to add to the vector store. There can be a maximum of 10000 files in a vector store.
          items: {}
          maxItems: 10000
        chunking_strategy:
          $ref: "#/components/schemas/CreateAssistantRequest_tool_resources_file_search_vector_stores_inner_chunking_strategy"
        metadata:
          additionalProperties:
            type: string
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be\nuseful for storing additional information about the object\
            \ in a structured\nformat, and querying for objects via API or the dashboard.\
            \ \n\nKeys are strings with a maximum length of 64 characters. Values\
            \ are strings\nwith a maximum length of 512 characters.\n"
          x-oaiTypeLabel: map
          nullable: true
    CreateAssistantRequest_tool_resources_file_search:
      example:
        vector_store_ids:
        - vector_store_ids
        vector_stores:
        - chunking_strategy:
            type: auto
          metadata:
            key: metadata
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
      oneOf:
      - required:
        - vector_store_ids
      - required:
        - vector_stores
      properties:
        vector_store_ids:
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items: {}
          maxItems: 1
        vector_stores:
          description: |
            A helper to create a [vector store](/docs/api-reference/vector-stores/object) with file_ids and attach it to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items:
            $ref: "#/components/schemas/CreateAssistantRequest_tool_resources_file_search_vector_stores_inner"
          maxItems: 1
    CreateAssistantRequest_tool_resources:
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      example:
        code_interpreter:
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
        file_search:
          vector_store_ids:
          - vector_store_ids
          vector_stores:
          - chunking_strategy:
              type: auto
            metadata:
              key: metadata
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
      properties:
        code_interpreter:
          $ref: "#/components/schemas/CreateAssistantRequest_tool_resources_code_interpreter"
        file_search:
          $ref: "#/components/schemas/CreateAssistantRequest_tool_resources_file_search"
      nullable: true
    Web_search_user_location:
      description: |
        Approximate location parameters for the search.
      example:
        approximate:
          country: country
          city: city
          timezone: timezone
          region: region
        type: approximate
      properties:
        type:
          description: |
            The type of location approximation. Always `approximate`.
          enum:
          - approximate
          type: string
          x-stainless-const: true
        approximate:
          $ref: "#/components/schemas/WebSearchLocation"
      required:
      - approximate
      - type
      nullable: true
    Web_search:
      description: |
        This tool searches the web for relevant results to use in a response.
        Learn more about the [web search tool](/docs/guides/tools-web-search?api-mode=chat).
      example:
        search_context_size: medium
        user_location:
          approximate:
            country: country
            city: city
            timezone: timezone
            region: region
          type: approximate
      properties:
        user_location:
          $ref: "#/components/schemas/Web_search_user_location"
        search_context_size:
          $ref: "#/components/schemas/WebSearchContextSize"
      title: Web search
    CreateChatCompletionRequest_allOf_response_format:
      description: |
        An object specifying the format that the model must output.

        Setting to `{ "type": "json_schema", "json_schema": {...} }` enables
        Structured Outputs which ensures the model will match your supplied JSON
        schema. Learn more in the [Structured Outputs
        guide](/docs/guides/structured-outputs).

        Setting to `{ "type": "json_object" }` enables the older JSON mode, which
        ensures the message the model generates is valid JSON. Using `json_schema`
        is preferred for models that support it.
      oneOf:
      - $ref: "#/components/schemas/ResponseFormatText"
      - $ref: "#/components/schemas/ResponseFormatJsonSchema"
      - $ref: "#/components/schemas/ResponseFormatJsonObject"
    CreateChatCompletionRequest_allOf_audio:
      description: |
        Parameters for audio output. Required when audio output is requested with
        `modalities: ["audio"]`. [Learn more](/docs/guides/audio).
      example:
        voice: ash
        format: wav
      properties:
        voice:
          $ref: "#/components/schemas/VoiceIdsShared"
        format:
          description: |
            Specifies the output audio format. Must be one of `wav`, `mp3`, `flac`,
            `opus`, or `pcm16`.
          enum:
          - wav
          - aac
          - mp3
          - flac
          - opus
          - pcm16
          type: string
      required:
      - format
      - voice
      nullable: true
    CreateChatCompletionRequest_allOf_function_call:
      deprecated: true
      description: |
        Deprecated in favor of `tool_choice`.

        Controls which (if any) function is called by the model.

        `none` means the model will not call a function and instead generates a
        message.

        `auto` means the model can pick between generating a message or calling a
        function.

        Specifying a particular function via `{"name": "my_function"}` forces the
        model to call that function.

        `none` is the default when no functions are present. `auto` is the default
        if functions are present.
      oneOf:
      - description: |
          `none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a function.
        enum:
        - none
        - auto
        type: string
      - $ref: "#/components/schemas/ChatCompletionFunctionCallOption"
    CreateChatCompletionResponse_choices_inner_logprobs:
      description: Log probability information for the choice.
      example:
        refusal:
        - top_logprobs:
          - logprob: 7.061401241503109
            bytes:
            - 9
            - 9
            token: token
          - logprob: 7.061401241503109
            bytes:
            - 9
            - 9
            token: token
          logprob: 5.637376656633329
          bytes:
          - 2
          - 2
          token: token
        - top_logprobs:
          - logprob: 7.061401241503109
            bytes:
            - 9
            - 9
            token: token
          - logprob: 7.061401241503109
            bytes:
            - 9
            - 9
            token: token
          logprob: 5.637376656633329
          bytes:
          - 2
          - 2
          token: token
        content:
        - top_logprobs:
          - logprob: 7.061401241503109
            bytes:
            - 9
            - 9
            token: token
          - logprob: 7.061401241503109
            bytes:
            - 9
            - 9
            token: token
          logprob: 5.637376656633329
          bytes:
          - 2
          - 2
          token: token
        - top_logprobs:
          - logprob: 7.061401241503109
            bytes:
            - 9
            - 9
            token: token
          - logprob: 7.061401241503109
            bytes:
            - 9
            - 9
            token: token
          logprob: 5.637376656633329
          bytes:
          - 2
          - 2
          token: token
      properties:
        content:
          description: A list of message content tokens with log probability information.
          items:
            $ref: "#/components/schemas/ChatCompletionTokenLogprob"
          type: array
          nullable: true
        refusal:
          description: A list of message refusal tokens with log probability information.
          items:
            $ref: "#/components/schemas/ChatCompletionTokenLogprob"
          type: array
          nullable: true
      required:
      - content
      - refusal
      nullable: true
    CreateChatCompletionResponse_choices_inner:
      example:
        finish_reason: stop
        index: 0
        message:
          role: assistant
          function_call:
            name: name
            arguments: arguments
          refusal: refusal
          annotations:
          - type: url_citation
            url_citation:
              start_index: 1
              end_index: 6
              title: title
              url: url
          - type: url_citation
            url_citation:
              start_index: 1
              end_index: 6
              title: title
              url: url
          tool_calls:
          - function:
              name: name
              arguments: arguments
            id: id
            type: function
          - function:
              name: name
              arguments: arguments
            id: id
            type: function
          audio:
            expires_at: 5
            transcript: transcript
            data: data
            id: id
          content: content
        logprobs:
          refusal:
          - top_logprobs:
            - logprob: 7.061401241503109
              bytes:
              - 9
              - 9
              token: token
            - logprob: 7.061401241503109
              bytes:
              - 9
              - 9
              token: token
            logprob: 5.637376656633329
            bytes:
            - 2
            - 2
            token: token
          - top_logprobs:
            - logprob: 7.061401241503109
              bytes:
              - 9
              - 9
              token: token
            - logprob: 7.061401241503109
              bytes:
              - 9
              - 9
              token: token
            logprob: 5.637376656633329
            bytes:
            - 2
            - 2
            token: token
          content:
          - top_logprobs:
            - logprob: 7.061401241503109
              bytes:
              - 9
              - 9
              token: token
            - logprob: 7.061401241503109
              bytes:
              - 9
              - 9
              token: token
            logprob: 5.637376656633329
            bytes:
            - 2
            - 2
            token: token
          - top_logprobs:
            - logprob: 7.061401241503109
              bytes:
              - 9
              - 9
              token: token
            - logprob: 7.061401241503109
              bytes:
              - 9
              - 9
              token: token
            logprob: 5.637376656633329
            bytes:
            - 2
            - 2
            token: token
      properties:
        finish_reason:
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            `content_filter` if content was omitted due to a flag from our content filters,
            `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
          enum:
          - stop
          - length
          - tool_calls
          - content_filter
          - function_call
          type: string
        index:
          description: The index of the choice in the list of choices.
          type: integer
        message:
          $ref: "#/components/schemas/ChatCompletionResponseMessage"
        logprobs:
          $ref: "#/components/schemas/CreateChatCompletionResponse_choices_inner_logprobs"
      required:
      - finish_reason
      - index
      - logprobs
      - message
    CreateChatCompletionStreamResponse_choices_inner:
      properties:
        delta:
          $ref: "#/components/schemas/ChatCompletionStreamResponseDelta"
        logprobs:
          $ref: "#/components/schemas/CreateChatCompletionResponse_choices_inner_logprobs"
        finish_reason:
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            `content_filter` if content was omitted due to a flag from our content filters,
            `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
          enum:
          - stop
          - length
          - tool_calls
          - content_filter
          - function_call
          type: string
          nullable: true
        index:
          description: The index of the choice in the list of choices.
          type: integer
      required:
      - delta
      - finish_reason
      - index
    CreateCompletionRequest_model:
      anyOf:
      - type: string
      - enum:
        - gpt-3.5-turbo-instruct
        - davinci-002
        - babbage-002
        type: string
      description: |
        ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.
      x-oaiTypeLabel: string
    CreateCompletionRequest_prompt:
      default: <|endoftext|>
      description: |
        The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

        Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.
      oneOf:
      - default: ""
        example: This is a test.
        type: string
      - items:
          default: ""
          example: This is a test.
          type: string
        type: array
      - example: "[1212, 318, 257, 1332, 13]"
        items:
          type: integer
        minItems: 1
        type: array
      - example: "[[1212, 318, 257, 1332, 13]]"
        items:
          items:
            type: integer
          minItems: 1
          type: array
        minItems: 1
        type: array
      nullable: true
    CreateCompletionResponse_choices_inner_logprobs:
      example:
        top_logprobs:
        - key: 5.962133916683182
        - key: 5.962133916683182
        token_logprobs:
        - 1.4658129805029452
        - 1.4658129805029452
        tokens:
        - tokens
        - tokens
        text_offset:
        - 6
        - 6
      properties:
        text_offset:
          items:
            type: integer
          type: array
        token_logprobs:
          items:
            type: number
          type: array
        tokens:
          items:
            type: string
          type: array
        top_logprobs:
          items:
            additionalProperties:
              type: number
          type: array
      nullable: true
    CreateCompletionResponse_choices_inner:
      example:
        finish_reason: stop
        index: 0
        text: text
        logprobs:
          top_logprobs:
          - key: 5.962133916683182
          - key: 5.962133916683182
          token_logprobs:
          - 1.4658129805029452
          - 1.4658129805029452
          tokens:
          - tokens
          - tokens
          text_offset:
          - 6
          - 6
      properties:
        finish_reason:
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            or `content_filter` if content was omitted due to a flag from our content filters.
          enum:
          - stop
          - length
          - content_filter
          type: string
        index:
          type: integer
        logprobs:
          $ref: "#/components/schemas/CreateCompletionResponse_choices_inner_logprobs"
        text:
          type: string
      required:
      - finish_reason
      - index
      - logprobs
      - text
    CreateContainerBody_expires_after:
      description: Container expiration time in seconds relative to the 'anchor' time.
      example:
        minutes: 0
        anchor: last_active_at
      properties:
        anchor:
          description: Time anchor for the expiration time. Currently only 'last_active_at'
            is supported.
          enum:
          - last_active_at
          type: string
        minutes:
          type: integer
      required:
      - anchor
      - minutes
    CreateEmbeddingRequest_input:
      description: |
        Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for all embedding models), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens. In addition to the per-input token limit, all embedding  models enforce a maximum of 300,000 tokens summed across all inputs in a  single request.
      example: The quick brown fox jumped over the lazy dog
      oneOf:
      - default: ""
        description: The string that will be turned into an embedding.
        example: This is a test.
        title: string
        type: string
      - description: The array of strings that will be turned into an embedding.
        items:
          default: ""
          example: "['This is a test.']"
          type: string
        maxItems: 2048
        minItems: 1
        type: array
      - description: The array of integers that will be turned into an embedding.
        example: "[1212, 318, 257, 1332, 13]"
        items:
          type: integer
        maxItems: 2048
        minItems: 1
        type: array
      - description: The array of arrays containing integers that will be turned into
          an embedding.
        example: "[[1212, 318, 257, 1332, 13]]"
        items:
          items:
            type: integer
          minItems: 1
          type: array
        maxItems: 2048
        minItems: 1
        type: array
    CreateEmbeddingRequest_model:
      anyOf:
      - type: string
      - enum:
        - text-embedding-ada-002
        - text-embedding-3-small
        - text-embedding-3-large
        type: string
      description: |
        ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.
      example: text-embedding-3-small
      x-oaiTypeLabel: string
    CreateEmbeddingResponse_usage:
      description: The usage information for the request.
      example:
        prompt_tokens: 1
        total_tokens: 5
      properties:
        prompt_tokens:
          description: The number of tokens used by the prompt.
          type: integer
        total_tokens:
          description: The total number of tokens used by the request.
          type: integer
      required:
      - prompt_tokens
      - total_tokens
    TemplateInputMessages_template_inner:
      oneOf:
      - $ref: "#/components/schemas/EasyInputMessage"
      - $ref: "#/components/schemas/EvalItem"
    TemplateInputMessages:
      properties:
        type:
          description: The type of input messages. Always `template`.
          enum:
          - template
          type: string
        template:
          description: "A list of chat messages forming the prompt or context. May\
            \ include variable references to the `item` namespace, ie {{item.name}}."
          items:
            $ref: "#/components/schemas/TemplateInputMessages_template_inner"
          type: array
      required:
      - template
      - type
      title: TemplateInputMessages
    ItemReferenceInputMessages:
      properties:
        type:
          description: The type of input messages. Always `item_reference`.
          enum:
          - item_reference
          type: string
        item_reference:
          description: "A reference to a variable in the `item` namespace. Ie, \"\
            item.input_trajectory\""
          type: string
      required:
      - item_reference
      - type
      title: ItemReferenceInputMessages
    CreateEvalCompletionsRunDataSource_input_messages:
      description: "Used when sampling from a model. Dictates the structure of the\
        \ messages passed into the model. Can either be a reference to a prebuilt\
        \ trajectory (ie, `item.input_trajectory`), or a template with variable references\
        \ to the `item` namespace."
      oneOf:
      - $ref: "#/components/schemas/TemplateInputMessages"
      - $ref: "#/components/schemas/ItemReferenceInputMessages"
    CreateEvalCompletionsRunDataSource_sampling_params:
      properties:
        temperature:
          default: 1
          description: A higher temperature increases randomness in the outputs.
          type: number
        max_completion_tokens:
          description: The maximum number of tokens in the generated output.
          type: integer
        top_p:
          default: 1
          description: An alternative to temperature for nucleus sampling; 1.0 includes
            all tokens.
          type: number
        seed:
          default: 42
          description: "A seed value to initialize the randomness, during sampling."
          type: integer
        response_format:
          $ref: "#/components/schemas/CreateChatCompletionRequest_allOf_response_format"
        tools:
          description: |
            A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.
          items:
            $ref: "#/components/schemas/ChatCompletionTool"
          type: array
    CreateEvalCompletionsRunDataSource_source:
      description: Determines what populates the `item` namespace in this run's data
        source.
      oneOf:
      - $ref: "#/components/schemas/EvalJsonlFileContentSource"
      - $ref: "#/components/schemas/EvalJsonlFileIdSource"
      - $ref: "#/components/schemas/EvalStoredCompletionsSource"
    SimpleInputMessage:
      example:
        role: role
        content: content
      properties:
        role:
          description: "The role of the message (e.g. \"system\", \"assistant\", \"\
            user\")."
          type: string
        content:
          description: The content of the message.
          type: string
      required:
      - content
      - role
      title: SimpleInputMessage
    CreateEvalJsonlRunDataSource_source:
      description: Determines what populates the `item` namespace in the data source.
      oneOf:
      - $ref: "#/components/schemas/EvalJsonlFileContentSource"
      - $ref: "#/components/schemas/EvalJsonlFileIdSource"
    CreateEvalRequest_data_source_config:
      description: The configuration for the data source used for the evaluation runs.
        Dictates the schema of the data used in the evaluation.
      oneOf:
      - $ref: "#/components/schemas/CreateEvalCustomDataSourceConfig"
      - $ref: "#/components/schemas/CreateEvalLogsDataSourceConfig"
      - $ref: "#/components/schemas/CreateEvalStoredCompletionsDataSourceConfig"
    CreateEvalRequest_testing_criteria_inner:
      oneOf:
      - $ref: "#/components/schemas/CreateEvalLabelModelGrader"
      - $ref: "#/components/schemas/EvalGraderStringCheck"
      - $ref: "#/components/schemas/EvalGraderTextSimilarity"
      - $ref: "#/components/schemas/EvalGraderPython"
      - $ref: "#/components/schemas/EvalGraderScoreModel"
    ChatMessage:
      properties:
        role:
          description: "The role of the message (e.g. \"system\", \"assistant\", \"\
            user\")."
          type: string
        content:
          description: The content of the message.
          type: string
      required:
      - content
      - role
      title: ChatMessage
    InputMessagesTemplate_template_inner:
      oneOf:
      - $ref: "#/components/schemas/ChatMessage"
      - $ref: "#/components/schemas/EvalItem"
    InputMessagesTemplate:
      properties:
        type:
          description: The type of input messages. Always `template`.
          enum:
          - template
          type: string
        template:
          description: "A list of chat messages forming the prompt or context. May\
            \ include variable references to the `item` namespace, ie {{item.name}}."
          items:
            $ref: "#/components/schemas/InputMessagesTemplate_template_inner"
          type: array
      required:
      - template
      - type
      title: InputMessagesTemplate
    InputMessagesItemReference:
      properties:
        type:
          description: The type of input messages. Always `item_reference`.
          enum:
          - item_reference
          type: string
        item_reference:
          description: "A reference to a variable in the `item` namespace. Ie, \"\
            item.name\""
          type: string
      required:
      - item_reference
      - type
      title: InputMessagesItemReference
    CreateEvalResponsesRunDataSource_input_messages:
      description: "Used when sampling from a model. Dictates the structure of the\
        \ messages passed into the model. Can either be a reference to a prebuilt\
        \ trajectory (ie, `item.input_trajectory`), or a template with variable references\
        \ to the `item` namespace."
      oneOf:
      - $ref: "#/components/schemas/InputMessagesTemplate"
      - $ref: "#/components/schemas/InputMessagesItemReference"
    CreateEvalResponsesRunDataSource_sampling_params_text:
      description: |
        Configuration options for a text response from the model. Can be plain
        text or structured JSON data. Learn more:
        - [Text inputs and outputs](/docs/guides/text)
        - [Structured Outputs](/docs/guides/structured-outputs)
      example:
        format:
          type: text
      properties:
        format:
          $ref: "#/components/schemas/TextResponseFormatConfiguration"
    CreateEvalResponsesRunDataSource_sampling_params:
      properties:
        temperature:
          default: 1
          description: A higher temperature increases randomness in the outputs.
          type: number
        max_completion_tokens:
          description: The maximum number of tokens in the generated output.
          type: integer
        top_p:
          default: 1
          description: An alternative to temperature for nucleus sampling; 1.0 includes
            all tokens.
          type: number
        seed:
          default: 42
          description: "A seed value to initialize the randomness, during sampling."
          type: integer
        tools:
          description: |
            An array of tools the model may call while generating a response. You
            can specify which tool to use by setting the `tool_choice` parameter.

            The two categories of tools you can provide the model are:

            - **Built-in tools**: Tools that are provided by OpenAI that extend the
              model's capabilities, like [web search](/docs/guides/tools-web-search)
              or [file search](/docs/guides/tools-file-search). Learn more about
              [built-in tools](/docs/guides/tools).
            - **Function calls (custom tools)**: Functions that are defined by you,
              enabling the model to call your own code. Learn more about
              [function calling](/docs/guides/function-calling).
          items:
            $ref: "#/components/schemas/Tool"
          type: array
        text:
          $ref: "#/components/schemas/CreateEvalResponsesRunDataSource_sampling_params_text"
    CreateEvalResponsesRunDataSource_source:
      description: Determines what populates the `item` namespace in this run's data
        source.
      oneOf:
      - $ref: "#/components/schemas/EvalJsonlFileContentSource"
      - $ref: "#/components/schemas/EvalJsonlFileIdSource"
      - $ref: "#/components/schemas/EvalResponsesSource"
    CreateEvalRunRequest_data_source:
      description: Details about the run's data source.
      oneOf:
      - $ref: "#/components/schemas/CreateEvalJsonlRunDataSource"
      - $ref: "#/components/schemas/CreateEvalCompletionsRunDataSource"
      - $ref: "#/components/schemas/CreateEvalResponsesRunDataSource"
    CreateFineTuningJobRequest_model:
      anyOf:
      - type: string
      - enum:
        - babbage-002
        - davinci-002
        - gpt-3.5-turbo
        - gpt-4o-mini
        type: string
      description: |
        The name of the model to fine-tune. You can select one of the
        [supported models](/docs/guides/fine-tuning#which-models-can-be-fine-tuned).
      example: gpt-4o-mini
      x-oaiTypeLabel: string
    CreateFineTuningJobRequest_hyperparameters_batch_size:
      default: auto
      description: |
        Number of examples in each batch. A larger batch size means that model parameters
        are updated less frequently, but with lower variance.
      oneOf:
      - enum:
        - auto
        type: string
        x-stainless-const: true
      - maximum: 256
        minimum: 1
        type: integer
    CreateFineTuningJobRequest_hyperparameters_learning_rate_multiplier:
      default: auto
      description: |
        Scaling factor for the learning rate. A smaller learning rate may be useful to avoid
        overfitting.
      oneOf:
      - enum:
        - auto
        type: string
        x-stainless-const: true
      - minimum: 0
        type: number
    CreateFineTuningJobRequest_hyperparameters_n_epochs:
      default: auto
      description: |
        The number of epochs to train the model for. An epoch refers to one full cycle
        through the training dataset.
      oneOf:
      - enum:
        - auto
        type: string
        x-stainless-const: true
      - maximum: 50
        minimum: 1
        type: integer
    CreateFineTuningJobRequest_hyperparameters:
      deprecated: true
      description: |
        The hyperparameters used for the fine-tuning job.
        This value is now deprecated in favor of `method`, and should be passed in under the `method` parameter.
      example:
        batch_size: auto
        n_epochs: auto
        learning_rate_multiplier: auto
      properties:
        batch_size:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_hyperparameters_batch_size"
        learning_rate_multiplier:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_hyperparameters_learning_rate_multiplier"
        n_epochs:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_hyperparameters_n_epochs"
    CreateFineTuningJobRequest_integrations_inner_wandb:
      description: |
        The settings for your integration with Weights and Biases. This payload specifies the project that
        metrics will be sent to. Optionally, you can set an explicit display name for your run, add tags
        to your run, and set a default entity (team, username, etc) to be associated with your run.
      example:
        name: name
        project: my-wandb-project
        entity: entity
        tags:
        - custom-tag
        - custom-tag
      properties:
        project:
          description: |
            The name of the project that the new run will be created under.
          example: my-wandb-project
          type: string
        name:
          description: |
            A display name to set for the run. If not set, we will use the Job ID as the name.
          type: string
          nullable: true
        entity:
          description: |
            The entity to use for the run. This allows you to set the team or username of the WandB user that you would
            like associated with the run. If not set, the default entity for the registered WandB API key is used.
          type: string
          nullable: true
        tags:
          description: |
            A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some
            default tags are generated by OpenAI: "openai/finetune", "openai/{base-model}", "openai/{ftjob-abcdef}".
          items:
            example: custom-tag
            type: string
          type: array
      required:
      - project
    CreateFineTuningJobRequest_integrations_inner:
      example:
        wandb:
          name: name
          project: my-wandb-project
          entity: entity
          tags:
          - custom-tag
          - custom-tag
        type: wandb
      properties:
        type:
          enum:
          - wandb
          type: string
          x-stainless-const: true
        wandb:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_integrations_inner_wandb"
      required:
      - type
      - wandb
    CreateImageEditRequest_image:
      anyOf:
      - format: binary
        type: string
      - items:
          format: binary
          type: string
        maxItems: 16
        type: array
      description: "The image(s) to edit. Must be a supported image file or an array\
        \ of images.\n\nFor `gpt-image-1`, each image should be a `png`, `webp`, or\
        \ `jpg` file less \nthan 50MB. You can provide up to 16 images.\n\nFor `dall-e-2`,\
        \ you can only provide one image, and it should be a square \n`png` file less\
        \ than 4MB.\n"
    CreateImageEditRequest_model:
      anyOf:
      - type: string
      - enum:
        - dall-e-2
        - gpt-image-1
        type: string
        x-stainless-const: true
      default: dall-e-2
      description: The model to use for image generation. Only `dall-e-2` and `gpt-image-1`
        are supported. Defaults to `dall-e-2` unless a parameter specific to `gpt-image-1`
        is used.
      example: gpt-image-1
      x-oaiTypeLabel: string
      nullable: true
    CreateImageRequest_model:
      anyOf:
      - type: string
      - enum:
        - dall-e-2
        - dall-e-3
        - gpt-image-1
        type: string
      default: dall-e-2
      description: "The model to use for image generation. One of `dall-e-2`, `dall-e-3`,\
        \ or `gpt-image-1`. Defaults to `dall-e-2` unless a parameter specific to\
        \ `gpt-image-1` is used."
      example: gpt-image-1
      x-oaiTypeLabel: string
      nullable: true
    CreateImageVariationRequest_model:
      anyOf:
      - type: string
      - enum:
        - dall-e-2
        type: string
        x-stainless-const: true
      default: dall-e-2
      description: The model to use for image generation. Only `dall-e-2` is supported
        at this time.
      example: dall-e-2
      x-oaiTypeLabel: string
      nullable: true
    CreateMessageRequest_content_oneOf_inner:
      oneOf:
      - $ref: "#/components/schemas/MessageContentImageFileObject"
      - $ref: "#/components/schemas/MessageContentImageUrlObject"
      - $ref: "#/components/schemas/MessageRequestContentTextObject"
    CreateMessageRequest_content:
      oneOf:
      - description: The text contents of the message.
        title: Text content
        type: string
      - description: "An array of content parts with a defined type, each can be of\
          \ type `text` or images can be passed with `image_url` or `image_file`.\
          \ Image types are only supported on [Vision-compatible models](/docs/models)."
        items:
          $ref: "#/components/schemas/CreateMessageRequest_content_oneOf_inner"
        minItems: 1
        type: array
    CreateMessageRequest_attachments_inner_tools_inner:
      oneOf:
      - $ref: "#/components/schemas/AssistantToolsCode"
      - $ref: "#/components/schemas/AssistantToolsFileSearchTypeOnly"
    CreateMessageRequest_attachments_inner:
      example:
        file_id: file_id
        tools:
        - type: code_interpreter
        - type: code_interpreter
      properties:
        file_id:
          description: The ID of the file to attach to the message.
          type: string
        tools:
          description: The tools to add this file to.
          items:
            $ref: "#/components/schemas/CreateMessageRequest_attachments_inner_tools_inner"
          type: array
    CreateModerationRequest_input_oneOf_inner_oneOf_image_url:
      description: Contains either an image URL or a data URL for a base64 encoded
        image.
      properties:
        url:
          description: Either a URL of the image or the base64 encoded image data.
          example: https://example.com/image.jpg
          format: uri
          type: string
      required:
      - url
    CreateModerationRequest_input_oneOf_inner_oneOf:
      description: An object describing an image to classify.
      properties:
        type:
          description: Always `image_url`.
          enum:
          - image_url
          type: string
          x-stainless-const: true
        image_url:
          $ref: "#/components/schemas/CreateModerationRequest_input_oneOf_inner_oneOf_image_url"
      required:
      - image_url
      - type
    CreateModerationRequest_input_oneOf_inner_oneOf_1:
      description: An object describing text to classify.
      properties:
        type:
          description: Always `text`.
          enum:
          - text
          type: string
          x-stainless-const: true
        text:
          description: A string of text to classify.
          example: I want to kill them
          type: string
      required:
      - text
      - type
    CreateModerationRequest_input_oneOf_inner:
      oneOf:
      - $ref: "#/components/schemas/CreateModerationRequest_input_oneOf_inner_oneOf"
      - $ref: "#/components/schemas/CreateModerationRequest_input_oneOf_inner_oneOf_1"
    CreateModerationRequest_input:
      description: |
        Input (or inputs) to classify. Can be a single string, an array of strings, or
        an array of multi-modal input objects similar to other models.
      oneOf:
      - default: ""
        description: A string of text to classify for moderation.
        example: I want to kill them.
        type: string
      - description: An array of strings to classify for moderation.
        items:
          default: ""
          example: I want to kill them.
          type: string
        type: array
      - description: An array of multi-modal inputs to the moderation model.
        items:
          $ref: "#/components/schemas/CreateModerationRequest_input_oneOf_inner"
        type: array
    CreateModerationRequest_model:
      anyOf:
      - type: string
      - enum:
        - omni-moderation-latest
        - omni-moderation-2024-09-26
        - text-moderation-latest
        - text-moderation-stable
        type: string
      default: omni-moderation-latest
      description: |
        The content moderation model you would like to use. Learn more in
        [the moderation guide](/docs/guides/moderation), and learn about
        available models [here](/docs/models#moderation).
      example: omni-moderation-2024-09-26
      x-oaiTypeLabel: string
      nullable: false
    CreateModerationResponse_results_inner_categories:
      description: "A list of the categories, and whether they are flagged or not."
      example:
        illicit/violent: true
        self-harm/instructions: true
        harassment: true
        violence/graphic: true
        illicit: true
        self-harm/intent: true
        hate/threatening: true
        sexual/minors: true
        harassment/threatening: true
        hate: true
        self-harm: true
        sexual: true
        violence: true
      properties:
        hate:
          description: "Content that expresses, incites, or promotes hate based on\
            \ race, gender, ethnicity, religion, nationality, sexual orientation,\
            \ disability status, or caste. Hateful content aimed at non-protected\
            \ groups (e.g., chess players) is harassment."
          type: boolean
        hate/threatening:
          description: "Hateful content that also includes violence or serious harm\
            \ towards the targeted group based on race, gender, ethnicity, religion,\
            \ nationality, sexual orientation, disability status, or caste."
          type: boolean
        harassment:
          description: "Content that expresses, incites, or promotes harassing language\
            \ towards any target."
          type: boolean
        harassment/threatening:
          description: Harassment content that also includes violence or serious harm
            towards any target.
          type: boolean
        illicit:
          description: "Content that includes instructions or advice that facilitate\
            \ the planning or execution of wrongdoing, or that gives advice or instruction\
            \ on how to commit illicit acts. For example, \"how to shoplift\" would\
            \ fit this category."
          type: boolean
          nullable: true
        illicit/violent:
          description: "Content that includes instructions or advice that facilitate\
            \ the planning or execution of wrongdoing that also includes violence,\
            \ or that gives advice or instruction on the procurement of any weapon."
          type: boolean
          nullable: true
        self-harm:
          description: "Content that promotes, encourages, or depicts acts of self-harm,\
            \ such as suicide, cutting, and eating disorders."
          type: boolean
        self-harm/intent:
          description: "Content where the speaker expresses that they are engaging\
            \ or intend to engage in acts of self-harm, such as suicide, cutting,\
            \ and eating disorders."
          type: boolean
        self-harm/instructions:
          description: "Content that encourages performing acts of self-harm, such\
            \ as suicide, cutting, and eating disorders, or that gives instructions\
            \ or advice on how to commit such acts."
          type: boolean
        sexual:
          description: "Content meant to arouse sexual excitement, such as the description\
            \ of sexual activity, or that promotes sexual services (excluding sex\
            \ education and wellness)."
          type: boolean
        sexual/minors:
          description: Sexual content that includes an individual who is under 18
            years old.
          type: boolean
        violence:
          description: "Content that depicts death, violence, or physical injury."
          type: boolean
        violence/graphic:
          description: "Content that depicts death, violence, or physical injury in\
            \ graphic detail."
          type: boolean
      required:
      - harassment
      - harassment/threatening
      - hate
      - hate/threatening
      - illicit
      - illicit/violent
      - self-harm
      - self-harm/instructions
      - self-harm/intent
      - sexual
      - sexual/minors
      - violence
      - violence/graphic
    CreateModerationResponse_results_inner_category_scores:
      description: A list of the categories along with their scores as predicted by
        model.
      example:
        illicit/violent: 2.3021358869347655
        self-harm/instructions: 3.616076749251911
        harassment: 1.4658129805029452
        violence/graphic: 1.2315135367772556
        illicit: 5.637376656633329
        self-harm/intent: 9.301444243932576
        hate/threatening: 6.027456183070403
        sexual/minors: 4.145608029883936
        harassment/threatening: 5.962133916683182
        hate: 0.8008281904610115
        self-harm: 7.061401241503109
        sexual: 2.027123023002322
        violence: 7.386281948385884
      properties:
        hate:
          description: The score for the category 'hate'.
          type: number
        hate/threatening:
          description: The score for the category 'hate/threatening'.
          type: number
        harassment:
          description: The score for the category 'harassment'.
          type: number
        harassment/threatening:
          description: The score for the category 'harassment/threatening'.
          type: number
        illicit:
          description: The score for the category 'illicit'.
          type: number
        illicit/violent:
          description: The score for the category 'illicit/violent'.
          type: number
        self-harm:
          description: The score for the category 'self-harm'.
          type: number
        self-harm/intent:
          description: The score for the category 'self-harm/intent'.
          type: number
        self-harm/instructions:
          description: The score for the category 'self-harm/instructions'.
          type: number
        sexual:
          description: The score for the category 'sexual'.
          type: number
        sexual/minors:
          description: The score for the category 'sexual/minors'.
          type: number
        violence:
          description: The score for the category 'violence'.
          type: number
        violence/graphic:
          description: The score for the category 'violence/graphic'.
          type: number
      required:
      - harassment
      - harassment/threatening
      - hate
      - hate/threatening
      - illicit
      - illicit/violent
      - self-harm
      - self-harm/instructions
      - self-harm/intent
      - sexual
      - sexual/minors
      - violence
      - violence/graphic
    CreateModerationResponse_results_inner_category_applied_input_types:
      description: A list of the categories along with the input type(s) that the
        score applies to.
      example:
        illicit/violent:
        - text
        - text
        self-harm/instructions:
        - text
        - text
        harassment:
        - text
        - text
        violence/graphic:
        - text
        - text
        illicit:
        - text
        - text
        self-harm/intent:
        - text
        - text
        hate/threatening:
        - text
        - text
        sexual/minors:
        - text
        - text
        harassment/threatening:
        - text
        - text
        hate:
        - text
        - text
        self-harm:
        - text
        - text
        sexual:
        - text
        - text
        violence:
        - text
        - text
      properties:
        hate:
          description: The applied input type(s) for the category 'hate'.
          items:
            enum:
            - text
            type: string
            x-stainless-const: true
          type: array
        hate/threatening:
          description: The applied input type(s) for the category 'hate/threatening'.
          items:
            enum:
            - text
            type: string
            x-stainless-const: true
          type: array
        harassment:
          description: The applied input type(s) for the category 'harassment'.
          items:
            enum:
            - text
            type: string
            x-stainless-const: true
          type: array
        harassment/threatening:
          description: The applied input type(s) for the category 'harassment/threatening'.
          items:
            enum:
            - text
            type: string
            x-stainless-const: true
          type: array
        illicit:
          description: The applied input type(s) for the category 'illicit'.
          items:
            enum:
            - text
            type: string
            x-stainless-const: true
          type: array
        illicit/violent:
          description: The applied input type(s) for the category 'illicit/violent'.
          items:
            enum:
            - text
            type: string
            x-stainless-const: true
          type: array
        self-harm:
          description: The applied input type(s) for the category 'self-harm'.
          items:
            enum:
            - text
            - image
            type: string
          type: array
        self-harm/intent:
          description: The applied input type(s) for the category 'self-harm/intent'.
          items:
            enum:
            - text
            - image
            type: string
          type: array
        self-harm/instructions:
          description: The applied input type(s) for the category 'self-harm/instructions'.
          items:
            enum:
            - text
            - image
            type: string
          type: array
        sexual:
          description: The applied input type(s) for the category 'sexual'.
          items:
            enum:
            - text
            - image
            type: string
          type: array
        sexual/minors:
          description: The applied input type(s) for the category 'sexual/minors'.
          items:
            enum:
            - text
            type: string
            x-stainless-const: true
          type: array
        violence:
          description: The applied input type(s) for the category 'violence'.
          items:
            enum:
            - text
            - image
            type: string
          type: array
        violence/graphic:
          description: The applied input type(s) for the category 'violence/graphic'.
          items:
            enum:
            - text
            - image
            type: string
          type: array
      required:
      - harassment
      - harassment/threatening
      - hate
      - hate/threatening
      - illicit
      - illicit/violent
      - self-harm
      - self-harm/instructions
      - self-harm/intent
      - sexual
      - sexual/minors
      - violence
      - violence/graphic
    CreateModerationResponse_results_inner:
      example:
        category_scores:
          illicit/violent: 2.3021358869347655
          self-harm/instructions: 3.616076749251911
          harassment: 1.4658129805029452
          violence/graphic: 1.2315135367772556
          illicit: 5.637376656633329
          self-harm/intent: 9.301444243932576
          hate/threatening: 6.027456183070403
          sexual/minors: 4.145608029883936
          harassment/threatening: 5.962133916683182
          hate: 0.8008281904610115
          self-harm: 7.061401241503109
          sexual: 2.027123023002322
          violence: 7.386281948385884
        flagged: true
        category_applied_input_types:
          illicit/violent:
          - text
          - text
          self-harm/instructions:
          - text
          - text
          harassment:
          - text
          - text
          violence/graphic:
          - text
          - text
          illicit:
          - text
          - text
          self-harm/intent:
          - text
          - text
          hate/threatening:
          - text
          - text
          sexual/minors:
          - text
          - text
          harassment/threatening:
          - text
          - text
          hate:
          - text
          - text
          self-harm:
          - text
          - text
          sexual:
          - text
          - text
          violence:
          - text
          - text
        categories:
          illicit/violent: true
          self-harm/instructions: true
          harassment: true
          violence/graphic: true
          illicit: true
          self-harm/intent: true
          hate/threatening: true
          sexual/minors: true
          harassment/threatening: true
          hate: true
          self-harm: true
          sexual: true
          violence: true
      properties:
        flagged:
          description: Whether any of the below categories are flagged.
          type: boolean
        categories:
          $ref: "#/components/schemas/CreateModerationResponse_results_inner_categories"
        category_scores:
          $ref: "#/components/schemas/CreateModerationResponse_results_inner_category_scores"
        category_applied_input_types:
          $ref: "#/components/schemas/CreateModerationResponse_results_inner_category_applied_input_types"
      required:
      - categories
      - category_applied_input_types
      - category_scores
      - flagged
    CreateResponse_allOf_input:
      description: |
        Text, image, or file inputs to the model, used to generate a response.

        Learn more:
        - [Text inputs and outputs](/docs/guides/text)
        - [Image inputs](/docs/guides/images)
        - [File inputs](/docs/guides/pdf-files)
        - [Conversation state](/docs/guides/conversation-state)
        - [Function calling](/docs/guides/function-calling)
      oneOf:
      - description: |
          A text input to the model, equivalent to a text input with the
          `user` role.
        title: Text input
        type: string
      - description: |
          A list of one or many input items to the model, containing
          different content types.
        items:
          $ref: "#/components/schemas/InputItem"
        type: array
    CreateRunRequest_model:
      anyOf:
      - type: string
      - $ref: "#/components/schemas/AssistantSupportedModels"
      description: "The ID of the [Model](/docs/api-reference/models) to be used to\
        \ execute this run. If a value is provided here, it will override the model\
        \ associated with the assistant. If not, the model associated with the assistant\
        \ will be used."
      example: gpt-4o
      x-oaiTypeLabel: string
      nullable: true
    CreateSpeechRequest_model:
      anyOf:
      - type: string
      - enum:
        - tts-1
        - tts-1-hd
        - gpt-4o-mini-tts
        type: string
      description: |
        One of the available [TTS models](/docs/models#tts): `tts-1`, `tts-1-hd` or `gpt-4o-mini-tts`.
      x-oaiTypeLabel: string
    CreateThreadAndRunRequest_model:
      anyOf:
      - type: string
      - enum:
        - gpt-4.1
        - gpt-4.1-mini
        - gpt-4.1-nano
        - gpt-4.1-2025-04-14
        - gpt-4.1-mini-2025-04-14
        - gpt-4.1-nano-2025-04-14
        - gpt-4o
        - gpt-4o-2024-11-20
        - gpt-4o-2024-08-06
        - gpt-4o-2024-05-13
        - gpt-4o-mini
        - gpt-4o-mini-2024-07-18
        - gpt-4.5-preview
        - gpt-4.5-preview-2025-02-27
        - gpt-4-turbo
        - gpt-4-turbo-2024-04-09
        - gpt-4-0125-preview
        - gpt-4-turbo-preview
        - gpt-4-1106-preview
        - gpt-4-vision-preview
        - gpt-4
        - gpt-4-0314
        - gpt-4-0613
        - gpt-4-32k
        - gpt-4-32k-0314
        - gpt-4-32k-0613
        - gpt-3.5-turbo
        - gpt-3.5-turbo-16k
        - gpt-3.5-turbo-0613
        - gpt-3.5-turbo-1106
        - gpt-3.5-turbo-0125
        - gpt-3.5-turbo-16k-0613
        type: string
      description: "The ID of the [Model](/docs/api-reference/models) to be used to\
        \ execute this run. If a value is provided here, it will override the model\
        \ associated with the assistant. If not, the model associated with the assistant\
        \ will be used."
      example: gpt-4o
      x-oaiTypeLabel: string
      nullable: true
    CreateThreadAndRunRequest_tool_resources_code_interpreter:
      example:
        file_ids:
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        - file_ids
      properties:
        file_ids:
          default: []
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.
          items:
            type: string
          maxItems: 20
          type: array
    CreateThreadAndRunRequest_tool_resources:
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      example:
        code_interpreter:
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
        file_search:
          vector_store_ids:
          - vector_store_ids
      properties:
        code_interpreter:
          $ref: "#/components/schemas/CreateThreadAndRunRequest_tool_resources_code_interpreter"
        file_search:
          $ref: "#/components/schemas/AssistantObject_tool_resources_file_search"
      nullable: true
    CreateThreadRequest_tool_resources_code_interpreter:
      example:
        file_ids:
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        - file_ids
      properties:
        file_ids:
          default: []
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.
          items: {}
          maxItems: 20
    CreateThreadRequest_tool_resources_file_search:
      example:
        vector_store_ids:
        - vector_store_ids
        vector_stores:
        - chunking_strategy:
            type: auto
          metadata:
            key: metadata
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
      oneOf:
      - required:
        - vector_store_ids
      - required:
        - vector_stores
      properties:
        vector_store_ids:
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.
          items: {}
          maxItems: 1
        vector_stores:
          description: |
            A helper to create a [vector store](/docs/api-reference/vector-stores/object) with file_ids and attach it to this thread. There can be a maximum of 1 vector store attached to the thread.
          items:
            $ref: "#/components/schemas/CreateAssistantRequest_tool_resources_file_search_vector_stores_inner"
          maxItems: 1
    CreateThreadRequest_tool_resources:
      description: |
        A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      example:
        code_interpreter:
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
        file_search:
          vector_store_ids:
          - vector_store_ids
          vector_stores:
          - chunking_strategy:
              type: auto
            metadata:
              key: metadata
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
      properties:
        code_interpreter:
          $ref: "#/components/schemas/CreateThreadRequest_tool_resources_code_interpreter"
        file_search:
          $ref: "#/components/schemas/CreateThreadRequest_tool_resources_file_search"
      nullable: true
    CreateTranscriptionRequest_model:
      anyOf:
      - type: string
      - enum:
        - whisper-1
        - gpt-4o-transcribe
        - gpt-4o-mini-transcribe
        type: string
        x-stainless-const: true
      description: |
        ID of the model to use. The options are `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, and `whisper-1` (which is powered by our open source Whisper V2 model).
      example: gpt-4o-transcribe
      x-oaiTypeLabel: string
    CreateTranscriptionRequest_chunking_strategy:
      anyOf:
      - default:
        - auto
        description: |
          Automatically set chunking parameters based on the audio. Must be set to `"auto"`.
        enum:
        - auto
        type: string
        x-stainless-const: true
      - $ref: "#/components/schemas/VadConfig"
      description: "Controls how the audio is cut into chunks. When set to `\"auto\"\
        `, the server first normalizes loudness and then uses voice activity detection\
        \ (VAD) to choose boundaries. `server_vad` object can be provided to tweak\
        \ VAD detection parameters manually. If unset, the audio is transcribed as\
        \ a single block. "
      x-oaiTypeLabel: string
      nullable: true
    CreateTranscriptionResponseJson_logprobs_inner:
      example:
        logprob: 0.8008281904610115
        bytes:
        - 6.027456183070403
        - 6.027456183070403
        token: token
      properties:
        token:
          description: The token in the transcription.
          type: string
        logprob:
          description: The log probability of the token.
          type: number
        bytes:
          description: The bytes of the token.
          items:
            type: number
          type: array
    CreateTranscriptionResponseJson_usage:
      description: Token usage statistics for the request.
      oneOf:
      - $ref: "#/components/schemas/TranscriptTextUsageTokens"
      - $ref: "#/components/schemas/TranscriptTextUsageDuration"
    CreateTranslationRequest_model:
      anyOf:
      - type: string
      - enum:
        - whisper-1
        type: string
        x-stainless-const: true
      description: |
        ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.
      example: whisper-1
      x-oaiTypeLabel: string
    CreateVectorStoreRequest_chunking_strategy:
      description: "The chunking strategy used to chunk the file(s). If not set, will\
        \ use the `auto` strategy. Only applicable if `file_ids` is non-empty."
      oneOf:
      - $ref: "#/components/schemas/AutoChunkingStrategyRequestParam"
      - $ref: "#/components/schemas/StaticChunkingStrategyRequestParam"
    EasyInputMessage_content:
      description: |
        Text, image, or audio input to the model, used to generate a response.
        Can also contain previous assistant responses.
      oneOf:
      - description: |
          A text input to the model.
        title: Text input
        type: string
      - $ref: "#/components/schemas/InputMessageContentList"
    Eval_data_source_config:
      description: Configuration of data sources used in runs of the evaluation.
      oneOf:
      - $ref: "#/components/schemas/EvalCustomDataSourceConfig"
      - $ref: "#/components/schemas/EvalLogsDataSourceConfig"
      - $ref: "#/components/schemas/EvalStoredCompletionsDataSourceConfig"
    Eval_testing_criteria_inner:
      oneOf:
      - $ref: "#/components/schemas/EvalGraderLabelModel"
      - $ref: "#/components/schemas/EvalGraderStringCheck"
      - $ref: "#/components/schemas/EvalGraderTextSimilarity"
      - $ref: "#/components/schemas/EvalGraderPython"
      - $ref: "#/components/schemas/EvalGraderScoreModel"
    Output_text:
      description: |
        A text output from the model.
      properties:
        type:
          description: |
            The type of the output text. Always `output_text`.
          enum:
          - output_text
          type: string
          x-stainless-const: true
        text:
          description: |
            The text output from the model.
          type: string
      required:
      - text
      - type
      title: Output text
    EvalItem_content:
      description: |
        Text inputs to the model - can contain template strings.
      oneOf:
      - description: |
          A text input to the model.
        title: Text input
        type: string
      - $ref: "#/components/schemas/InputTextContent"
      - $ref: "#/components/schemas/Output_text"
    EvalJsonlFileContentSource_content_inner:
      example:
        item:
          key: ""
        sample:
          key: ""
      properties:
        item:
          additionalProperties: true
          type: object
        sample:
          additionalProperties: true
          type: object
      required:
      - item
    EvalRun_result_counts:
      description: Counters summarizing the outcomes of the evaluation run.
      example:
        total: 6
        failed: 5
        passed: 5
        errored: 1
      properties:
        total:
          description: Total number of executed output items.
          type: integer
        errored:
          description: Number of output items that resulted in an error.
          type: integer
        failed:
          description: Number of output items that failed to pass the evaluation.
          type: integer
        passed:
          description: Number of output items that passed the evaluation.
          type: integer
      required:
      - errored
      - failed
      - passed
      - total
    EvalRun_per_model_usage_inner:
      example:
        completion_tokens: 9
        prompt_tokens: 7
        model_name: model_name
        total_tokens: 3
        invocation_count: 2
        cached_tokens: 2
      properties:
        model_name:
          description: The name of the model.
          type: string
        invocation_count:
          description: The number of invocations.
          type: integer
        prompt_tokens:
          description: The number of prompt tokens used.
          type: integer
        completion_tokens:
          description: The number of completion tokens generated.
          type: integer
        total_tokens:
          description: The total number of tokens used.
          type: integer
        cached_tokens:
          description: The number of tokens retrieved from cache.
          type: integer
      required:
      - cached_tokens
      - completion_tokens
      - invocation_count
      - model_name
      - prompt_tokens
      - total_tokens
    EvalRun_per_testing_criteria_results_inner:
      example:
        testing_criteria: testing_criteria
        passed: 4
        failed: 7
      properties:
        testing_criteria:
          description: A description of the testing criteria.
          type: string
        passed:
          description: Number of tests passed for this criteria.
          type: integer
        failed:
          description: Number of tests failed for this criteria.
          type: integer
      required:
      - failed
      - passed
      - testing_criteria
    EvalRun_data_source:
      description: Information about the run's data source.
      oneOf:
      - $ref: "#/components/schemas/CreateEvalJsonlRunDataSource"
      - $ref: "#/components/schemas/CreateEvalCompletionsRunDataSource"
      - $ref: "#/components/schemas/CreateEvalResponsesRunDataSource"
    EvalRunOutputItem_sample_input_inner:
      description: An input message.
      example:
        role: role
        content: content
      properties:
        role:
          description: "The role of the message sender (e.g., system, user, developer)."
          type: string
        content:
          description: The content of the message.
          type: string
      required:
      - content
      - role
    EvalRunOutputItem_sample_output_inner:
      example:
        role: role
        content: content
      properties:
        role:
          description: "The role of the message (e.g. \"system\", \"assistant\", \"\
            user\")."
          type: string
        content:
          description: The content of the message.
          type: string
    EvalRunOutputItem_sample_usage:
      description: Token usage details for the sample.
      example:
        completion_tokens: 5
        prompt_tokens: 5
        total_tokens: 1
        cached_tokens: 2
      properties:
        total_tokens:
          description: The total number of tokens used.
          type: integer
        completion_tokens:
          description: The number of completion tokens generated.
          type: integer
        prompt_tokens:
          description: The number of prompt tokens used.
          type: integer
        cached_tokens:
          description: The number of tokens retrieved from cache.
          type: integer
      required:
      - cached_tokens
      - completion_tokens
      - prompt_tokens
      - total_tokens
    EvalRunOutputItem_sample:
      description: A sample containing the input and output of the evaluation run.
      example:
        output:
        - role: role
          content: content
        - role: role
          content: content
        top_p: 3.616076749251911
        input:
        - role: role
          content: content
        - role: role
          content: content
        max_completion_tokens: 9
        finish_reason: finish_reason
        seed: 2
        usage:
          completion_tokens: 5
          prompt_tokens: 5
          total_tokens: 1
          cached_tokens: 2
        temperature: 7.061401241503109
        model: model
        error:
          code: code
          message: message
      properties:
        input:
          description: An array of input messages.
          items:
            $ref: "#/components/schemas/EvalRunOutputItem_sample_input_inner"
          type: array
        output:
          description: An array of output messages.
          items:
            $ref: "#/components/schemas/EvalRunOutputItem_sample_output_inner"
          type: array
        finish_reason:
          description: The reason why the sample generation was finished.
          type: string
        model:
          description: The model used for generating the sample.
          type: string
        usage:
          $ref: "#/components/schemas/EvalRunOutputItem_sample_usage"
        error:
          $ref: "#/components/schemas/EvalApiError"
        temperature:
          description: The sampling temperature used.
          type: number
        max_completion_tokens:
          description: The maximum number of tokens allowed for completion.
          type: integer
        top_p:
          description: The top_p value used for sampling.
          type: number
        seed:
          description: The seed used for generating the sample.
          type: integer
      required:
      - error
      - finish_reason
      - input
      - max_completion_tokens
      - model
      - output
      - seed
      - temperature
      - top_p
      - usage
    FileSearchToolCall_results_inner:
      properties:
        file_id:
          description: |
            The unique ID of the file.
          type: string
        text:
          description: |
            The text that was retrieved from the file.
          type: string
        filename:
          description: |
            The name of the file.
          type: string
        attributes:
          additionalProperties:
            $ref: "#/components/schemas/VectorStoreFileAttributes_value"
          description: "Set of 16 key-value pairs that can be attached to an object.\
            \ This can be \nuseful for storing additional information about the object\
            \ in a structured \nformat, and querying for objects via API or the dashboard.\
            \ Keys are strings \nwith a maximum length of 64 characters. Values are\
            \ strings with a maximum \nlength of 512 characters, booleans, or numbers.\n"
          maxProperties: 16
          x-oaiTypeLabel: map
          nullable: true
        score:
          description: |
            The relevance score of the file - a value between 0 and 1.
          format: float
          type: number
    FineTuneChatRequestInput_messages_inner:
      oneOf:
      - $ref: "#/components/schemas/ChatCompletionRequestSystemMessage"
      - $ref: "#/components/schemas/ChatCompletionRequestUserMessage"
      - $ref: "#/components/schemas/FineTuneChatCompletionRequestAssistantMessage"
      - $ref: "#/components/schemas/ChatCompletionRequestToolMessage"
      - $ref: "#/components/schemas/ChatCompletionRequestFunctionMessage"
    FineTuneDPOHyperparameters_beta:
      default: auto
      description: |
        The beta value for the DPO method. A higher beta value will increase the weight of the penalty between the policy and reference model.
      oneOf:
      - enum:
        - auto
        type: string
        x-stainless-const: true
      - maximum: 2
        minimum: 0
        type: number
    FineTuneDPOHyperparameters_batch_size:
      default: auto
      description: |
        Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.
      oneOf:
      - enum:
        - auto
        type: string
        x-stainless-const: true
      - maximum: 256
        minimum: 1
        type: integer
    FineTuneDPOHyperparameters_learning_rate_multiplier:
      default: auto
      description: |
        Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.
      oneOf:
      - enum:
        - auto
        type: string
        x-stainless-const: true
      - minimum: 0
        type: number
    FineTuneDPOHyperparameters_n_epochs:
      default: auto
      description: |
        The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.
      oneOf:
      - enum:
        - auto
        type: string
        x-stainless-const: true
      - maximum: 50
        minimum: 1
        type: integer
    FineTunePreferenceRequestInput_input:
      properties:
        messages:
          items:
            $ref: "#/components/schemas/FineTuneChatRequestInput_messages_inner"
          minItems: 1
          type: array
        tools:
          description: A list of tools the model may generate JSON inputs for.
          items:
            $ref: "#/components/schemas/ChatCompletionTool"
          type: array
        parallel_tool_calls:
          default: true
          description: "Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling)\
            \ during tool use."
          type: boolean
    FineTuneReinforcementHyperparameters_compute_multiplier:
      default: auto
      description: |
        Multiplier on amount of compute used for exploring search space during training.
      oneOf:
      - enum:
        - auto
        type: string
        x-stainless-const: true
      - maximum: 10
        minimum: 0.000010
        type: number
    FineTuneReinforcementHyperparameters_eval_interval:
      default: auto
      description: |
        The number of training steps between evaluation runs.
      oneOf:
      - enum:
        - auto
        type: string
        x-stainless-const: true
      - minimum: 1
        type: integer
    FineTuneReinforcementHyperparameters_eval_samples:
      default: auto
      description: |
        Number of evaluation samples to generate per training step.
      oneOf:
      - enum:
        - auto
        type: string
        x-stainless-const: true
      - minimum: 1
        type: integer
    FineTuneReinforcementMethod_grader:
      description: The grader used for the fine-tuning job.
      oneOf:
      - $ref: "#/components/schemas/GraderStringCheck"
      - $ref: "#/components/schemas/GraderTextSimilarity"
      - $ref: "#/components/schemas/GraderPython"
      - $ref: "#/components/schemas/GraderScoreModel"
      - $ref: "#/components/schemas/GraderMulti"
    FineTuneReinforcementRequestInput_messages_inner:
      oneOf:
      - $ref: "#/components/schemas/ChatCompletionRequestDeveloperMessage"
      - $ref: "#/components/schemas/ChatCompletionRequestUserMessage"
      - $ref: "#/components/schemas/FineTuneChatCompletionRequestAssistantMessage"
      - $ref: "#/components/schemas/ChatCompletionRequestToolMessage"
    FineTuningJob_error:
      description: "For fine-tuning jobs that have `failed`, this will contain more\
        \ information on the cause of the failure."
      example:
        code: code
        param: param
        message: message
      properties:
        code:
          description: A machine-readable error code.
          type: string
        message:
          description: A human-readable error message.
          type: string
        param:
          description: "The parameter that was invalid, usually `training_file` or\
            \ `validation_file`. This field will be null if the failure was not parameter-specific."
          type: string
          nullable: true
      required:
      - code
      - message
      - param
      nullable: true
    FineTuningJob_hyperparameters_batch_size:
      default: auto
      description: |
        Number of examples in each batch. A larger batch size means that model parameters
        are updated less frequently, but with lower variance.
      oneOf:
      - enum:
        - auto
        type: string
        x-stainless-const: true
      - maximum: 256
        minimum: 1
        type: integer
      nullable: true
    FineTuningJob_hyperparameters:
      description: The hyperparameters used for the fine-tuning job. This value will
        only be returned when running `supervised` jobs.
      example:
        batch_size: auto
        n_epochs: auto
        learning_rate_multiplier: auto
      properties:
        batch_size:
          $ref: "#/components/schemas/FineTuningJob_hyperparameters_batch_size"
        learning_rate_multiplier:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_hyperparameters_learning_rate_multiplier"
        n_epochs:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_hyperparameters_n_epochs"
    FineTuningJobCheckpoint_metrics:
      description: Metrics at the step number during the fine-tuning job.
      example:
        full_valid_mean_token_accuracy: 3.616076749251911
        valid_loss: 2.3021358869347655
        full_valid_loss: 9.301444243932576
        train_mean_token_accuracy: 5.637376656633329
        valid_mean_token_accuracy: 7.061401241503109
        train_loss: 5.962133916683182
        step: 1.4658129805029452
      properties:
        step:
          type: number
        train_loss:
          type: number
        train_mean_token_accuracy:
          type: number
        valid_loss:
          type: number
        valid_mean_token_accuracy:
          type: number
        full_valid_loss:
          type: number
        full_valid_mean_token_accuracy:
          type: number
    GraderMulti_graders:
      oneOf:
      - $ref: "#/components/schemas/GraderStringCheck"
      - $ref: "#/components/schemas/GraderTextSimilarity"
      - $ref: "#/components/schemas/GraderPython"
      - $ref: "#/components/schemas/GraderScoreModel"
      - $ref: "#/components/schemas/GraderLabelModel"
    ImageGenTool_input_image_mask:
      additionalProperties: true
      description: "Optional mask for inpainting. Contains `image_url` \n(string,\
        \ optional) and `file_id` (string, optional).\n"
      properties:
        image_url:
          description: |
            Base64-encoded mask image.
          type: string
        file_id:
          description: |
            File ID for the mask image.
          type: string
    ImagesResponse_usage_input_tokens_details:
      description: The input tokens detailed information for the image generation.
      example:
        text_tokens: 5
        image_tokens: 2
      properties:
        text_tokens:
          description: The number of text tokens in the input prompt.
          type: integer
        image_tokens:
          description: The number of image tokens in the input prompt.
          type: integer
      required:
      - image_tokens
      - text_tokens
    ImagesResponse_usage:
      description: |
        For `gpt-image-1` only, the token usage information for the image generation.
      example:
        input_tokens_details:
          text_tokens: 5
          image_tokens: 2
        total_tokens: 6
        output_tokens: 5
        input_tokens: 1
      properties:
        total_tokens:
          description: The total number of tokens (images and text) used for the image
            generation.
          type: integer
        input_tokens:
          description: The number of tokens (images and text) in the input prompt.
          type: integer
        output_tokens:
          description: The number of image tokens in the output image.
          type: integer
        input_tokens_details:
          $ref: "#/components/schemas/ImagesResponse_usage_input_tokens_details"
      required:
      - input_tokens
      - input_tokens_details
      - output_tokens
      - total_tokens
    Invite_projects_inner:
      example:
        role: member
        id: id
      properties:
        id:
          description: Project's public ID
          type: string
        role:
          description: Project membership role
          enum:
          - member
          - owner
          type: string
    InviteRequest_projects_inner:
      example:
        role: member
        id: id
      properties:
        id:
          description: Project's public ID
          type: string
        role:
          description: Project membership role
          enum:
          - member
          - owner
          type: string
      required:
      - id
      - role
    MCP_allowed_tools_filter:
      additionalProperties: true
      description: |
        A filter object to specify which tools are allowed.
      properties:
        tool_names:
          description: List of allowed tool names.
          items:
            type: string
          type: array
      title: MCP allowed tools filter
    MCPTool_allowed_tools:
      description: |
        List of allowed tool names or a filter object.
      oneOf:
      - description: A string array of allowed tool names
        items:
          type: string
        type: array
      - $ref: "#/components/schemas/MCP_allowed_tools_filter"
      nullable: true
    MCP_tool_approval_filter_always:
      description: |
        A list of tools that always require approval.
      properties:
        tool_names:
          description: List of tools that require approval.
          items:
            type: string
          type: array
    MCP_tool_approval_filter_never:
      description: |
        A list of tools that never require approval.
      properties:
        tool_names:
          description: List of tools that do not require approval.
          items:
            type: string
          type: array
    MCP_tool_approval_filter:
      additionalProperties: true
      properties:
        always:
          $ref: "#/components/schemas/MCP_tool_approval_filter_always"
        never:
          $ref: "#/components/schemas/MCP_tool_approval_filter_never"
      title: MCP tool approval filter
    MCPTool_require_approval:
      default: always
      description: Specify which of the MCP server's tools require approval.
      oneOf:
      - $ref: "#/components/schemas/MCP_tool_approval_filter"
      - description: "Specify a single approval policy for all tools. One of `always`\
          \ or \n`never`. When set to `always`, all tools will require approval. When\
          \ \nset to `never`, all tools will not require approval.\n"
        enum:
        - always
        - never
        title: MCP tool approval setting
        type: string
      nullable: true
    MessageContentImageFileObject_image_file:
      example:
        file_id: file_id
        detail: auto
      properties:
        file_id:
          description: "The [File](/docs/api-reference/files) ID of the image in the\
            \ message content. Set `purpose=\"vision\"` when uploading the File if\
            \ you need to later display the file content."
          type: string
        detail:
          default: auto
          description: "Specifies the detail level of the image if specified by the\
            \ user. `low` uses fewer tokens, you can opt in to high resolution using\
            \ `high`."
          enum:
          - auto
          - low
          - high
          type: string
      required:
      - file_id
    MessageContentImageUrlObject_image_url:
      properties:
        url:
          description: "The external URL of the image, must be a supported image types:\
            \ jpeg, jpg, png, gif, webp."
          format: uri
          type: string
        detail:
          default: auto
          description: "Specifies the detail level of the image. `low` uses fewer\
            \ tokens, you can opt in to high resolution using `high`. Default value\
            \ is `auto`"
          enum:
          - auto
          - low
          - high
          type: string
      required:
      - url
    MessageContentTextAnnotationsFileCitationObject_file_citation:
      properties:
        file_id:
          description: The ID of the specific File the citation is from.
          type: string
      required:
      - file_id
    MessageContentTextAnnotationsFilePathObject_file_path:
      properties:
        file_id:
          description: The ID of the file that was generated.
          type: string
      required:
      - file_id
    MessageContentTextObject_text_annotations_inner:
      oneOf:
      - $ref: "#/components/schemas/MessageContentTextAnnotationsFileCitationObject"
      - $ref: "#/components/schemas/MessageContentTextAnnotationsFilePathObject"
    MessageContentTextObject_text:
      properties:
        value:
          description: The data that makes up the text.
          type: string
        annotations:
          items:
            $ref: "#/components/schemas/MessageContentTextObject_text_annotations_inner"
          type: array
      required:
      - annotations
      - value
    MessageDeltaContentImageFileObject_image_file:
      properties:
        file_id:
          description: "The [File](/docs/api-reference/files) ID of the image in the\
            \ message content. Set `purpose=\"vision\"` when uploading the File if\
            \ you need to later display the file content."
          type: string
        detail:
          default: auto
          description: "Specifies the detail level of the image if specified by the\
            \ user. `low` uses fewer tokens, you can opt in to high resolution using\
            \ `high`."
          enum:
          - auto
          - low
          - high
          type: string
    MessageDeltaContentImageUrlObject_image_url:
      properties:
        url:
          description: "The URL of the image, must be a supported image types: jpeg,\
            \ jpg, png, gif, webp."
          type: string
        detail:
          default: auto
          description: "Specifies the detail level of the image. `low` uses fewer\
            \ tokens, you can opt in to high resolution using `high`."
          enum:
          - auto
          - low
          - high
          type: string
    MessageDeltaContentTextAnnotationsFileCitationObject_file_citation:
      properties:
        file_id:
          description: The ID of the specific File the citation is from.
          type: string
        quote:
          description: The specific quote in the file.
          type: string
    MessageDeltaContentTextAnnotationsFilePathObject_file_path:
      properties:
        file_id:
          description: The ID of the file that was generated.
          type: string
    MessageDeltaContentTextObject_text_annotations_inner:
      oneOf:
      - $ref: "#/components/schemas/MessageDeltaContentTextAnnotationsFileCitationObject"
      - $ref: "#/components/schemas/MessageDeltaContentTextAnnotationsFilePathObject"
    MessageDeltaContentTextObject_text:
      properties:
        value:
          description: The data that makes up the text.
          type: string
        annotations:
          items:
            $ref: "#/components/schemas/MessageDeltaContentTextObject_text_annotations_inner"
          type: array
    MessageDeltaObject_delta_content_inner:
      oneOf:
      - $ref: "#/components/schemas/MessageDeltaContentImageFileObject"
      - $ref: "#/components/schemas/MessageDeltaContentTextObject"
      - $ref: "#/components/schemas/MessageDeltaContentRefusalObject"
      - $ref: "#/components/schemas/MessageDeltaContentImageUrlObject"
    MessageDeltaObject_delta:
      description: The delta containing the fields that have changed on the Message.
      properties:
        role:
          description: The entity that produced the message. One of `user` or `assistant`.
          enum:
          - user
          - assistant
          type: string
        content:
          description: The content of the message in array of text and/or images.
          items:
            $ref: "#/components/schemas/MessageDeltaObject_delta_content_inner"
          type: array
    MessageObject_incomplete_details:
      description: "On an incomplete message, details about why the message is incomplete."
      example:
        reason: content_filter
      properties:
        reason:
          description: The reason the message is incomplete.
          enum:
          - content_filter
          - max_tokens
          - run_cancelled
          - run_expired
          - run_failed
          type: string
      required:
      - reason
      nullable: true
    MessageObject_content_inner:
      oneOf:
      - $ref: "#/components/schemas/MessageContentImageFileObject"
      - $ref: "#/components/schemas/MessageContentImageUrlObject"
      - $ref: "#/components/schemas/MessageContentTextObject"
      - $ref: "#/components/schemas/MessageContentRefusalObject"
    MessageStreamEvent_oneOf:
      description: "Occurs when a [message](/docs/api-reference/messages/object) is\
        \ created."
      properties:
        event:
          enum:
          - thread.message.created
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/MessageObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    MessageStreamEvent_oneOf_1:
      description: "Occurs when a [message](/docs/api-reference/messages/object) moves\
        \ to an `in_progress` state."
      properties:
        event:
          enum:
          - thread.message.in_progress
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/MessageObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    MessageStreamEvent_oneOf_2:
      description: "Occurs when parts of a [Message](/docs/api-reference/messages/object)\
        \ are being streamed."
      properties:
        event:
          enum:
          - thread.message.delta
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/MessageDeltaObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)"
    MessageStreamEvent_oneOf_3:
      description: "Occurs when a [message](/docs/api-reference/messages/object) is\
        \ completed."
      properties:
        event:
          enum:
          - thread.message.completed
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/MessageObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    MessageStreamEvent_oneOf_4:
      description: "Occurs when a [message](/docs/api-reference/messages/object) ends\
        \ before it is completed."
      properties:
        event:
          enum:
          - thread.message.incomplete
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/MessageObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    ModifyAssistantRequest_model:
      anyOf:
      - type: string
      - $ref: "#/components/schemas/AssistantSupportedModels"
      description: |
        ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.
    ModifyAssistantRequest_tool_resources_code_interpreter:
      example:
        file_ids:
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        - file_ids
      properties:
        file_ids:
          default: []
          description: |
            Overrides the list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.
          items:
            type: string
          maxItems: 20
          type: array
    ModifyAssistantRequest_tool_resources_file_search:
      example:
        vector_store_ids:
        - vector_store_ids
      properties:
        vector_store_ids:
          description: |
            Overrides the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items:
            type: string
          maxItems: 1
          type: array
    ModifyAssistantRequest_tool_resources:
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      example:
        code_interpreter:
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
        file_search:
          vector_store_ids:
          - vector_store_ids
      properties:
        code_interpreter:
          $ref: "#/components/schemas/ModifyAssistantRequest_tool_resources_code_interpreter"
        file_search:
          $ref: "#/components/schemas/ModifyAssistantRequest_tool_resources_file_search"
      nullable: true
    ModifyThreadRequest_tool_resources_file_search:
      example:
        vector_store_ids:
        - vector_store_ids
      properties:
        vector_store_ids:
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.
          items:
            type: string
          maxItems: 1
          type: array
    ModifyThreadRequest_tool_resources:
      description: |
        A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      example:
        code_interpreter:
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
        file_search:
          vector_store_ids:
          - vector_store_ids
      properties:
        code_interpreter:
          $ref: "#/components/schemas/CreateThreadAndRunRequest_tool_resources_code_interpreter"
        file_search:
          $ref: "#/components/schemas/ModifyThreadRequest_tool_resources_file_search"
      nullable: true
    PredictionContent_content:
      description: |
        The content that should be matched when generating a model response.
        If generated tokens would match this content, the entire model response
        can be returned much more quickly.
      oneOf:
      - description: |
          The content used for a Predicted Output. This is often the
          text of a file you are regenerating with minor changes.
        title: Text content
        type: string
      - description: "An array of content parts with a defined type. Supported options\
          \ differ based on the [model](/docs/models) being used to generate the response.\
          \ Can contain text inputs."
        items:
          $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartText"
        minItems: 1
        type: array
    ProjectApiKey_owner:
      example:
        service_account:
          role: owner
          name: name
          created_at: 5
          id: id
          object: organization.project.service_account
        type: user
        user:
          added_at: 1
          role: owner
          name: name
          id: id
          email: email
          object: organization.project.user
      properties:
        type:
          description: '`user` or `service_account`'
          enum:
          - user
          - service_account
          type: string
        user:
          $ref: "#/components/schemas/ProjectUser"
        service_account:
          $ref: "#/components/schemas/ProjectServiceAccount"
    RealtimeConversationItem_content_inner:
      properties:
        type:
          description: |
            The content type (`input_text`, `input_audio`, `item_reference`, `text`).
          enum:
          - input_audio
          - input_text
          - item_reference
          - text
          type: string
        text:
          description: |
            The text content, used for `input_text` and `text` content types.
          type: string
        id:
          description: |
            ID of a previous conversation item to reference (for `item_reference`
            content types in `response.create` events). These can reference both
            client and server created items.
          type: string
        audio:
          description: |
            Base64-encoded audio bytes, used for `input_audio` content type.
          type: string
        transcript:
          description: |
            The transcript of the audio, used for `input_audio` content type.
          type: string
    RealtimeResponse_status_details_error:
      description: "A description of the error that caused the response to fail, \n\
        populated when the `status` is `failed`.\n"
      properties:
        type:
          description: The type of error.
          type: string
        code:
          description: "Error code, if any."
          type: string
    RealtimeResponse_status_details:
      description: Additional details about the status.
      properties:
        type:
          description: "The type of error that caused the response to fail, corresponding\
            \ \nwith the `status` field (`completed`, `cancelled`, `incomplete`, \n\
            `failed`).\n"
          enum:
          - completed
          - cancelled
          - failed
          - incomplete
          type: string
        reason:
          description: "The reason the Response did not complete. For a `cancelled`\
            \ Response, \none of `turn_detected` (the server VAD detected a new start\
            \ of speech) \nor `client_cancelled` (the client sent a cancel event).\
            \ For an \n`incomplete` Response, one of `max_output_tokens` or `content_filter`\
            \ \n(the server-side safety filter activated and cut off the response).\n"
          enum:
          - turn_detected
          - client_cancelled
          - max_output_tokens
          - content_filter
          type: string
        error:
          $ref: "#/components/schemas/RealtimeResponse_status_details_error"
    RealtimeResponse_usage_input_token_details:
      description: Details about the input tokens used in the Response.
      properties:
        cached_tokens:
          description: The number of cached tokens used in the Response.
          type: integer
        text_tokens:
          description: The number of text tokens used in the Response.
          type: integer
        audio_tokens:
          description: The number of audio tokens used in the Response.
          type: integer
    RealtimeResponse_usage_output_token_details:
      description: Details about the output tokens used in the Response.
      properties:
        text_tokens:
          description: The number of text tokens used in the Response.
          type: integer
        audio_tokens:
          description: The number of audio tokens used in the Response.
          type: integer
    RealtimeResponse_usage:
      description: "Usage statistics for the Response, this will correspond to billing.\
        \ A \nRealtime API session will maintain a conversation context and append\
        \ new \nItems to the Conversation, thus output from previous turns (text and\
        \ \naudio tokens) will become the input for later turns.\n"
      properties:
        total_tokens:
          description: "The total number of tokens in the Response including input\
            \ and output \ntext and audio tokens.\n"
          type: integer
        input_tokens:
          description: "The number of input tokens used in the Response, including\
            \ text and \naudio tokens.\n"
          type: integer
        output_tokens:
          description: "The number of output tokens sent in the Response, including\
            \ text and \naudio tokens.\n"
          type: integer
        input_token_details:
          $ref: "#/components/schemas/RealtimeResponse_usage_input_token_details"
        output_token_details:
          $ref: "#/components/schemas/RealtimeResponse_usage_output_token_details"
    RealtimeResponse_max_output_tokens:
      description: |
        Maximum number of output tokens for a single assistant response,
        inclusive of tool calls, that was used in this response.
      oneOf:
      - type: integer
      - enum:
        - inf
        type: string
        x-stainless-const: true
    RealtimeResponseCreateParams_tools_inner:
      example:
        name: name
        description: description
        type: function
        parameters: "{}"
      properties:
        type:
          description: "The type of the tool, i.e. `function`."
          enum:
          - function
          type: string
          x-stainless-const: true
        name:
          description: The name of the function.
          type: string
        description:
          description: "The description of the function, including guidance on when\
            \ and how \nto call it, and guidance about what to tell the user when\
            \ calling \n(if anything).\n"
          type: string
        parameters:
          description: Parameters of the function in JSON Schema.
          type: object
    RealtimeResponseCreateParams_max_response_output_tokens:
      description: |
        Maximum number of output tokens for a single assistant response,
        inclusive of tool calls. Provide an integer between 1 and 4096 to
        limit output tokens, or `inf` for the maximum available tokens for a
        given model. Defaults to `inf`.
      oneOf:
      - type: integer
      - enum:
        - inf
        type: string
        x-stainless-const: true
    RealtimeResponseCreateParams_conversation:
      description: "Controls which conversation the response is added to. Currently\
        \ supports\n`auto` and `none`, with `auto` as the default value. The `auto`\
        \ value\nmeans that the contents of the response will be added to the default\n\
        conversation. Set this to `none` to create an out-of-band response which \n\
        will not add items to default conversation.\n"
      oneOf:
      - type: string
      - default: auto
        enum:
        - auto
        - none
        type: string
    RealtimeServerEventConversationCreated_conversation:
      description: The conversation resource.
      properties:
        id:
          description: The unique ID of the conversation.
          type: string
        object:
          description: "The object type, must be `realtime.conversation`."
          type: string
    RealtimeServerEventConversationItemInputAudioTranscriptionFailed_error:
      description: Details of the transcription error.
      properties:
        type:
          description: The type of error.
          type: string
        code:
          description: "Error code, if any."
          type: string
        message:
          description: A human-readable error message.
          type: string
        param:
          description: "Parameter related to the error, if any."
          type: string
    RealtimeServerEventError_error:
      description: Details of the error.
      properties:
        type:
          description: |
            The type of error (e.g., "invalid_request_error", "server_error").
          type: string
        code:
          description: "Error code, if any."
          type: string
          nullable: true
        message:
          description: A human-readable error message.
          type: string
        param:
          description: "Parameter related to the error, if any."
          type: string
          nullable: true
        event_id:
          description: |
            The event_id of the client event that caused the error, if applicable.
          type: string
          nullable: true
      required:
      - message
      - type
    RealtimeServerEventRateLimitsUpdated_rate_limits_inner:
      properties:
        name:
          description: |
            The name of the rate limit (`requests`, `tokens`).
          enum:
          - requests
          - tokens
          type: string
        limit:
          description: The maximum allowed value for the rate limit.
          type: integer
        remaining:
          description: The remaining value before the limit is reached.
          type: integer
        reset_seconds:
          description: Seconds until the rate limit resets.
          type: number
    RealtimeServerEventResponseContentPartAdded_part:
      description: The content part that was added.
      properties:
        type:
          description: "The content type (\"text\", \"audio\")."
          enum:
          - audio
          - text
          type: string
        text:
          description: The text content (if type is "text").
          type: string
        audio:
          description: Base64-encoded audio data (if type is "audio").
          type: string
        transcript:
          description: The transcript of the audio (if type is "audio").
          type: string
    RealtimeServerEventResponseContentPartDone_part:
      description: The content part that is done.
      properties:
        type:
          description: "The content type (\"text\", \"audio\")."
          enum:
          - audio
          - text
          type: string
        text:
          description: The text content (if type is "text").
          type: string
        audio:
          description: Base64-encoded audio data (if type is "audio").
          type: string
        transcript:
          description: The transcript of the audio (if type is "audio").
          type: string
    RealtimeSession_input_audio_transcription:
      description: |
        Configuration for input audio transcription, defaults to off and can be  set to `null` to turn off once on. Input audio transcription is not native to the model, since the model consumes audio directly. Transcription runs  asynchronously through [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription) and should be treated as guidance of input audio content rather than precisely what the model heard. The client can optionally set the language and prompt for transcription, these offer additional guidance to the transcription service.
      properties:
        model:
          description: |
            The model to use for transcription, current options are `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, and `whisper-1`.
          type: string
        language:
          description: |
            The language of the input audio. Supplying the input language in
            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format
            will improve accuracy and latency.
          type: string
        prompt:
          description: |
            An optional text to guide the model's style or continue a previous audio
            segment.
            For `whisper-1`, the [prompt is a list of keywords](/docs/guides/speech-to-text#prompting).
            For `gpt-4o-transcribe` models, the prompt is a free text string, for example "expect words related to technology".
          type: string
    RealtimeSession_turn_detection:
      description: |
        Configuration for turn detection, ether Server VAD or Semantic VAD. This can be set to `null` to turn off, in which case the client must manually trigger model response.
        Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.
        Semantic VAD is more advanced and uses a turn detection model (in conjuction with VAD) to semantically estimate whether the user has finished speaking, then dynamically sets a timeout based on this probability. For example, if user audio trails off with "uhhm", the model will score a low probability of turn end and wait longer for the user to continue speaking. This can be useful for more natural conversations, but may have a higher latency.
      properties:
        type:
          default: server_vad
          description: |
            Type of turn detection.
          enum:
          - server_vad
          - semantic_vad
          type: string
        eagerness:
          default: auto
          description: |
            Used only for `semantic_vad` mode. The eagerness of the model to respond. `low` will wait longer for the user to continue speaking, `high` will respond more quickly. `auto` is the default and is equivalent to `medium`.
          enum:
          - low
          - medium
          - high
          - auto
          type: string
        threshold:
          description: "Used only for `server_vad` mode. Activation threshold for\
            \ VAD (0.0 to 1.0), this defaults to 0.5. A \nhigher threshold will require\
            \ louder audio to activate the model, and \nthus might perform better\
            \ in noisy environments.\n"
          type: number
        prefix_padding_ms:
          description: "Used only for `server_vad` mode. Amount of audio to include\
            \ before the VAD detected speech (in \nmilliseconds). Defaults to 300ms.\n"
          type: integer
        silence_duration_ms:
          description: "Used only for `server_vad` mode. Duration of silence to detect\
            \ speech stop (in milliseconds). Defaults \nto 500ms. With shorter values\
            \ the model will respond more quickly, \nbut may jump in on short pauses\
            \ from the user.\n"
          type: integer
        create_response:
          default: true
          description: |
            Whether or not to automatically generate a response when a VAD stop event occurs.
          type: boolean
        interrupt_response:
          default: true
          description: |
            Whether or not to automatically interrupt any ongoing response with output to the default
            conversation (i.e. `conversation` of `auto`) when a VAD start event occurs.
          type: boolean
    RealtimeSession_input_audio_noise_reduction:
      description: |
        Configuration for input audio noise reduction. This can be set to `null` to turn off.
        Noise reduction filters audio added to the input audio buffer before it is sent to VAD and the model.
        Filtering the audio can improve VAD and turn detection accuracy (reducing false positives) and model performance by improving perception of the input audio.
      example:
        type: near_field
      properties:
        type:
          description: |
            Type of noise reduction. `near_field` is for close-talking microphones such as headphones, `far_field` is for far-field microphones such as laptop or conference room microphones.
          enum:
          - near_field
          - far_field
          type: string
    Tracing_Configuration:
      description: "Configuration options for tracing. Set to null to disable tracing.\
        \ Once \ntracing is enabled for a session, the configuration cannot be modified.\n\
        \n`auto` will create a trace for the session with default values for the \n\
        workflow name, group id, and metadata.\n"
      oneOf:
      - default: auto
        description: |
          Default tracing mode for the session.
        enum:
        - auto
        type: string
        x-stainless-const: true
      - $ref: "#/components/schemas/Tracing_Configuration"
      title: Tracing Configuration
    RealtimeSessionCreateRequest_input_audio_transcription:
      description: |
        Configuration for input audio transcription, defaults to off and can be set to `null` to turn off once on. Input audio transcription is not native to the model, since the model consumes audio directly. Transcription runs asynchronously through [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription) and should be treated as guidance of input audio content rather than precisely what the model heard. The client can optionally set the language and prompt for transcription, these offer additional guidance to the transcription service.
      example:
        model: model
        language: language
        prompt: prompt
      properties:
        model:
          description: |
            The model to use for transcription, current options are `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, and `whisper-1`.
          type: string
        language:
          description: |
            The language of the input audio. Supplying the input language in
            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format
            will improve accuracy and latency.
          type: string
        prompt:
          description: |
            An optional text to guide the model's style or continue a previous audio
            segment.
            For `whisper-1`, the [prompt is a list of keywords](/docs/guides/speech-to-text#prompting).
            For `gpt-4o-transcribe` models, the prompt is a free text string, for example "expect words related to technology".
          type: string
    RealtimeSessionCreateRequest_turn_detection:
      description: |
        Configuration for turn detection, ether Server VAD or Semantic VAD. This can be set to `null` to turn off, in which case the client must manually trigger model response.
        Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.
        Semantic VAD is more advanced and uses a turn detection model (in conjuction with VAD) to semantically estimate whether the user has finished speaking, then dynamically sets a timeout based on this probability. For example, if user audio trails off with "uhhm", the model will score a low probability of turn end and wait longer for the user to continue speaking. This can be useful for more natural conversations, but may have a higher latency.
      example:
        silence_duration_ms: 1
        create_response: true
        interrupt_response: true
        prefix_padding_ms: 6
        eagerness: auto
        threshold: 0.8008281904610115
        type: server_vad
      properties:
        type:
          default: server_vad
          description: |
            Type of turn detection.
          enum:
          - server_vad
          - semantic_vad
          type: string
        eagerness:
          default: auto
          description: |
            Used only for `semantic_vad` mode. The eagerness of the model to respond. `low` will wait longer for the user to continue speaking, `high` will respond more quickly. `auto` is the default and is equivalent to `medium`.
          enum:
          - low
          - medium
          - high
          - auto
          type: string
        threshold:
          description: |
            Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A
            higher threshold will require louder audio to activate the model, and
            thus might perform better in noisy environments.
          type: number
        prefix_padding_ms:
          description: |
            Used only for `server_vad` mode. Amount of audio to include before the VAD detected speech (in
            milliseconds). Defaults to 300ms.
          type: integer
        silence_duration_ms:
          description: |
            Used only for `server_vad` mode. Duration of silence to detect speech stop (in milliseconds). Defaults
            to 500ms. With shorter values the model will respond more quickly,
            but may jump in on short pauses from the user.
          type: integer
        create_response:
          default: true
          description: |
            Whether or not to automatically generate a response when a VAD stop event occurs.
          type: boolean
        interrupt_response:
          default: true
          description: |
            Whether or not to automatically interrupt any ongoing response with output to the default
            conversation (i.e. `conversation` of `auto`) when a VAD start event occurs.
          type: boolean
    RealtimeSessionCreateRequest_tools_inner:
      example:
        name: name
        description: description
        type: function
        parameters: "{}"
      properties:
        type:
          description: "The type of the tool, i.e. `function`."
          enum:
          - function
          type: string
          x-stainless-const: true
        name:
          description: The name of the function.
          type: string
        description:
          description: |
            The description of the function, including guidance on when and how
            to call it, and guidance about what to tell the user when calling
            (if anything).
          type: string
        parameters:
          description: Parameters of the function in JSON Schema.
          type: object
    RealtimeSessionCreateRequest_client_secret_expires_after:
      description: |
        Configuration for the ephemeral token expiration.
      example:
        seconds: 7
        anchor: created_at
      properties:
        anchor:
          description: |
            The anchor point for the ephemeral token expiration. Only `created_at` is currently supported.
          enum:
          - created_at
          type: string
        seconds:
          default: 600
          description: |
            The number of seconds from the anchor point to the expiration. Select a value between `10` and `7200`.
          type: integer
      required:
      - anchor
    RealtimeSessionCreateRequest_client_secret:
      description: |
        Configuration options for the generated client secret.
      example:
        expires_after:
          seconds: 7
          anchor: created_at
      properties:
        expires_after:
          $ref: "#/components/schemas/RealtimeSessionCreateRequest_client_secret_expires_after"
    RealtimeSessionCreateResponse_client_secret:
      description: Ephemeral key returned by the API.
      example:
        expires_at: 0
        value: value
      properties:
        value:
          description: |
            Ephemeral key usable in client environments to authenticate connections
            to the Realtime API. Use this in client-side environments rather than
            a standard API token, which should only be used server-side.
          type: string
        expires_at:
          description: |
            Timestamp for when the token expires. Currently, all tokens expire
            after one minute.
          type: integer
      required:
      - expires_at
      - value
    RealtimeSessionCreateResponse_input_audio_transcription:
      description: "Configuration for input audio transcription, defaults to off and\
        \ can be \nset to `null` to turn off once on. Input audio transcription is\
        \ not native \nto the model, since the model consumes audio directly. Transcription\
        \ runs\nasynchronously and should be treated as rough guidance\nrather than\
        \ the representation understood by the model.\n"
      example:
        model: model
      properties:
        model:
          description: |
            The model to use for transcription.
          type: string
    RealtimeSessionCreateResponse_turn_detection:
      description: "Configuration for turn detection. Can be set to `null` to turn\
        \ off. Server \nVAD means that the model will detect the start and end of\
        \ speech based on \naudio volume and respond at the end of user speech.\n"
      example:
        silence_duration_ms: 5
        prefix_padding_ms: 5
        threshold: 1.4658129805029452
        type: type
      properties:
        type:
          description: |
            Type of turn detection, only `server_vad` is currently supported.
          type: string
        threshold:
          description: "Activation threshold for VAD (0.0 to 1.0), this defaults to\
            \ 0.5. A \nhigher threshold will require louder audio to activate the\
            \ model, and \nthus might perform better in noisy environments.\n"
          type: number
        prefix_padding_ms:
          description: "Amount of audio to include before the VAD detected speech\
            \ (in \nmilliseconds). Defaults to 300ms.\n"
          type: integer
        silence_duration_ms:
          description: "Duration of silence to detect speech stop (in milliseconds).\
            \ Defaults \nto 500ms. With shorter values the model will respond more\
            \ quickly, \nbut may jump in on short pauses from the user.\n"
          type: integer
    RealtimeTranscriptionSessionCreateRequest_input_audio_transcription:
      description: |
        Configuration for input audio transcription. The client can optionally set the language and prompt for transcription, these offer additional guidance to the transcription service.
      example:
        model: gpt-4o-transcribe
        language: language
        prompt: prompt
      properties:
        model:
          description: |
            The model to use for transcription, current options are `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, and `whisper-1`.
          enum:
          - gpt-4o-transcribe
          - gpt-4o-mini-transcribe
          - whisper-1
          type: string
        language:
          description: |
            The language of the input audio. Supplying the input language in
            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format
            will improve accuracy and latency.
          type: string
        prompt:
          description: |
            An optional text to guide the model's style or continue a previous audio
            segment.
            For `whisper-1`, the [prompt is a list of keywords](/docs/guides/speech-to-text#prompting).
            For `gpt-4o-transcribe` models, the prompt is a free text string, for example "expect words related to technology".
          type: string
    RealtimeTranscriptionSessionCreateRequest_turn_detection:
      description: |
        Configuration for turn detection, ether Server VAD or Semantic VAD. This can be set to `null` to turn off, in which case the client must manually trigger model response.
        Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.
        Semantic VAD is more advanced and uses a turn detection model (in conjuction with VAD) to semantically estimate whether the user has finished speaking, then dynamically sets a timeout based on this probability. For example, if user audio trails off with "uhhm", the model will score a low probability of turn end and wait longer for the user to continue speaking. This can be useful for more natural conversations, but may have a higher latency.
      example:
        silence_duration_ms: 1
        create_response: true
        interrupt_response: true
        prefix_padding_ms: 6
        eagerness: auto
        threshold: 0.8008281904610115
        type: server_vad
      properties:
        type:
          default: server_vad
          description: |
            Type of turn detection.
          enum:
          - server_vad
          - semantic_vad
          type: string
        eagerness:
          default: auto
          description: |
            Used only for `semantic_vad` mode. The eagerness of the model to respond. `low` will wait longer for the user to continue speaking, `high` will respond more quickly. `auto` is the default and is equivalent to `medium`.
          enum:
          - low
          - medium
          - high
          - auto
          type: string
        threshold:
          description: |
            Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A
            higher threshold will require louder audio to activate the model, and
            thus might perform better in noisy environments.
          type: number
        prefix_padding_ms:
          description: |
            Used only for `server_vad` mode. Amount of audio to include before the VAD detected speech (in
            milliseconds). Defaults to 300ms.
          type: integer
        silence_duration_ms:
          description: |
            Used only for `server_vad` mode. Duration of silence to detect speech stop (in milliseconds). Defaults
            to 500ms. With shorter values the model will respond more quickly,
            but may jump in on short pauses from the user.
          type: integer
        create_response:
          default: true
          description: |
            Whether or not to automatically generate a response when a VAD stop event occurs. Not available for transcription sessions.
          type: boolean
        interrupt_response:
          default: true
          description: |
            Whether or not to automatically interrupt any ongoing response with output to the default
            conversation (i.e. `conversation` of `auto`) when a VAD start event occurs. Not available for transcription sessions.
          type: boolean
    RealtimeTranscriptionSessionCreateRequest_client_secret_expires_at:
      description: |
        Configuration for the ephemeral token expiration.
      example:
        seconds: 5
        anchor: created_at
      properties:
        anchor:
          default: created_at
          description: |
            The anchor point for the ephemeral token expiration. Only `created_at` is currently supported.
          enum:
          - created_at
          type: string
        seconds:
          default: 600
          description: |
            The number of seconds from the anchor point to the expiration. Select a value between `10` and `7200`.
          type: integer
    RealtimeTranscriptionSessionCreateRequest_client_secret:
      description: |
        Configuration options for the generated client secret.
      example:
        expires_at:
          seconds: 5
          anchor: created_at
      properties:
        expires_at:
          $ref: "#/components/schemas/RealtimeTranscriptionSessionCreateRequest_client_secret_expires_at"
    RealtimeTranscriptionSessionCreateResponse_client_secret:
      description: |
        Ephemeral key returned by the API. Only present when the session is
        created on the server via REST API.
      example:
        expires_at: 0
        value: value
      properties:
        value:
          description: |
            Ephemeral key usable in client environments to authenticate connections
            to the Realtime API. Use this in client-side environments rather than
            a standard API token, which should only be used server-side.
          type: string
        expires_at:
          description: |
            Timestamp for when the token expires. Currently, all tokens expire
            after one minute.
          type: integer
      required:
      - expires_at
      - value
    RealtimeTranscriptionSessionCreateResponse_input_audio_transcription:
      description: |
        Configuration of the transcription model.
      example:
        model: gpt-4o-transcribe
        language: language
        prompt: prompt
      properties:
        model:
          description: |
            The model to use for transcription. Can be `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, or `whisper-1`.
          enum:
          - gpt-4o-transcribe
          - gpt-4o-mini-transcribe
          - whisper-1
          type: string
        language:
          description: |
            The language of the input audio. Supplying the input language in
            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format
            will improve accuracy and latency.
          type: string
        prompt:
          description: |
            An optional text to guide the model's style or continue a previous audio
            segment. The [prompt](/docs/guides/speech-to-text#prompting) should match
            the audio language.
          type: string
    ReasoningItem_summary_inner:
      properties:
        type:
          description: |
            The type of the object. Always `summary_text`.
          enum:
          - summary_text
          type: string
          x-stainless-const: true
        text:
          description: |
            A short summary of the reasoning used by the model when generating
            the response.
          type: string
      required:
      - text
      - type
    Response_allOf_incomplete_details:
      description: |
        Details about why the response is incomplete.
      properties:
        reason:
          description: The reason why the response is incomplete.
          enum:
          - max_output_tokens
          - content_filter
          type: string
      nullable: true
    Response_allOf_instructions:
      description: |
        A system (or developer) message inserted into the model's context.

        When using along with `previous_response_id`, the instructions from a previous
        response will not be carried over to the next response. This makes it simple
        to swap out system (or developer) messages in new responses.
      oneOf:
      - description: "A text input to the model, equivalent to a text input with the\
          \ \n`developer` role.\n"
        type: string
      - description: "A list of one or many input items to the model, containing \n\
          different content types.\n"
        items:
          $ref: "#/components/schemas/InputItem"
        type: array
      nullable: true
    JSON_schema:
      description: |
        Structured Outputs configuration options, including a JSON Schema.
      properties:
        description:
          description: |
            A description of what the response format is for, used by the model to
            determine how to respond in the format.
          type: string
        name:
          description: |
            The name of the response format. Must be a-z, A-Z, 0-9, or contain
            underscores and dashes, with a maximum length of 64.
          type: string
        schema:
          additionalProperties: true
          description: |
            The schema for the response format, described as a JSON Schema object.
            Learn how to build JSON schemas [here](https://json-schema.org/).
          title: JSON schema
          type: object
        strict:
          default: false
          description: |
            Whether to enable strict schema adherence when generating the output.
            If set to true, the model will always follow the exact schema defined
            in the `schema` field. Only a subset of JSON Schema is supported when
            `strict` is `true`. To learn more, read the [Structured Outputs
            guide](/docs/guides/structured-outputs).
          type: boolean
          nullable: true
      required:
      - name
      title: JSON schema
    ResponsePromptVariables_value:
      oneOf:
      - type: string
      - $ref: "#/components/schemas/InputTextContent"
      - $ref: "#/components/schemas/InputImageContent"
      - $ref: "#/components/schemas/InputFileContent"
      x-oaiExpandable: true
      x-oaiTypeLabel: map
    ResponseProperties_tool_choice:
      description: |
        How the model should select which tool (or tools) to use when generating
        a response. See the `tools` parameter to see how to specify which tools
        the model can call.
      oneOf:
      - $ref: "#/components/schemas/ToolChoiceOptions"
      - $ref: "#/components/schemas/ToolChoiceTypes"
      - $ref: "#/components/schemas/ToolChoiceFunction"
      - $ref: "#/components/schemas/ToolChoiceMCP"
    ResponseReasoningSummaryPartAddedEvent_part:
      description: |
        The summary part that was added.
      properties:
        type:
          description: The type of the summary part. Always `summary_text`.
          enum:
          - summary_text
          type: string
          x-stainless-const: true
        text:
          description: The text of the summary part.
          type: string
      required:
      - text
      - type
    ResponseReasoningSummaryPartDoneEvent_part:
      description: |
        The completed summary part.
      properties:
        type:
          description: The type of the summary part. Always `summary_text`.
          enum:
          - summary_text
          type: string
          x-stainless-const: true
        text:
          description: The text of the summary part.
          type: string
      required:
      - text
      - type
    ResponseUsage_input_tokens_details:
      description: A detailed breakdown of the input tokens.
      properties:
        cached_tokens:
          description: "The number of tokens that were retrieved from the cache. \n\
            [More on prompt caching](/docs/guides/prompt-caching).\n"
          type: integer
      required:
      - cached_tokens
    ResponseUsage_output_tokens_details:
      description: A detailed breakdown of the output tokens.
      properties:
        reasoning_tokens:
          description: The number of reasoning tokens.
          type: integer
      required:
      - reasoning_tokens
    RunGraderResponse_metadata_errors:
      example:
        sample_parse_error: true
        python_grader_runtime_error_details: python_grader_runtime_error_details
        unresponsive_reward_error: true
        model_grader_refusal_error: true
        truncated_observation_error: true
        other_error: true
        formula_parse_error: true
        python_grader_server_error_type: python_grader_server_error_type
        python_grader_server_error: true
        model_grader_server_error: true
        invalid_variable_error: true
        python_grader_runtime_error: true
        model_grader_server_error_details: model_grader_server_error_details
        model_grader_parse_error: true
      properties:
        formula_parse_error:
          type: boolean
        sample_parse_error:
          type: boolean
        truncated_observation_error:
          type: boolean
        unresponsive_reward_error:
          type: boolean
        invalid_variable_error:
          type: boolean
        other_error:
          type: boolean
        python_grader_server_error:
          type: boolean
        python_grader_server_error_type:
          type: string
          nullable: true
        python_grader_runtime_error:
          type: boolean
        python_grader_runtime_error_details:
          type: string
          nullable: true
        model_grader_server_error:
          type: boolean
        model_grader_refusal_error:
          type: boolean
        model_grader_parse_error:
          type: boolean
        model_grader_server_error_details:
          type: string
          nullable: true
      required:
      - formula_parse_error
      - invalid_variable_error
      - model_grader_parse_error
      - model_grader_refusal_error
      - model_grader_server_error
      - model_grader_server_error_details
      - other_error
      - python_grader_runtime_error
      - python_grader_runtime_error_details
      - python_grader_server_error
      - python_grader_server_error_type
      - sample_parse_error
      - truncated_observation_error
      - unresponsive_reward_error
    RunGraderResponse_metadata:
      example:
        token_usage: 1
        scores:
          key: ""
        name: name
        type: type
        sampled_model_name: sampled_model_name
        errors:
          sample_parse_error: true
          python_grader_runtime_error_details: python_grader_runtime_error_details
          unresponsive_reward_error: true
          model_grader_refusal_error: true
          truncated_observation_error: true
          other_error: true
          formula_parse_error: true
          python_grader_server_error_type: python_grader_server_error_type
          python_grader_server_error: true
          model_grader_server_error: true
          invalid_variable_error: true
          python_grader_runtime_error: true
          model_grader_server_error_details: model_grader_server_error_details
          model_grader_parse_error: true
        execution_time: 6.027456183070403
      properties:
        name:
          type: string
        type:
          type: string
        errors:
          $ref: "#/components/schemas/RunGraderResponse_metadata_errors"
        execution_time:
          type: number
        scores:
          additionalProperties: true
          type: object
        token_usage:
          type: integer
          nullable: true
        sampled_model_name:
          type: string
          nullable: true
      required:
      - errors
      - execution_time
      - name
      - sampled_model_name
      - scores
      - token_usage
      - type
    RunObject_required_action_submit_tool_outputs:
      description: Details on the tool outputs needed for this run to continue.
      example:
        tool_calls:
        - function:
            name: name
            arguments: arguments
          id: id
          type: function
        - function:
            name: name
            arguments: arguments
          id: id
          type: function
      properties:
        tool_calls:
          description: A list of the relevant tool calls.
          items:
            $ref: "#/components/schemas/RunToolCallObject"
          type: array
      required:
      - tool_calls
    RunObject_required_action:
      description: Details on the action required to continue the run. Will be `null`
        if no action is required.
      example:
        submit_tool_outputs:
          tool_calls:
          - function:
              name: name
              arguments: arguments
            id: id
            type: function
          - function:
              name: name
              arguments: arguments
            id: id
            type: function
        type: submit_tool_outputs
      properties:
        type:
          description: "For now, this is always `submit_tool_outputs`."
          enum:
          - submit_tool_outputs
          type: string
          x-stainless-const: true
        submit_tool_outputs:
          $ref: "#/components/schemas/RunObject_required_action_submit_tool_outputs"
      required:
      - submit_tool_outputs
      - type
      nullable: true
    RunObject_last_error:
      description: The last error associated with this run. Will be `null` if there
        are no errors.
      example:
        code: server_error
        message: message
      properties:
        code:
          description: "One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`."
          enum:
          - server_error
          - rate_limit_exceeded
          - invalid_prompt
          type: string
        message:
          description: A human-readable description of the error.
          type: string
      required:
      - code
      - message
      nullable: true
    RunObject_incomplete_details:
      description: Details on why the run is incomplete. Will be `null` if the run
        is not incomplete.
      example:
        reason: max_completion_tokens
      properties:
        reason:
          description: The reason why the run is incomplete. This will point to which
            specific token limit was reached over the course of the run.
          enum:
          - max_completion_tokens
          - max_prompt_tokens
          type: string
      nullable: true
    RunStepDeltaObject_delta_step_details:
      description: The details of the run step.
      oneOf:
      - $ref: "#/components/schemas/RunStepDeltaStepDetailsMessageCreationObject"
      - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsObject"
    RunStepDeltaObject_delta:
      description: The delta containing the fields that have changed on the run step.
      properties:
        step_details:
          $ref: "#/components/schemas/RunStepDeltaObject_delta_step_details"
    RunStepDeltaStepDetailsMessageCreationObject_message_creation:
      properties:
        message_id:
          description: The ID of the message that was created by this run step.
          type: string
    RunStepDeltaStepDetailsToolCallsCodeObject_code_interpreter_outputs_inner:
      oneOf:
      - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject"
      - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputImageObject"
    RunStepDeltaStepDetailsToolCallsCodeObject_code_interpreter:
      description: The Code Interpreter tool call definition.
      properties:
        input:
          description: The input to the Code Interpreter tool call.
          type: string
        outputs:
          description: "The outputs from the Code Interpreter tool call. Code Interpreter\
            \ can output one or more items, including text (`logs`) or images (`image`).\
            \ Each of these are represented by a different object type."
          items:
            $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObject_code_interpreter_outputs_inner"
          type: array
    RunStepDeltaStepDetailsToolCallsCodeOutputImageObject_image:
      properties:
        file_id:
          description: "The [file](/docs/api-reference/files) ID of the image."
          type: string
    RunStepDeltaStepDetailsToolCallsFunctionObject_function:
      description: The definition of the function that was called.
      properties:
        name:
          description: The name of the function.
          type: string
        arguments:
          description: The arguments passed to the function.
          type: string
        output:
          description: "The output of the function. This will be `null` if the outputs\
            \ have not been [submitted](/docs/api-reference/runs/submitToolOutputs)\
            \ yet."
          type: string
          nullable: true
    RunStepDeltaStepDetailsToolCallsObject_tool_calls_inner:
      oneOf:
      - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObject"
      - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsFileSearchObject"
      - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsFunctionObject"
    RunStepDetailsMessageCreationObject_message_creation:
      example:
        message_id: message_id
      properties:
        message_id:
          description: The ID of the message that was created by this run step.
          type: string
      required:
      - message_id
    RunStepDetailsToolCallsCodeObject_code_interpreter_outputs_inner:
      oneOf:
      - $ref: "#/components/schemas/RunStepDetailsToolCallsCodeOutputLogsObject"
      - $ref: "#/components/schemas/RunStepDetailsToolCallsCodeOutputImageObject"
    RunStepDetailsToolCallsCodeObject_code_interpreter:
      description: The Code Interpreter tool call definition.
      properties:
        input:
          description: The input to the Code Interpreter tool call.
          type: string
        outputs:
          description: "The outputs from the Code Interpreter tool call. Code Interpreter\
            \ can output one or more items, including text (`logs`) or images (`image`).\
            \ Each of these are represented by a different object type."
          items:
            $ref: "#/components/schemas/RunStepDetailsToolCallsCodeObject_code_interpreter_outputs_inner"
          type: array
      required:
      - input
      - outputs
    RunStepDetailsToolCallsCodeOutputImageObject_image:
      properties:
        file_id:
          description: "The [file](/docs/api-reference/files) ID of the image."
          type: string
      required:
      - file_id
    RunStepDetailsToolCallsFileSearchObject_file_search:
      description: "For now, this is always going to be an empty object."
      properties:
        ranking_options:
          $ref: "#/components/schemas/RunStepDetailsToolCallsFileSearchRankingOptionsObject"
        results:
          description: The results of the file search.
          items:
            $ref: "#/components/schemas/RunStepDetailsToolCallsFileSearchResultObject"
          type: array
      x-oaiTypeLabel: map
    RunStepDetailsToolCallsFileSearchResultObject_content_inner:
      properties:
        type:
          description: The type of the content.
          enum:
          - text
          type: string
          x-stainless-const: true
        text:
          description: The text content of the file.
          type: string
    RunStepDetailsToolCallsFunctionObject_function:
      description: The definition of the function that was called.
      properties:
        name:
          description: The name of the function.
          type: string
        arguments:
          description: The arguments passed to the function.
          type: string
        output:
          description: "The output of the function. This will be `null` if the outputs\
            \ have not been [submitted](/docs/api-reference/runs/submitToolOutputs)\
            \ yet."
          type: string
          nullable: true
      required:
      - arguments
      - name
      - output
    RunStepDetailsToolCallsObject_tool_calls_inner:
      oneOf:
      - $ref: "#/components/schemas/RunStepDetailsToolCallsCodeObject"
      - $ref: "#/components/schemas/RunStepDetailsToolCallsFileSearchObject"
      - $ref: "#/components/schemas/RunStepDetailsToolCallsFunctionObject"
    RunStepObject_step_details:
      description: The details of the run step.
      oneOf:
      - $ref: "#/components/schemas/RunStepDetailsMessageCreationObject"
      - $ref: "#/components/schemas/RunStepDetailsToolCallsObject"
    RunStepObject_last_error:
      description: The last error associated with this run step. Will be `null` if
        there are no errors.
      example:
        code: server_error
        message: message
      properties:
        code:
          description: One of `server_error` or `rate_limit_exceeded`.
          enum:
          - server_error
          - rate_limit_exceeded
          type: string
        message:
          description: A human-readable description of the error.
          type: string
      required:
      - code
      - message
      nullable: true
    RunStepStreamEvent_oneOf:
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ is created."
      properties:
        event:
          enum:
          - thread.run.step.created
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunStepObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    RunStepStreamEvent_oneOf_1:
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ moves to an `in_progress` state."
      properties:
        event:
          enum:
          - thread.run.step.in_progress
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunStepObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    RunStepStreamEvent_oneOf_2:
      description: "Occurs when parts of a [run step](/docs/api-reference/run-steps/step-object)\
        \ are being streamed."
      properties:
        event:
          enum:
          - thread.run.step.delta
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunStepDeltaObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)"
    RunStepStreamEvent_oneOf_3:
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ is completed."
      properties:
        event:
          enum:
          - thread.run.step.completed
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunStepObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    RunStepStreamEvent_oneOf_4:
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ fails."
      properties:
        event:
          enum:
          - thread.run.step.failed
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunStepObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    RunStepStreamEvent_oneOf_5:
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ is cancelled."
      properties:
        event:
          enum:
          - thread.run.step.cancelled
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunStepObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    RunStepStreamEvent_oneOf_6:
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ expires."
      properties:
        event:
          enum:
          - thread.run.step.expired
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunStepObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    RunStreamEvent_oneOf:
      description: "Occurs when a new [run](/docs/api-reference/runs/object) is created."
      properties:
        event:
          enum:
          - thread.run.created
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_1:
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ a `queued` status."
      properties:
        event:
          enum:
          - thread.run.queued
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_2:
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ an `in_progress` status."
      properties:
        event:
          enum:
          - thread.run.in_progress
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_3:
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ a `requires_action` status."
      properties:
        event:
          enum:
          - thread.run.requires_action
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_4:
      description: "Occurs when a [run](/docs/api-reference/runs/object) is completed."
      properties:
        event:
          enum:
          - thread.run.completed
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_5:
      description: "Occurs when a [run](/docs/api-reference/runs/object) ends with\
        \ status `incomplete`."
      properties:
        event:
          enum:
          - thread.run.incomplete
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_6:
      description: "Occurs when a [run](/docs/api-reference/runs/object) fails."
      properties:
        event:
          enum:
          - thread.run.failed
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_7:
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ a `cancelling` status."
      properties:
        event:
          enum:
          - thread.run.cancelling
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_8:
      description: "Occurs when a [run](/docs/api-reference/runs/object) is cancelled."
      properties:
        event:
          enum:
          - thread.run.cancelled
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_9:
      description: "Occurs when a [run](/docs/api-reference/runs/object) expires."
      properties:
        event:
          enum:
          - thread.run.expired
          type: string
          x-stainless-const: true
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunToolCallObject_function:
      description: The function definition.
      example:
        name: name
        arguments: arguments
      properties:
        name:
          description: The name of the function.
          type: string
        arguments:
          description: The arguments that the model expects you to pass to the function.
          type: string
      required:
      - arguments
      - name
    SpeechAudioDoneEvent_usage:
      description: |
        Token usage statistics for the request.
      properties:
        input_tokens:
          description: Number of input tokens in the prompt.
          type: integer
        output_tokens:
          description: Number of output tokens generated.
          type: integer
        total_tokens:
          description: Total number of tokens used (input + output).
          type: integer
      required:
      - input_tokens
      - output_tokens
      - total_tokens
    SubmitToolOutputsRunRequest_tool_outputs_inner:
      example:
        output: output
        tool_call_id: tool_call_id
      properties:
        tool_call_id:
          description: The ID of the tool call in the `required_action` object within
            the run object the output is being submitted for.
          type: string
        output:
          description: The output of the tool call to be submitted to continue the
            run.
          type: string
    TranscriptTextDeltaEvent_logprobs_inner:
      properties:
        token:
          description: |
            The token that was used to generate the log probability.
          type: string
        logprob:
          description: |
            The log probability of the token.
          type: number
        bytes:
          description: |
            The bytes that were used to generate the log probability.
          items:
            type: integer
          type: array
    TranscriptTextUsageTokens_input_token_details:
      description: Details about the input tokens billed for this request.
      example:
        audio_tokens: 5
        text_tokens: 5
      properties:
        text_tokens:
          description: Number of text tokens billed for this request.
          type: integer
        audio_tokens:
          description: Number of audio tokens billed for this request.
          type: integer
    UsageTimeBucket_result_inner:
      oneOf:
      - $ref: "#/components/schemas/UsageCompletionsResult"
      - $ref: "#/components/schemas/UsageEmbeddingsResult"
      - $ref: "#/components/schemas/UsageModerationsResult"
      - $ref: "#/components/schemas/UsageImagesResult"
      - $ref: "#/components/schemas/UsageAudioSpeechesResult"
      - $ref: "#/components/schemas/UsageAudioTranscriptionsResult"
      - $ref: "#/components/schemas/UsageVectorStoresResult"
      - $ref: "#/components/schemas/UsageCodeInterpreterSessionsResult"
      - $ref: "#/components/schemas/CostsResult"
    VectorStoreFileAttributes_value:
      oneOf:
      - maxLength: 512
        type: string
      - type: number
      - type: boolean
    VectorStoreFileBatchObject_file_counts:
      example:
        in_progress: 6
        total: 2
        cancelled: 5
        completed: 1
        failed: 5
      properties:
        in_progress:
          description: The number of files that are currently being processed.
          type: integer
        completed:
          description: The number of files that have been processed.
          type: integer
        failed:
          description: The number of files that have failed to process.
          type: integer
        cancelled:
          description: The number of files that where cancelled.
          type: integer
        total:
          description: The total number of files.
          type: integer
      required:
      - cancelled
      - completed
      - failed
      - in_progress
      - total
    VectorStoreFileContentResponse_data_inner:
      example:
        text: text
        type: type
      properties:
        type:
          description: The content type (currently only `"text"`)
          type: string
        text:
          description: The text content
          type: string
    VectorStoreFileObject_last_error:
      description: The last error associated with this vector store file. Will be
        `null` if there are no errors.
      example:
        code: server_error
        message: message
      properties:
        code:
          description: One of `server_error` or `rate_limit_exceeded`.
          enum:
          - server_error
          - unsupported_file
          - invalid_file
          type: string
        message:
          description: A human-readable description of the error.
          type: string
      required:
      - code
      - message
      nullable: true
    VectorStoreFileObject_chunking_strategy:
      description: The strategy used to chunk the file.
      oneOf:
      - $ref: "#/components/schemas/StaticChunkingStrategyResponseParam"
      - $ref: "#/components/schemas/OtherChunkingStrategyResponseParam"
    VectorStoreObject_file_counts:
      example:
        in_progress: 1
        total: 7
        cancelled: 2
        completed: 5
        failed: 5
      properties:
        in_progress:
          description: The number of files that are currently being processed.
          type: integer
        completed:
          description: The number of files that have been successfully processed.
          type: integer
        failed:
          description: The number of files that have failed to process.
          type: integer
        cancelled:
          description: The number of files that were cancelled.
          type: integer
        total:
          description: The total number of files.
          type: integer
      required:
      - cancelled
      - completed
      - failed
      - in_progress
      - total
    VectorStoreSearchRequest_query:
      description: A query string for a search
      oneOf:
      - {}
      - items:
          description: A list of queries to search for.
          minItems: 1
    VectorStoreSearchRequest_filters:
      description: A filter to apply based on file attributes.
      oneOf:
      - $ref: "#/components/schemas/ComparisonFilter"
      - $ref: "#/components/schemas/CompoundFilter"
    VectorStoreSearchRequest_ranking_options:
      additionalProperties: true
      description: Ranking options for search.
      example:
        score_threshold: 0.6027456183070403
        ranker: auto
      properties:
        ranker:
          default: auto
          enum:
          - auto
          - default-2024-11-15
        score_threshold:
          default: 0
          maximum: 1
          minimum: 0
    WebSearchToolCall_action:
      description: |
        An object describing the specific action taken in this web search call.
        Includes details on how the model used the web (search, open_page, find).
      oneOf:
      - $ref: "#/components/schemas/WebSearchActionSearch"
      - $ref: "#/components/schemas/WebSearchActionOpenPage"
      - $ref: "#/components/schemas/WebSearchActionFind"
    WebhookBatchCancelled_data:
      description: |
        Event data payload.
      example:
        id: id
      properties:
        id:
          description: |
            The unique ID of the batch API request.
          type: string
      required:
      - id
    WebhookEvalRunCanceled_data:
      description: |
        Event data payload.
      example:
        id: id
      properties:
        id:
          description: |
            The unique ID of the eval run.
          type: string
      required:
      - id
    WebhookFineTuningJobCancelled_data:
      description: |
        Event data payload.
      example:
        id: id
      properties:
        id:
          description: |
            The unique ID of the fine-tuning job.
          type: string
      required:
      - id
    WebhookResponseCancelled_data:
      description: |
        Event data payload.
      example:
        id: id
      properties:
        id:
          description: |
            The unique ID of the model response.
          type: string
      required:
      - id
  securitySchemes:
    ApiKeyAuth:
      scheme: bearer
      type: http
x-oaiMeta:
  navigationGroups:
  - id: responses
    title: Responses
  - id: chat
    title: Chat Completions
  - id: webhooks
    title: Webhooks
  - id: realtime
    title: Realtime
    beta: true
  - id: endpoints
    title: Platform APIs
  - id: vector_stores
    title: Vector stores
  - id: containers
    title: Containers
  - id: assistants
    title: Assistants
    beta: true
  - id: administration
    title: Administration
  - id: legacy
    title: Legacy
  groups:
  - id: responses
    title: Responses
    description: |
      OpenAI's most advanced interface for generating model responses. Supports
      text and image inputs, and text outputs. Create stateful interactions
      with the model, using the output of previous responses as input. Extend
      the model's capabilities with built-in tools for file search, web search,
      computer use, and more. Allow the model access to external systems and data
      using function calling.

      Related guides:
      - [Quickstart](/docs/quickstart?api-mode=responses)
      - [Text inputs and outputs](/docs/guides/text?api-mode=responses)
      - [Image inputs](/docs/guides/images?api-mode=responses)
      - [Structured Outputs](/docs/guides/structured-outputs?api-mode=responses)
      - [Function calling](/docs/guides/function-calling?api-mode=responses)
      - [Conversation state](/docs/guides/conversation-state?api-mode=responses)
      - [Extend the models with tools](/docs/guides/tools?api-mode=responses)
    navigationGroup: responses
    sections:
    - type: endpoint
      key: createResponse
      path: create
    - type: endpoint
      key: getResponse
      path: get
    - type: endpoint
      key: deleteResponse
      path: delete
    - type: endpoint
      key: cancelResponse
      path: cancel
    - type: endpoint
      key: listInputItems
      path: input-items
    - type: object
      key: Response
      path: object
    - type: object
      key: ResponseItemList
      path: list
  - id: responses-streaming
    title: Streaming
    description: |
      When you [create a Response](/docs/api-reference/responses/create) with
      `stream` set to `true`, the server will emit server-sent events to the
      client as the Response is generated. This section contains the events that
      are emitted by the server.

      [Learn more about streaming responses](/docs/guides/streaming-responses?api-mode=responses).
    navigationGroup: responses
    sections:
    - type: object
      key: ResponseCreatedEvent
      path: <auto>
    - type: object
      key: ResponseInProgressEvent
      path: <auto>
    - type: object
      key: ResponseCompletedEvent
      path: <auto>
    - type: object
      key: ResponseFailedEvent
      path: <auto>
    - type: object
      key: ResponseIncompleteEvent
      path: <auto>
    - type: object
      key: ResponseOutputItemAddedEvent
      path: <auto>
    - type: object
      key: ResponseOutputItemDoneEvent
      path: <auto>
    - type: object
      key: ResponseContentPartAddedEvent
      path: <auto>
    - type: object
      key: ResponseContentPartDoneEvent
      path: <auto>
    - type: object
      key: ResponseTextDeltaEvent
      path: <auto>
    - type: object
      key: ResponseTextDoneEvent
      path: <auto>
    - type: object
      key: ResponseRefusalDeltaEvent
      path: <auto>
    - type: object
      key: ResponseRefusalDoneEvent
      path: <auto>
    - type: object
      key: ResponseFunctionCallArgumentsDeltaEvent
      path: <auto>
    - type: object
      key: ResponseFunctionCallArgumentsDoneEvent
      path: <auto>
    - type: object
      key: ResponseFileSearchCallInProgressEvent
      path: <auto>
    - type: object
      key: ResponseFileSearchCallSearchingEvent
      path: <auto>
    - type: object
      key: ResponseFileSearchCallCompletedEvent
      path: <auto>
    - type: object
      key: ResponseWebSearchCallInProgressEvent
      path: <auto>
    - type: object
      key: ResponseWebSearchCallSearchingEvent
      path: <auto>
    - type: object
      key: ResponseWebSearchCallCompletedEvent
      path: <auto>
    - type: object
      key: ResponseReasoningSummaryPartAddedEvent
      path: <auto>
    - type: object
      key: ResponseReasoningSummaryPartDoneEvent
      path: <auto>
    - type: object
      key: ResponseReasoningSummaryTextDeltaEvent
      path: <auto>
    - type: object
      key: ResponseReasoningSummaryTextDoneEvent
      path: <auto>
    - type: object
      key: ResponseImageGenCallCompletedEvent
      path: <auto>
    - type: object
      key: ResponseImageGenCallGeneratingEvent
      path: <auto>
    - type: object
      key: ResponseImageGenCallInProgressEvent
      path: <auto>
    - type: object
      key: ResponseImageGenCallPartialImageEvent
      path: <auto>
    - type: object
      key: ResponseMCPCallArgumentsDeltaEvent
      path: <auto>
    - type: object
      key: ResponseMCPCallArgumentsDoneEvent
      path: <auto>
    - type: object
      key: ResponseMCPCallCompletedEvent
      path: <auto>
    - type: object
      key: ResponseMCPCallFailedEvent
      path: <auto>
    - type: object
      key: ResponseMCPCallInProgressEvent
      path: <auto>
    - type: object
      key: ResponseMCPListToolsCompletedEvent
      path: <auto>
    - type: object
      key: ResponseMCPListToolsFailedEvent
      path: <auto>
    - type: object
      key: ResponseMCPListToolsInProgressEvent
      path: <auto>
    - type: object
      key: ResponseCodeInterpreterCallInProgressEvent
      path: <auto>
    - type: object
      key: ResponseCodeInterpreterCallInterpretingEvent
      path: <auto>
    - type: object
      key: ResponseCodeInterpreterCallCompletedEvent
      path: <auto>
    - type: object
      key: ResponseCodeInterpreterCallCodeDeltaEvent
      path: <auto>
    - type: object
      key: ResponseCodeInterpreterCallCodeDoneEvent
      path: <auto>
    - type: object
      key: ResponseOutputTextAnnotationAddedEvent
      path: <auto>
    - type: object
      key: ResponseQueuedEvent
      path: <auto>
    - type: object
      key: ResponseReasoningDeltaEvent
      path: <auto>
    - type: object
      key: ResponseReasoningDoneEvent
      path: <auto>
    - type: object
      key: ResponseReasoningSummaryDeltaEvent
      path: <auto>
    - type: object
      key: ResponseReasoningSummaryDoneEvent
      path: <auto>
    - type: object
      key: ResponseErrorEvent
      path: <auto>
  - id: chat
    title: Chat Completions
    description: |
      The Chat Completions API endpoint will generate a model response from a
      list of messages comprising a conversation.

      Related guides:
      - [Quickstart](/docs/quickstart?api-mode=chat)
      - [Text inputs and outputs](/docs/guides/text?api-mode=chat)
      - [Image inputs](/docs/guides/images?api-mode=chat)
      - [Audio inputs and outputs](/docs/guides/audio?api-mode=chat)
      - [Structured Outputs](/docs/guides/structured-outputs?api-mode=chat)
      - [Function calling](/docs/guides/function-calling?api-mode=chat)
      - [Conversation state](/docs/guides/conversation-state?api-mode=chat)

      **Starting a new project?** We recommend trying [Responses](/docs/api-reference/responses)
      to take advantage of the latest OpenAI platform features. Compare
      [Chat Completions with Responses](/docs/guides/responses-vs-chat-completions?api-mode=responses).
    navigationGroup: chat
    sections:
    - type: endpoint
      key: createChatCompletion
      path: create
    - type: endpoint
      key: getChatCompletion
      path: get
    - type: endpoint
      key: getChatCompletionMessages
      path: getMessages
    - type: endpoint
      key: listChatCompletions
      path: list
    - type: endpoint
      key: updateChatCompletion
      path: update
    - type: endpoint
      key: deleteChatCompletion
      path: delete
    - type: object
      key: CreateChatCompletionResponse
      path: object
    - type: object
      key: ChatCompletionList
      path: list-object
    - type: object
      key: ChatCompletionMessageList
      path: message-list
  - id: chat-streaming
    title: Streaming
    description: |
      Stream Chat Completions in real time. Receive chunks of completions
      returned from the model using server-sent events.
      [Learn more](/docs/guides/streaming-responses?api-mode=chat).
    navigationGroup: chat
    sections:
    - type: object
      key: CreateChatCompletionStreamResponse
      path: streaming
  - id: webhook-events
    title: Webhook Events
    description: "Webhooks are HTTP requests sent by OpenAI to a URL you specify when\
      \ certain\nevents happen during the course of API usage. \n\n[Learn more about\
      \ webhooks](/docs/guides/webhooks).\n"
    navigationGroup: webhooks
    sections:
    - type: object
      key: WebhookResponseCompleted
      path: <auto>
    - type: object
      key: WebhookResponseCancelled
      path: <auto>
    - type: object
      key: WebhookResponseFailed
      path: <auto>
    - type: object
      key: WebhookResponseIncomplete
      path: <auto>
    - type: object
      key: WebhookBatchCompleted
      path: <auto>
    - type: object
      key: WebhookBatchCancelled
      path: <auto>
    - type: object
      key: WebhookBatchExpired
      path: <auto>
    - type: object
      key: WebhookBatchFailed
      path: <auto>
    - type: object
      key: WebhookFineTuningJobSucceeded
      path: <auto>
    - type: object
      key: WebhookFineTuningJobFailed
      path: <auto>
    - type: object
      key: WebhookFineTuningJobCancelled
      path: <auto>
    - type: object
      key: WebhookEvalRunSucceeded
      path: <auto>
    - type: object
      key: WebhookEvalRunFailed
      path: <auto>
    - type: object
      key: WebhookEvalRunCanceled
      path: <auto>
  - id: realtime
    title: Realtime
    beta: true
    description: |
      Communicate with a GPT-4o class model in real time using WebRTC or
      WebSockets. Supports text and audio inputs and ouputs, along with audio
      transcriptions.
      [Learn more about the Realtime API](/docs/guides/realtime).
    navigationGroup: realtime
  - id: realtime-sessions
    title: Session tokens
    description: |
      REST API endpoint to generate ephemeral session tokens for use in client-side
      applications.
    navigationGroup: realtime
    sections:
    - type: endpoint
      key: create-realtime-session
      path: create
    - type: endpoint
      key: create-realtime-transcription-session
      path: create-transcription
    - type: object
      key: RealtimeSessionCreateResponse
      path: session_object
    - type: object
      key: RealtimeTranscriptionSessionCreateResponse
      path: transcription_session_object
  - id: realtime-client-events
    title: Client events
    description: |
      These are events that the OpenAI Realtime WebSocket server will accept from the client.
    navigationGroup: realtime
    sections:
    - type: object
      key: RealtimeClientEventSessionUpdate
      path: <auto>
    - type: object
      key: RealtimeClientEventInputAudioBufferAppend
      path: <auto>
    - type: object
      key: RealtimeClientEventInputAudioBufferCommit
      path: <auto>
    - type: object
      key: RealtimeClientEventInputAudioBufferClear
      path: <auto>
    - type: object
      key: RealtimeClientEventConversationItemCreate
      path: <auto>
    - type: object
      key: RealtimeClientEventConversationItemRetrieve
      path: <auto>
    - type: object
      key: RealtimeClientEventConversationItemTruncate
      path: <auto>
    - type: object
      key: RealtimeClientEventConversationItemDelete
      path: <auto>
    - type: object
      key: RealtimeClientEventResponseCreate
      path: <auto>
    - type: object
      key: RealtimeClientEventResponseCancel
      path: <auto>
    - type: object
      key: RealtimeClientEventTranscriptionSessionUpdate
      path: <auto>
    - type: object
      key: RealtimeClientEventOutputAudioBufferClear
      path: <auto>
  - id: realtime-server-events
    title: Server events
    description: |
      These are events emitted from the OpenAI Realtime WebSocket server to the client.
    navigationGroup: realtime
    sections:
    - type: object
      key: RealtimeServerEventError
      path: <auto>
    - type: object
      key: RealtimeServerEventSessionCreated
      path: <auto>
    - type: object
      key: RealtimeServerEventSessionUpdated
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationCreated
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemCreated
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemRetrieved
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemInputAudioTranscriptionCompleted
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemInputAudioTranscriptionDelta
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemInputAudioTranscriptionFailed
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemTruncated
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemDeleted
      path: <auto>
    - type: object
      key: RealtimeServerEventInputAudioBufferCommitted
      path: <auto>
    - type: object
      key: RealtimeServerEventInputAudioBufferCleared
      path: <auto>
    - type: object
      key: RealtimeServerEventInputAudioBufferSpeechStarted
      path: <auto>
    - type: object
      key: RealtimeServerEventInputAudioBufferSpeechStopped
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseCreated
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseOutputItemAdded
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseOutputItemDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseContentPartAdded
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseContentPartDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseTextDelta
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseTextDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseAudioTranscriptDelta
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseAudioTranscriptDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseAudioDelta
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseAudioDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseFunctionCallArgumentsDelta
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseFunctionCallArgumentsDone
      path: <auto>
    - type: object
      key: RealtimeServerEventTranscriptionSessionUpdated
      path: <auto>
    - type: object
      key: RealtimeServerEventRateLimitsUpdated
      path: <auto>
    - type: object
      key: RealtimeServerEventOutputAudioBufferStarted
      path: <auto>
    - type: object
      key: RealtimeServerEventOutputAudioBufferStopped
      path: <auto>
    - type: object
      key: RealtimeServerEventOutputAudioBufferCleared
      path: <auto>
  - id: audio
    title: Audio
    description: |
      Learn how to turn audio into text or text into audio.

      Related guide: [Speech to text](/docs/guides/speech-to-text)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createSpeech
      path: createSpeech
    - type: endpoint
      key: createTranscription
      path: createTranscription
    - type: endpoint
      key: createTranslation
      path: createTranslation
    - type: object
      key: CreateTranscriptionResponseJson
      path: json-object
    - type: object
      key: CreateTranscriptionResponseVerboseJson
      path: verbose-json-object
    - type: object
      key: SpeechAudioDeltaEvent
      path: speech-audio-delta-event
    - type: object
      key: SpeechAudioDoneEvent
      path: speech-audio-done-event
    - type: object
      key: TranscriptTextDeltaEvent
      path: transcript-text-delta-event
    - type: object
      key: TranscriptTextDoneEvent
      path: transcript-text-done-event
  - id: images
    title: Images
    description: |
      Given a prompt and/or an input image, the model will generate a new image.
      Related guide: [Image generation](/docs/guides/images)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createImage
      path: create
    - type: endpoint
      key: createImageEdit
      path: createEdit
    - type: endpoint
      key: createImageVariation
      path: createVariation
    - type: object
      key: ImagesResponse
      path: object
  - id: embeddings
    title: Embeddings
    description: |
      Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
      Related guide: [Embeddings](/docs/guides/embeddings)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createEmbedding
      path: create
    - type: object
      key: Embedding
      path: object
  - id: evals
    title: Evals
    description: |
      Create, manage, and run evals in the OpenAI platform.
      Related guide: [Evals](/docs/guides/evals)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createEval
      path: create
    - type: endpoint
      key: getEval
      path: get
    - type: endpoint
      key: updateEval
      path: update
    - type: endpoint
      key: deleteEval
      path: delete
    - type: endpoint
      key: listEvals
      path: list
    - type: endpoint
      key: getEvalRuns
      path: getRuns
    - type: endpoint
      key: getEvalRun
      path: getRun
    - type: endpoint
      key: createEvalRun
      path: createRun
    - type: endpoint
      key: cancelEvalRun
      path: cancelRun
    - type: endpoint
      key: deleteEvalRun
      path: deleteRun
    - type: endpoint
      key: getEvalRunOutputItem
      path: getRunOutputItem
    - type: endpoint
      key: getEvalRunOutputItems
      path: getRunOutputItems
    - type: object
      key: Eval
      path: object
    - type: object
      key: EvalRun
      path: run-object
    - type: object
      key: EvalRunOutputItem
      path: run-output-item-object
  - id: fine-tuning
    title: Fine-tuning
    description: |
      Manage fine-tuning jobs to tailor a model to your specific training data.
      Related guide: [Fine-tune models](/docs/guides/fine-tuning)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createFineTuningJob
      path: create
    - type: endpoint
      key: listPaginatedFineTuningJobs
      path: list
    - type: endpoint
      key: listFineTuningEvents
      path: list-events
    - type: endpoint
      key: listFineTuningJobCheckpoints
      path: list-checkpoints
    - type: endpoint
      key: listFineTuningCheckpointPermissions
      path: list-permissions
    - type: endpoint
      key: createFineTuningCheckpointPermission
      path: create-permission
    - type: endpoint
      key: deleteFineTuningCheckpointPermission
      path: delete-permission
    - type: endpoint
      key: retrieveFineTuningJob
      path: retrieve
    - type: endpoint
      key: cancelFineTuningJob
      path: cancel
    - type: endpoint
      key: resumeFineTuningJob
      path: resume
    - type: endpoint
      key: pauseFineTuningJob
      path: pause
    - type: object
      key: FineTuneChatRequestInput
      path: chat-input
    - type: object
      key: FineTunePreferenceRequestInput
      path: preference-input
    - type: object
      key: FineTuneReinforcementRequestInput
      path: reinforcement-input
    - type: object
      key: FineTuningJob
      path: object
    - type: object
      key: FineTuningJobEvent
      path: event-object
    - type: object
      key: FineTuningJobCheckpoint
      path: checkpoint-object
    - type: object
      key: FineTuningCheckpointPermission
      path: permission-object
  - id: graders
    title: Graders
    description: |
      Manage and run graders in the OpenAI platform.
      Related guide: [Graders](/docs/guides/graders)
    navigationGroup: endpoints
    sections:
    - type: object
      key: GraderStringCheck
      path: string-check
    - type: object
      key: GraderTextSimilarity
      path: text-similarity
    - type: object
      key: GraderScoreModel
      path: score-model
    - type: object
      key: GraderLabelModel
      path: label-model
    - type: object
      key: GraderPython
      path: python
    - type: object
      key: GraderMulti
      path: multi
    - type: endpoint
      key: runGrader
      path: run
    - type: endpoint
      key: validateGrader
      path: validate
      beta: true
  - id: batch
    title: Batch
    description: |
      Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount.
      Related guide: [Batch](/docs/guides/batch)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createBatch
      path: create
    - type: endpoint
      key: retrieveBatch
      path: retrieve
    - type: endpoint
      key: cancelBatch
      path: cancel
    - type: endpoint
      key: listBatches
      path: list
    - type: object
      key: Batch
      path: object
    - type: object
      key: BatchRequestInput
      path: request-input
    - type: object
      key: BatchRequestOutput
      path: request-output
  - id: files
    title: Files
    description: |
      Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch API](/docs/guides/batch).
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createFile
      path: create
    - type: endpoint
      key: listFiles
      path: list
    - type: endpoint
      key: retrieveFile
      path: retrieve
    - type: endpoint
      key: deleteFile
      path: delete
    - type: endpoint
      key: downloadFile
      path: retrieve-contents
    - type: object
      key: OpenAIFile
      path: object
  - id: uploads
    title: Uploads
    description: |
      Allows you to upload large files in multiple parts.
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createUpload
      path: create
    - type: endpoint
      key: addUploadPart
      path: add-part
    - type: endpoint
      key: completeUpload
      path: complete
    - type: endpoint
      key: cancelUpload
      path: cancel
    - type: object
      key: Upload
      path: object
    - type: object
      key: UploadPart
      path: part-object
  - id: models
    title: Models
    description: |
      List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: listModels
      path: list
    - type: endpoint
      key: retrieveModel
      path: retrieve
    - type: endpoint
      key: deleteModel
      path: delete
    - type: object
      key: Model
      path: object
  - id: moderations
    title: Moderations
    description: |
      Given text and/or image inputs, classifies if those inputs are potentially harmful across several categories.
      Related guide: [Moderations](/docs/guides/moderation)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createModeration
      path: create
    - type: object
      key: CreateModerationResponse
      path: object
  - id: vector-stores
    title: Vector stores
    description: |
      Vector stores power semantic search for the Retrieval API and the `file_search` tool in the Responses and Assistants APIs.

      Related guide: [File Search](/docs/assistants/tools/file-search)
    navigationGroup: vector_stores
    sections:
    - type: endpoint
      key: createVectorStore
      path: create
    - type: endpoint
      key: listVectorStores
      path: list
    - type: endpoint
      key: getVectorStore
      path: retrieve
    - type: endpoint
      key: modifyVectorStore
      path: modify
    - type: endpoint
      key: deleteVectorStore
      path: delete
    - type: endpoint
      key: searchVectorStore
      path: search
    - type: object
      key: VectorStoreObject
      path: object
  - id: vector-stores-files
    title: Vector store files
    description: |
      Vector store files represent files inside a vector store.

      Related guide: [File Search](/docs/assistants/tools/file-search)
    navigationGroup: vector_stores
    sections:
    - type: endpoint
      key: createVectorStoreFile
      path: createFile
    - type: endpoint
      key: listVectorStoreFiles
      path: listFiles
    - type: endpoint
      key: getVectorStoreFile
      path: getFile
    - type: endpoint
      key: retrieveVectorStoreFileContent
      path: getContent
    - type: endpoint
      key: updateVectorStoreFileAttributes
      path: updateAttributes
    - type: endpoint
      key: deleteVectorStoreFile
      path: deleteFile
    - type: object
      key: VectorStoreFileObject
      path: file-object
  - id: vector-stores-file-batches
    title: Vector store file batches
    description: |
      Vector store file batches represent operations to add multiple files to a vector store.
      Related guide: [File Search](/docs/assistants/tools/file-search)
    navigationGroup: vector_stores
    sections:
    - type: endpoint
      key: createVectorStoreFileBatch
      path: createBatch
    - type: endpoint
      key: getVectorStoreFileBatch
      path: getBatch
    - type: endpoint
      key: cancelVectorStoreFileBatch
      path: cancelBatch
    - type: endpoint
      key: listFilesInVectorStoreBatch
      path: listBatchFiles
    - type: object
      key: VectorStoreFileBatchObject
      path: batch-object
  - id: containers
    title: Containers
    description: |
      Create and manage containers for use with the Code Interpreter tool.
    navigationGroup: containers
    sections:
    - type: endpoint
      key: CreateContainer
      path: createContainers
    - type: endpoint
      key: ListContainers
      path: listContainers
    - type: endpoint
      key: RetrieveContainer
      path: retrieveContainer
    - type: endpoint
      key: DeleteContainer
      path: deleteContainer
    - type: object
      key: ContainerResource
      path: object
  - id: container-files
    title: Container Files
    description: |
      Create and manage container files for use with the Code Interpreter tool.
    navigationGroup: containers
    sections:
    - type: endpoint
      key: CreateContainerFile
      path: createContainerFile
    - type: endpoint
      key: ListContainerFiles
      path: listContainerFiles
    - type: endpoint
      key: RetrieveContainerFile
      path: retrieveContainerFile
    - type: endpoint
      key: RetrieveContainerFileContent
      path: retrieveContainerFileContent
    - type: endpoint
      key: DeleteContainerFile
      path: deleteContainerFile
    - type: object
      key: ContainerFileResource
      path: object
  - id: assistants
    title: Assistants
    beta: true
    description: |
      Build assistants that can call models and use tools to perform tasks.

      [Get started with the Assistants API](/docs/assistants)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createAssistant
      path: createAssistant
    - type: endpoint
      key: listAssistants
      path: listAssistants
    - type: endpoint
      key: getAssistant
      path: getAssistant
    - type: endpoint
      key: modifyAssistant
      path: modifyAssistant
    - type: endpoint
      key: deleteAssistant
      path: deleteAssistant
    - type: object
      key: AssistantObject
      path: object
  - id: threads
    title: Threads
    beta: true
    description: |
      Create threads that assistants can interact with.

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createThread
      path: createThread
    - type: endpoint
      key: getThread
      path: getThread
    - type: endpoint
      key: modifyThread
      path: modifyThread
    - type: endpoint
      key: deleteThread
      path: deleteThread
    - type: object
      key: ThreadObject
      path: object
  - id: messages
    title: Messages
    beta: true
    description: |
      Create messages within threads

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createMessage
      path: createMessage
    - type: endpoint
      key: listMessages
      path: listMessages
    - type: endpoint
      key: getMessage
      path: getMessage
    - type: endpoint
      key: modifyMessage
      path: modifyMessage
    - type: endpoint
      key: deleteMessage
      path: deleteMessage
    - type: object
      key: MessageObject
      path: object
  - id: runs
    title: Runs
    beta: true
    description: |
      Represents an execution run on a thread.

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createRun
      path: createRun
    - type: endpoint
      key: createThreadAndRun
      path: createThreadAndRun
    - type: endpoint
      key: listRuns
      path: listRuns
    - type: endpoint
      key: getRun
      path: getRun
    - type: endpoint
      key: modifyRun
      path: modifyRun
    - type: endpoint
      key: submitToolOuputsToRun
      path: submitToolOutputs
    - type: endpoint
      key: cancelRun
      path: cancelRun
    - type: object
      key: RunObject
      path: object
  - id: run-steps
    title: Run steps
    beta: true
    description: |
      Represents the steps (model and tool calls) taken during the run.

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: listRunSteps
      path: listRunSteps
    - type: endpoint
      key: getRunStep
      path: getRunStep
    - type: object
      key: RunStepObject
      path: step-object
  - id: assistants-streaming
    title: Streaming
    beta: true
    description: |
      Stream the result of executing a Run or resuming a Run after submitting tool outputs.
      You can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun),
      [Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs)
      endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.
      Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
      [Assistants API quickstart](/docs/assistants/overview) to learn more.
    navigationGroup: assistants
    sections:
    - type: object
      key: MessageDeltaObject
      path: message-delta-object
    - type: object
      key: RunStepDeltaObject
      path: run-step-delta-object
    - type: object
      key: AssistantStreamEvent
      path: events
  - id: administration
    title: Administration
    description: |
      Programmatically manage your organization.
      The Audit Logs endpoint provides a log of all actions taken in the organization for security and monitoring purposes.
      To access these endpoints please generate an Admin API Key through the [API Platform Organization overview](/organization/admin-keys). Admin API keys cannot be used for non-administration endpoints.
      For best practices on setting up your organization, please refer to this [guide](/docs/guides/production-best-practices#setting-up-your-organization)
    navigationGroup: administration
  - id: admin-api-keys
    title: Admin API Keys
    description: |
      Admin API keys enable Organization Owners to programmatically manage various aspects of their organization, including users, projects, and API keys. These keys provide administrative capabilities, such as creating, updating, and deleting users; managing projects; and overseeing API key lifecycles.

      Key Features of Admin API Keys:

      - User Management: Invite new users, update roles, and remove users from the organization.

      - Project Management: Create, update, archive projects, and manage user assignments within projects.

      - API Key Oversight: List, retrieve, and delete API keys associated with projects.

      Only Organization Owners have the authority to create and utilize Admin API keys. To manage these keys, Organization Owners can navigate to the Admin Keys section of their API Platform dashboard.

      For direct access to the Admin Keys management page, Organization Owners can use the following link:

      [https://platform.openai.com/settings/organization/admin-keys](https://platform.openai.com/settings/organization/admin-keys)

      It's crucial to handle Admin API keys with care due to their elevated permissions. Adhering to best practices, such as regular key rotation and assigning appropriate permissions, enhances security and ensures proper governance within the organization.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: admin-api-keys-list
      path: list
    - type: endpoint
      key: admin-api-keys-create
      path: create
    - type: endpoint
      key: admin-api-keys-get
      path: listget
    - type: endpoint
      key: admin-api-keys-delete
      path: delete
    - type: object
      key: AdminApiKey
      path: object
  - id: invite
    title: Invites
    description: Invite and manage invitations for an organization.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-invites
      path: list
    - type: endpoint
      key: inviteUser
      path: create
    - type: endpoint
      key: retrieve-invite
      path: retrieve
    - type: endpoint
      key: delete-invite
      path: delete
    - type: object
      key: Invite
      path: object
  - id: users
    title: Users
    description: |
      Manage users and their role in an organization.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-users
      path: list
    - type: endpoint
      key: modify-user
      path: modify
    - type: endpoint
      key: retrieve-user
      path: retrieve
    - type: endpoint
      key: delete-user
      path: delete
    - type: object
      key: User
      path: object
  - id: projects
    title: Projects
    description: |
      Manage the projects within an orgnanization includes creation, updating, and archiving or projects.
      The Default project cannot be archived.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-projects
      path: list
    - type: endpoint
      key: create-project
      path: create
    - type: endpoint
      key: retrieve-project
      path: retrieve
    - type: endpoint
      key: modify-project
      path: modify
    - type: endpoint
      key: archive-project
      path: archive
    - type: object
      key: Project
      path: object
  - id: project-users
    title: Project users
    description: |
      Manage users within a project, including adding, updating roles, and removing users.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-project-users
      path: list
    - type: endpoint
      key: create-project-user
      path: creeate
    - type: endpoint
      key: retrieve-project-user
      path: retrieve
    - type: endpoint
      key: modify-project-user
      path: modify
    - type: endpoint
      key: delete-project-user
      path: delete
    - type: object
      key: ProjectUser
      path: object
  - id: project-service-accounts
    title: Project service accounts
    description: |
      Manage service accounts within a project. A service account is a bot user that is not associated with a user.
      If a user leaves an organization, their keys and membership in projects will no longer work. Service accounts
      do not have this limitation. However, service accounts can also be deleted from a project.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-project-service-accounts
      path: list
    - type: endpoint
      key: create-project-service-account
      path: create
    - type: endpoint
      key: retrieve-project-service-account
      path: retrieve
    - type: endpoint
      key: delete-project-service-account
      path: delete
    - type: object
      key: ProjectServiceAccount
      path: object
  - id: project-api-keys
    title: Project API keys
    description: |
      Manage API keys for a given project. Supports listing and deleting keys for users.
      This API does not allow issuing keys for users, as users need to authorize themselves to generate keys.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-project-api-keys
      path: list
    - type: endpoint
      key: retrieve-project-api-key
      path: retrieve
    - type: endpoint
      key: delete-project-api-key
      path: delete
    - type: object
      key: ProjectApiKey
      path: object
  - id: project-rate-limits
    title: Project rate limits
    description: |
      Manage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-project-rate-limits
      path: list
    - type: endpoint
      key: update-project-rate-limits
      path: update
    - type: object
      key: ProjectRateLimit
      path: object
  - id: audit-logs
    title: Audit logs
    description: |
      Logs of user actions and configuration changes within this organization.
      To log events, an Organization Owner must activate logging in the [Data Controls Settings](/settings/organization/data-controls/data-retention).
      Once activated, for security reasons, logging cannot be deactivated.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-audit-logs
      path: list
    - type: object
      key: AuditLog
      path: object
  - id: usage
    title: Usage
    description: |
      The **Usage API** provides detailed insights into your activity across the OpenAI API. It also includes a separate [Costs endpoint](/docs/api-reference/usage/costs), which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.

      While the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the [Costs endpoint](/docs/api-reference/usage/costs) or the [Costs tab](/settings/organization/usage) in the Usage Dashboard, which will reconcile back to your billing invoice.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: usage-completions
      path: completions
    - type: object
      key: UsageCompletionsResult
      path: completions_object
    - type: endpoint
      key: usage-embeddings
      path: embeddings
    - type: object
      key: UsageEmbeddingsResult
      path: embeddings_object
    - type: endpoint
      key: usage-moderations
      path: moderations
    - type: object
      key: UsageModerationsResult
      path: moderations_object
    - type: endpoint
      key: usage-images
      path: images
    - type: object
      key: UsageImagesResult
      path: images_object
    - type: endpoint
      key: usage-audio-speeches
      path: audio_speeches
    - type: object
      key: UsageAudioSpeechesResult
      path: audio_speeches_object
    - type: endpoint
      key: usage-audio-transcriptions
      path: audio_transcriptions
    - type: object
      key: UsageAudioTranscriptionsResult
      path: audio_transcriptions_object
    - type: endpoint
      key: usage-vector-stores
      path: vector_stores
    - type: object
      key: UsageVectorStoresResult
      path: vector_stores_object
    - type: endpoint
      key: usage-code-interpreter-sessions
      path: code_interpreter_sessions
    - type: object
      key: UsageCodeInterpreterSessionsResult
      path: code_interpreter_sessions_object
    - type: endpoint
      key: usage-costs
      path: costs
    - type: object
      key: CostsResult
      path: costs_object
  - id: certificates
    beta: true
    title: Certificates
    description: |
      Manage Mutual TLS certificates across your organization and projects.

      [Learn more about Mutual TLS.](https://help.openai.com/en/articles/10876024-openai-mutual-tls-beta-program)
    navigationGroup: administration
    sections:
    - type: endpoint
      key: uploadCertificate
      path: uploadCertificate
    - type: endpoint
      key: getCertificate
      path: getCertificate
    - type: endpoint
      key: modifyCertificate
      path: modifyCertificate
    - type: endpoint
      key: deleteCertificate
      path: deleteCertificate
    - type: endpoint
      key: listOrganizationCertificates
      path: listOrganizationCertificates
    - type: endpoint
      key: listProjectCertificates
      path: listProjectCertificates
    - type: endpoint
      key: activateOrganizationCertificates
      path: activateOrganizationCertificates
    - type: endpoint
      key: deactivateOrganizationCertificates
      path: deactivateOrganizationCertificates
    - type: endpoint
      key: activateProjectCertificates
      path: activateProjectCertificates
    - type: endpoint
      key: deactivateProjectCertificates
      path: deactivateProjectCertificates
    - type: object
      key: Certificate
      path: object
  - id: completions
    title: Completions
    legacy: true
    navigationGroup: legacy
    description: |
      Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation#text-generation-models) to leverage our best and newest models.
    sections:
    - type: endpoint
      key: createCompletion
      path: create
    - type: object
      key: CreateCompletionResponse
      path: object

